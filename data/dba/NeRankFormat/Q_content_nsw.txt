2 version control methodologies help teams people track database schema changes
5 differences nosql traditional rdbms last months nosql frequently mentioned technical news significant features relative traditional rdbms level physical logical differences occur best places use nosql
14 earn lost migration expect drawbacks migration really unnecessary change applications situation
20 symfony application innodb database 2gb tables majority size database resides single table 2gb currently using mysqldump backup database nightly due comcast connection oftentimes running dump manually connection server timeout dump complete causing rerun dump currently run cron dump nightly dumps run manually way speed dumps connection timeout issue also limit time server occupied process btw currently working reducing size overall database resolve issue
21 techniques tools work sqlite medium size traffic concurrency db environment
29 im looking beginner intermediate level sql puzzles point trainees practice im aware http sqlzoo net great resource anything else could suggest
33 title says see config options like many ms would determine query slow
36 ive heard long time ago tool helps tweek mysql settings better performance cant seam find aware use ab apache simulate high traffic generate slow log however crashes already happened production mode dont know crashed tweeked config
43 create index filter specific range subset table mysql afaik impossible create directly think possible simulate feature example want create index name column rows status active functionality would called filtered index sql server partial index postgres
46 use indexes like developpers mostly well index im sure lot subtle way optimize database using index im sure specific implementation dbms question good examples use index except basic obvious cases dbms optimize database specify index table
47 database files built using sql compatable work around
48 way traverse tree data sql know connect oracle another way sql implementations im asking using connect easier writing loop recursive function run query result since people seem confused phrase tree data explain mean regards tables parent id similar field contains primary key another row table question comes experience working data stored way oracle database knew connect isnt implemented dbmss one use standard sql one would create new table alias parent one would want go could easily get hand
56 ive running auto index tool ms sql database modified script originating microsoft looks index statistics tables automated auto indexing stats list recommendations indexes need creating edit indexes described take information dmvs tell database engine would use indexes available scripts take top recommendations seeks user impact etc put table edit partially taken larry colemans answer order clarify scripts new database admin quick search around net reluctant take plunge blindly add recommended indexes however experienced field looking advice determine whether recommendations necessary need run sql profiler better examine code queries tables advice
59 im interested mainly mysql postgresql could answer following general logical scenario would useful distinguish empty string null would physical storage implications storing empty string null empty string another field way
62 based traversing tree like data relational database using sql question would like know way regularly used describe tree like data relational databases considering physical implications im assuming rdbms special features handling regular sql ansi common available features doubt im always interested mysql postgresql eventually sqlite
63 mysql better always allow nulls unless know field required always use null unless know field contain nulls doesnt matter know dbmss say use null much possible allowing nulls requires extra bit byte per record store null status
64 good way migrate db changes development qa production environments currently script change sql file attach tfs work item work peer reviewed work ready testing sql run qa work qa tested work ready production sql run production databases problem manual relies developer remembering attach sql peer reviewer catching developer forgets sometimes ends tester qa deployer discovers problem secondary problem sometimes end needing manually coordinate changes two separate tasks change database object may way still seems like automated way flagging issues something setup development shop full developers lot db experience projects db oriented mainly net ms sql shop currently using ms tfs work items track work handy code changes links changesets work items find exactly changes need include migrating qa production environments currently using db project may switch future maybe part answer used source control system taking care things like would like thing sql
81 like get latest executed statements within database along performance indicators like know sql statements cpu disk intensive
82 found sqlplusinterface rather outdated quite nice commands keywords disposal example arrow key previous history entry available good replacement extension sqlplus could gui better stays useful via ssh command line utility sql plus main command line tool operate oracle database
86 currently use phpmyadmin database administration works well enough im interested tools might work quickly efficiently etc best alternative admin tools mysql nix box
93 ive wanting use joins im trouble visualizing output know put use lets say tables create table cities id int unsigned primary key auto increment city tinyblob create table users id int unsigned primary key auto increment username tinyblob city int unsigned foreign key city references cities id application run sql query get users profile data would use join get city associated users record would outputted record appear
94 looking structure php mysql based websites ive seen appears terribly difficult discern database password dig bit theres invariably setup configuration file someplace stores information logging db basic precaution making sure databases privileges appropriately restricted remote requests options available could implement projects protect information
111 example database 3nf always 1nf 2nf hold
123 dominant topologies data warehouse modelling star snowflake designed one many relationships mind query readability performance structure degrades severely faced many many relationship modelling schemes ways implement many many relationship dimensions fact table dimension data warehouse compromises inflict regards necessary granularity query performance
126 recently one asp net applications displayed database deadlock error requested check fix error managed find cause deadlock stored procedure rigorously updating table within cursor first time ive seen error didnt know track fix effectively tried possible ways know finally found table updated doesnt primary key luckily identity column later found developer scripted database deployment messed added primary key problem solved felt happy came back project research found reason deadlock apparently circular wait condition caused deadlock updates apparently take longer without primary key primary key know isnt well defined conclusion im posting missing primary key problem conditions cause deadlock mutual exclusion hold wait preemption circular wait prevent track deadlocks
127 true stored procedures prevent sql injection attacks postgresql databases little research found sql server oracle mysql safe sql injection even use stored procedures however problem exist postgresql stored procedure implementation postgresql core prevent sql injection attacks something else postgresql also susceptible sql injection even use stored procedures please show example book site paper etc
135 know letters mean extract transform load used first thought transform phase could plenty different joins data ive extracted data sources later realized join different etl handy transform phase calculate output result string transformation input data sources csv xml plain file joins handy high level transformation within etl thank
144 want column distinct values either use constraint create table t1 id int primary key code varchar10 unique null go use unique index create table t2 id int primary key code varchar10 null go create unique index t2 t2code columns unique constraints seem good candidates unique indexes known reasons use unique constraints use unique indexes instead
152 one practices ive seen performed dbas organization treat full database export using tools like exp expdp backup would good practice would advantages using rman approach
153 new sql wanted know difference two join types select user inner join telephone user id id select user left outer join telephone user id id use one
194 assuming production oltp system predominantly innodb tables common symptoms mistuned misconfigured system configuration parameters commonly change defaults spot potential bottlenecks problem recognize troubleshoot active problems anecdotes detailing specific status variables diagnostics would appreciated
197 somewhat know answer question already always feel though need pick topic basic understanding generally speaking single index includes fields might querying sorting given time isnt likely useful yet seen type thing someone thought well put stuff index database use find needs without ever seen execution plan actual queries run imagine table like id int pk uid name varchar50 customerid int foreign key datecreated datetime might see single index including name customerid datecreated fields understanding index would used query like example select id name customerid datecreated representatives customerid order datecreated query seems better idea would index including customerid datecreated fields customerid field first would create index would data organized way query could quickly find needs order needs another thing see perhaps frequently first individual indexes field one name customerid datecreated fields unlike first example type arrangement seems sometimes least partially useful querys execution plan may show least using index customerid select records using index datecreated field sort know broad question specific answer particular query particular set tables usually see execution plan says going otherwise take specifics tables queries account also know depends often query might run opposed overhead maintaining particular index suppose im asking general starting point indexes idea specific indexes specific frequently pulled queries fields order clauses make sense
201 databases recommended used embedded databases store data within application embedded database may may synchronize back larger system database
232 im designing database multiple lookup tables containing possible attributes main entities im thinking using character key identify lookup values rather auto incrementing integer store attribute ids main tables ill see meaningful values rather random numbers performance implications using character field primary key rather integer im using mysql matters edit lookup tables new records added infrequently manually maintained character based keys manually created well heres example cuisines id description chnse chinese italn italian mxicn mexican
239 guidelines rules thumb determine store aggregate values calculate fly example suppose widgets users rate see schema time display widget could calculate average user rating ratings table alternatively could store average rating widget table would save calculate rating every time display widget id recalculate average rating time user rated widget ratings widgets widget id widget id user id name rating avg rating column question
252 title sums im reasonably well php comfortable getting need values pulled mysql however interest expanding knowledge ive wondering perhaps would efficient technique long run equivalent due roughly amount processing end cases one presents distinct advantage
255 collation influence query speed size table change depending collation want build website must support possible languages lets take google would recommended collation need store characters searches website return something th ng input must case insensitive well know best choice make collation better suits case
262 time time consumers database processes ask estimate given task done feel like know read explain database engines trouble trying translate ask minutes anyone know good rule thumb use particular database realize isnt going hard fast rule even able give ballpark figure could useful instances
264 ive reading around reasons use guid int int smaller faster easy remember keeps chronological sequence guid advantage found unique case guid would better int ive seen int flaws except number limit many cases irrelevant exactly guid created actually think purpose serving primary key simple table example real application using guid something guid uniqueidentifier type sql server
270 asp net mvc app works database sql server r2 express edition need perform regular task updating records database unfortunately express edition lacks sql agent approach would recommend
283 interested know methods people using keep track changes made database including table definition changes new objects packages changes etc use flat files external version control system triggers software
287 years ago common write exists select table condition last year noticed many sql scripts switched using number instead star exists select table condition saw oracle example exists select null common pattern oracle performance arguments use something like
299 oracle deprecating os authentication according oracle database security guide says aware remote os authent parameter deprecated oracle database 11g release retained backward compatibility addition security information tools consider os external authentication security problem trying understand case advantages see os authentication without os authentication applications must store passwords variety applications security model vulnerabilities domain authentication already secure database security slows access database prevent users remember one domain password made create secure domain passwords easily made create even less secure database passwords number different databases must connect increases
309 testing application need code stable simulates deadlock database site sql script possible thank added reproducing deadlocks involving one table
310 ive got mysql server database approximately tables taking 4gb vast majority tables myisam fine part dont need transactions application gaining traffic certain tables impacted table locking updates thats reason tables innodb conversion smaller tables 100k rows dont take long causing minimal downtime however tracking tables approaching million rows way speed alter table engine innodb large tables methods convert minimizing downtime write heavy tables
320 raid redundant arrays inexpensive disks comes different configurations raid raid recommended raid configuration set use installing oracle database database mainly used data warehouse
321 according restrictions stored routines triggers dynamic sql used restriction lifted stored procedures version later limitation place lift procedures functions triggers
322 would like build distributed system need store data databases would helpful use uuid guid primary key tables assume drawbacks design since uuid guid quite large almost random alternative use auto incremented int long drawbacks using uuid guid primary key tables probably use derby javadb clients postgresql server dbms
337 could change sql server r2 express default collation whole server particular database way using visual interface sql server management studio server properties window corresponding database properties window property available editing
338 server oracle database 11g enterprise edition release 64bit easy quick way change sids test databases server dropping recreating database option im looking something requiring less time option assign names clients tnsnames ora prone errors administrated centrally compared time drop create database sql server amount time required create new oracle database excessively greater sql server rename sql server instances usually rename server sql server running problems rename server
351 instance really nothing merely installed intended one project never actually got done server project done duplicate another server since instance want rename done would investigation googling says really possible additional consultation coworkers says might well install 2k8 instance move
358 sql server case quickly shrink files log data databases instance could go ssms right click choose tasks shrink im looking something faster scripted create database scripts forgot ballooned sizes defaults dont need quite much space reserved files project
364 ok start screwed created databases using create script roughly like artificial linebreaks names paths wrapping purposes create database example primary name nexample data filename nj sqlserver2008 mssql instance example mdf size 446046kb maxsize unlimited filegrowth log name nexample log filename nj sqlserver2008 mssql instance example ldf size 664505kb maxsize 2048gb filegrowth go scripted existing development database wanted get something going screwed didnt change sizes something reasonable like 4096kb cant shrink logfile roughly 600mb know went wrong fix easily
381 meaning dop context sql server
385 ive got single database 5gb running server 8gb ram vast majority tables myisam 3gb im soon going converting innodb going slow process focusing write intensive tables first anything wrong running dedicated server types storage engines exist
390 question refers number parameter msdn documentation dont create multiple stored procedures sql server differentiated number drop single drop create procedure dbo stored proc1 select go create procedure dbo stored proc1 select go exec stored proc1 returns go exec stored proc1 returns go drop stored proc1 drops go wonder feature used anybody something useful historic curiosity
394 table single column sensitive data want grant broad use table without exposing one column know create view gives access non sensitive columns however postgresql allows grant column level permissions form grant select col1 coln table role engines provide capability
401 found new title called sql server denali drop list msdn didnt find much information whats new documentation preview see top new features sql server denali anyone detailed information new features significant bug fixes release im hoping someone used tested new features sequences extended filestream thanks eric humphrey offset fetch order clause memory manager changes lag lead partition order clause thanks gbn aarons list
405 two ways connect oracle administrator using sqlplus sqlplus sys sysdba sqlplus system manager accounts uses different purposes suppose tasks two schemas meant use one among
409 see thread tools technologies build stack exchange network database specifications database sql server r2 running microsoft windows server enterprise edition x64 necessarily mean oracle wont job indicate good part far true reasons
411 known account name like sa pose security threat database using windows authentication sql server impose password policyif set say account lockout times
431 statements like create table insert etc take semicolon end create table employees demo employee id number6 first name varchar220 last name varchar225 constraint emp last name nn demo null others like set echo connect system manager go without semicolon well reasoning behind decide put semicolon
434 thread difference sys system accounts oracle databases understand sys schema supposed used database still administrator change password schema database connect without password connect even password changed
435 sql desc dual name null type dummy varchar21 sql select dual sql find really strange column named dual select statement work also dont see behaviour create dual table sql create table dual2dummy varchar21 table created sql desc dual2 name null type dummy varchar21 sql select dual2 rows selected sql
440 possible convert huge myisam table innodb without taking application offline requires insert couple rows table every second possible suspend minutes obviously alter table engine innodb work therefor plan create new table innodb engine copy content end suspend application log thread rename table unfortunately even copying small batches rows generates significant lag time edit existing rows never changed table used logging
442 sqlserver introduced something called sqlcmd mode msdn link first glance mode adds variable subsitution command line batch files escaping os commands feature used environments production test
445 luckily isnt current issue current workplace pretty well supplied dba knowledge team however small development teams uncommon experience one team nominated de facto dba small team theres rarely enough work full time dba dbas production dbas dont want get involved supporting dev test environments tester programmer expected pick role ive seen people getting suddenly landed hey joes leaving youre new dba training budget youll teach fun resources recommend someone finds suddenly position get speed development dba role basic tasks aim tackle first keep things ticking
461 title doesnt make much sense couldnt think better title problem following tables projects id name customers id id project name payments id id customer date sum users enters system access certain project want list payments project pretty easy select payments id customer select id customers id project question isnt better add column id project payments table way queries easier faster
467 due size transaction log file grew gb delete disk running space know good practice anyway performance bad anyone know whether possible improve performace situation
468 realy rarely use triggers met problem first time lot tables triggers every table would like know change order firing triggers every table possible get information added good enoght article mssqltips found
482 know insert sql table slow number reasons existence insert triggers table lots enforced constraints checked usually foreign keys page splits clustered index row inserted middle table updating related non clustered indexes blocking activity table poor io write response time anything missed tell responsible specific case measure impact page splits vs non clustered index updates vs everything else stored proc inserts rows time temp table takes seconds per 10k rows thats unacceptably slow causes spids time ive looked execution plan see insert clustered index task index seeks fk lookups still doesnt tell sure takes long triggers table handful fkeys appear properly indexed sql database
486 job work javaee application postgresql database although sysadmin productions servers also manages database servers full time dba makes wonder would imagine full time dedicated dba would work exclusively oracle database overlooking something correct assuming dedicated postgres dbas ps im asking sheer curiosity pps wanted tag question dba apparently would new tag could someone make
505 decent amount data database well formed tables good relationships redundancy data far go normalization performance drawbacks much normalization
511 want search string names columns present database working maintenance project databases deal tables im looking quick way recommend
530 shelf application uses microsoft sql database within application pick choose various selection criteria report application runs reports believe query plan issue first report run day runs fast minutes report run first report takes hour night run scheduled task stops starts sql server agent sql server approximately databases within one instance sql server databases performance issues one shelf product mentioned earlier way clear query plans sql server currently memory without impacting users rely databases server
545 im contemplating setting master slave replication database slave server used redundancy possibly reports server however one biggest issues im running already maxed power datacenter adding another physical server option existing database server fairly utilized far cpu load averages never really get quad core leading idea toss new drives double memory 8gb run second mysql instance physical machine instance would separate disks database anything wrong idea edit info ive luckily never anything bad enough happen take server trying plan ahead course nightly backups could recover figured redundant data separate disks would provide quicker solution master servers drives failed obviously entire machine goes reporting aspect tables would report myisam expensive reads tables written bog server assumption slave server report wouldnt affect main server long threw enough ram since cpu load hasnt issue yet
550 reason performance stability shouldnt
561 best resources learning operate administer mongodb plenty resources developing actually creates problem youve got plenty development competence really need filter noise developers cant afford hire dba yet need get reasonably good keeping mongo cluster stable performant etc beyond faqs quickstart guides good repositories info good blogs follow etc
567 find procedure function exists mysql database discovery option like show procedures like show tables
573 weve looking using ssds oracle speed test migration runs currently takes hours complete migration run depnding volume data obviously lots performance tweaking weve number cheap linux boxes using various runs analysis cost ssds direct dell prohibitive wondering anyone experience using consumer ssds crucial micron ones realise trim support would issue linux using centos anyone used windows counter
581 mean following creating index table rows takes time creating index table ntake approximately time im trying achieve estimate time takes create index production database creating index much smaller test database
586 postresql im trying create view look like existing table different column names works create replace view gfam nice builds select family tree family tree id family tree family tree name family tree family tree description gfam family tree makes duplicate family tree table following attempt fails create replace view gfam nice builds select family tree family tree id family tree family tree name family tree family tree description gfam family tree error change name view column family tree id rename columns
598 one project working need set particular field unique problem field null want constraint ignored sql server use filtered index shown available earlier versions sql create unique nonclustered index user username iuc user pinnr username null dont think available sql server fact blog post indicates workaround using trigger check uniqueness anyone example maybe alternative unfortunately upgrading sql server option particular client
606 sql sever database remote hosted dedicated server work using sql server management studio installed either server local computer first case work using remote desktop makes work little bit slower second case need open additional port servers firewall comfortable user experience recommended practice two
612 table least million records rows created custom app reads several sharepoint site collections stores item urls table since read site collections serial manner first thousands rows belong first site collection next thousands belong second site collection another app reads table sequential manner however way end sending http requests site collection longer time know could get random results table second app option change way second app works question take rows table shuffule store back table update sql server r2 database server
629 ive got process grabs bunch records 1000s operates im done need mark large number processed indicate big list ids im trying avoid updates loop pattern id like find efficient way send bag ids ms sql server stored proc proposal table valued parameters define table type id field send table full ids update proposal xml parameter varchar openxml proc body proposal list parsing id rather avoid possible seems unwieldy error prone preference among ideas ive missed
647 looking rolling cms system require creation around tables within primary mysql database system database data store several hundred small website front ends might draw modest load around 150k unique viewers per month might scale short notice im looking advice around kind hardware used cost effective also ability scale need arises would also like advice around software configuration mysql setup clustered straight forward mysql high number open files advice greatly appreciated
651 posted stackoverflow please let know delete one im working db2 database far see regexp supported without additional libraries implement something similar explained article bringing power regular expression matching sql know emulate sql statement regular expression like aofdmep z0 sidbfkfpo edit hypothesis found acceptable case like predicate user name like unsafe doesnt cover cases dont fixed char match
653 apologies bad title wasnt sure would good title currently simplified view data im working agent commission smith neo morpheus need calculate percentage total commission agent responsible agent smith percentage would calculated agent smiths commission sumcommission expected data would agent commission commission smith neo morpheus function returning commission agent another function returning percentage commission sumcommission problem sumcommission gets calculated every row given query would run data warehouse data set would rather large currently records quite honestly bad approach imo way sumcommission calculate every row fetched thinking something lines part query first part would fetch sumcommission package variable type second part would refer pre calculated value im sure accomplish limited using sql im running oracle 10g r2
659 user getting ora indicating password expire within six days ran following alter profile default limit password life time unlimited try log user message still executing select dba profiles resource name like password life time shows values really changed unlimited
667 im working application uses dynamic query select statement based user input discussing security dbas want convert dynamic select statement stored procedure built dynamic sql using mssql figure convert oracle sql create procedure getcustomer firstn nvarchar20 null lastn nvarchar20 null cusername nvarchar10 null cid nvarchar15 null declare sql nvarchar4000 select sql firstname lastname username userid customer firstn null select sql sql firstname like firstn lastn null select sql sql lastname like lastn cusername null select sql sql username like cusername cid null select sql sql userid like cid exec sp executesql sql firstname nvarchar20 lastname nvarchar20 cusername nvarchar10 cid nvarchar15 firstn lastn cusername cid please note want prevent sql injection want add string together built separate class creating dynamic query application net almost lines code handle everything prevent sql injection dbas told want stored procedures control input output
668 way audit logins mysql id like able create username employee thereby create audit trail logins however googling turned good results audit better least would nice know logged would even better see executed query logs mostly tell clients since potentially sensitive information database obviously able audit queries executed user would also give us ability better pinpoint cause security issue one arise
682 im finding user show grants username localhost im thinking perhaps username slightly different want wildcard search database users update clarification im thinking maybe ive clear wildcard meant wanted able search part users name users whos name matches pattern system needed 5k users although thats performance loss huge dont want look one time either
688 want replicate contents mysql database ms sql server database possible anyone outline steps required order achieve thanks
692 performance hit select across another db physical machine databases physical machine running within sql instance instance somstoreproc db run select somefields db dbo sometable far read internet people seem indicate
696 prior oracle using custom aggregate function concatenate column row added listagg function trying use instead problem need eliminate duplicates results dont seem able example create table listaggtest select rownum num1 decoderownum12to charrownum num2 dual connect rownum select listaggtest num1 num2 duplicate want see num1 num2s listagg version close doesnt eliminate duplicates select num1 listaggnum2 within group order null num2s listaggtest solution worse continuing use custom aggregate function
710 manage application large nearly 1tb data million rows one table oracle database back end database doesnt really anything sprocs triggers anything data store every month required purge records two main tables criteria purge varies combination row age couple status fields typically end purging million rows per month add million rows week via imports currently delete batches rows ie delete comit delete commit repeat attempting delete entire batch one time makes database unresponsive hour depending rows deleting rows batches like rough system typically time permits course week allowing script run continuously result performance degradation unacceptable user believe kind batch deleting also degrades index performance impacts eventually cause performance database degrade indexes one table index data size actually larger data script one people uses purge begin loop delete tbl raw dist event date date date mm dd yyyy rownum exit sql rowcount commit end loop commit end database must weve got day maintenance window year im looking better method removing records ive yet find suggestions
712 want able run query get crucial information databases status want query able tell whether database good state query inherited check select name suspectdb databasepropertyname nissuspect suspect databasepropertyname nisoffline offline databasepropertyname nisemergencymode emergency dbaccessname hasdbaccess sysdatabases databasepropertyname nissuspect databasepropertyname nisoffline databasepropertyname nisemergencymode dbaccessname query returns results assumption made database suspect potentially bad state better way
728 know system product technique would allow wrap one relational databases one object oriented virtual database could call multi database object oriented proxy let illustrate principle basically pink thing middle hereafter object proxy would contain definitions business entities mappings data multiple relational databases applications would request insert update delete data object proxy would magically synchronize underlying relational databases possible system exist
736 possible duplicate files database wondering theres good reason still use blob fields database couple years ago worked db bunch images db slow couldnt see good reason keep images inside db got images stored filenames instead smart move would place
742 currently running script performs dbcc indexdefrag every table sql server database one table time using dbcc dbreindex instead indexdefrag option due space constraints uptime requirements noticed takes long time certain tables defragmented instance examine sys dm exec requests dynamic management view see following indexdefrag currently churning away clustered index table table id dbcc indexdefrag know long time defragmentation process completes leaving aside fact script currently running eventually defragment tables harm manually running another dbcc indexdefrag clustered index another table current command executes tables actually defragmented time
756 production sql server seeing intermittent enormous spikes data traffic 200mbit causing network io waits turn cause query timeouts find queries returning big result sets
760 table four columns non nullable data four needed distinguish unique record means make primary key would need comprise columns queries table almost always pull back single record columns filtered query since every column need searched primary key benefit besides enforcing uniqueness records
763 came across view database today first statement clause shouldnt return true every record would someone write isnt filtering records
771 understand may difference meaning intent two behavioral performance differences clustered primary key clustered unique index
788 using postgresql v8 tables involved employee emaillist table employee column1 column2 email1 email2 column5 column6 table emaillist email tables joined way either employee email1 employee email2 matching entry rows returned select employee email1 employee email2 e1 email null email1 matched e2 email null email2 matched employee left join emaillist e1 e1 email employee email1 left join emaillist e2 e2 email employee email2 e1 email null e2 email null column email varchar256 emaillist table indexed response time seconds table count statistics currently employee got records emaillist got records tables expected grow future good idea approach index varchar column question immediately strike mind reason weve indexed varchar column application experts advice suggestion highly appreciated current query index response time seconds reasonable scope tuning users real time experience opinion based kind table size response time note actual requirement use case explained detail
790 let us review dba exchange oracle question sql server sauces code little formatting create procedure getcustomer firstn nvarchar20 null lastn nvarchar20 null cusername nvarchar10 null cid nvarchar15 null begin declare sql nvarchar4000 select sql firstname lastname username userid customer firstn null select sql sql firstname like firstn lastn null select sql sql lastname like lastn cusername null select sql sql username like cusername cid null select sql sql userid like cid exec sp executesql sql firstname nvarchar20 lastname nvarchar20 cusername nvarchar10 cid nvarchar15 firstn lastn cusername cid end go sauce mentioned second note lines code prevent sql injection feeling neednt shield stored procedure question sql server procedure immune sql injection satisfying solution respect performance
808 ive heard mention statistics sql server keeps default tracking use information improve database
817 know sql management studio right click table trigger key script object way programmatically given objects name way find objects primary keys foreign keys triggers associated given table script programmatically
818 developer use sql profiler quite often good debugging tool track code analyse performance problems ive always used development environment controlled way start application get specific state start trace profiler perform specific sequence actions application stop trace examine results sql profiler practically used production environment first concern would degrade performance second concern production arent triggering interesting actions would leave profiler running long period analyse results would result set become unwieldy taking much disk space hard query anyone use sql profiler production
845 wondering way execute sql loader script sql plus using oracle 10g
854 large database 6tb whose transaction log file deleted sql server shut tried detaching reattaching database undeleting transaction log file nothing worked far currently running alter database dbname rebuild log name dbname filename logfilepath given size database probably take days complete questions difference command following one dbcc checkdb dbname repair allow data loss executing repair allow data loss instead worth noting data derived sources database rebuilt however suspect much quicker repair database reinsert data update keeping score alter database rebuild log command completed around 36hrs reported warning log database dbname rebuilt transactional consistency lost restore chain broken server longer context previous log files need know run dbcc checkdb validate physical consistency database put dbo mode ready make database available use need reset database options delete extra log files ran dbcc checkdb took 13hrs successful lets say weve learnt importance database backups granting project managers access server
858 recently found mysql doesnt support rollback ddl alter table used postgresql struck odd friend mine told even oracle doesnt allow technical reasons supporting simply uninteresting feature edit found comparison looks like many dbmses support transactional ddl
861 im trying optimize following statement vi castmonthgetdate nvarchar castyeargetdate nvarchar cast number varchar statement produces value like vi1 number parameter would like optimize terms removing redundant cast statements providing efficient way concatenate strings integers
872 need optimize following query select things omitted articles blogpost id articles id articleid blogposts join articles articles blogpost id blogposts id blogposts deleted blogposts title like de blogposts visible blogposts date published order blogposts date created desc limit explain select gives following result id select type table type possible keys key key len ref rows extra simple articles blogpost id null null null using temporary using filesort simple blogposts eq ref primary primary articles blogpost id using first take articles blogposts blogposts entries improve query articlepost use index update index set blogposts date created removing blogposts title like condition date published doesnt anything remove articles id articleid use blogpost id index articles sounds strange someone knows actually need new explain looks like id select type table type possible keys key key len ref rows extra simple articles index blogpost id blogpost id null using index using temporary using filesort simple blogposts eq ref primary primary articles blogpost id using
888 ms sql server whats best way update updated updated set fields table ive seen done triggers code etc upside ive seen triggers happens place downside occasions administrator bulk fix table doesnt want obliterate username time last user update note dont want timestamp want windows user id human readable date time last change looking recommend good choice
907 standard sql run multiple databases single server help diagnose problems select name type maxcase sc text like remote else end relevant servername server db name dbname sysobjects nolock join syscomments sc nolock id sc id sc text like emote group name type order type name execute databases single server besides manually connecting one time executing
916 table identity column say create table id id int identity11 val varchar30 well known select copy id id results copy id identity id following stack overflow question mentions listing columns explicitly lets try select id val copy id id oops even case id identity column want table like create table without id id int val varchar30
917 tell three possible ways backing sql server database full backup differential backup log shipping pros cons strategy situations employed
940 determine table exists sql server database sql server
955 query want resulting records ordered randomly uses clustered index include order likely return records order index ensure random row order understand likely truly random pseudo random good enough needs
956 like many others upgraded instance mysql since weve running error repeats perform certain actions attempting view run stored procedure attempting insert table adding trigger insert actions executing select lenghtdescription id table misspelling length spelled correctly error display error question column count mysql proc wrong expected found table probably corrupted reported bug basically lack backwards compatibility appears confusion resolve issue mysqls documentation says solution dump stored procedures upgrade restore bug report mentioned earlier shows dubious results bug report suggests running mysql upgrade possible solution albeit concerning warnings however reported elsewhere solution doesnt always work unfortunate circumstance test box test possible solutions development box pending os upgrade allow us install versions mysql want install hesitant try solution production environment unless verified working people encountered issue correct way resolve issue outside waiting official patch solution mysql losing stored procedures ideal also route willing take resolve issue provided better alternatives solve issue cleanly
973 new oracle databases would like develop data dictionary er diagrams existing databases tips scripts tools
983 given database hold user records form unique auto increment field sake example inter user messages time comes approaches max signed unsigned number current datatype bit int im guessing database server would overflow tries assign number next entry avoid happening without changing datatype sake question keep adding records would would use ints example varchars several days since ive asked hypothetical question would like know professional would
1014 someone worked extensibly sql wise least two top db products oracle sql server informix sybase db2 teradata know different db vendors sql dialects since come oracle background especially interested analytical functions model clauses hierachical queries start connect comes mind feature usual select probably question boils extent features regulated ansi standard practically id like know rule thumbs would indicate take sql dml statement runs one database let run database
1018 example tables starting prefix dp starting ex question drop tables starting dp one query
1021 im using expressmaint windows scheduled tasks create weekly full daily differential backups ms sql server r2 express databases weekly fulls expressmaint local sqlexpress db backup reports ru weeks rv backup data bu weeks bv daily diffs expressmain local sqlexpress dif backup reports ru weeks rv backup data bu days bv come restore certain point restore backup individually way chain series backups single restore played correct order try get error exception occurred executing transact sql statement batch microsoft sqlserver connectioninfo additional information media loaded foo bar fullbackup bak formatted support media families media families expected according backup device specification restore headeronly terminating abnormally microsoft sql server error help click http go microsoft com fwlinkprodname microsoft sql server prodver evtsrc mssqlserver evtid linkid edit using restore dialog tasks menu right click database select restore device add bak files wish restore add single bak file im ok add multiple files receive error
1031 currently whenever write query adding columns contain nulls resort wrapping field isnull coalesce coalescescore10 coalescescore20 better way handle standard practice
1038 need move whole bunch large millions rows tables one sql2008 database another originally used import export wizard destination tables missing primary foreign keys indexes constraints triggers etc identity columns also converted plain ints think missed checkbox wizard whats right way couple tables would go back source script table definition indexes etc run index creation portions script destination many tables seems impractical wasnt quite much data could use create scripts wizard script source including data 72m row script doesnt seem like good idea
1040 main differences database administrators software engineers extent software engineer know details underlying database border two professions
1043 remember stackoverflow podcasts fog creek use database per customer fogbugz assume means fogbugz demand servers 10s thousands databases starting develop web app similar problem solve lots customers isolated data problems expect using database per customer solve initial thoughts advantages database per customer simpler database schema simpler backups backup customer turn without really impacting customers makes easy export given customers data better cache performance write one active tables impacts single customer performed write easier scale across hardware example need go servers move half customers new server disadvantages mysql cope databases would performance suck changes schema hard replicate across databases would really really automated plan versioning schema script understands take database one version another anything common customers might awkward impossible similar analytics want perform across customers might impossible track usage across customers example
1044 im huge fan lot redgate tools however current workplace paranoid anything interacting live servers particular affecting performance question specifically sql search tool impact server im assuming initial indexing interact idea impact server customised index live servers subsequent connections refreshes determining change indexed performance load impact server
1083 table following texts key word searching search written query select id textvalue dbo searchlike textvalue like search modify query records search text returned shouldnt taking lsearch per image first three records returned
1099 astor data greenplum gridsql allow massive parallel processing sql queries also built around postgresql technology licensing issues reasons seems like myisam acid complient therefore running issues mvcc like seen postgresql far better suited building high performance data warehouses olap load require transactions far see
1121 know question might sound stupid never understood part sql plus works sql pl sql know whether code sql pl sql code loop sql anymore pl sql extension sql loops conditionals etc sql code default pl sql code isnt demarcation sql pl sql two examples differentiating sql pl sql triggerred question difference two create table statements https stackoverflow com questions oracle 11g varray objects
1126 working team trying implement eav system decided split attribute value tables type debating using different tables different size ranges varchar ex table varchar10 table varchar11 varchar500 table varchar501 varcharmax always impression varchar going use size needed know going gains performance would worth extra coding logic would needed
1141 latest version management studio one ships sql server finally transact sql intellisense feature however box works sql server instances workaround asked question ago stackoverflow unfortunately nobody knew trick maybe luck problem
1144 ive inherited database contains several procedures lines long complex nested sub selects going levels deep places desperately need refactor sanity begin level confidence still work would write unit tests net recommend similar approach
1166 use database name dot sql server something like myapp sales cause problems
1170 possible somehow t1 select seq nothing type dual union select seq nothing type dual union select seq something type dual union select seq something type dual union select seq something type dual union select seq something type dual t2 select compare type dual union select compare type dual select t2 t1 t1 t2 case t2 compare type t1 type like nothing else t1 type like nothing end know clause correct help would great knowing type statement possible dont want write dynamic sql write different sql statements thanks
1183 making database accounting sales type system similar car sales database would like make transactions following real world actions salesman creates new product shipped onto floor itempk car make year price salesman changes price salesman creates sale entry product sold salespk itemforeignkey price sold salesman salesman cancels item removed product salesman cancels sale cancelled sale examples found online generic like transaction would like something resembling trying understand anybody good similar related sql examples look design people use transactions sales databases done kind sql transaction could make outline could made closed real question thread far stack overflow need example sql transaction procedures sales tracking financial database latest update user send new inputs changes cancellations application application data products display parent node child nodes saleschild node products display product custom featureschild node products display product price current status child node products display app package data xml format execute sql stored procedures transactions holding together xml table conversions sql tables designed parent child node structure using something like described answers related question stack overflow https stackoverflow com wish book designing multi user sales databases stored procedure transactions used related user apps scratch app xml database please let know know good one chapter book
1201 oracle database backup recovery basics 10g release says archived redo logs key successful media recovery back regularly wonder backups archive logs important would possible point time recovery using regular rman full incremental datafile backups
1206 designing baseball simulation program run problem designing boxscore schema problem want track many runs scored inning way actual program use dynamic array grows inning played unfamiliar game baseball games usually nine innings long unless game tied still end 9th inning baseball games therefore undetermined length means design database columns runs scored inning well technically innings teams one idea serialize array encode base64 storing database however know good technique use wondering anyone better idea case matters database developing around postgresql suggestions greatly appreciated thanks
1215 typically see sql uses something like select employees epmloyeetypeid select id type name emp replace select employees inner join type id epmloyeetypeid name emp possible inverse case like instead clause insert subscriptionsprojectid recordtypecid ntid active added lastupdate updateby select projectid recordtypecid ntid getdate getdate ntid check chk chk activestatus exists select subscriptionid subscriptions projectid projectid ntid ntid recordtypecid chk recordtypecid additional considerations insert subscriptionsprojectid recordtypecid ntidactive added lastupdate updateby select projectid recordtypecid ntid1 getdate getdate ntid check chk left join subscriptions subs subs recordtypecid chk recordtypecid ntid ntid projectid projectid chk activestatus subs subscriptionid null
1229 calculate mysql max connections take consideration
1230 im dev inherited mostly functioning box need except machine name still old dev name username dt username lt ease id network want rename old username username naturally affect sql well thought would ask experienced advice need rename machine know sp sprocs run run need restart box need certain level privilege destroy existing windows based auth box accounts ad accounts anyways
1245 question inspired comment posted latest serverfault blog post guys still using linq sql know use sql server profiler totracestring method see generated queries analyze however looking opinions people hands experience administering databases accessed applications utilizing entity framework entity framework queries common cause performance problems linq queries optimized cases raw transact sql solution
1261 im fairly new tuning innodb im slowly changing tables necessary myisam innodb ive got 100mb innodb increased innodb buffer pool size variable 128mb mysql show variables like innodb buffer variable name value innodb buffer pool size row set sec went change innodb log file size value example cnf mysqls innodb configuration page comments change log file size buffer size cnf looks like innodb innodb buffer pool size 128m innodb log file size 32m restart server get error innodb initializing buffer pool size 0m innodb completed initialization buffer pool innodb error log file ib logfile0 different size bytes innodb specified cnf file bytes error plugin innodb init function returned error error plugin innodb registration storage engine failed question safe delete old log files another method change innodb log file size variable
1281 started learn pgadmin iii manage postgresql database wasnt easy use application create created table pgadmin iii add auto increment functionality column id type integer
1282 type db sql mysql console output nothing see ibdata1 file growing dont know many gb grow would like see progress indicator kind ideas
1283 used phpmyadmin manage mysql database would like manage postgresql database postgresql database server webserver dont use php good free tools managing postgresql database tried pgadmin iii far intuitive application use compared phpmyadmin used postgresql dbas usually using use graphical tools like pgadmin iii mostly command line tools
1285 trying learn postgresql administration started learning use psql command line tool log psql username postgres list databases tables tried ds nothing listed created two databases tables pgadmin iii know listed
1298 table columns type ntext peculiar reasons client wants migrate column type nvarcharmax potential threat careful possibility data loss nvarcharmax limitations
1301 migrating tables coming dbmss oracle one standard tasks replace varcharn fields varchar2n fields provided oracle call datatype varchar2 varchar like dbmss
1305 following two queries seem equivalent executed sql plus select user tables select user tables difference versions
1326 ive waiting hours gb sql file imported simple type site sql mysql command see ibdata1 growing still currently nearly gb considering triggers stored procedures end sql think mysql adding data key indexes site sql generated using command another server mysqldump databases site add drop database add create database add drop table single transaction triggers whats taking long
1346 work print shop decent sized archive old print jobs currently find job search smb share win2000 server looks hundred thousand files job data organized year month customer name job contents job inside last folder way create database query job desc job number basically simple search faster searching windows search would great tried windows index service finds doc file folder names pdfs future planning making sql database complete info entered job created easily queried future hoping throw together something make easier search older orders
1359 one corporate standards separate filegroup file user tables indexes set default need qualify create table statements looks like fileid system tables mdf fileid log ldf fileid user stuff ndf anyone help understand original justification mandated ill come clean state think voodoo wrong edit aware use filegroups separation indexes partitions archives well restore piecemeal question use separate filegroup volume system tables
1371 query delete test id select id select test temp order rand limit sometimes delete row sometimes rows sometimes nothing write form set var select id select test temp order rand limit delete test id var work correctly problem subquery
1410 state machine needs push pop file names different users would traditionally use stacks choice data structure needs done using database since dont way retain data structure incoming web requests wondering would good way implement stack functionality using databases need support pushfilename user push filename user popuser pop top filename user edit prototyping idea using sqlite3 python thanks
1423 designing database many relationships among tables need book teaches database design well looking book table relationships simple complex covered extensively maybe case studies book
1426 sql server get current date without time part using getdate would like time
1437 looking hierarchical database management system one came across ibms ims opensource systems one use
1457 many times ive brought end software development effort told something like okay weve got new code requires tables change data migrated seems like every time one shoot hip best guess scenario feel like weakest skill set dba id like get patterns approaching managing testing data migrations please clue best practices get learning material help get better area
1467 im new postgresql try create table database psql write create table mail user user char50 null domain char50 null password char50 null get error error syntax error near user line user char50 null whats wrong fix thank
1485 sql command run determine recovery model database want know full recovery
1493 use sql server web application back end apparently iterate records code whenever multiple insertion scenario never tried multple insertion using xml think reading many blogs xml manipulation using sql server process pretty tideous question insertion via xml much efficient traditional insertion generic way serialize class manipulate xml sql insert also read data xml deserialize xml usual object
1497 audit table tracks actions table database create table track table id int16 unsigned null userid smallint16 unsigned null tablename varchar255 null default tupleid int16 unsigned null date insert datetime null action char12 null default classname varchar255 null primary key id key userid userid key tableid tablenametupleiddate insert key actiondate actiondate insert engine innodb default charset latin1 need start archiving outdated items table grown 50million rows fastest way could delete rows delete table time based tablename works pretty well tables write heavy wont complete query deletes items associated delete action tupleid tablename combination delete track table tablename sometable tupleid select distinct tupleid track table tablename sometable action delete date insert date subcurdate interval day let run server days never completed largest table explain output switch delete select id select type table type possible keys key key len ref rows extra primary track table ref tableid tableid const using dependent subquery track table ref tableidactiondate tableid constfunc using using temporary million rows shouldnt take days delete would think innodb buffer pool size set 3gb server set use one file per table ways improve innodb delete performance running mysql mac osx
1523 example alter session set nls date format dd mon yyyy hh24 mi ss changes date format session nls
1527 wonder question hasnt already asked google results dont show high quality tool open source also free ok solutions data warehouses specifically business intelligence tools experiences course masters programm worked ms business intelligence mssql data warehouse storage want get topic tools open compareable tools business intelligence mostly database independent experience edit marians comment stephanies answer see formulated question wrong aware dwh reporting optimized databases stephanies explanation clear interessted get data optimised forms kind bi software tools techniques
1547 database query could result big result set client displays data receives data network idea minimize amount transferred data retrieving first results database sending client provide possibility jump second page retrieve next results etc something similar google offers question effective way implementing paging want make sure mssql uses cache much possible executed everytime change paging clients querying database time used sql engine ms sql ideas use prepared sql statemenst ensure execution plan sharing use row count variable retrieve needed rows really effective way think would better retrieve whole result set implement paging code sends data client thank tips regards tomas
1554 best practices running sql server virtual machine line transaction activities low high amount data processing purpose providing reporting data multiple web sites
1570 application needs data freshly updated database possible case way getting data besides timer based requesting polling database work ms sql server net applications entity framework id like get knowing types databases well
1577 given certain kind wait find queries causing waits safely production sql r2 server particular case wondering async network io
1584 databases consist lots tables using integer surrogate key primary key half primary keys identity columns database development started days sql server one rules followed beginning avoid creating clustered index based incrementing key find index optimization tips using sql server sql server strong impression circumstances changed meanwhile primary key columns perfect first candidates clustered index table
1592 linux default mysql grant tables created mysql install db script work windows default grant tables installed windows looking response google results packed full automatically installed windows case installer distribution zip package besides help mysql installed data directory damaged replaced
1632 middle debate whether better make primary key identity columns udf explicitly generates unique id arguing identity column partner arguing generating values manually claims putting udf another table udf lock resource increment id table one field called id value use global unique identifier table id inserting simpler move data servers environments identify constraint moving one db data another similar db lets say staging dummy data testing non production may want pull records yesterday staging testing implementation makes sense
1635 answer better identity columns generated unique id values mrdenny says sql denali comes support sequences efficient identity cant create something efficient im sure knowing oracles sequences either create trigger insert encapsulate insert call stored procedure pray forget properly use sequence ad hoc insert doubt advantages sequences obvious
1637 standard follow naming tables views instance good idea put something like tbl beginning table names designate code lookup tables way like ct lut codes dos donts im using ms sql server many databases many tables would nice something use standard supporting rational
1654 many many table indexed kind index would best heres example table create table user role userid int roleid int edit drachenstern added table def based original comments assumed ints
1656 new shop error started show repeatedly event type error event source sqlserveragent event category alert engine event id description unable read local eventlog reason event log file corrupted event type information event source sqlserveragent event category alert engine event id date time user computer xxxxxxx description attempting open local eventlog event type warning event source sqlserveragent event category alert engine event id description successfully opened local eventlog note events may missed server shut unexpectedly shutdown stopped events concerns happening anyone know means importantly kind measures need take prevent happening
1677 would like good tool designing database schema tables columns data types relations today mostly pen paper would like good design tool good maybe free database design tool
1692 order partition existing non partitioned table possible use either exchange partition dbms redefinition decide possibilities choose table partitioning depend many data reside table one operation safer
1694 store ip address registered users database wondering many characters declare column support ipv6 well maximum length ip address
1699 possible achieve performance improvements indexes techniques like table partitioning becomes necessary question relates performance course different partitions put different tablespaces effects achieved indices words performance wise possible achieve performance improvements indices partitioning tables
1705 recently viewed query cache important tool improve query performance today listening podcast discussed tuning query cache using better memory caching solution memcache also mentioned cases query cache helpful general recommendation would enabled demand using select sql cache query cache type config setting question assuming youve got caching solution like memcache place type circumstances would make query cache optimal edit added link
1714 sql server become unpredictable late im scratching head queries executed seconds changing plans taking minutes taking time full table scan index spool first obvious thing statistics obsolete causing optimizer get confused convinced case firstly underlying data isnt significantly changing adding one days data ontop years data already table secondly auto create statistics auto update statistics true however optimizer getting confused running sql tuning advisor gives lots multi column create statistics statements seem fix next bit sql misbehaves ideas strategy use approach root causing normal statistics arent sufficient
1726 late ive facing lot row lock contentions table contention seems particular table generally happens developer starts transaction oracle forms front end screen developer starts another transaction different session using screen minutes front end seems unresponsive checking sessions shows row lock contention solution everyone throws around kill sessions database developer done eliminate row lock contentions would possible find line stored procedure causing row lock contentions would general guideline reduce avoid eliminate problems coding question feels open ended insufficient information please feel free edit let know ill best add additional information table question lot inserts updates id say one busiest tables sp fairly complex simplify fetches data various tables populates work tables lot arithmetic operations occur work table result work table inserted updated table question database version oracle database 10g enterprise edition release 64bit flow logic executed order sessions transaction isnt kept open long least think locks occur active execution transactions update table row count larger expected million rows also tracing session found couple update statements table utilizing index im sure column referenced clause indexed im currently rebuilding index
1728 im selecting table long text columns id like wrap long lines maximum line length select test test id text lorem ipsum dolor sit amet consectetur adipiscing elit mauris lorem test id text lorem ipsum dolor sit amet consectetur adipiscing elit mauris lorem
1732 database model user table role table want control access rights different elements access granted either role single user table definition users roles items create table users id serial null primary key username character varying unique password character varying first name character varying last name character varying create table roles id serial null primary key name character varying null description character varying create table element id serial null primary key name character varying null description character varying two different ways designing rights one table rights type column rights tables one element want control access pros cons one rights table vs one rights table per element suitable way
1742 question bytea oid blobs large objects etc table containing primary key integer field bytea field id like enter data bytea field presumably done one pl languages may look pl python future still testing experimenting would simply like insert data file server using standard sql statements aware administrators write permission server would able insert data way would like im concerned stage users would inserting bytea data present searched various stackexchange sites postgresql archives internet generally able find answer edit discussion implies want possible bytea fields used edit similar question remains unanswered solved details provided psycopg website provided basis solution ive written python may also possible insert binary data bytea column using pl python dont know possible using pure sql
1750 using sql server performing huge delete clauses basically equivalent truncate table statement except im allowed use truncate problem table huge million rows takes hour complete way making faster without using truncate disabling dropping indexes log already separate disk suggestions welcome
1755 databases use real multidimensional indices oracle ever using several indices get data tables always take one seems highest selectivity dbms
1765 another sql server question simple query gives cpu intensive sql since counters reset select top sumqs total worker time total cpu time sumqs execution count total execution count qs plan handle st text sys dm exec query stats qs cross apply sys dm exec sql textqs plan handle st group qs plan handle st text order sumqs total worker time desc question exactly plan handle doesnt appear hash plan like oracle ask want able detect situation plan statement changes question plan handle interested actual plan example select sys dm exec query plan 0x060006001f176406b8413043000000000000000000000000 query plan column get link click displays xml document save disk whatever sqlplan double click windows displays correctly management studio surely must way avoid step question way convert xml back textual format like old days set showplan text want able view graphically also automate diffing meaningful way thanks
1767 current project happens often need extend columns couple characters varchar20 varchar30 reality much really matter good optimized impact allowing even chars normal input fields email chars ok good limit gain set expect longer mail addresses usually tables rows columns use sql server would interesting know different dbs handle issues case impact low would expect would help get good arguments backed links convince dba long field paranoia isnt really necessary case im learn
1775 table use store answers questions need able find users certain answers particular questions table consists following data user id question id answer value sally pooch sally peach john pooch john duke want find users answer pooch question peach question following sql obviously work select user id answers question id answer value pooch question id answer value peach first thought self join table answer looking select user id answers answers user id user id question id answer value pooch question id answer value peach works since allow arbitrary number search filters need find something much efficient next solution something like select user id countquestion id answers question id answer value peach question id answer value pooch group user id countquestion id however want users able take questionnaire twice could potentially two answers question answers table im loss whats best way approach thanks
1792 performance issues certain database queries large possible result sets query question three ands clause order clauses matter put asi event time clause first since would remove results clauses improve run time query query select distinct activity seismo info activity seismo info activity seismo info asi activity id null activity seismo info asi seismo id activity seismo info asi event time activity seismo info asi event time order activity seismo info asi event time desc explain query id select type table type possible keys key key len ref rows extra simple act range act fi 1act fi act fi null using using filesort using php mysql 51a 3ubuntu5 propel symfony
1805 request like one select estimateid creationuserid estimatestatusvalueid languageid locationid estimatoruserid filterunitsystemtypeid estimatenumber revisionnumber creationdate modificationdate projectdescription isbsdq closingdate closingtime closingupdatedon deadlinedate isreceived inclusion exclusion misc note workdeadlines comments validity planslocation plansreceivedfrom price estimate estimates order closingdate asc closingtime asc run query ssms get executing time 953ms run query linq query get executing time 1813ms linq query use net sqlclient data provider issued entityframework edmx file issue anybody knows big difference execution times requests execute different context database verified execution plans request use index satisfy respective query see execution plan request use sql profiler trap show plan xml event compare one ssms
1811 recently discovered mysql memory engine wasnt aware database work hobby projects learn need go seems like option give drastically improved performance im wondering drawbacks go two know need enough ram hold tables question tables lost machine shuts believe shouldnt issue since im using aws ec2 move instance type memory needed believe mitigate dumping back disk needed issues memory engine ever give worse performance either myisam innodb think read something indices different engine something need worry
1814 full backup week daily diff total db 80gb diffs start 1gb gradually grow approximately 5gb ok sudden jump 40gb almost every week would happen investigate im reasonably sure actual db usage uniform spikes
1847 resources recommend sql server developer wanting learn oracle basics looking comprehensive whitepaper blog post describing differences systems answering questions like create identity column data type equivalent float
1866 heard podcast orms good solution execution plan reuse lead increased execution plan cache affects performance nhibernate handle execution plan execution plan reused nhibernate
1876 starting learn execution plans confused exactly hash match works would used simple join select posts title users displayname posts join users posts owneruserid users id option maxdop understand results top index scan become hash able row bottom index clustered scan looked understand hash tables work least degree confused values exactly get hashed example like would make sense common field id hashed case hash number
1883 im using ubuntu server installed postgresql using apt get install postgresql would like use built sha1 function seems install pgcrypto first dont know install pgcrypto try install using apt get install pgcrypto dont find files starting pgcrypto system tried find name pgcrypto install pgcrypto use digestword hashsha1 function database queries update im struggling install pgcrypto another ubuntu machine installing package using sudo apt get install postgresql contrib install current postgresql database
1910 want know use int lookup tables primary key instead using lookup value primary key cases would string understand using nvarchar50 rather int would use way space linked table many records hand using lookup value directly would basically save us join imagine would big saving join always required working web app counts quite bit advantages using int primary key specifically lookup table standard thing
1927 trying execute fairly large insert select mysql jdbc got following exception exception thread main java sql sqlexception memory needed bytes com mysql jdbc sqlerror createsqlexceptionsqlerror java since im actually returning resultset object thought java heap space shouldnt issue however tried anyway good tried execute statement mysql workbench got essentially thing error code memory needed bytes plenty ram complete operations enough fit whole table im selecting im guessing various settings need tweak take advantage memory im running amazon ec2 high memory double extra large instance windows server ami ive tried fiddling ini file use better settings know might made things worse heres dump file client port mysql default character set latin1 mysqld port basedir program files mysql mysql server datadir programdata mysql mysql server data character set server latin1 default storage engine innodb sql mode strict trans tablesno auto create userno engine substitution max connections query cache size 1024m table cache tmp table size 25g thread cache size myisam max sort file size 100g myisam repair threads myisam sort buffer size 10g key buffer size 5000m bulk insert buffer size 4000m read buffer size 8000m read rnd buffer size 8000m sort buffer size 1g innodb additional mem pool size 26m innodb flush log trx commit innodb log buffer size 13m innodb buffer pool size 23g innodb log file size 622m innodb thread concurrency innodb file per table true join buffer size 4g max heap table size 10g matter changing settings work better environment settings use im one ever uses instance use personal hobby project involves statistical analysis large datasets im free let consume available resources queries matter changing settings problem thanks help offer better configure everything
1942 switch schemabinding view without recreating
1998 every day csv file generated script two columns column name column size mailbox years worth files would like able import database sql house could install mysql anything else matter want able see growth patterns users time basic reports another problem ill solve later time want data db instead hundreds flat files kind db good simple best im db guy would mostly learning project
2009 im responsible creating database project fields rarely going value every records im trying work best way store database far see options add column table extra value add linked table references original table records need store value use xml data type original table store values options ive considered im trying work pros cons method far tell would easiest would take least amount space im struggling find many resources
2041 systematic way force postgresql load specific table memory least read disk cached system
2050 looking decommission sql server instance couple databases still remaining tell still used users web application found forum thread sql query could run retrieve last query date seems work want know information valid enough drop databases alternative methods would help well
2063 query cause deadlock update top1 system queue set statusid id internalid internalid select top internalid system queue isoutgoing isoutgoing statusid order messageid asc internalid asc deadlock graph added keylock hobtid dbid objectname dbo system queue indexname pk system queue id lock5b25cc80 mode associatedobjectid owner list owner id processc6fe40 mode owner list waiter list waiter id processc7b8e8 mode requesttype wait waiter list keylock keylock hobtid dbid objectname dbo system queue indexname ix system queue directionbystatus id lock48cf3180 mode associatedobjectid owner list owner id processc7b8e8 mode owner list waiter list waiter id processc6fe40 mode requesttype wait waiter list keylock added thank sankar article solutions avoid type deadlock eliminate unnecessary columns reader projection look clustered index add required columns contained columns non clustered index make index covering reader look clustered index avoid updates maintain non clustered index
2072 using pentaho data integration even pentaho bought call last free version went website recently see released another version find favorite open source etl much open anymore quite free know alternatives affordable easy use etl tools
2084 db files growing fast designer weekly report makes gb growth finally dont enough space disk number un reported weeks counting options perform need recommendations shrink database shrinking gives space os detach attach db external disk network storage network storage supported sql server change raid config double disk size safest option also dangerous raid config change thanks great helpful answers regarding question checked log file space unused shrunk since db used need reports time request always need access db think performance wont issue
2109 faster reporting performance analysis want insert web server logs sql server allow us see traffic patterns issues slowdowns near real time daemon listens request response events load balancer bulk inserts database however get around gb logs per day need keep week around least raw form best way store data best way delete old entries weve talked storing days data table log would entries day dropping oldest table view could created span day tables easy querying feasible
2124 want find causing high sql compilations compilations seeing performance monitor counters take seeing lot sql compilations means queries system getting cached following reasons many adhoc queries running queries sql cache update table1 set col1 string longer characters key column int plans timing removed cache cache running space plans used long enough thing goes near capturing cache inserts profiler stored procedures sp cacheinserts looks stored procedure cache tried following get adhoc queries select cp refcounts refcounts becomes plan excluded cache cp usecounts cp objtype st dbid st objectid st text qp query plan sys dm exec cached plans cp cross apply sys dm exec sql text cp plan handle st cross apply sys dm exec query plan cp plan handle qp thought queries caused compiles ones objtype adhoc could also relate compilations run profiler capture queries causing compilations exculde list going right direction single query use achive sql compilations without much work resources helped achiving knowledge http social msdn microsoft com forums en sqldatabaseengine thread 954b4fba 42e3 86e7 e5172abe0c83 http www sqlteam com forums topic asptopic id http technet microsoft com en nz library cc966425en us aspx http www sqlservercentral com forums topic914951 aspx help really appreciated
2137 quick way finding hitting database especially log files going crazy sql profiler
2174 database marked suspect restore last backup please advise
2195 anyone explain like operator implemented current database systems mysql postgres point references explain naive approach would inspect record executing regular expression partial string match field interest feeling hope systems something smarter
2296 good way make stored procs robust enough scale well also contain error handling additionally whats best way handle multiple error scenarios stored proc intelligent feedback system return meaningful error information calling apps
2342 read definition 1nf attribute relation atomic please tell atomic
2357 comment question mentions slight difference stored procedrues stored funtions postgresql comment links wikipedia article dont seem apply used select statement syntax seem little bit confusing create function emp stamp returns trigger emp stamp begin end emp stamp language plpgsql create trigger emp stamp insert update emp row execute procedure emp stamp create function refer procedure whats difference two
2361 table looks like event id item id person id event date aug aug aug null aug aug aug aug need get latest maxevent date non null person id per item id come fairly simple pl sql approach trying get job done straight sql anyone idea side note event id always sequential like two redundant db servers thanks ahead time
2387 try drop database get error drop database dbname currently use however run sp who2 definitely sessions connected database ive also set database single user mode rollback immediate happening
2471 answers comments dba se version programmers se version question arguments putting application logic database layer revealing divide dbas programmers workplaces could dbas differently work better programmers issues like study tools languages programmers using understand difficulties face particularly working well designed databases encourage programmers better educated databases advantages business logic database level change way define interfaces data using programmer friendly transactional apis eg issues backwards compatibility
2511 seem remember oracle difference uttering select count table select countany non null column table differences two statements
2515 would like duplicate database server keep date either running scheduled service day sql server take care internally dont need transform data copy databasea databaseb never databaseb databasea would set replication services ssis job advantages disadvantages reason staging application read writes staging database every night new data live database pulled staging database live database updated daily new events want ensure staging environment resembles live environment much possible thanks greg
2524 table user table row particular user id field let alone primary key
2531 small rows table called restrictions postgresql database values deleted inserted daily basis would like table called restrictions deleted every row deleted restrictions stored automatically since restrictions serial id duplicates write trigger postgresql
2545 environment sql server sp3 stored proc takes int input want cast char int call stored proc seems get syntax error foo see someone help find please thank much create procedure testme test int begin select test end declare foo char6 set foo 11test exec testme test castsubstring foo12 int
2562 parsing log file lines legacy proprietary application nice easy query db log lines unique integer id unix timestamp character hex string sadly timestamps always guaranteed unique also thus varchar character hex id appended timestamp unique tested 400k records select table takes seconds go completely redesigning table drastic way want sure using pk opposed auto incrementing int performance hit never really worked table using something regular int pk developer dba using innodb engine fk relations small tables mysql admin showing data length table 150mb index length 21mb 380k rows said im developer dba current situation dont really one bring googling found pretty wide array answers often delved topics raised questions im hoping someone give concise answer least point resources edit changed column char14 removed one large text column somewhat superfluous seems improved time good deal took table size 80mb im still looking suggestions
2569 relation efficient way return multiple aggregates single stored proc email type application want select messages inbox user problem normalize header part emails db flat data goes message table cc bcc get stored another table whats best way select messages full meaning denormalize full message record contains message pertinent fields including message table fields related records recipient table related message per pk fk relationship one thing placing much weight efficiency sql solution code gets executed many many times likely run sql entire db context view db schema
2572 would like use integrated security internal application domain unfortunately ive never able get work well would like assign entire exchange active directory group role sql server read write access certain tables way wouldnt create operator whenever someone hired delete operator whenever someone fired possible steps would take
2574 tables schema intended used read updated three month question refers performance maintenance backup restore export import temporary tablespace better use different one case
2599 im getting new core server sql server database would like create files temp db put one separate drive one drives fails sql server continue function using files
2624 table stores images range size kb since images small ive taken microsofts advice used filestream data type table constructed simply create table screenshot id bigint null data varbinarymax null constraint pk screenshot primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary table heavily inserted million records past week rarely selected key using hilo algorithm part new rows added end ive problems lot processes try insert table locking contention queries timing waiting locks migrate table file group drive improve insert performance decrease contention type situation
2626 heard storing indexes different filegroup drive increases performance database drive doesnt go back forth index data index refers also heard myth advisable store nonclustered indexes separate filegroup drive perfmon profiler evidence would lead arrive conclusion hardware play role decision whether raid san used single drive
2631 site working lot backend cron activity queries executed every second day slow page loads second thinking best thing would create two databases synchronize daily however know worried synchronization slow block db access really dont like idea taking site offline even minutes wondering separate databases best solution problem would something else better would synchronize database without interfering much user experience thanks much btw running php mysql could servers
2634 sometimes snafu run kill query xxxxxxx twenty thirty times sort kill command missing account dont like typing
2650 table potentially store hundreds thousands integers desc id key table field type null key default extra id key int16 pri null program large set integers id like see integers id key column far ive come following approaches iterate integer perform select count count id key table id key id key count id key missing table seems like horrible horrible way create temporary table insert values temporary table perform join two tables create temporary table id key table temp id key int16 primary key insert id key table temp values select temp id key id key table temp temp left join id key table main temp id key main id key main killid null drop table id key table temp seems like best approach however im sure far better approach havent thought yet id prefer create temporary table use one query determine integers missing proper query type search mysql
2662 sql server machine dbmail setup correctly configured able use notify operator exec msdb dbo sp send dbmail queue emails problem queued mails never go see emails queue query select msdb dbo sysmail unsentitems restart sql server service mails go receive emails inbox far pattern could find question way troubleshoot dbmail read steps msdn much help urls articles could help much appreciated
2677 looking create timestamp fields date time style fields best way name put record timestamp
2678 show binlog format mysql server dont like set xx permanently xx statement row mixed
2684 ever justify using query hint seeing nolock every single query hits busy server point developers think default hate seeing code thousands times tried explain allowing dirty reads end bad data eventually believe performance tradeoff well worth database mess wonder performance issues clear example present case abuse nolock hint would appreciated
2687 tasked devising maintenance plan sql server databases know backups want daily full database backup transactional log backups every minutes problem comes figuring tasks want often far mind correct flaws thinking better way backup tables full backup daily backup selected tables full backup hourly backup transaction logs every minutes check database integrity daily reorganize index daily update statistics daily shrink database weekly rebuild index weekly maintenance cleanup daily remembered reading time ago set similar plan another job tasks dont need run daily basis run daily ones escapes could use little guidance creating better maintenance plan reduce data loss disaster wont tax system running peak hours also increase performance
2701 lnnvl oracle built function returns true conditions evaluating false unknown returns false conditions evaluating true question would benefit returning opposite truth condition rather handling null values example suppose emp table startcommission currentcommission columns may contain nulls following returns rows neither value null select emp startcommission currentcommission wanted include rows either commission null could something like select emp startcommission currentcommission startcommission null currentcommission null would seem like function would exist shorten syntax using lnnvl returns non equal records records nulls select emp lnnvlstartcommission currentcommission adding returns rows without nulls seems desired functionality case would keep true conditions true false conditions false unknown conditions evaluate true really created low use case really likely want turn unknown true true false false true create table emp startcommission number32 currentcommission number32 insert emp values nullnull insert emp values null insert emp values 2null insert emp values
2710 disclaimer please bear someone uses databases tiny fraction work time time programming job every odd month need search fix add something oracle database repeatedly needed write complex sql queries ad hoc queries queries built applications large parts queries repeated code writing abominations traditional programming language would get deep trouble yet yet unable find decent technique prevent sql query code repetition edit 1st want thank answerers provided excellent improvements original example however question example repetitiveness sql queries answers jackp leigh far great job showing reduce repetitiveness writing better queries however even face repetitiveness apparently removed always nagged sql traditional programming languages refactor quite lot minimize repetitiveness code sql seems tools allow except writing less repetitive statement begin note removed oracle tag would genuinely interested whether theres database scripting language allows something heres one gem cobbled together today basically reports difference set columns single table please skim following code esp large query end ill continue create table test queries create table test attribs id number primary key name varchar2300 unique attr1 varchar22000 attr2 varchar22000 attr3 integer attr4 number attr5 varchar22000 insert test data insert test attribs values alfred foobar insert test attribs values batman foobar insert test attribs values chris foobar insert test attribs values dorothee foobar insert test attribs values emilia barfoo insert test attribs values francis barfoo insert test attribs values gustav foobar insert test attribs values homer foobar insert test attribs values ingrid foobar insert test attribs values jason bob insert test attribs values konrad bob insert test attribs values lucas foobar insert test attribs values dup alfred foobar insert test attribs values dup chris foobar insert test attribs values dup dorothee foobar insert test attribs values dup gustav foobar insert test attribs values dup homer foobar insert test attribs values dup ingrid foo insert test attribs values martha bob create comparison view create replace view ta selfcmp select t1 id id t2 id id t1 name name t2 name name dup t1 attr1 attr1 t1 attr2 attr2 t1 attr3 attr3 t1 attr4 attr4 t1 attr5 attr5 t2 attr1 attr1 t2 attr2 attr2 t2 attr3 attr3 t2 attr4 attr4 t2 attr5 attr5 test attribs t1 test attribs t2 t1 id t2 id t1 name t2 name t1 name replacet2 name dup note piece horrible code repetition create comparison report compare 1st attribute select attr1 different id id name name dup castattr1 varchar22000 val1 castattr1 varchar22000 val2 ta selfcmp attr1 attr1 attr1 null attr1 null attr1 null attr1 null union compare 2nd attribute select attr2 different id id name name dup castattr2 varchar22000 val1 castattr2 varchar22000 val2 ta selfcmp attr2 attr2 attr2 null attr2 null attr2 null attr2 null union compare 3rd attribute select attr3 different id id name name dup castattr3 varchar22000 val1 castattr3 varchar22000 val2 ta selfcmp attr3 attr3 attr3 null attr3 null attr3 null attr3 null union compare 4th attribute select attr4 different id id name name dup castattr4 varchar22000 val1 castattr4 varchar22000 val2 ta selfcmp attr4 attr4 attr4 null attr4 null attr4 null attr4 null union compare 5th attribute select attr5 different id id name name dup castattr5 varchar22000 val1 castattr5 varchar22000 val2 ta selfcmp attr5 attr5 attr5 null attr5 null attr5 null attr5 null see query generate difference report uses sql select block times could easily times strikes absolutely brain dead im allowed say wrote code havent able find good solution would query actual application code could write function cobbles together query string id execute query string building strings horrible horrible test maintain application code written language pl sql feels wrong hurts alternatively used pl sql like id guess procedural means make query maintainable unrolling something expressed single query procedural steps prevent code repetition feels wrong query would needed view database far understand would way actually maintain view definition posted actually maintenance page view definition wasnt far statement obviously changing anything view required regexp text search view definition whether sub statement used another line whether needed changing title goes techniques prevent write abominations
2716 sql server reduce log files size without dbcc shrinking know shrinking log file free space also cause fragmentation checkpoint simple mode backing transaction log full mode trick working one scenarios advice links help preventing log file fragmentation
2736 im trying import oracle export oracle xe get following messages import xe fehlerhaft import done we8mswin1252 character set al16utf16 nchar character set import server uses al32utf8 character set possible charset conversion ideas import dump oracle xe edit given table create table bdata artikel key varchar23 null name varchar260 null abkuerzung varchar25 null get errors like imp row rejected due oracle error imp oracle error encountered ora value large column bdata artikel abkuerzung actual maximum column abl column aufbewahrungsl sung column afbl rows missing import
2743 say get resultset back following query select sys database files given resultset want able query column names types create tables store results good way performing sql
2758 column created type timestamp without time zone default postgresql database select colums nice readable format per default select created mytable created would like get timestamp milliseconds long something like select myformatcreated mytable created get timestamp column milliseconds postgresql response jack get difference use timestamp time zone see error difference gets time zone create table table 2created timestamp time zone create table insert table created values insert select created extractepoch created table created date part rows difference bug may daylight saving times moment also interesting using timestamp insert timestamp insert table created values timestamp0 insert insert table created values timestamp1 insert select created extractepoch created table created date part
2763 would set maximum time query wait lock mysql timing
2770 planing soon highly loaded postgresql databases expirience managing mysql databases high load use postgresql want know best tools day day database management status reporting course console best one want know options expirience welcome
2784 ive table multi column unique index job id keyword id would also need add another index job id frequent query performs group column million rows could take im asking instead
2790 audit coming wondering physical electronic logical access controls auditor would look auditing database erp system im really new process guidance would appreciated
2796 unix timestamp number seconds since midnight utc january get correct unix timestamp postgresql comparing currenttimestamp com timestamp 1e5b de dont get expected time postgresql returns correct timestamp select extractepoch doesnt select extractepoch time zone utc live time zone utc correct way get current unix timestamp postgresql returns correct time time zone select another comparison select extractepoch extractepoch time zone utc date part date part row unix timestamp web sites
2804 would like use default value column used rows returned possible postgresql way solve something like select maxpost id max id default table org id rows org id table want return
2824 using tool requires specific tables db2 database primary key defined way using select statement db see given table one thanks
2868 using memory engine tables associated particular mysql query speed access paramount project reason noticed large amount disk write still occurs windows swapping ram disk prevent happening edit global variables mysql show global variables variable name value auto increment increment auto increment offset autocommit automatic sp privileges back log basedir program files mysql mysql server big tables binlog cache size binlog direct non transactional updates binlog format statement binlog stmt cache size bulk insert buffer size character set client latin1 character set connection latin1 character set database latin1 character set filesystem binary character set results latin1 character set server latin1 character set system utf8 character sets dir program files mysql mysql server share charsets collation connection latin1 swedish ci collation database latin1 swedish ci collation server latin1 swedish ci completion type chain concurrent insert auto connect timeout datadir programdata mysql mysql server data date format datetime format default storage engine myisam default week format delay key write delayed insert limit delayed insert timeout delayed queue size div precision increment engine condition pushdown event scheduler expire logs days flush flush time foreign key checks ft boolean syntax ft max word len ft min word len ft query expansion limit ft stopword file built general log general log file programdata mysql mysql server data fxmachine log group concat max len compress yes crypt csv yes dynamic loading yes geometry yes innodb disabled ndbcluster openssl disabled partitioning yes profiling yes query cache yes rtree keys yes ssl disabled symlink yes hostname fxmachine ignore builtin innodb init connect init file init slave interactive timeout join buffer size keep files create key buffer size key cache age threshold key cache block size key cache division limit large files support large page size large pages lc messages en us lc messages dir program files mysql mysql server share lc time names en us license gpl local infile lock wait timeout log log bin log bin trust function creators log error programdata mysql mysql server data fxmachine err log output file log queries using indexes log slave updates log slow queries log warnings long query time low priority updates lower case file system lower case table names max allowed packet max binlog cache size max binlog size max binlog stmt cache size max connect errors max connections max delayed threads max error count max heap table size max insert delayed threads max join size max length sort data max long data size max prepared stmt count max relay log size max seeks key max sort length max sp recursion depth max tmp tables max user connections max write lock count min examined row limit multi range count myisam data pointer size myisam max sort file size myisam mmap size myisam recover options myisam repair threads myisam sort buffer size myisam stats method nulls unequal myisam use mmap named pipe net buffer length net read timeout net retry count net write timeout new old old alter table old passwords open files limit optimizer prune level optimizer search depth optimizer switch index merge onindex merge union onindex merge sort union onindex merge inter engine condition pushdown performance schema performance schema events waits history long size performance schema events waits history size performance schema max cond classes performance schema max cond instances performance schema max file classes performance schema max file handles performance schema max file instances performance schema max mutex classes performance schema max mutex instances performance schema max rwlock classes performance schema max rwlock instances performance schema max table handles performance schema max table instances performance schema max thread classes performance schema max thread instances pid file programdata mysql mysql server data fxmachine pid plugin dir program files mysql mysql server lib plugin port preload buffer size profiling profiling history size protocol version query alloc block size query cache limit query cache min res unit query cache size query cache type query cache wlock invalidate query prealloc size range alloc block size read buffer size read read rnd buffer size relay log relay log index relay log info file relay log info relay log purge relay log recovery relay log space limit report host report password report port report user rpl recovery rank secure auth secure file priv server id shared memory shared memory base name mysql skip external locking skip name resolve skip networking skip show database slave compressed protocol slave exec mode strict slave load tmpdir windows temp slave net timeout slave skip errors slave transaction retries slave type conversions slow launch time slow query log slow query log file programdata mysql mysql server data fxmachine slow log socket mysql sort buffer size sql auto null sql big selects sql big tables sql buffer result sql log bin sql log sql low priority updates sql max join size sql mode strict trans tablesno auto create userno engine substitution sql notes sql quote show create sql safe updates sql select limit sql slave skip counter sql warnings ssl ca ssl capath ssl cert ssl cipher ssl key storage engine myisam sync binlog sync frm sync master info sync relay log sync relay log info system time zone eastern daylight time table definition cache table open cache thread cache size thread concurrency thread handling one thread per connection thread stack time format time zone system timed mutexes tmp table size tmpdir windows temp transaction alloc block size transaction prealloc size tx isolation repeatable read unique checks updatable views limit yes version version comment mysql community server gpl version compile machine x86 version compile os win64 wait timeout
2895 somewhat new using standard sql databases currently working mysql mostly havent run across many usages yet useful negative rather signed keys indexing table
2905 know lot database administrators years old database administration like mean getting experience least years database administrator hard
2918 h2 single threaded database good reputation regarding performance databases multi threaded question multi thread database become interesting single thread database many users many processes trigger anyone experience share summary usual bottleneck disk access ssds fast fragile failure procedure must one long query single thread system block others configuring multi threading system tricky multithreaded databases beneficial even single core systems
2967 got question two databases oracle 10g lets call information various tables want get partial copy tables constantly check changes sync want ask method technique maybe ideas knowing cant make change selects triggers thank help patience possible edits advance additional information thanks answers dont know relevant found minus operator though im sure works sub table select
2973 table items item id serial name varchar10 item group int table items ver id serial item id int name varchar10 item group int want insert row items ver items short sql syntax tried insert items ver values select items item id get syntax error error syntax error near select line insert items ver values select items item tried insert items ver select items item id worked better got error error column item group type integer expression type character varying line insert items ver select items item id may columns defined different order tables column order matter hoped postgresql match column names
2978 im writing script populate tables data testing would like write something like following dont know im oracle 11g set enabled user id seq nextval pseudocode set disabled user id seq nextval pseudocode insert users id usr name values enabled user id andrew insert car car id car name usr id values carseq nextval ford enabled user id insert users id usr name values disabled user id andrew insert car car id car name usr id values carseq nextval ford disabled user id know could rearrange queries use sequence currval reference id prefer id saved properly named variables maybe wrap script declare begin end im hoping concise way addition may seems case declare variables declare block im trying declare user id number100 begin insert test user values user id andrew sysdate end get following error caused java sql sqlexception ora line column pls encountered symbol end file expecting one following mod remainder rem exponent like like2 like4 likec multiset member submultiset points variable declaration im using java load script file running using oracle jdbc driver ojdbc14 jar oracle 11g server table test user created create table test users id number10 null name varchar2100 date ins date default sysdate primary key id
3005 installed postgresql computer mac os using one click installer try access postgresql using psql command doesnt seem available get message psql bash psql command found install something configure postgresql use computer
3042 sql server allows use select statements similar select firstname lastname city dbo customers try execute query oracle database get following error ora missing expression missing expression doesnt oracle support queries
3056 sql server configuration manager used configure certain settings like connection protocols service start etc possible make changes done sql server configuration manager using tsql statements ssms
3093 ive recently finished project many db tables created tables contain temporary garbage looking simple way list tables way list db tables sorted according creation date
3102 would like issue parameterized oracle via sqlplus parameters provided text file way query parameters reasonable person prompted would like eliminate user error entering parameter reason need issue parameterized query seeing huge difference performance straight sql statement query issued parameterized query application would like remove application code chain difference evident oracle tools
3110 sql server databases full mode hourly transaction log backups possible determine rebuilding indexes database grow log file database much grow straight answer directions would really appreciated thanks advance
3115 want know certain postgresql table part inheritance relationship parent child tables query inheritance data stored
3134 sql computing databases two fields table together identify records uniquely whats proper way calling composite compound keys ive seen web uses im really sure
3139 organic environment meaning people piled code code ten years minimal oversight documentation server use several databases believe longer used id love delete leave three actually use reckless extreme could disable databases wait someone scream could leave running forever case steps found valuable identifying whether server used also steps would recommend ensure one moves forward disabling systems remain conveniently reversible period time rename objects rather deleting outright thanks
3140 create incremental number oracle sql query without create table tried using clause failed get expected result using oracle 10g code tryit seems working table3 select years dual union select t3 years table3 t3 t3 years select years table3 expected result want
3148 would like benchmark sql queries agains postgresql database way time sql queries using psql
3153 database sql server windows server want move data mysql database ubuntu server tried using sql server import export wizard mysql odbc driver correctly accesses databases xml files containing specifications type conversion exist specifications limited correctly create anyone know either create type conversion files get better tool transferring data
3160 since varchar takes disk space proportional size field reason shouldnt always define varchar maximum varchar8000 sql server create table see anyone varchar100 tell wrong varchar8000
3204 recently database server important db broke grub linux issue id prefer solve still access filesystem chance transfer database moving directories content equal machine bit ubuntu postgres edit ubuntu postgresql data directory var lib postgresql main usr local pgsql data
3221 id like limit rows columns come back show table status command mysql way get information select statement manipulate results normal way
3223 almost certainly cause question thought worth separating two hypothesis based following log would love falsified verified hypothesis deadlock actually result following queries original query hidden based understanding innodb status shows recent transactions correct based log checked code found following two queries executed sequence db execute update people set iphone device id null iphone device id people id deviceid user people id hard coded query snippet simplify things db execute update people set company id name dad password pass temp password null reset password hash null email redacted gmail com phone null mobile null iphone device id iphone device id blah iphone device time last checkin location lat lat location long lng gps strength picture blob id authority active date created last login panic mode battery level battery state unplugged people id db execute basically executenonquery system data dbcommand object sequence queries result deadlock hypothesis two different field orders two queries causes issue wrap two queries transaction resolve deadlock latest detected deadlock transaction transaction active sec os thread id starting index read mysql tables use locked lock wait lock structs heap size row locks mysql thread id query id localhost famdev searching rows update update people set iphone device id null iphone device id iphone device id blah people id waiting lock granted record locks space id page bits index primary table family people trx id lock mode locks rec gap waiting record lock heap physical record fields compact format info bits len hex asc len hex 000002b8eedf asc len hex asc len hex 80000000000004c6 asc len hex asc dad len hex data0 asc data1 truncated sql null sql null len hex data2 asc redacted gmail com sql null sql null len hex data3 asc iphone data4 truncated len hex data5 asc len hex data6 asc len hex data7 asc len hex data8 asc len hex asc len hex data9 asc len hex data10 asc len hex asc len hex data11 asc jl len hex data12 asc len hex asc len hex data13 asc len hex data14 asc unplugged transaction transaction active sec os thread id starting index read thread declared inside innodb mysql tables use locked lock structs heap size row locks undo log entries mysql thread id query id localhost famdev updating update people set company id name dad password pass temp password null reset password hash null email redacted gmail com phone null mobile null iphone device id iphone device id blah iphone device time last checkin location lat lat location long lng gps strength picture blob id authority active date created last login panic mode battery level battery state unplugged people id holds locks record locks space id page bits index primary table family people trx id lock mode locks rec gap record lock heap physical record fields compact format info bits len hex asc len hex 000002b8eedf asc len hex asc len hex 80000000000004c6 asc len hex asc dad len hex data0 asc data1 truncated sql null sql null len hex data2 asc redacted gmail com sql null sql null len hex data3 asc iphone data4 truncated len hex data5 asc len hex data6 asc len hex data7 asc len hex data8 asc len hex asc len hex data9 asc len hex data10 asc len hex asc len hex data11 asc jl len hex data12 asc len hex asc len hex data13 asc len hex data14 asc unplugged waiting lock granted record locks space id page bits index primary table family people trx id lock mode locks rec gap waiting record lock heap physical record fields compact format info bits len hex asc len hex 000002b8eedf asc len hex asc len hex 80000000000004c6 asc len hex asc dad len hex data0 asc data1 truncated sql null sql null len hex data2 asc redacted gmail com sql null sql null len hex data3 asc iphone data4 truncated len hex data5 asc len hex data6 asc len hex data7 asc len hex data8 asc len hex asc len hex data9 asc len hex data10 asc len hex asc len hex data11 asc jl len hex data12 asc len hex asc len hex data13 asc len hex data14 asc unplugged
3225 running quite loaded postgresql server need take snapshots certain tables certain time midnight tables pretty loaded lot updates inserts best way edited table snapshot records changing day added actually one idea add insert update trigger table shapshoted write changes another table partitioned daily basis please tell god idea
3229 vendor database want extract transform certain information dont want change structure original database due licensing therefor wondering put together views vendor database storing second sql server database together replicated transformed data second database supposed live beside first one server possible views like loose lot performance querying views
3251 materialized viewmv log used allow mv fast refresh modifies data changed however various conditions prevent mv using log therefore require complete refresh oracle implemented atomic complete refresh delete insert every record even ultimately changes data way make replication intelligent regard redo generation merge followed delete requires querying source twice would worth bulk collect data bulk merge delete better way update explored using global temporary table staging area although use less half redo still use much
3255 trying get idea size hot data part rather large table wondering could done directly mysql know percona version mysql access figures like number rows accessed per table would actually need data per row basis row id read times row id read times id auto increment column
3276 table columns id name created date would like add column use alter table table add column email varchar255 column added created date column way specify position new column add name get table like id name email created date
3281 table create table names id serial name varchar20 want last inserted id table without using returning id insert seem function currval dont understand use tried select currval id names id seq select currvalnames id seq select currvalnames id seq regclass none work use currval get last inserted id
3289 migrating database new schema want validate data moved correctly traditional data comparison tools compare two databases differences schemas case changes table designs data old schema new one moved around bit need make sure correct tens millions rows manual inspection option tools could aid type comparison libraries frameworks could help kick start development custom solution im happy use database specific solution necessary case sql server soluton im comparing two data sets creating view table old database fields new database table compare data using technique described shortest fastest easiest way compare two tables sql server union im lucky migration overall table structure similar old database fields moved one table another dropped added case dropped added nothing compare fields moved aggregated calculations view provide correct information comparison union comparison shows rows differences soon data correct get empty result set
3323 microsoft article determine appropriate page file size bit versions windows server windows r2 provides guidance calculating page file size bit windows windows 2008r2 doubt works fine general purpose servers im wondering guidance sql server 2008r2 running windows r2 bit im presuming want little memory data hitting page file otherwise sql could hitting disk twice data sql server even allow data memory hit page file ive hunted sql server r2 books online guidance havent yet found mention page file use heres potential usage scenario given physical server 64gb ram pagefile necessary entire 64gb ram gear 96gb pagefile seem bit excessive single file know conventional wisdom windows couples pagefile memory attempt make swapping apps easier ram true less 64gb pagefile hinder performance
3343 large sql server test database 9tb want reduced size disk deleting unused tables purging significant amounts data size disk reducing ive looked shrink task ssms options bewildering shrink database files options
3345 thought occurred recently suspicion idea might insane couple benefits im perceiving facilitate automated logging via triggers control mysql connections per web application user level obviously would yield ridiculously long table users penalties arent yet clear user table properly indexed ologn single user lookups
3375 want performance test aka bake mysql server rpm forks percona server mariadb possibly others im hoping asking question better understand methodology behind setting proper performance test planned using sysbench run actual test im open anything steps taking ensure test results apples apples comparison rdbms variant get started evaluate results advice give
3394 first im developer dba sysadmin please gentle im working application workflow single user action trigger complex changes database creating hundreds records tables updating hundreds records others etc tables touched action due complexity hard manually revert changes run another test development time simply insert rollback statement near end workflow get close commiting changes need test real thing local copy production database work case dumping restoring tests faster writing script undo changes faster still slowing lot restore takes around minutes ageing laptop way save snapshot current state database quickly restore im guaranteed user system root access database dump 100mb tared gziped postgresql version thanks advance helpful ideas
3467 know mysql limits auto increment columns primary keys first thought performance restriction since probably counter table somewhere must locked order get value cant multiple auto increment columns table thanks
3480 run website 250mm rows one table another table join queries 15mm rows sample structures mastertable id userid created updated 15mm rows detailstable id masterid somecolumn 250mm rows usertable id role created username 12k rows regularly queries tables one grabbing statistics free users 10k free users select count1 detailstable dt join mastertable mt mt id dt masterid join usertable ut ut id mt userid ut role null mt created date1 date2 problem query times run long damn time due fact joins happens long case would wiser use wheres instead joins possibly column
3509 sql desc tab1 name null type id number name varchar21000 sql select tab1 id name sql select tab1 id avgid select tab1 id avgid error line ora group function allowed sql error clear says done dont see query makes perfect sense select rows tab1 whose id value greater average
3512 new data mart design need clear concepts read bit dimension modelling see fact tables store foreign key references dimension tables suppose phonenumber dimension table phone extension dimension table tables different details combine understand dimension tables integer primary keys better performance fact table integer primary key also store foreign key references dimension tables suppose situation phone numbers phone extension related phone numbers need extension phone numbers extension fact table would foreign key references dimension tables capture situation phone numbers extension vice versa extension phonenumbers capture information phonenumber fk fact table value phone extension foreign key null non related objects recorded fact tables also need generate report data mart start querying fact table retrieving dimension key values report straight dimension table thanks time reading appreciate help
3519 need implement basic personalized user functionality website standard structure databases type like common practice user info data single table user row info split among different tables linked together maybe efficiency im tremendously concerned security point ill obviously want password encryption long tried find looking google avail let know question needs clarification anything
3540 currently executing imp command following parameters file dmp log log fromuser myuser touser myuser following errors occur imp oracle error encountered ora tns protocol adapter error imp import terminated unsuccessfully however tnsping successfully looks values tnsnames ora file question dump file created 10g cause issue import 11g error something else unable diagnose
3552 want use syslog logging mysql5 ubuntu10 lts found information output error log syslog mysqld safe syslog want use syslog logging general logs slow query logs please advise write config file could find reference manual http dev mysql com doc refman en log destinations html
3605 several work packages setup job sql server agent sometimes run together best way run given sequence im bit surprised sql server agent able include jobs job steps executed try
3628 ive trying use sql server management studio 2008s built solution explorer manage project weeks struggling ive decided dont really care convenience features actually quite hindrance unfortunately place work ms shop pretty stuck ways want go back command line crave vim ive installed local subversion repository tortisesvn front end replace mentioned solution explorer running quite well also installed vim still working customizing humming however one thing yet find solution run commands sql server via command line im used mysql postgres command line prompt since used past using going classes however cant seem find way execute scripts via command line windows currently edit vim refresh page ssms execute would prefer even touch smss unless needed ive seen posts suggesting sqlsharp went page get feeling isnt quite im looking edit really wish possible answer check marks campbell technical right answer ive tried times keep getting error try sqlcmd researching named pipes operating even though set enabled doesnt seem work trying success tried copy paste management studio method ridiculous decided maybe hardcode correct
3647 following text extract oracle documentation start instance mount open database done unrestricted mode allowing access users restricted mode allowing access database administrators mount database previously started opened instance use sql statement alter database mount clause follows alter database mount read directly http download oracle com docs cd b19306 server b14231 start htm first part gives impression mounting instance database mount database previously started opened instance part gives impression mounting database instance one understanding right anyone help explain please thanks
3653 daily routine need drop bulk load database problem webapp relying database cant drop database like would good way tackle problem
3674 client given data wants visualised project dont know db format hes pretty unclear also access table structures dont know read definitely flat file several files dataset file dat biggest far file id small file ind half size dat first bytes dat file 6e case magic numbers used extensions ring bells software determine format
3682 would like expert opinion best practices comes column naming background according wikipedia following syntax select employees join timesheets using employeeid efficient select employees join timesheets employees employeeid timesheets employeeid however join using syntax works primary key columns globally unique names thus wonder considered right thing personally always used create tables pk column id foreign key column othertable id way possible use using natural join links design styles best practice guides table design would appreciated
3688 mean data valid accurate according database integrity
3694 took backup sql server database mdf ldf files together total around gb bak file gb smaller first guess one version set data smaller another version containing data would data compression compression usually yields much better compression ratio especially highly ordered data database tables also compressed data cant easily compressed know bak files compressed data isnt compressed nothings discarded whole point making backup able restore identical state afterwards whats thats unaccounted
3696 im currently making mmorpg game could thousand players online time probably wishful thinking first wanted use mysql heard isnt fast enough scale dbms fast enough much like sql server learned sql server school
3710 first post means qualified windows server storage server sql server administrator mostly unix guy however tasked job investigate firm small software startup infrastructure includes windows server windows storage server sql server used exclusively finance hr sales legal administration depts devs unix need get ideas around protect windows based infrastructure insider attacks precisely rogue system administrators current system administration role played temp theory access passwords login credentials whatever likes technology audit logs tamper proof backups etc setup like onetime whose credentials available extremely trusted person maybe ceo system admin tasks performed temp chap worst case admin removes deliberately corrupts modifies certain files alters database content acts tracked proven rectified understand probably pure dba question pardon willfully posting didnt find appropriate se forum found quite interesting windows server infrastructure discussions
3737 company currently hosts databases per sql server instance databases see performance start deteriorate database size ranges 50mb 60gb extreme probably average maybe gb good metrics collect would get determine bottleneck performance limitation sql server many databases cached procedure plans hundreds stored procedures hundreds databases inefficient queries combination likely help us increase number databases per server schemas identical databases separate customers data maybe refactoring everything combine multiple customers one db filter customer optimizing queries extreme maybe sql server limitation
3751 represent latitude longitude postgres without using postgis system using allow sql passthrough use postgis
3754 table oracle database select pkcol count mytable group pkcol count yields pkcol count trying remove duplicate rows delete mytable pkcol yields ora index mytable pk mt partition index usable state im using oracle dataaccess client oraclebulkcopy fill table far understand documentation oracle primary key constraints checked obviously checked found bulkcopy two times succession ended duplicates row im using deleting rows im using table similar primary key source result expect problems embedded deep inside ms build scripts end duplicates rows guess ignoring primary key first place clear bug bulkcopy allowed ignore primary key constraints edit meanwhile found conflicting rows normally inserted script bulkcopy called problem reduces known problem bulkcopy doesnt check primary keys
3760 large table varchar20 column need modify become varchar50 column typically performing alter table adding tinyint particular table takes minutes complete really saturday sunday night avoid affecting users database possible would like modification prior column also indexed presume make alter table slower rebuild index modifying column length web app set mysql replication environment slaves one master recall reading somewhere one method first perform alter table slave minimising impact users master wont try replicate alter table command slaves question best way modify table minimum disruption users edit table innodb
3768 common best practices length data type common fields like first name last name address email sex state city country phone number etc
3794 sql server database data file 2gb size log file 8gb pre databases could use backup log truncate option longer available later databases script truncates log file use mydatabase go alter database mydatabase set recovery simple wait dbcc shrinkfilemydatabase log alter database mydatabase set recovery full wait go truncates log file completely question affect performance perform two full backups daily log really necessary far data roll forward concerned
3816 tablex modified two ways client direct inserts client uses stored procedure inserts records determinate way clients call direct stored proc trigger tablex thank
3828 database varchar column contains integers varying length want sort comes 70a comes able patindex cte case statements clause however wondering collation would unecessary
3831 us probably agree using database indexes good many indexes performance actually degraded general rule fields indexed fields indexed rules using indexes striking balance many enough indexes order achieve performance improvements degradation
3849 wrote query shoots syntax error would select maxrow select row number overorder id desc row users error desc incorrect syntax near dont get
3856 sql server r2 save results csv headers work around copying pasting copy headers grab headers paste csv etc better way
3889 following cnf client password somepass password use every user host database connect way specify config different passwords different things dont type
3913 company many branch offices branch db server sql server others sql server schema servers whenever want ddl like adding column etc either connecting server one one running ddl script osql batch file built tool ddl several servers third party tools preferably free ones
3914 company wants use mysql one software product product open source legal use freely postgresql okay purpose
3972 table columns im trying insert columns get error code many columns table rows important thing number columns limitations table want create columns possible
3980 stored procedure accepts various varchar parameters middle tier code calls procedure consistent terms values submits example sometimes parameter like transport description submitted null sometimes empty string terms client empty string simply means value entered convert empty varchar parameters null inserting data cant decide falls realm best practice preserve integrity data bad idea im representing actually submitted database note inserts updates tracked audit log
3999 suppose two queries frequently run database select userid username usergender users userid user select userid username usergender users username like name two separate stored procedures single one creates statements dynamically using sp executesql two stored procedures need modify procedures ever want add remove column select statement use dynamic sql presumably sacrificing small amount performance case maintainability adherence dry principle dont repeat using dynamic sql would take precedence performance gain stored procedure
4000 sql server database regularly transfer client site takes long time dont direct connection transfer file web based file transfer application database currently 10gb however dont need data audit tables tables hold calculated values generated looked creating filegroup hold audit tables hoping could backup restore primary filegroup backup fine restoring get error saying im restoring database possible restore part database different server using filegroups better way
4018 trying migrate database sql server part sbs sql server r2 express edition naively tried using sql server export import wizard worked degree seemed try import views tables left stored procedures altogether least painful way performing sort migration
4021 copy mytable file csv delimiter csv rw peter peter file csv psql tells error could open file file csv reading permission denied read file thanks update looks like something called apparmor installed default ubuntu seems functionality selinux mentioned comments update removing apparmor still problem selinux installed regarding comment access copy run superuser account gives different error message file permissions copied understand readable everyone update tried get file postgres user gets stuck particular place tree drwxr peter peter phm postgres dexter home peter pypacks cd phm bash cd phm permission denied suppose put file somewhere else strange
4040 mostly self taught comes database designs posing question settled common structure wondering efficient industry standard method databases design user table persons activty tracked another table understand beauty database sorts efficiencies activity table gather many many events fairly quickly every user using regularly thus becoming huge table fairly quickly moderate user usage best practice let grow way tier tables splitting different tables based dates per amount users something else userdata activity id auto uint many id auto uint username text userid uint email text timestamp time additional info type id elsewhere additional info would like know improve anything help learn
4043 someone running query sql server database remotely system crashed backup query want see run server possible find query log history somewhere
4106 order confident databases entry level job candidate completed oca certification want know career paths follow one go data mining bi via certification heard dba quite boring risky experimental people
4114 old database mysql server four years old uninstall mysql server install latest release restore backup gain performance benefits guess new version release says many performance benefits
4115 never dipped hands mysql cluster want know benefit best use performance benefits
4118 im granting following rights user grant super user host include rights dbname given grant dbname user host thank
4124 production mysql database running well want improve query performances never used partitions going manuals two tables involve composite key columns bill num bill date want create partition bill date table consists records four years want know new partitioned table accommodate future years also want know whether need make changes table name existing queries replace table name new partitioned table name
4129 problems backing databases update poking around system trying figure one query ran returned result got error user specified definer cittool exist using lock tables investigation appears definer views old developer account purged system databases views problem used infrequently kept around archival purposes views definer longer exists easy way change definer different account everything way get mysqldump simply dump views file could edit file recreate views
4137 im problem permissions oracle 10g im hoping someone help make sense schema table granted select table role grant select user1 example table example role grant role user grant example role user2 user2 wants create view top table create replace view user2 example view select user1 example table throws error however ora insufficient privileges though select permission via role create view object found grant object directly user would work grant select user1 example table user2 anyway wanted use roles lot tables lot users dont want maintain million different grants individual users
4141 im thinking using partition function want know supported dont tell good idea use columns partitioned tables
4152 im process designing database im second thoughts initial design decisions product types follows models parts replacement part kits options option first design planned separate tables product types id say fields would table created product type separate tables associations need create instance model many options option many models option also many parts part many options option instead separate tables could create table called product encompasses model part replacement part kits options could one field called type differentiate model options etc suppose side several fields would never used left null certain product types im guessing best practices would come play option would greatly reduce complexity db design also wouldnt worry referencing bunch tables pulling data queries
4154 sql server database simple mode dont care transaction log bakcups simple mode transaction log seems grow full mode truncate automagically time point truncate shrink manually
4162 following stored procedure works great except set orderby ordernumber get following error conversion failed converting nvarchar value sk11270 data type int sk11270 value ordernumber column nvarchar50 run identical query orderby column works fine im completely lost head hurts anyone see anything obvious would causing problem thanks advance ideas rich works sp jobs 120jobnumberasc97truetruetruetruetruetruetruetruetruefalsetruefalsetruefalse0 doesnt sp jobs 120ordernumberasc97truetruetruetruetruetruetruetruetruefalsetruefalsetruefalse0 procedure dbo sp jobs pagenumber int pagesize int filterexpression varchar500 orderby varchar50 orderdirection varchar50 customerid int shownotset bit showplaced bit showproofed bit showreproofed bit showapproved bit showontime bit showlate bit showproblem bit showcompleted bit showdispatched bit showunapproved bit showclosed bit showreturned bit shownostock bit userid int recompile begin keys select top pagenumber pagesize row number order case orderdirection asc case orderby jobnumber p1 jobnumber orderby ordernumber p1 ordernumber orderby custid p1 custid orderby status p1 masterjobstatusid orderby datein p1 datein orderby datedue p1 datedue orderby dateout p1 dateout else null end end asc case orderdirection desc case orderby jobnumber p1 jobnumber orderby ordernumber p1 ordernumber orderby custid p1 custid orderby status p1 masterjobstatusid orderby datein p1 datein orderby datedue p1 datedue orderby dateout p1 dateout else null end end desc rn p1 jobnumberp1 custidp1 dateinp1 dateduep1 dateoutp1 clientp1 masterjobstatusidp1 masterjobstatustimestampp1 owneridp1 stockcompletep1 ordernumber vw jobs list p1 nolock customerid custid customerid userid ownerid userid shownotset masterjobstatusid showplaced masterjobstatusid showproofed masterjobstatusid showreproofed masterjobstatusid showapproved masterjobstatusid showontime masterjobstatusid showlate masterjobstatusid showproblem masterjobstatusid showcompleted masterjobstatusid showdispatched masterjobstatusid showunapproved masterjobstatusid showclosed masterjobstatusid showreturned masterjobstatusid shownostock stockcomplete search like filterexpression selectedkeys select top pagesizesk rnsk jobnumbersk custidsk dateinsk dateduesk dateoutsk ordernumbersk masterjobstatusid keys sk sk rn pagenumber pagesize select sk rnj jobnumberj owneridj descriptionj clientsk custidsk ordernumber castdateaddd castisnullsk datein0 datetime nvarchar datein castdateaddd castisnullsk datedue0 datetime nvarchar dateduecastdateaddd castisnullsk dateout0 datetime nvarchar dateout del methodticket invoiceemailed invoiceprinted invoiceexported invoicecomplete jobstatusj masterjobstatusidj masterjobstatustimestampjs masterjobstatusstockcomplete selectedkeys sk join vw jobs list nolock jobnumber sk jobnumber join tbl system masterjobstatus js nolock masterjobstatusid js masterjobstatusid end
4163 system work lot stored procedures sql scripts make use temporary tables using tables good practice drop many colleagues almost much experienced typically truncate table mytemp drop table mytemp typically use single drop table scripts good reason truncate immediately drop
4177 websites books etc recommend improve basic knowledge microsoft business intelligence ssas ssis ssrs please remember im newbie technical bi tool possible would great retrieve material task work would similiar lab task university fullmetalboy
4210 example say table businessbusinessid lattitude longitude indexed course also million records say want find businesses closest example would select business formula compute distance example select business top theory computer compute distance biz practice lattitude longitude within certain range computed want php sql example grateful answer far using mysql anything efficient obvious solution mysql spatial compute distance function either
4214 short data type latitude longitude sql command call get first nearest restaurants example detail 100k biz record lattitude longitude see mysql actually support data type called point use instead mysql support kdtree storage system http en wikipedia org wiki file kdtree animation gif best use point data type rather regular float data type store latitutude longitude eventually want find things like first restaurants closest points example databases contains lot biz points obviously computing distance one one every records every points would hence sucks notice aware simpler solution described application like yelp retrieve distance information data base efficiently implement self start thats good answer however think one creme crop answer outperform right fact storing location based latitude longitude finding stuffs nearest common problem expect mysql special design pattern learn thanks
4215 object table populated integrated service change needed another database certain points need manually add posts another table objectobjectgroup objectid objectgroupid needed object objecttype certain integer value since integration service doesnt handle kind update im thinking adding trigger object table pseudo code would following object objecttype begin object objectnumber like string pattern begin insert objectobjectgroup values end end setup wise better way terms performance
4218 tl dr identify sql server build find implies hotfix also imply hotfixes listed versions installed hotfix build installed found following list microsoft sql server version numbers meaning terms service packs hotfixes product versions etc sql server version database sqlsecurity com question best illustrated example excerpt list rtm q915793 interested rtm q910416 rtm q932557 list find sql server connected version imply hot fix q915793 installed hot fixes q915793 q910416 q932557 installed ie build imply previous hotfixes installed follow bonus question fixed pattern versions exceptions rule
4252 application fires insert query mysql database add records want know whether records get auto committed run rollback command database perform rollback rollback possible commit
4255 pile sql databases around long time varying reasons experienced transaction log autogrowth regular backups keep transaction log usage control files still large fragmented id like reclaim space boost performance reducing number vlfs however id also prefer disrupt scheduled backups dbcc shrinkfile affect transaction log backup chain change add truncateonly command note one time fix im well aware regularly shrinking logfiles bad thing databases configured rational initial sizes autogrowth settings backups run perfectly every day history would issue
4274 ive seen lot people use coalesce function place isnull internet searches ive found coalesce ansi standard advantage know expect using however isnull seems easier read since seems clear also realize isnull kind tricky since acts differently different database servers different languages mind boils style standards given style subjective reason use coalesce isnull vice versa specifically performance advantage one
4283 rebuild indexes relational database sql server case rebuilding indexes regular basis
4286 im middle database server migration cant figure googling searching list database privileges privileges across server postgresql using psql command line tool im ubuntu postgresql version
4291 recently realized need use special syntax null compare literal null null work
4340 http en wikipedia org wiki database engine mentions database engines aka storage engines storage engines used oracle database
4347 two sql agent jobs scheduled run different intervals first job runs full backup day second job runs transaction log backups every fifteen minutes database grown full backup taking longer originally planned even compression ive noticed logs transaction log backups running time change schedule transaction log backup doesnt run full backup running matter
4363 software runtime need check connected user privileges tables across different schemas found research came across views tab privs recd tab privs use one views another better way thanks
4373 sentryone plan explorer work advertised legitimate gotchas something concerned looks like shows hot path color commpared ssmss nightmare view estimated execution plan concerns modify data maliciously otherwise edit heard never heard company
4441 even microsoft discourages use sql server authentication mode applications require ive read best practice let users use sa login directly instead using windows authentication allowing accounts account groups sysadmin privileges isnt essentially thing advantages disadvantages best practice increase security sql server instances apply production instances internal development instances
4475 suggestion bol fairly vague back master often necessary protect data sufficiently business needs recommend regular backup schedule supplement additional backup substantial update venture find details types operations cause master updated require backup take place include following creating deleting user database user database grows automatically accommodate new data master affected adding removing files filegroups adding logins operations related login security database security operations adding user database affect master changing server wide database configuration options creating removing logical backup devices configuring server distributed queries remote procedure calls rpcs adding linked servers remote logins logins added windows groups dont make changes database mean one time backup master sufficient standard backup interval master database
4479 googling around seems mixed reports whether size varchar2 column oracle impacts performance would like give question varchar size little twist hope get insight given multiline free text fields short stuff like names want store oracle database point wrt performance otherwise maxing varchar capacity varchar24000 oracle choosing smaller value likely sufficient cases anyway
4494 seems odd mysql would handle internally deadlock found trying get lock try restarting transaction oracle db work around issue oracle owns innodb
4506 whats best way add columns large production tables sql server r2 according microsofts books online changes specified alter table implemented immediately changes require modifications rows table alter table updates rows alter table acquires schema modify lock table make sure connections reference even metadata table change except online index operations require short sch lock end http msdn microsoft com en us library ms190273 aspx large table millions rows take taking outage option whats best way handle kind situation
4511 would think would fairly simply question ive actually difficult time finding answer question move rows data within partitioned table one partition another simply updating partition column crosses partition boundary example table partition key create table sampletable sampleid int primary key sampleresults varchar100 null partition function maps primary key create partition function mypartitionfunc int range left values move row first partition third partition changing sampleid say note im tagging sql server since support partitioning handle differently
4521 may asking wrong question title facts customer service folk complaining slow response times customer lookups administration interface django based site using postgres started logging slow queries discovered culprit select count auth user upper auth user email text like uppere deyk query taking upwards seconds run heres query plan provided explain query plan aggregate cost rows width seq scan auth user cost rows width filter upperemail text deyk text query generated django orm django queryset generated django admin application dont control query index seems like logical solution tried creating index speed hasnt made difference create index auth user email upper auth user using btree upperemail text wrong speed query
4540 good practice would adverse effects use set columns identify row unique one foriegn key three float data types im attempting build table keys linked would describe unique entry table im curious good plan attack better way visual purposes picture following table inventory items organized like following table symbolic primary key lines relationships sheet class sheet type sheet size sheet class sheet type sheet size sheet class sheet type length width thickness data may present following way brevity ive excluded bringing linked columns sheet class sheet type sheet size tables sheet class sheet type length width thickness column values aluminum h32 t6 steel crs stands ive shown schema use simple auto increment integer primary key entries sheet size table however id like know better use combination sheet type length width thickness columns instead given entry sheet size share unique qualities auto incrementing field wouldnt demonstrate well enough best route take im explaining situation well enough please let know im finding needing break portions class vs type vs actual stock sizes inventoried material logic purposes im kind feedback guidance would appreciated update answers posted ive decided combination marks answer zeros answer decided good idea place unique constraint length width thickness columns also like idea breaking material sizes unique rows linking relationship unfortunately accept answers going accept zeros taking feel critical look problem offering schema adjustment thank everyone answers
4557 ive heard kinds horror stories around gremlins living database triggers worse systems brought addition trigger caused chain cascading ones im considering implementing strict policy use database triggers separation concerns initial thought say database triggers shall used purpose capturing maintaining audit trail anyone similar policies strong arguments policy
4576 developing product part operation must track large number files directories idea store stat information database boot create watches file files change queued database group sync remote database synced order priority number information database entries stat info entire database read boot file path necessary queued files priority field nothing else needs searched insertions slow ive found couple databases think work im sure would best redis store file path key stat data value queue would list mongodb query options redis still fast im thinking nosql database would best solution isnt much relational logic going total data size isnt large something like mb closer mb look sqlite seems simple enough embed installable application since distributed application end users high load server database doesnt support many simultaneous users main priority find database whose model makes sense question database would applicable situation also databases would make sense application like
4603 gone definition http en wikipedia org wiki database engine several times database engine storage engine underlying software component database management system dbms uses create read update delete crud data database understand left isnt crud databases database engine performs functions rest database
4610 know tend avoid cursors loops within sql server every cost situations absolutely need procedural queries set based queries give results understand difference two never come situation need use cursor im wondering situations
4622 think familiar database normalization question guidelines use want denormalize tables
4630 inspired post https twitter com sqlchicken status heaps considered index structure strictly table structure without index
4654 background would like provide subset database required reproduce select query goal make computational workflow reproducible reproducible research question way incorporate select statement script dumps queried data new database database could installed new mysql server statement would work new database new database contain records addition used query update clarification interested csv dump query results need able dump database subset installed another machine query reproducible modifiable respect dataset example example analysis might query subset data requires records multiple example tables select table1 id table1 level table2 name table2 level table1 join table2 table1 id table2 table1 id join table3 table3 id table2 table3 id table3 name fee fi fo fum
4679 lost sa password machine log machine directly using account admin group sql server management studio allow log using windows authentication plan simply log server connect via windows authentication reset sa use new password since cant connect via windows authentication wont work else reset sa password
4693 need confirm understand something correctly recently viewed question user posted answer linq like db table column addminutes1 datetime select unfamiliar linq would expect output statement tested fairness select table dateaddmin column getdate posted reply saying datetime manipulation variable case getdate fact statement reflect something like select table column dateaddmin getdate reply bits im unsure assume following indexes used manipulation column query plans different partly tested assuming 1st query actually perform worse 2nd question missed anything reasoning correct lastly body good articles sargability
4696 im using dapper execute following query sql server r2 express instance asp net mvc net application insert customers type name address contactname contactnumber contactemail supplier values type name address contactname contactnumber contactemail supplier select identity call connection query int sql throwing invalid cast exception ive debugged point dapper calls getvalue returned sqldatareader return type getvalue object inspecting debugger shows boxed decimal change select select cast identity int return getvalue boxed int exception isnt thrown id column definitely type int would select identity return decimal additional information database brand new customers table object ive added user tables views triggers stored procedures database rows database ids column isnt beyond limits int table definition create table dbo customers id int identity11 null type int null name nvarchar null address nvarchar null contactname nvarchar null contactnumber nvarchar null contactemail nvarchar null supplier nvarchar null constraint pk customers primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary
4706 read much sides debate signficant performance gain using stored procedures raw queries specifically interested sql server would interested databases
4717 im using matlab feed database time im getting many connections error always using opendb closedb pair fast feeding wait inserted row connecting host localhost user root password uptime threads questions slow queries opens flush tables open tables queries per second avg current database forwind connection closed current status connections open add row connecting host localhost user root password uptime threads questions slow queries opens flush tables open tables queries per second avg current database forwind connection closed current status connections open add row
4721 consider situation schema names one table table names another table possible something like following pseudo code select value select schema name schemas select table name tables break query three selects
4750 question consists three parts sure database design perfect returning database design change issues adding new column deleting column changing data type add new table etc considered bad practice normal websites books training erd normalization want lot samples practices case studies recommended answers strengthen skill database design avoid poor database designs ive made note dont need books explain concepts need practices examples case studies recommended answers
4760 tried find information blocking sql server could find concise explanation happens could please enlighten
4777 given task migrate postgresql database another server im using pgadmin ubuntu way using backup restore using custom compress format backup utf8 encoding original database utf8 like database favela drop database favela create database favela owner favela encoding utf8 tablespace favela connection limit im creating database exactly like destination server restore database backup file using restore option gives errors pg restore restoring data table arena pg restore archiver db error processing toc pg restore archiver db error toc entry table data arena favela pg restore archiver db copy failed error invalid byte sequence encoding utf8 0xe3a709 hint error also happen byte sequence match encoding expected server controlled client encoding context copy arena line check record triggered error fact vartext fields diacritical characters like used portuguese example ca manually remove text records error passes next record since copy error stops inserting data table dont want replace manually one one accomplish kinda strange utf8 shouldnt kind problems right dont know got first place im migrating database supose somehow database like latin1 improperly changed utf8 way check table database invalid utf8 sequences way enforce reconvert characters uft8 dont run problems execute restore thanks advance
4782 two datetime columns sql server need query without time portion datetime currently query looks something resembling example dates select date startdate union select date dateaddday date dates date enddate select distinct id table cross apply dates date convertdatetime convertvarchar startdate convertdatetime convertvarchar enddate results full clustered index scan surprise surprise trying think ways making faster actual query takes mins thought following havent tried yet ran time earlier use computed column date part index said computed column sure even possible use indexed view sure possible work easiest way would update column remove time information ideas update thanks answers far think point question missed slightly unclear wanted bad aiming optimise date conversion part query amount data im dealing tiny reality cross apply year long date range sorry confusion optimising rest query see people saying using consider following parameters passed date range eg 1st end month start date table appear parameters date range eg end date date range end date table appear parameters date range eg start date date range lastly start end date table parameters date range personally given could never get solution work way could get work properly miss anything using cte saying date startdate enddate hope clears things thanks
4794 want enforce one record table considered default value queries views might access table basically want guarantee query always return exactly one row select id zip postalcodes isdefault true would sql
4810 query non deterministic query following select sumfloat1 float2 coalescefloat31 table run query get deterministic result seems case query run many times last integer result differ different runs columns floatnull float truncation runs
4814 see another question mine generating test data theme right point im still generating test data hand however process always generates small amounts data usually five ten rows since manual process tools automate process particularly id like able generate 1mil rows
4839 im accidental dba still learning see dmv activity monitor process blocking another process done simply kill processes way release maybe preemptively preempt blocking
4859 sql server oracle dense rank functions way something similar mongodb without resort mapreduce words suppose sql select clause like select dense rank overorder somefield desc somerank best way thing mongodb note repost mongodb question im hoping get feedback dbas
4884 dont know oracle heard oracle dbas saying working oracle dba harder difficult demanding working sql server statement basis
4906 trying restore backup sql server express database got following error restore failed server sqlexpress microsoft sqlserver smoextended system data sqlclient sqlerror database backed server running version version incompatible server running version either restore database server supports backup use backup compatible server microsoft sqlserver smo way get backup compatible older case version newer case version sql server express
4936 boot sql server san drives might availiable yet way delay sql server start minute right restart sql server boot server
4965 db ddladmin fixed database role include db datareader db datawriter rights dont grant rights explicitly
4968 general always use ints know theory best practice though since use smallest data type guaranteed store data example better use tinyint know data store null small chance expanding later however reason know storage purposes using byte row instead bytes impacts using tinyint smallint even bigint int saving space hard drive
4984 possible clear tables one request tried following result delete abcdefghijklmno jos bet details jos bet 1x2 jos bet 1x2 best jos bet 1x2 prev jos bet 1x3 jos bet 1x3 best jos bet 1x3 prev jos bet hcp jos bet hcp best jos bet hcp prev jos bet ou kjos bet ou best jos bet ou prev jos bet debug jos bet deleted
5014 read extra data stored per row might see performance degradation risks eg affect recovery database anything else need take advantage plan execute commands alter database databasename set read committed snapshot alter database databasename set allow snapshot isolation believe give us something closer oracle one transaction updating transactions still read old data correct looking sick locking problems sql server hoping might reduce occasional deadlocks users see help overall performance application encourage developers one operation per transaction without fear
5022 collegue want get access one sql server instance ill give rights instance rights add modify server logins add modify maintenanace plans create backups databases schedule agent jobs dont want give sysadmin rights rights given
5038 reading slow sql query sure optimize got thinking general performance queries surely need results first table tables joined small possible joining inner joins question order make queries tiny bit faster example select select table1 col val inner join table2 col col2 better faster select table1 inner join table2 col col2 table1 col val theory follows might correct implementation trying remember sql server internals book read msft press query processor first gets left table table1 joins second table table2 forms cartesian product filtering necessary rows applicable performs order group clauses seelct statement last statement table smaller sql engine less work forming cartesian products reach statement reduced result set filter memory could far mark unreal like said theory thoughts note ive thought question havent chance run tests self yet note tagged sql server dont know anything implementation mysql etc please feel free answer comment anyway
5061 research checking tables records last updated modified deleted lead pseudo column known ora rowscn first select maxora rowscn tablename take note number insert update delete check max value appears increment type change youre wondering cache list entities windows service service runs two load balanced servers theres separate instance running update occurs server server needs know want cache maxora rowscn variable every time application goes insert update delete record get new max database value different obviously knows needs go get new list database actual question snags aware might result insert update deletion record incrementing value edit someone add ora rowscn tag
5071 database architecture allows multiple customers exist database yet split mulitple database administrative reasons patching backup etc question would performance implications consolidated customers single db question current multiple customer db may say database consolidated dbs wed one db customers would make much difference performance
5107 id like know way send notification deadlock queries would required understand sql server takes care deadlocks simply would like information queries involved found following determine long running queries select creation time last execution time total physical reads total logical reads total logical writes execution count total worker time total elapsed time total elapsed time execution count avg elapsed time substringst text qs statement start offset case statement end offset datalengthst text else qs statement end offset end qs statement start offset statement text sys dm exec query stats qs cross apply sys dm exec sql textqs sql handle st total elapsed time min order total elapsed time execution count desc id like know right way go better way determine query takes longer specific interval say min shown thanks
5131 query mysql follows select distinct tablea cola tablea colb tableb cola tablea left join tableb tablea colc tableb cola whereconditions order tablea cola desc tableb cola asc limit executing query takes approximately seconds due size respective tables however query lot faster seconds select tablea cola tablea colb tableb cola tablea left join tableb tablea colc tableb cola whereconditions order tablea cola desc tableb cola asc limit im aware may result non distinct rows im sure situation taken care php code front end actually want compare data two result sets result approximately rows limited anyone think way sql instead via php script ive compared first rows eye without issues know takes one exception 101st row mess everything need query execute times every often see rows one result set
5146 table select items id item position usb cable sd card mouse keyboard monitor sorting table gives result select items order position id item position keyboard usb cable mouse monitor sd card want update table save order position column select items id item position keyboard usb cable mouse monitor sd card done single query manually loop rows manual update case order fully defined usb cable keyboard arbitrarily decided order
5160 table always getting data ordering column case order datenum however selection slow ordering possible order table datenum column defined unique defined index would selection faster
5166 setting cmptlevel sql server inhibits use pivot apply doesnt affect use analytical functions rational behind
5211 increasing column nvarchar width necessarily drop table words width changed production environment active users figured size increasing opposed decreasing wouldnt problem
5222 remember reading one article database design also remember said field properties null dont remember case though seem think application developer wouldnt test null possible nonexistent data value instance empty string strings case dates datetime time sql server youd use historic bottomed date ideas
5233 true rdbms systems optimized commit operations much slower faster rollback operations
5236 im working windows application uses local postgres database stores information temporary table id like look temporary table pgadmin dbvis tell error access temporary tables sessions trying query data tried changing permissions schema table didnt seem help even though im accessing database user program least dbvis setting change database allows root access session database
5278 sql server table contains types results float nvarchar30 datetime separate columns want ensure given row one column result columns null simplest check constraint achieve context trying retrofit ability capture non numeric results existing system adding two new columns table constraint prevent one result per row economical approach necessarily correct one update sorry data type snafu sadly wasnt intending result types indicated interpreted sql server datatypes generic terms fixed
5302 im trying set database mirroring sql server 2008r2 ive taken full backup transactional backup principal database ive restored norecovery however mirror database stuck recovering mode hit start mirroring principal says cant connect wrong edit probably state database rather large mdf file 8gb could edit2 ive also tried firewalls turned know firewall issue edit3 ive run sql mark suggested principal results http piersonthe net principal xls mirror http piersonthe net mirror xls worth noting got following error ran query mirror msg level state line database rhscmssites opened middle restore
5332 testing migration scripts copy production data scripts run fine development data found curious situation constraint changed im issuing drop add commands alter table dup calle drop constraint dup calle uk1 alter table dup calle add constraint dup calle uk1 unique control id calle ayto dupl enable drop command worked fine add one failed im vicious circle drop constraint doesnt exist initial drop worked expected ora drop constraint nonexistent constraint create name already exists ora name already used existing object type dup calle uk1 sql developers search box owner table name tablescape everything matches isnt different object name original constraint table appears constraint details constraint appear tables details questions whats explanation ensure wont happen make real upgrade live server server 10g xe dont enough reputation create tag
5333 lets examine two statements condition condition condition condition condition true condition checked condition false condition checked conditions sql server engine optimize conditions clause programmers place conditions right order sure sql server optimizer resolves right manner added thank jack link surprise sql code select true result else select false result select true result else select false result raise divide zero exception case conclusion vb short circuiting cant sql server truly answer lets take look work conditions vb short circuiting defined language specifications speed code execution bother evaluating conditions first one already true conditions first one already false developers aware sql server works differently cost based system get optimal execution plan query query processor evaluate every condition assign cost costs evaluated whole form threshold must lower defined threshold sql server good plan cost lower defined threshold plan used whole process repeated different mix condition costs cost either scan seek merge join hash join etc short circuiting available vb simply isnt possible might think forcing use index column counts short circuiting doesnt forces use index shortens list possible execution plans system still cost based developer must aware sql server short circuiting like done programming languages theres nothing force
5346 many databases fields defined varchars hasnt much problem since live work america language exists american ahem working databases years ive found eventually run problems limited nature varchar field modify fields store data nvarchars make another update table converting varchar field nvarchar thought still way ive long since made mental decision define new text fields nvarchar instead varchar learned text books school years ago new release sql server last year continue support varchar datatype instead using nvarchar know often argued nvarchars twice large varchars storage space usage could one arguement maitaining varcars however todays users could define nvarchars store data utf instead default utf want save storage space would allow bit encoding primarily desirable giving assurance rare byte character gets inserted db wouldt break anything missing something good reason hasnt changed past years
5365 database tried defragment tables running sql select alter index name reorganize char10 alter index name rebuild sys tables copying pasting output new query window running got errors still fragmentation tried running commands separately still fragmentation note made aware reorganize unnecessary aaron im aware could use dynamic sql automate ran determine still fragmentation select sys dm db index physical stats db id null null null null avg fragmentation percent got database id object id index id partition number index type desc alloc unit type desc index depth index level avg fragmentation percent fragment count avg fragment size pages page count avg page space used percent record count ghost record count version ghost record count min record size bytes max record size bytes avg record size bytes forwarded record count compressed page count clustered index row data null null null null null null null null null clustered index row data null null null null null null null null null clustered index row data null null null null null null null null null clustered index row data null null null null null null null null null clustered index row data null null null null null null null null null nonclustered index row data null null null null null null null null null clustered index row data null null null null null null null null null know missing something real basic dont know
5385 software developer aspiring dba try encorporate best practices design sql server databases time software sits top sql server make best possible design prior development like software developer added functionality bugs change requirements demands altered created database objects question query tuning proactive reactive words weeks heavy code database modification set aside day check query performance tune based even seems running okay aware less average performance database check going back proverbial chalkboard query tuning take lot time depending initial database design could minimal benefit im curious accepted modus operandi
5390 looks like database sharding great huge collections lots fairly sized collections lets say collection documents big comments sharding effective also effective collections documents think question still valid table oriented databases replace collections tables documents rows possible id like know theoretical answer well answer specific mongodb scenario different theoretical answer
5417 id like give hints advise following scenario considering using microsofts sql server r2 express business web application web application wont cruds wont high data traffic simple web forms data scalability web application basically focused employee data like personal information vacancy control daily frequency control ive seen ive estimated maximum simultaneous users generating data traffic also employee table hold maximum records physical limitations think fine since dont think maximum employee generate gb next say ten years since ive read express edition manages gb ram uses cpu thought itd best ask think manage keep good response performance case please advise using sql server r2 express database manager keep mind free aditional info windows server gb ram tb hd
5422 hello thanks taking time read question using mysql want sort results using order one specific column results must ordered according specific criteria column example following table want order group showing first group items end group items names group susanita miguelito mafalda manolito libertad felipe guille thanks advance
5432 understand mutating table errors caused design flaw problematic query old query recently put production throws mutating table error dba solved problem know exactly causes mutating table errors would dba fixed problem
5455 table rows gb table space bytes per row table three columns varchar100 datetime20 smallint average length text varchar field raw data around bytes per row varchar datetime2 bit integer note space data indices im using value reported properties storage general data space course must overhead bytes per row seems like lot especially large table might anyone else seen similar multipliers factors influence amount extra space required comparison tried creating table two int fields rows data space required mb bytes per row compared bytes raw data another test table int varchar100 populated text real table uses bytes per row rows would expect plus little production table considerably overhead larger id expect index sizes roughly logn dont see space required actual data non linear thanks advance pointers edit fields listed null real table clustered pk varchar field datetime2 field order two tests first int clustered pk matters table record ping results fields url ping date time latency milliseconds data constantly appended never updated data deleted periodically cut records per hour per url edit interesting answer suggests index much reading writing rebuilding may beneficial case space consumed concern write performance important one may better flabby indices
5460 long would take upgrade oracle db 1t data 10g 11g usually roughly need estimate time since prod db thanks much
5468 something like directive use script force ssms enable disable sqlcmd mode
5487 read somewhere long time ago book states allow nested view sql server sure reason cant might remember incorrect statement students select studentid first name last name schoolid students create view vw eligible student select students enroll year teachers select teacherid first name last name schoolid teachers create view vw eligible teacher select teachers hascert enroll year schools create view vw eligible school select top percent schoolid school name schools sh join vw eligible student schoolid sh schoolid join vw eligible teacher schoolid schoolid workplace investigated one house database application checked objects found two three layers view stack remind read past one help explaining ok want know limited sql server database design general additional info updated example company change bit general without many technical many columns example mostly nested view used based abstract aggregated view example large student table hundred columns say eligible student view based students enrolls year student eligible view could use places stored procedure
5525 running microsoft sql server profiler every suggests bunch new indexes statistics create estimated improvement understanding every added index make sql select query faster also update insert query slower since indexes adjusted wonder many indexes statistics maybe clear answer rule thumb
5588 using database setup vendors application horrifically hard read database table names documentation stored see one might want obfuscate table structure proprietary app one selling points application enterprise resource planning customizability table names like aptrx accounts payable transactions apmaster curiously vendors table extremely complex database wondering logic convention simply obfuscated intentionally otherwise best knowledge length table name wont affect performance noticeably correct database complex hundreds tables sorting makes sense cant imagine accountspayabletransactions isnt preferable aptrx
5602 following indexed view defined sql server download working schema gist testing purposes create view dbo balances schemabinding select user id currency id sumtransaction amount balance amount count big transaction count dbo transactions group user id currency id go create unique clustered index uq balances user id currency id dbo balances user id currency id go user id currency id transaction amount defined null columns dbo transactions however look view definition management studios object explorer marks balance amount transaction count null able columns view ive taken look several discussions one relevant suggest shuffling functions may help sql server recognize view column always null shuffling possible case though since expressions aggregate functions isnull sum allowed indexed views way help sql server recognize balance amount transaction countare null able concerns columns mistakenly identified null able two concerns could think application objects mapped balances view getting incorrect definition balance limited cases certain optimizations available query optimizer since guarantee view two columns null either concerns big deal concerns keep mind
5634 looking name data manipulation language dml would assume contained statements actually manipulating data far know select statement used query data change taking insert select account select part dml
5666 ive presented dedicated mysql servers never use single core im developer dba mysql need help setup servers quite hefty olap datawarehouse dw type load primary 96gb ram cores single raid array test 32gb ram cores biggest db gb total around 1tb mostly innodb tables solaris intel mysql note biggest db replicated one oltp dr server dw loaded isnt full dw last months weeks smaller oltp db observations test server separate connections concurrent different alter table drop key add index tables million rows cpu usage goes one core maxed higher alters take minutes single smallest takes questions setting patch required allow one core used doesnt mysql use cores available like rdbms consequence replication notes understand difference rdbms thread os thread im asking form parallelism system variables innodb threads sub optimallooking quick win short term im unable change disk layout os tweaked needed single alter table smallest table takes minutes shocking imo edit innodb thread concurrency set yes wrong wont make mysql use multiple cores innodb buffer pool size 80gb primary 10gb test another instance shut ok innodb file per table edit innodb flush log trx commit innodb use sys malloc innodb flush method direct show variables doesnt show innodb doublewrite file system zfs sysadmin found http blogs oracle com realneel entry mysql innodb zfs best practices test innodb flush method isnt showing direct follow rolandomysqldbas settings let know ive missed anything important cheers update changed innodb flush method thread settings rolandomysqldbas answer result core used tests positive result
5744 run explain analyze command given query im difficult time interpreting outputted time value example actual time internal decimals represent repeating characters sorry may noobish question want make sure im interpreting results correctly groupaggregate cost rows width actual time rows loops
5761 working tuning database queries one products decided pop open profiler qa environment see shows saw every insert called call made sp executesql text insert statement seems big hit way turn environment sql server r2 standard windows server r2 enterprise gb ram 2x4 xeon
5774 whenever manually insert row table sql server management studio database sql server new row appears top list rather bottom im using identity columns results things like id row first row second row third row rows fetched explicitly ordered results different appearance rows fetched web app changes top query returns know order happening data inserted web application inserts application result first first ordering latest insert bottom ids row setting server management studio causes improper ordering
5780 benefits table level locking used myisam storage engine row level locking lots benefits like concurrent updates reads lock table edit widely considered table level locking prevents deadlocks prevention deadlocks cost concurrency worthwhile
5815 table create table mytable id serial name varchar10 primary key want add names table exist table already cases return id postgresql seen scripts single sql statement insert return id insert mytable name values jonas returning id works first time returns id fails jonas already exist table want return id even insert fails possible postgresql
5834 must admit question quite broad ill try narrowing bit company developers sql server based installations running customers sites database sizes 100gb concurrent users intranet applications nobody us real good experience running maintaining administrating whatever databases customers even much working ok till cant tell sure everything right didnt hit areas situations arent proficient im looking essential things need know running database dbas point view know hard facts know matters day day job subjects gather deeper knowledge ive heard care face first time im aware question software engineers dbas quite looking also lots books around id like hear practical experience
5859 trying delete duplicates keeping single record shorter id following query deletes duplicates take lot iterations delete copies keeping original ones delete emailtable id select select id emailtable group email countemail mysql edit ddl create table emailtable id mediumint9 null auto increment email varchar200 null default primary key id engine myisam auto increment default charset latin1 edit worked like charm lead dtest delete emailtable exists select select minid minid emailtable group email count minid id
5887 oltp database hosted sql azure instance want pull copy database cloud run heavy extracts olap style queries without impacting source database pull copy database local sql server instance
5903 database ms sql2005 backup whenever try create backup selected database sql mgm studio get error backup full text catalog permitted online database crated detaching another database copying data log files attaching copies new database make full text catalog online also tried set use full text search false without success error
5926 importance ram established fact far less material available importance cores multithreading comes usage cpu mysql talking difference running mysql 4cores vs 6cores vs 8cores different storage engines use cpu differently
5989 remember learning dbms course master information services students save typing type select t1 id t2 stuff sometable t1 inner join othertable t2 t1 id t2 id acceptable stored procedures seems like harm readability statement saving extremely minor amount time functional logical reason seems add ambiguity rather remove acceptable reason see using format adding semantically meaningful alias example sometable idstable table name isnt descriptive enough table aliasing bad practice misuse helpful system
5995 im taking class databases theyre using oracle 10g class im trouble installing database windows auth problems thought id attempt 11g 11g backwards compatible learning able use added 11g features
6031 need restore users connected thought disconnected every process apparently management studio kick everyone else backup
6035 generally bottleneck rdbms mysql user performance disk access ssd provides great performance compared conventional spindle drives question possible improve performance attaching multiple drives reduced space way heads available read data like replacing 2tb 2k rpm drive 500gb 2k rpm drives
6051 suppose following table data create table int int index kk engine memory insert values issuing select order clause mysql sort records default
6108 understand one benefit surrogate artificial keys general change convenient true whether single multiple field long artificial however sometimes seems matter policy auto incrementing integer field primary key table always best idea single field key clear question artificial vs natural whether artificial keys single field
6115 couple questions regarding working indexes postgresql friends table following index friends user id1 user id2 user id1 user id2 foreign keys user table equivalent indexuser id1user id2 indexuser id2user id1 create primary keyuser id1user id2 automatically create indexes indexes first question equivalent index created primary key command
6117 currently scheduled task fires night calls sqlcmd exe passes sql script run backup shown pretty small company growing needs due major growth business side losing days data point would cost tens thousands dollars vs couple hundred time last year migrate db platform different solution data mirroring occurs major redundancy like sql azure best thing get frequent backups script force db offline run script users interacting db use companycrm go backup database companycrm disk crmbackups companycrmcrm bak format medianame companycrm backup name full backup companycrm go update wow obviously much dedicated dba community thanks feedback far thing missing hows shown sql command im using daily backups incremental log backup examples mia large db currently runs sqlexpress say ha sql azure im specifically referring architecture place small business instance currently running server server crashes time recover becomes sticking point sql azure becomes attractive
6122 need exclusive access database possible using sql command detach users postgres database maybe closing connections gaining exclusive access unit testing tests run manually danger involved old dead connections affected users connecting unittest databases old dead connections come developing happens time test written fails exit clean someone also needs keep locked users disconnecting production scenario see scott marlowes answer https dba stackexchange com see also similar question dba drop connections specific database without stopping server
6145 problem really proving tricky one quite annoying sql server management studio days ago intellisense working great sudden stopped icon enabled toolbar menu tools options text editor sql intellisense says enabled tried refeshing intellisense cache ctrl shft doesnt work either ideas happened intellisense need get back
6150 following warning mysqld log warning unsafe statement written binary log using statement format since binlog format statement statement unsafe uses limit clause unsafe set rows included predicted want switch replication format mixed according mysql document switching replication format runtime recommended temporary tables exist temporary tables logged using statement based replication whereas row based replication logged question identify temporary tables exist switch binary log format safely
6158 posted stackoverflow suggested query better suited im trying encourage use monitoring autovacuum postgresql databases one objection hit often people dont trust autovacuum bugs autovacuum mean ignored preference scheduling vacuuming mostly tables small approach appears work however larger also heavily updated tables really doesnt work dead tuple counts increase exceed max fsm pages tables dont get cleaned etc etc im wondering anyone reference autovacuum buggy working experience shown autovac works fine necessary adding entries pg autovacuum table trick id like understand problem autovacuum one exists
6191 tables partitioned several indexes replicated slave copying snap shot verified safe new slave upgrading mysqld restarting replication im getting innodb crashes error message invalid pointer errors happened across servers different hardware running alter table coalesce partion problem goes away table question larger scope though identify innodb table corruption rephrased assess innodb table health check table tool available identify problems pre crash sure matters crashes occurred running version log socket opt mysql sock port percona server gpl release rel21 revision
6197 table roughly rows need modify column definition allow nulls change script perform change would like able run script change occur column definition hasnt already changed test column definition identify column null null
6246 software developer helping team hire mysql dba core challenges facing slower queries performance due hibernate database management backups tuning patches security scalability due increase data new data sources accumulation older data plan start data mining data warehousing future sure direction usually programming cases ask developers build something interview bit hard dba interview fashion give suggestions interview conducted
6252 pretty much databases certain servers require full recovery model dont transaction log backups default always create databases specify simple recovery model quite often certain practical reasons many databases created using ssms however mistakes made operator forget specify simple recovery model leads suprise days later box struggling disk space due three four 60gb log files never truncated make simple recovery model default setting new databases configuring recovery model model database however recommended could come back bite way future
6297 bak file client transferred developer offices problem investigation backup currently 25gb restored database size however needs 100gb restored believe database set 75gb transaction log size restoring database shrink log file way restore
6310 case simple mysql database sql query interface want know database structure queries list tables show tables command see individual column names select statement shows empty set data present thus used
6327 sql server instances installed server table structures data stored procedure deployed stored procedure performs differently takes seconds one instance seconds execute procedure think possible reasons index fragmentation outdated statistics defragmented indexes updated statistics still luck ideas issue thanks
6368 table like id val kind want make select return first row val ordering kind sample output id val kind build query
6383 database job runs night create warehouse table using new database server san gotten process hours minutes optimized run shortest amount time experimentation index nolock force order loop join maxdop im happy improvement hate knowing query takes long im perfectly ok bottlenecks long know query running significant periods time obvious resources underutilized sql server times
6387 got following error message regarding sql query im running program sql server sql heterogeneous queries require ansi nulls ansi warnings options set connection ensures consistent query semantics enable options reissue query severity fixing easy set ansi nulls ansi warnings wanted know heterogeneous query google search brings dozens results telling set ansi nulls ansi warnings nothing explaining term means query update srv db dbo table set column select column srv1 db dbo table im thinking due connecting multiple database engines one query ive never gotten error otherwise heterogeneous refer querying two different database engines context
6395 read document transaction id wraparound something really dont understand document following url http www postgresql org docs static routine vacuuming html vacuum wraparound preventing transaction id wraparound failures postgresqls mvcc transaction semantics depend able compare transaction id xid numbers row version insertion xid greater current transactions xid future visible current transaction since transaction ids limited size bits cluster runs long time billion transactions would suffer transaction id wraparound xid counter wraps around zero sudden transactions past appear future means output become invisible short catastrophic data loss actually data still thats cold comfort get avoid necessary vacuum every table every database least every two billion transactions dont understand statements would suffer transaction id wraparound xid counter wraps around zero sudden transactions past appear future means output become invisible someone explain database suffers transaction id wraparound would transactions past appear future short want know postgresql data loss situation transaction id wraparound autovacuum personal views get current transaction id using txid current function whoes output bit cycled think insertion transaction id tuples knows xmin nerver greater xid get txid current function except use pg resetxlog reset reset transaction id shuting postgresql server right thanks
6417 tables database cached tell sql server cache tables pages flush single table cache flushing cache option im using sql server sql server r2
6468 several tables records uniquely identified several broad business fields past ive used fields pk benefits mind simplicity extraneous fields one index clustering allows fast merge joins range based filters however ive heard case made creating synthetic identity int pk instead enforcing business key separate unique constraint advantage narrow pk makes much smaller secondary indices table indices pk dont see reason favor second approach though large table probably best assume indices may necessary future therefore favor narrow synthetic pk missing considerations incidentally im arguing using synthetic keys data warehouses im interested use single broad pk use narrow pk plus broad uk
6474 two tables 1st table called kimlik id ad ahmet mehmet ali 2nd table called siparis id kimlikid tarih miktar want list via sql query persons doesnt give order result ad tarih ali
6504 trigger insert trigger fails insert fails way let insert proceed even trigger fails edit use trigger send email new record entered want record saved regardless email sent would sp
6507 way execute multiple operations using statement something like select tbl begin open outcursor select select count outcount end want select data count
6512 attempting run maintenance plan receive following error executing query failed following error index partition table reorganized page level locking disabled currently row level locking enabled index enable page level locking unsure repercussions question difference two locking schemes real world production consequences
6526 created database mysql query run query mysql version get run time import database another mysql server hardware run query get 120s sometimes mysql hangs difference tested versions possible query takes longer newer version something like mysql structure change sorry cant put query query like select fl passenger ticket fl aganc name agancname fl pnr remark remark fl pnr reservetime reservetime fl pnr cancelpnr fl flight date fromcity fromcity fl flight date tocity tocity fl flight date flightdate flightdate fl flightdate capacity adultper adultper fl flightdate capacity childper childper fl flightdate capacity infantper infantper fl flightdate capacity cancel cancelsegment fl flightdate capacity tax1adultpric fl flightdate capacity tax1childpric fl flightdate capacity tax1infantpric fl flightdate capacity tax2adultpric fl flightdate capacity tax2childpric fl flightdate capacity tax2infantpric fl flightdate capacity tax3adultpric fl flightdate capacity tax4adultpric fl flightdate capacity tax5adultpric taxxtadultpric fl flightdate capacity tax3childpric fl flightdate capacity tax4childpric fl flightdate capacity tax5childpric taxxtchildpric fl flightdate capacity tax3infantpric fl flightdate capacity tax4infantpric fl flightdate capacity tax5infantpric taxxtinfantpric fl passenger ticket inner join fl pnr fl passenger ticket pnrid fl pnr pnrid inner join fl aganc fl pnr agancid fl aganc agancid left join fl flightdate capacity fl pnr pnrid fl flightdate capacity pnrid left join fl flight date fl flightdate capacity flightdateid fl flight date flightdateid fl passenger ticket ticketnumber fl passenger ticket pnrid fl pnr agancid fl flightdate capacity aganccharterid fl flightdate capacity cancel fl pnr reservetime fl pnr reservetime order fl passenger ticket rowid fl pnr reservetime joins table innodb records result rows columns explain result show variables like innodb result
6539 mysql use composite index lookup condition doesnt include columns forming left prefix mysql use index perform lookups columns form leftmost prefix index quote answer postgresql caught attention somewhat different oracle sometimes also use columns beginning index definition circumstances oracle least 11g lookup without left prefix columns existing query
6577 recently set new virtual machine running windows server slapped copy sql server server running use without hitch two weeks real maintenance weve done move partition database files resided done nearly week ago ran database engine tuning advisor look suggestions new indices yesterday around 12pm 5pm software used usual someone notified program longer seemed work properly checked database data specific use program gone every table fifty tables seemed wiped records talking application developers extensive length became clear wasnt remotely possible capability software scramble get back feet cloned backup vm running copy restarting running five day ever since consequently weve logs events leading problem seen anything like happen records tables database gone anyone reasonable theory could occur anything would reasonable measure prevention
6607 difficulty grab idea pros cons table partitioning start work project would tables one main data table hold million records properly indexed table thinking limiting table records million way would create tables quite sure improve performance sitting machine 32gb ram using mysql tables would myisam big table would index id field complexities like full text search etc please also shed light table partitioning vs database partitioning
6647 according create index documentation columns combined single composite index key weve got table columns need form unique combination table performance sensitive rarely update values insert records need ensure avoid duplicating records thought could impose simple uniqueness constraint ideas im open avoiding unique index constraint entirely better way
6673 future mysql unknown havent time keep known effects oracle mysql since bought sun changes note either oracle mysql community since deal became public
6691 sql server sandbox installation local computer set memory sql server instance use mb running intensive operation memory usage rises mb operation sql server still holding memory free memory reservation
6697 general question sql server tables design currently table 600gb grows 3gb day table appropriate indecies becoming major hangup running queries size question split table multiple tables year month would fit departments split large data sets leverage partitioning built sql server appears using partitioning would require less code changes read partitioning still query one table server handles get data went multiple table route would handle pulling data multiple tables
6698 long running transaction called say t1 performs deletes updates inserts table sql server r2 time another process periodically runs select statements table default isolation settings read committed think t1 blocks select statements running transaction commits rolled back id like see select statements function consistent data even transaction underway believe snapshot isolation help sure im going right direction would best isolation level application secondly dont control process calling select statements control net application calls t1 would isolation level changes required select statements t1 would sufficient mark t1 different isolation level
6713 easiest efficient way design database perspective couple options applications data store design design database best initially writing application code gives advantage base data structure work disadvantage opinion lot changes application specifics affect data changes throughout application development cycle design database application comes fruition need database objects write application develop database parallel chronologically application advantages would less changes database structure see disadvantage would division time development effort application code database development experience find productive efficient method
6731 db scripts need migrated sql server r2 back often scripts created sql server r2 wont run sql server installation customers still use question experience knowledge really necessary setting compatibility level back sql server r2 fix issue unnoticed breaking scripts sql server msdn says compatibility level provides partial backward compatibility earlier versions sql server im unsure thanks would like concrete list features pass compatibility level break sql server link list short list could convert internal dont list save lot work
6736 select convertvarchar10 totalseconds convertvarchar10 totalseconds convertvarchar10 totalseconds seconds select datediff second dateouttime totalseconds attendance attn card register one
6792 story working almost years administrator deal sql server stuff knowledge self taught reading books dealings problems asking reading sites like want circularize certificate going learning try pass microsoft official exams programs start kind curses exams need look pretty confused whit many choices way go one local microsoft certified partner offered courses label microsoft certified professional server administrator equivalent mcsa also offering mscse enterprise administrator need one continue learning sql server administrator need ones correct name ms terminology sql server administrator exist sql server developer calling ms world extension already developers common ms languages
6834 triying create view simplest way like use soccerdb go create view exampledbaseii select id castname varchar namecastcity varchar city team go view keeps link table change table view also changes without creating creating new one possible im working sql server r2 thanxs
6840 key column internal use increasing integer would like second unique column uuid dont know function called default value sql server creating uuid java documentation one could suggest
6859 mysql db server s1 mysql version 3ubuntu12 log created master slave db server s2 mysql version 1ubuntu4 log db s1 using one data file ibdata dumping db s2 set innodb file per table made every table ibd file everything went fine smoothly restarting mysql s2 faced problem getting error error unknown table engine innodb query default database mydb try show engines get following show engines engine support comment transactions xa savepoints myisam default default engine mysql great performance mrg myisam yes collection identical myisam tables blackhole yes dev null storage engine anything write disappears csv yes csv storage engine memory yes hash based stored memory useful temporary tables federated federated mysql storage engine null null null archive yes archive storage engine innodb listed error log see innodb database physically writes file full wait innodb initialize created log files innodb data files corrupt new data files innodb created database started previous innodb time database shut innodb normally error plugin innodb init function returned error error plugin innodb registration storage engine failed warning neither relay log relay log index used replication may break mysql server acts slave hostname changed please use relay log s2 relay bin avoid problem tried delete ib logfiles didnt work well delete ib logfiles ibdata file innodb return back normally cant access innodb tables ie deleting ibdata1 restarting mysql desc article error 42s02 table mydb article doesnt exist innodb configuration cnf follows innodb file per table innodb flush method direct innodb log file size 1g innodb buffer pool size 4g innodb data file path ibdata1 10m autoextend innodb buffer pool size 384m innodb log file size 5m innodb lock wait timeout although table anybody faced issue idea highly appreciated thanks
6880 last week found insert update trigger wasnt working disabled enabled started working yet know stopped working way deal trigger recording value daily jobs used report purposes trigger goes dead days without notice error hot water using oracle 10g access db using sqldeveloper trigger create replace trigger master instance step trg insert update sysidstep idinstance idparent step id master wf instance step referencing old old new new row new sysid declare stepsysid number crcode varchar50 crdate date step id number begin step id new step id select ss sysid stepsysid template wf step ws inner join template step stage ss ss sysid ws stage id ws sysid step id stepsysid insert master fact cr progress values0 new instance idstepsysid new create dt end dbms output enable10000 dbms output put linestart print end
6883 question regarding use indexes start indexing right start performance problem arises also create temporary index executing query pros cons techniques
6900 im updating identity overflow check script account decimal numeric identity columns part check compute size data types range every identity column use calculate percentage range exhausted decimal numeric size range precision created bunch test tables decimal numeric identity columns attempted calculate ranges follows select power10 precision sys columns identity type decimal numeric threw following error msg level state line arithmetic overflow error converting float data type numeric narrowed identity columns type decimal38 maximum precision tried power calculation directly value following queries select power10 select convertfloat power10 select castpower10 float also resulted error sql server try convert output power type float numeric especially float higher precedence dynamically calculate range decimal numeric column possible precisions including course
6912 million rows database already didnt know postgresql uuid data type designed schema one tables 16m rows 5m records per shard growing 500k records per day still luxury taking production system hours required wont luxury one two weeks question worthwhile im wondering join performance disk space use full gzipd dump gib things nature table schema twitter interactions table public twitter interactions column type modifiers interaction id character36 null status text character varying1024 null screen name character varying40 null twitter user id bigint replying screen name character varying40 source character varying240 null tweet id bigint null created timestamp without time zone null indexes twitter interactions pkey primary key btree interaction id twitter interactions tweet id key unique btree tweet id index twitter interactions created btree created index twitter interactions screen name btree screen name triggers insert twitter interactions trigger insert twitter interactions row execute procedure twitter interactions insert trigger number child tables use list
6961 im network windows admin ive tasked overseeing sql server upgrade project need meet dbas discuss needs wants regarding upgrade dont want go totally blind thought would ask guys first moving sql server sql server r2 likely moving windows server r2 possible dba would concerns upgrade anything youd like see happen time
6962 lets say random table column named status real world values would either enabled disabled better columns data type int bool zero use enum values enabled disabled advantages disadvantages lets say instead two valid statuss even advantages disadvantages sway one side number required values increases
6975 big table million records move old records databasetable solution
6996 truncate transaction log sql server database possible best ways tried blog follows setting database simple recovery shrinking file setting full recovery fact losing valuable log data able restore point time also able use subsequent log files shrinking database file database adds fragmentation lot things first start taking proper log backup using following command instead truncating losing frequently backup log testdb disk nc backup testdb bak go remove code shrinking file taking proper log backups log file usually usually special cases excluded grow big
7023 create symmetric key securesymmetrickey algorithm desx encryption password nstrongpassword im trying figure sql server encryption ive executed code way find later password value securesymmetrickey im certificates im admin created create master key encryption password db master key password go know password later create certificate mycertificate subject certificate subject create symmetric key mysymetrickey algorithm triple des encryption certificate mycertificate ok hacker comes computer open symmetric key mysymetrickey decryption certificate mycertificate select convert nvarcharmax decryptbykeynamepass tbl1 protection certificates one asked password like password encryption first question needed know certificate name open symmetric key mysymetrickey decryption certificate mycertificate problem find certificate name protedtion decypher data hacker im using create symmetric key securesymmetrickey algorithm desx encryption password nstrongpassword declare str nvarchar100 set str lala open symmetric key securesymmetrickey decryption password nstrongpassword trying protect data data sent client server data sent plain text cant activate sql commands sending data people access sql server
7031 searching comparison table mysql sql server express comparisons include usage limit tools management dev backup monitoring simultaneous connection company need know install migrating access db opinion suggestions thank
7036 receive statistical data every seconds want store database analyze later example every seconds could receive number oranges sold store last seconds later want retrieve data database use generate charts showing information like number oranges sold store last hours last weeks last months last years dump everything one table seems like would grow quickly especially lots data sources stores thought data could averaged less granular time keep detailed records last couple hours entries db every seconds perhaps averages minute time spans last weeks keep averages day last months etc way large number recent records good number relatively older records old records however data still summed averaged one entry days months instead seconds approach make sense better approach would organize table would multiple tables sql probably mysql good fit would something work better thoughts would greatly appreciated
7038 taking backups databases good practice use logical backup device backup location benefit using backup devices
7044 wondering good solutions recording data nosql database converting rdbms example wanted capture data quickly like session logs want able create reports later favorite database postgres answer relevant postgres would great
7060 dedicated sql server r2 machine experiencing strange memory issues machine plenty resources including two quad core processors 16gb ram 64bit windows server r2 enterprise dell poweredge strange problem system reporting memory use sqlservr exe reporting 155mb use reason suspect sql server issue restart sqlservr exe process memory consumption returns normal period time anyone ideas start track issue thanks jason
7077 creating database records extend prior ad mysql date datetime fields support dates starting way would convenient either using bigint type count seconds using unix timestamp switching database software supports larger date ranges
7080 new databases hope help understand something take part query select mindate date assume dates null effect would would query break
7087 worked oracle many years used execute commit command manually bulk insert sql server auto commit default advantages well hazards want know whether newer versions oracle still auto commit default also want know put auto commit sql server
7093 using sql server express edition noticed recovery model set simple default changed option full want know options enable guarantee full recovery backup way take scheduled backups sql server express databases
7147 note question updated reflect currently using mysql done would like see much easier would switched cte supporting database self referencing table primary key id foreign key parent id field type null key default extra id int11 pri null auto increment parent id int11 yes null name varchar255 yes null notes text yes null given name query top level parent given name query ids associated record name foo context dba planning ask dba implement type hierarchical structure would like test queries motivation described kattge et al example relationships among ids table create new database called testdb set old unique checks unique checks unique checks set old foreign key checks foreign key checks foreign key checks set old sql mode sql mode sql mode traditional create schema exists testdb default character set latin1 collate latin1 swedish ci use testdb table testdb observations create table exists testdb observations id int null parent id int null name varchar45 null primary key id engine innodb set sql mode old sql mode set foreign key checks old foreign key checks set unique checks old unique checks add example data set insert observations values 3null 5null
7156 recently learned 1nf 2nf 3nf understand definitions differences also learned earlier removing relationships conceptual model using bridging entities time aware normal forms cool thing see normalization start one big messy relation normalization steps automatically take care dont consciously think ok bridging away however decided ask hypothetically level normalization specifically responsible removal relationships know 1nf could easily come examples 1nf however simple examples contrived bringing 2nf made go away sure definitive since seem creative coming exhaustive examples pose question 2nf relation exists still needs go 3nf removed 2nf consistently disallow thanks update let try explain better consider simple example table book author isbn title authorid authorname book1 a01 king book1 a02 tolkien book2 a01 king book3 a02 tolkien 1nf pk isbn authorid go 2nf remove partial dependencies isbn title authorid authorname end book author isbn authorid book isbn title author authorid authorname two real entity tables book author plus artificial bridge entity book author got going 2nf however started different manner made er book author relationship id create artificial book author table happened automatically 2nf question always happen 2nf sometimes need get 3nf create bridge however spell question think see huge error asking xnf bridge get created fact matter 1nf example nothing massive bridge going 2nf doesnt create bridge like creates land either side bridge pulling real entities bogus huge table going 2nf higher seems less bridging removing data redundancies course presented first place
7186 sql server parallel data warehouse solution benefit pdw compared normal dw architecture based sql server ssis ssas ssrs
7205 thought solved link work around works patch doesnt working microsoft support resolve http support microsoft com kb ok issue wanted throw stackoverflow see someone idea note sql server r2 issue deleting records table records takes minutes trigger enabled seconds trigger disabled table setup two tables call main secondary secondary contains records items want delete perform delete join secondary table process runs prior delete statement populate secondary table records deleted delete statement delete main id select secondary valueint1 secondary secondary guid 9ffd2c8dd3864ea7b78da22b2ed572d7 table lot columns different nc indexes tried bunch different things determined trigger issue turn page locking turned default gathered stats manually disabled auto gathering statistics verified index health fragmentation dropped clustered index table examined execution plan nothing showing missing indexes cost percent towards actual delete percent join merge records triggers table triggers one insert update delete operations modified code delete trigger return select one see many times fired fires one time entire operation expected alter trigger dbo tr main rd dbo main delete select return recap trigger statement takes minutes complete trigger statement takes seconds complete anyone ideas also note looking change architecture add remove indexes etc solution table center piece major data operations tweak tune indexes page locking etc allow major concurrency operations work without deadlocks execution plan xml names changed protect innocent xml version encoding utf showplanxml xmlns xsi http www w3 org xmlschema instance xmlns xsd http www w3 org xmlschema version build xmlns http schemas microsoft com sqlserver showplan batchsequence batch statements stmtsimple statementcompid statementestrows statementid statementoptmlevel full statementoptmearlyabortreason goodenoughplanfound statementsubtreecost statementtext delete main id select secondary valueint1 secondary secondary settmguid 9ddd2c8dd3864ea7b78da22b2ed572d7 statementtype delete queryhash 0xaea68d887c4092a1 queryplanhash 0x78164f2eef16b857 statementsetoptions ansi nulls true ansi padding true ansi warnings true arithabort false concat null yields null true numeric roundabort false quoted identifier true queryplan cachedplansize compiletime compilecpu compilememory relop avgrowsize estimatecpu estimateio estimaterebinds estimaterewinds estimaterows logicalop delete nodeid parallel false physicalop clustered index delete estimatedtotalsubtreecost outputlist update withunorderedprefetch true dmlrequestsort false object database mydatabase schema dbo table main index ix main indexkind clustered object database mydatabase schema dbo table main index pk main id indexkind nonclustered object database mydatabase schema dbo table main index uk main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered object database mydatabase schema dbo table main index uk main indexkind nonclustered object database mydatabase schema dbo table main index ix main indexkind nonclustered relop avgrowsize estimatecpu 85624e estimateio estimaterebinds estimaterewinds estimaterows logicalop top nodeid parallel false physicalop top estimatedtotalsubtreecost outputlist columnreference column uniq1002 columnreference database mydatabase schema dbo table main column relationshipid outputlist top rowcount true ispercent false withties false topexpression scalaroperator scalarstring const constvalue scalaroperator topexpression relop avgrowsize estimatecpu estimateio estimaterebinds estimaterewinds estimaterows logicalop left semi join nodeid parallel false physicalop merge join estimatedtotalsubtreecost outputlist columnreference column uniq1002 columnreference database mydatabase schema dbo table main column relationshipid outputlist merge manytomany false innersidejoincolumns columnreference database mydatabase schema dbo table secondary column valueint1 innersidejoincolumns outersidejoincolumns columnreference database mydatabase schema dbo table main column id outersidejoincolumns residual scalaroperator scalarstring mydatabase dbo main id mydatabase dbo secondary valueint1 compare compareop eq scalaroperator identifier columnreference database mydatabase schema dbo table main column id identifier scalaroperator scalaroperator identifier columnreference database mydatabase schema dbo table secondary column valueint1 identifier scalaroperator compare scalaroperator residual relop avgrowsize estimatecpu estimateio estimaterebinds estimaterewinds estimaterows logicalop index scan nodeid parallel false physicalop index scan estimatedtotalsubtreecost tablecardinality outputlist columnreference column uniq1002 columnreference database mydatabase schema dbo table main column id columnreference database mydatabase schema dbo table main column relationshipid outputlist indexscan ordered true scandirection forward forcedindex false forceseek false noexpandhint false definedvalues definedvalue columnreference column uniq1002 definedvalue definedvalue columnreference database mydatabase schema dbo table main column id definedvalue definedvalue columnreference database mydatabase schema dbo table main column relationshipid definedvalue definedvalues object database mydatabase schema dbo table main index pk main id indexkind nonclustered indexscan relop relop avgrowsize estimatecpu estimateio estimaterebinds estimaterewinds estimaterows logicalop index seek nodeid parallel false physicalop index seek estimatedtotalsubtreecost tablecardinality outputlist columnreference database mydatabase schema dbo table secondary column valueint1 outputlist indexscan ordered true scandirection forward forcedindex false forceseek false noexpandhint false definedvalues definedvalue columnreference database mydatabase schema dbo table secondary column valueint1 definedvalue definedvalues object database mydatabase schema dbo table secondary index ix secondary indexkind nonclustered seekpredicates seekpredicatenew seekkeys prefix scantype eq rangecolumns columnreference database mydatabase schema dbo table secondary column settmguid rangecolumns rangeexpressions scalaroperator scalarstring 9ddd2c8dd3864ea7b78da22b2ed572d7 const constvalue 9ddd2c8dd3864ea7b78da22b2ed572d7 scalaroperator rangeexpressions prefix seekkeys seekpredicatenew seekpredicates indexscan relop merge relop top relop update relop queryplan stmtsimple statements batch batchsequence showplanxml
7233 purely academic question much isnt causing problem im interested hear explanations behaviour take standard issue itzik ben gan cross join cte tally table use master go set ansi nulls go set quoted identifier go create function dbo tallytable int returns table schemabinding return e1n select union select union select union select union select union select union select union select union select union select rows e2n select e1 e1 rows e4n select e2 e2 rows e8n select e4 e4 rows select top row number order select null e8 go issue query create million row number table select countn dbo tallytable1000000 tt take look parallel execution plan query note actual row count prior gather streams operator gather streams operator row count expected stranger still value consistent vary run run result count always correct issue query forcing non parallel plan select countn dbo tallytable1000000 tt option maxdop time operators show correct actual row counts ive tried 2005sp3 2008r2 far results thoughts might cause
7239 want create view using clauses really cant find references correct syntax want smth like temptbl select create view someview select temptbl correct syntax using several clauses nothing useful msdn
7249 im trying create table management studio reading new sql newsequentialid function thought id give go im letting error message get formtemplate forms table error validating default column formtemplateid missing trick im definitely running sql server r2
7301 ms sql server writing one query conditional sort problem know sort conditional using two columns wrote code like working normaly select table order case pkr kol kol nci nci end know make conditional ordering two columns select table order case pkr kol nci kolnci kol mpci kolmpci end idea make dynamic tsql use sp executesql still looking better idea
7339 one report making query users suppose choice top values based percents fix amount rows two ideas calling two different sub stored procedure based passed param param percent begin exec sp data top percent end param perrow begin exec sp data top perrow end idea make dynamic tsql query something like declare command ncharmax select command select top10 case param percent percent else end table order exec sp executesql command third solution something like better approach first one avoiding dynamic tsql harder maintain code two places using mssql2005 databse
7350 sql statement inserts rows table clustered index column tracking number insert tabl name tracking number colb colc select tracking number col col staging table question help use order clause select statement clustered index column would gain acheived negated extra sort required order clause
7359 weve data loss dont reliable backup seems huge transaction logs thought might able use get back certain point possible help rebuild database using transaction logs sql server r2 btw posted stackoverflow
7390 design database going run postgresql used magnificent tool called mysql workbench mysql database useful looks good kind expect database designing software learn new database designing tool want popular one therefore question popular tools designing database postgresql
7429 im designing application considering options regarding database system since im familiar microsoft sql server would like know possible servers sharing files shown idea data raid system would grant us safety way would save effort synchronizing databases save money storage need one database time secondary use case failure first possible im open different approaches main problem database redundancy application must guarantee moment im using windows sql server 2008r2
7468 title pretty much sums running space backup disks need remove old backups set cant seem find information
7504 written ssis package load test data empty database tables large million rows ssis package completed commands run apprentice dba maximize performance database instance executed exec sp updatestats reported indexes required updating list things large amounts data loaded sql server take care
7515 office query pretty ugly runs pretty well production development environment 20sec 4sec respectively however testing environment takes 4hrs sql2005 latest patches running production development sql2008r2 running testing took look query plan shows sql2008r2 using tempdb way table spool lazy spool store returned rows linked server next step showing nested loops left anti semi join eating query line two operators 5398mb query plan sql shows use tempdb use left anti semi join sanitized code execution plans plan top 2008r2 bottom causing drastic slow change expecting see different execution plan doesnt bother dramatic slow query time troubles look underlying hardware since 2008r2 version using tempdb take look optimize usage better way write query thanks help insert table1 grouplock igroupid dlockeddate select table1 igroupid getdate table1 exists select linkedserver database table2 alias2 alias2 firstname alias2 lastname dbo fnremovenonlettertable1 fullname dbo fnremovenonlettertable1 fullname null alias2 firstname null alias2 lastname null alias2 familyname dbo fnremovenonlettertable1 familyname alias2 child1name dbo fnremovenonlettertable1 child1name dbo fnremovenonlettertable1 familyname null dbo fnremovenonlettertable1 child1name null alias2 familyname null alias2 child1name null alias2 stepfamilyname dbo fnremovenonlettertable1 stepfamilyname alias2 stepfamilynamechild1 dbo fnremovenonlettertable1 stepfamilynamechild2 alias2 stepfamilyname null alias2 stepfamilynamechild1 null dbo fnremovenonlettertable1 stepfamilyname null dbo fnremovenonlettertable1 stepfamilynamechild2 null exists select table3 inner join table4 table4 firstnametype table3 firstnametype inner join table5 table5 lastnametype table3 lastnametype table3 igroupid table1 igroupid table3 bisclosed table4 snametypeconstant new lastname table5 sfirstnameconstant new firstname edit executed query different sql2005 instance pretty much execution plan good one still sure two versions running better 2008r2 linked server 2008r2 instances 2008r2 instances dont deny code could use work code problem wouldnt see sameish exec plans across trials regardless sql version edit applied sp1 cu3 2008r2 instances still dice specifically set collocation linked server dice specifically set permissions user acct sysadmin instances dice also remembered sql server internals troubleshooting well see track thanks everyone help tips edit done various permission changes linked server ive used sql logins domain logins impersonated users used made using security context option created users sides linked server sysadmin rights server ideas would still like know sql2005 executing query dramatically different sql2008r2 query bad would seeing hrs run time sql2005 sql2008r2
7573 working project unsure difference way find cursor works way findone cursor works findone wrapper find limit1 looking around maybe someone knows mongodb special method working php api mongodb makes difference
7600 memory olap engines advantages traditional olap engines backed enough ram contain entire cubes example use molap engine ssas gb tb ram entire cube even star schema ram resident difference compared something like tm1 sap hana
7603 im searching way create query following lets consider tables products list products tags list tags tag ties table used associate tag product lets consider structure table products id int autoincrement name varchar name product tags id int autoincrement label varchar label tag tag ties id int autoincrement tag id int reference tag id ref id int reference product id want obtain products tagged tags id example query work returns products least one tags select name name id id products inner join tag ties ties id ties ref id ties ref id id ties tag id group id order name asc
7622 going storing application level events user added thing user updated etc public private consumption oversimplified model tables associations users id pk event type id pk description events id pk user id fk event type id fk created timestamp events reported timeline format newest events top user id also like add custom uri parameters events context user updated visa card overlooking potential pitfalls design
7647 view selects information information schema columns seems give columns views easy way tell rows columns views comparison information schema views need columns views want able tell
7652 im programmer dba gentle overview innodb mysql mod perl script persistent connections script called every seconds thousands users problem high disk io presumably caused updates slows everything creating huge bottleneck queries update single table set refreshtime current timestamp two table checks clause select count four table join indexes bunch ands clause still pretty simple select ab four table join four tables bunch ands clause also pretty simple query cache solutions im dba suspect possible table ram periodically every seconds updates onto disk event catastrophic failure automatically populate ram table disk table upon restart idea actually possible best solution options thoughts suggestions im programmer someone either knows someone fee point specific resources id appreciative create table openinvitations id int99 null auto increment createtime timestamp null default null repaccepttime timestamp null default null rep id varchar64 null default reprefreshtime timestamp null default null customer macaddr varchar14 null default customerrefreshtime timestamp null default null stage char1 null default parent varchar25 default null reason varchar64 default null primary key rep idcustomer macaddr unique key id id key customer macaddr customer macaddr constraint openinvitations ibfk foreign key rep id references rep id constraint openinvitations ibfk foreign key customer macaddr references customer macaddr engine innodb auto increment default charset latin1 id select type table type possible keys key key len ref rows extra simple oi ref primarycustomer macaddr customer macaddr const using using index simple eq ref primaryfk rep primary xxx oi rep id using simple eq ref primaryfk subscriber primary xxx subscriber id using simple eq ref primary primary xxx charge id using id select type table type possible keys key key len ref rows extra simple oi ref primarycustomer macaddr customer macaddr const using simple eq ref primaryfk rep primary xxx oi rep id using simple eq ref primaryfk subscriber primary xxx subscriber id using simple eq ref primary primary xxx charge id using id select type table type possible keys key key len ref rows extra simple openinvitations customer macaddr null null null using fixing query id select type table type possible keys key key len ref rows extra simple openinvitations ref customer macaddr customer macaddr const using
7660 checking sql server log see several entries like date source logon message login failed user sa reason password match login provided client date source logon message error severity state date source logon message login failed user sa reason password match login provided client date source logon message error severity state possible attack sql server chinese looked ip address ip lookup net stated chinese block ip adress firewall delete user sa protect web server best thanks advance
7689 understand index fragmentation possible cases found databases non clustered example alter table dbo claimlineinstitutional add constraint pk claimlineinsitutional primary key nonclustered claimlineinstitutionalid asc pad index statistics norecompute sort tempdb ignore dup key online allow row locks allow page locks fillfactor primary update querying dm db index physical stats avg fragmentation percent believe physical fragmentation seeing
7741 creating test database another question asked earlier remembered primary key able declared nonclustered would use nonclustered primary key opposed clustered primary key thanks advance
7742 like said comment im dba im still learning process heres scenario oracle server running couple schemas let call source would like send copy every objects another oracle server lets call target theres already objects need preserve ideally dont want shutdown source server also need keep already existing schemas target server new objects source need co exist target server already existing objects maybe using instances could accomplish dont know im suggesting could solutions achieve
7753 ive run problem production sql server temp table objects take long time drop obvious small synchronous drop used cant reproduce sql servers similarly specd numbers spindles serving tempdb data files split number files per physical core sql enterprise sp2 update one factor looking likely server databases another server also runs drops slow thats server ive got lot dbs second update restart problem servers allow create drop statements execute instantaneously performance test degrades next hours application running hits appears plateau ive got job running background testing every mins ill see results days see execution times think third update none executing statements shown latch waits cpu resources using sp whoisactive see delta interval seconds run running query cpu delta reports roughly milliseconds watch perf execution appears one core worth cpu spike execution time cpu boxes bit tough see via perfmon traffic occurring appears spiking cpu worth execution drop statements create destruction tiny temp tables unique names one column rows takes less 20ms servers test one server takes seconds vast majority time spent drop statements execution explicit waits blocking reported perfmon doesnt show load subsystem either data log files ive looked peak low usage times high number tables marked destruction low operation takes seconds handle drop statements matter issue causing perceivable clients slowdown responsiveness sample code created like objects get second timing appears 300ms per drop print convertvarchar30getdate113 create table objects1 id uniqueidentifier null create table objects12 id uniqueidentifier null drop table objects1 drop table objects12 print convertvarchar30getdate113 timing consistently seconds execute nov begin temp table creation nov end temp table creation nov begin temp table drop nov complete temp table drop could also run use tempdb dbcc loginfo record number rows returned please add output scripts original question noticed originally vlogs shrank regrew see fragmentation problem made difference current dbcc loginfo fileidfilesizestartoffsetfseqnostatusparitycreatelsn io stats output database namephysical nameio stall read msnum readsavg read stall msio stall write msnum writesavg write stall msio stallstotal ioavg io stall ms msdbh microsoft sql server mssql mssql data msdbdata mdf4769156581732958 tempdbh microsoft sql server mssql mssql data templog ldf54457301771 modelh microsoft sql server mssql mssql data modellog ldf5471224 tempdbp tempdb data3 mdf260606611120432 tempdbp tempdb data2 mdf248479311118082 tempdbp tempdb data5 mdf251446911120862 tempdbp tempdb data7 mdf254207011125512 tempdbp tempdb data6 mdf251776711122372 tempdbp tempdb data0 mdf247681111135702 tempdbp tempdb data4 mdf246217911116492 tempdbp tempdb data1 mdf245631711118592 modelh microsoft sql server mssql mssql data model mdf51947986 masterh microsoft sql server mssql mssql data master mdf4064073265 msdbh microsoft sql server mssql mssql data msdblog ldf80159508 masterh microsoft sql server mssql mssql data mastlog ldf6401414 waitstats output wait typewait time spctrunning pct pageiolatch ex0 tokenandpermuserstore size 2952kb select sumsingle pages kb multi pages kb securitytokencachesizekb sys dm os memory clerks name tokenandpermuserstore
7754 maximum number cores used single mysql server production setting
7773 going rebuild one ibm server scratch server dedicated sql server instance running windows r2 going make new raid configuration scsi gb drives inside machine ibm serverraid 8k controler would good way set raid levels two three one field controler considering make one following solutions use disk make raid pool use disks raid 1e pool use store database data os use disks raid pool use store database logs combination larger stripe unit size better server subscriber replicated database primary task going reporting data retrieval replication agent making writes size database around gb
7785 im trying run mysqldump create database snapshot im finding randomly stop midway without reporting error database relatively small 100mb using innodb im running like mysqldump force single transaction quick user myuser password mypass mydatabasehost mydb tmp snapshot sql checking exit code reports version mysqldump ver distrib redhat linux gnu i386 ive seen similar posts even official bug report neither solutions seem apply get mysqldump take complete database snapshot edit database currently resides amazons rds
7906 running script try find extraneous indexes select name tablename name indexname reserved page count spaceinmb sys dm db index usage stats inner join sys objects object id object id inner join sys indexes index id index id object id object id inner join sys dm db partition stats index id index id object id object id name tablename know last user seek scan lookup null users used index since last restart wondering system scans lookups seeks certain table found user activity one system activity days ago anyone insight system scans seeks lookups might tables seem really indexed like trim fat
7924 situation deploy instances applications one mysql database using table prefixing use different mysql databases instance application setup central database app1 table1 app1 table2 app1 tablen appn table1 appn table2 appn tablen end result large db many tables setup app1 db table1 table2 tablen appn db table1 table2 tablen end result many databases tables things equal amount data number app instances etc pros cons going either approach would detrimental database performance maintenance application php based run apache running mysql many thanks time thoughts
7927 really weird problem create new db script im getting extra tables added arent system type tables regular tables look like may come past project columns either ints nchar10 keys constraints triggers indices idea coming fix right delete tables bit annoying id like fix issue script wrote reproduces error create database go use go create table yid int identity constraint pk yid primary keyyid go create table zid int identity constraint pk zid primary keyzid go run script db created tables instead running select information schema tables lists extra tables base table exactly ones defined columns well happening sql server r2 microsoft sql server management studio
7956 case db im checking archive table keeps user history trigger store procedure time delete rows table order avoid oversize didnt design db im taking maintenance application use db dont know name stored procedures triggers want locate stored procedure trigger check code modify leave user history longer table someone told check sysobjects table actually see something name table information able retrieve advise thank
7983 recently saw question statement sql construct used often constructing dynamic sql effort write cleaner code perspective host language generally speaking addition sql statment negatively affect query performance im looking answer regard specific database system used db2 sql server ms access mysql unless impossible answer without getting specifics
7985 security reasons need server side running debian squeeze logging queries may changed content mysql db user issued rule general query log performance issues logs everything thats much io binary log doesnt log users name use tool like ngrep catch network traffic filter update delete etc get mess transactions cant know received query really executed couldnt find settings would let change behavior mysql inherent logs im looking solutions ive come two possibilities far write general query log named pipe attaching filter writer end pipe im concerned performance transmitting relevant logs separately server way id send queries twice db logging would difficult assure logs sync db transactions locks etc security reasons may wise trust client really send logs backgound users access db via java desktop application opens ssh tunnel mysql server im using eclipselink persistence provider application makes heavy use transactions server running shared environment better idea perform logging
7994 gb text file format etc need insert line table field create table dbo table field1 varchar null field2 varchar null efficient way inserting data premade program used done command line externally ive created script select records create sql query around insert takes better way better easier faster less overhead note ive tried 1m batch sizes query long sizes stuck 1k query used insert table field1 field2 select union select union select etc
8011 ive got innodb error mysql mysqld stopped cleanly managed lose ib logfile0 ib logfile1 afterward clean startup innodb done crash recovery went innodb force recovery business repaired hung myisam table replication ready go apart big numbers commified innodb error page log sequence number innodb future current system log sequence number innodb database may corrupt may copied innodb innodb tablespace innodb log files see innodb http dev mysql com doc refman en forcing recovery html innodb information slave server error spews hundreds found answer insert delete gb worth data log sequence number becomes inflated big enough http forums mysql com read php225016350163 msg magic number 64gb comes 4gb guys innodb log major number needed increase mines going gb take days ill keep working speeding script running parallel speed meantime im hoping someone else better answer silly
8028 making project need change around 36k records one table daily im wondering perform better delete rows insert new ones update already existing rows easier delete rows insert new ones going fragment table indexes impact performance would prefer make updates possible delete insert necessary going nightly service looking improve speed process concerned performance queries table general already million records nightly process affect delete insert records update existing ones possible nightly process
8033 im investigating column oriented databases came across vertica need feed vertica database code dont succeed grabbing information vertica im told use vsql copy command want issue insert statements vertica database done instance postgresql embedded sql linking postgres ecpg library binary idea thing exists vertica know way ideas
8111 installed postgresql pc win small java application connecting successfully login sa password connection works however refused pgadmin iii get error connecting server fe sendauth password supplied connect database pgadmin iii empty password edit test production code
8116 would like monitor many queries utilizing indexes program show live query performance index utilization note already aware slow log file usage
8119 coming mysql background stored procedure performance older article usability questionable evaluating postgresql new product company one things would like move application logic stored procedures im asking dos donts best practices using functions postgresql specifically regarding performance pitfalls
8128 starting design new data warehouse trying design date time dimensions work need able support multiple timezones probably least gmt ist pst est initially thinking would one wide combined date time dimension maybe minute granularity way one key fact tables different date time data supported timezones one dimension table date key gmt date gmt time ist date ist time etc kimball suggests separate day dimension time day dimension prevent table growing large data warehouse toolkit sounds fine however would mean two keys fact tables time zone need support one date one time day im inexperienced area im hoping someone knows tradeoffs two approaches performance vs management different time zone keys maybe approaches ive seen people talking separate row fact table per timezone seems like problem fact tables millions rows need quadruple add time zones minute grain well rows per year date time dimension table doesnt sound horrid performance wont know sure till test prototype queries concern separate time zone keys fact table query join dimension table different column based desired timezone perhaps something ssas takes care im sure thanks thoughts matt
8172 write sql read xml file postgresql xml value postgresql native xml data type xmlparse function parse text string type also ways read data filesystem copy statement among others dont see way write native postgresql sql statements read content filesystem entry use populate xml value
8182 graduate good knowledge sql done sql programming microsoft sql server academics want become oracle dba could please suggest structural way start learning also please suggest background work needed digging thanks
8351 running deadlock scenario participants deadlock appear single table single stored procedure deletes table drew conclusion based analysis sql error log time several deadlocks using msdn article guideline decipher trace error log table dextable stored procedure cleardextablerows defined another stored procedure insertdextablerow inserts rows dextable proc seem involved deadlock based entries sql error log dextable million rows tends grow steadily respondent table also large tends grow steadily accessed high traffic volume website pages frequently call cleardextablerows insertdextablerow quick succession deadlock occurred times per day past days ive enabled sql trace using dbcc traceon recently enabled flag theres good description output flags detecting ending deadlocks questions make sense one stored procedure cleardextablerows cause deadlock anyone offer good explanation happen recommend way fix suspicion delete statements causing contention pk dextable needs rebuilt frequently additional trace enable dig deeper cause deadlock want learn table definition create table dbo dextable exportid int null respondentid int null exported datetime null constraint pk dextable primary key clustered exportid asc respondentid asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary go alter table dbo dextable check add constraint fk dextable exports foreign key exportid references dbo exports exportid delete cascade go alter table dbo dextable check constraint fk dextable exports go alter table dbo dextable check add constraint fk dextable respondents foreign key respondentid references dbo respondents respondentid go alter table dbo dextable check constraint fk dextable respondents go alter table dbo dextable add default getdate exported go cleardextablerows clear respondents export records trigger export create procedure dbo cleardextablerows respondentid int delete dextable rowlock respondentid respondentid go insertdextablerow insert record noting export run particular respondent create procedure dbo insertdextablerow exportid int respondentid int exists select respondentid dextable exportid exportid respondentid respondentid begin insert dextable exportid respondentid exported values exportid respondentid getdate end else begin update dextable set exported getdate exportid exportid respondentid respondentid end go log entries im entirely sure whats helpful sql error log one recent deadlocks recent entries log top go back time read 58spid18sunknownthis instance sql server using process id since pm local utc informational message user action required 59spid20sunknownwaiter id process86a6478 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processac352e9b8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lockd32579f80 mode associatedobjectid 59spid20sunknownwaiter id process47eda8 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processac352e9b8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lockc48e52780 mode associatedobjectid 59spid20sunknownwaiter id processce50ce088 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processac352e9b8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id locka6ad4e580 mode associatedobjectid 59spid20sunknownwaiter id process8691198 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processcd7b1b048 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock95f600780 mode associatedobjectid 59spid20sunknownwaiter id process478da8 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processcd7b1b048 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock955c98200 mode associatedobjectid 59spid20sunknownwaiter id process700328 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processcd7b1b048 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock83fd3b200 mode associatedobjectid 59spid20sunknownwaiter id processffaef8 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processac352e9b8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock77b633580 mode associatedobjectid 59spid20sunknownwaiter id process86a6ef8 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processcd7b1b048 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lockdc536d580 mode associatedobjectid 59spid20sunknownwaiter event waitpipegetrow type consumer id processcd7b1b048 59spid20sunknownwaiter list 59spid20sunknownowner event waitnone type producer id process717198 59spid20sunknownowner event waitnone type producer id processffaef8 59spid20sunknownowner event waitnone type producer id process86a6478 59spid20sunknownowner event waitnone type producer id processdc28aeef8 59spid20sunknownowner event waitnone type producer id processce50ce088 59spid20sunknownowner event waitnone type producer id process47eda8 59spid20sunknownowner list 59spid20sunknownexchangeevent id port80314690 nodeid 59spid20sunknownwaiter id process717198 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processac352e9b8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock68f374980 mode associatedobjectid 59spid20sunknownwaiter id process716c58 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processcd7b1b048 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock60e8d8a80 mode associatedobjectid 59spid20sunknownwaiter id process47f198 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processdc28aeef8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lockb7c7f1c00 mode associatedobjectid 59spid20sunknownwaiter id processdc28aeef8 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processac352e9b8 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock7797b6500 mode associatedobjectid 59spid20sunknownwaiter event waitpipegetrow type consumer id processac352e9b8 59spid20sunknownwaiter list 59spid20sunknownowner event waitnone type producer id process6d5c18 59spid20sunknownowner event waitnone type producer id process716c58 59spid20sunknownowner event waitnone type producer id process478da8 59spid20sunknownowner event waitnone type producer id process8691198 59spid20sunknownowner event waitnone type producer id process86a6ef8 59spid20sunknownowner event waitnone type producer id process700328 59spid20sunknownowner event waitnone type producer id process47f198 59spid20sunknownowner list 59spid20sunknownexchangeevent id port80315870 nodeid 59spid20sunknownwaiter id process6d5c18 mode requesttype wait 59spid20sunknownwaiter list 59spid20sunknownowner id processcd7b1b048 mode 59spid20sunknownowner list 59spid20sunknownkeylock hobtid dbid objectname myserver database dbo dextable indexname pk dextable id lock46a62fe00 mode associatedobjectid 59spid20sunknownresource list 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id processdc28aeef8 taskpriority logused waitresource key d600a7d4a467 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0xce4278410 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id processce50ce088 taskpriority logused waitresource key d1007416f809 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x946b46d30 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknownproc database id object id 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id processcd7b1b048 taskpriority logused waittime schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid loginname iis apppool myserver database isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknownproc database id object id 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id processac352e9b8 taskpriority logused waittime schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid loginname iis apppool myserver database isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process86a6ef8 taskpriority logused waitresource key ab0001e10f4e waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0xdb9b53cc0 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process86a6478 taskpriority logused waitresource key 7500c3691103 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0xdb9b53a80 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process8691198 taskpriority logused waitresource key d20082032104 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0xabdc20870 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id processffaef8 taskpriority logused waitresource key f900d9903a2a waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0xd9f26e080 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process717198 taskpriority logused waitresource key 4700497f7879 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x8006dcc0 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process716c58 taskpriority logused waitresource key 5a00f098709d waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x6c020d880 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process700328 taskpriority logused waitresource key 51003376bf57 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x92beba3d0 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process6d5c18 taskpriority logused waitresource key 150048fb6c35 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0xdbadb2560 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process47f198 taskpriority logused waitresource key 4700c2a10b35 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x6c2da4080 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process47eda8 taskpriority logused waitresource key 2a004ee465b9 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x6c2da4870 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknowninputbuf 59spid20sunknownwhere respondentid respondentid 59spid20sunknowndelete dextable rowlock 59spid20sunknownframe procname myserver database dbo cleardextablerows line stmtstart sqlhandle 0x03000500f958193991f66b01a29e00000100000000000000 59spid20sunknownexecutionstack 59spid20sunknownprocess id process478da8 taskpriority logused waitresource key 1400c876e809 waittime ownerid transactionname delete lasttranstarted 16t20 xdes 0x857272d30 lockmode schedulerid kpid status suspended spid sbid ecid priority transcount lastbatchstarted 16t20 lastbatchcompleted 16t20 clientapp net sqlclient data provider hostname db13 hostpid isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 59spid20sunknownprocess list 59spid20sunknowndeadlock victim processdc28aeef8 59spid20sunknowndeadlock list 12spid83unknowndbcc traceon server process id spid informational message user action required
8374 would like input sql server 2008r2 ent ed 64bit cores 64gb ram one instance sql server patched fully max ram set 60000mb amount free ram according task manager days online change max ram 53gb days stabilize free ram sql process allocate ram according task manager come terms problem really goes without saying alot testing already havnt solved liking yet ohh get typical memory starvation lagging available ram free update inspired another related ram page https dba stackexchange com used two see ram used select top type memory clerk type sumsingle pages kb spa mem kb sys dm os memory clerks group type order sumsingle pages kb desc option recompile select db namedatabase id database name count cached size mb sys dm os buffer descriptors database id system databases database id resourcedb group db namedatabase id order cached size mb desc option recompile amount used shown first select kb second one mb total 52gb used sql server rest ram go task manager show right cached available free sqlservr exe memory private set max ram set 60000mb
8379 im testing transactional replication databases one machinevirtual otheralso virtual none virtual machines running anti virus working expected unless try insert blob considerable size 65mb case insert blob 3kb works fine im following error distribution agent failed create temporary files program files microsoft sql server com directory system returned errorcode problem documented already changed settings folder read anymore right click folder properties changed read attribute im sure right way grant permissions reason say anti virus running also read one source problem antivirus might block folder inspecting also tried change distribution profile oledb streaming also didnt work else solve problem
8456 want create role named cp defined privileges create roles granted cp role know oracle job examle grant resources user name means grant resources role user follwing test postgresql work body know create role cp grant privilege postgres create role cp login nosuperuser nocreatedb nocreaterole noinherit encrypted password cp create role postgres grant connect database skytf cp grant postgres skytf skytf connected database skytf user skytf skytf grant usage schema skytf cp grant skytf grant select skytf test cp grant create role cp grant cp role privilege cp skytf postgres postgres connected database postgres user postgres postgres create role cp login nosuperuser nocreatedb nocreaterole noinherit encrypted password cp create role skytf grant cp cp grant role test cp skytf skytf cp connected database skytf user cp skytf select skytf test limit error permission denied schema skytf line select skytf test limit
8461 open source metadata management solution id like create metadata repository hold details metadata database schemas tables data items hundreds enterprise databases im especially interested something automatically query schema data databases able track changes metadata related tables changes column data sizes tables columns added etc
8492 ado net documentation shows possibility setting transaction level sql transaction chaos sounds unpleasant feature presumably legitimate use set transaction isolation level command bol ah see use google bol nothing seems named chaos ado net modes match nicely documented levels addition chaos chaos level unfriendly name refs ado net enum
8496 designing sql server data schema subsequent queries sprocs views etc notion clustered index order data disk make sense consider db designs made explicitly deployed ssd platforms http msdn microsoft com en us library aa933131v sql aspx clustered index determines physical order data table physical disk platform design consider makes sense physical scan data retrieve sequential rows performant seek table ssd platform data read access uses identical seek concept physical order data reads sequential sense bits stored piece silicon process designining application database clustered index consideration relevant platform initial thought idea ordered data doesnt apply ssds storage seek retreival optimization edit know sql server create one im philosophizing whether makes sense think design optimization
8504 null value column order value ascending nulls sorted first select test union select union select null union select union select order test results null keep thinking null meant indeterminant possible unknown thats true wouldnt sort last since value could greater values sorting option somewhere im sql server 2008r2 suspect true across sql servers probably across rdbmss
8511 asked question stackoverflow wondered done correct best practise basically every object create going schema schema name reflecting usage example schemas audit admin amongst others turn leaves objects dbo ok anything else need
8514 options occurred one big delete statement example delete chunk smaller pieces 10k time create stored procedure im sending two query values
8533 rather short question using microsoft sql server version newer security related reasons prefer windows authentication sql server authentication point im interested security related concerns administrative differences two update difference leads security concern im surely interested
8580 configured ssl postgresql conf installed certificate etcetera ensure clients always connect ssl ssl make impossible connect without ssl encryption ways ensure clients always connect ssl tls kind regards kajmagnus
8599 way configure sql server limit number rows update statement modify say wanted limit rows someone fired update would modify rows would receive error preventive message
8618 using ms sql server table database records inserted deleted initially table empty java program probably inserts records another java program quickly access table deletes records records inserted manually run select query table basically see initial final state table table empty need know way see records least check something inserted deleted help appreciated
8627 read use isolationlevel readuncommitted query issue locks however tested saw following lock resource type hobt request mode shared hobt lock something related hbt heap binary tree lock would still get lock avoid shared locking querying without turning isolation level snapshot option testing sqlserver snapshot option set query performs select see sch required although sql server seems showing lock query come still issues shared lock according set transaction isolation level transact sql transactions running read uncommitted level issue shared locks prevent transactions modifying data read current transaction little confused
8680 new database administration face lot problems setting mysql master slave replication also face regular mysql replication troubleshooting issues anybody helps understand deal
8700 know common recommendation data volume sql server use kb blocks stripes since typically done entire extents cant find good information regarding log file however ive watching activity process monitor little appears log file sizes range bytes kb im guessing dependent size transaction logged large ones get split using multiple kb writes assuming partition aligned raid stripes would safe assume kb blocks stripes yield best performance things equal would expect smaller transactions ones byte writes arent coming heavily enough large block size penalty significant impact whereas much larger transactions writing lots kb blocks rapid succession would important tune
8708 learned client company work decided keep auto update statistics options sql servers dbas manually troubleshooting performance issues arise however kind make sense would want prevent statistics updated
8747 well learning dbms subject got many questions mind normalization one learnt lot confusion found whatever normalization process general common sense also even making projects also people used follow really needed followed companies asking question probably might consume time normalize database directly normalize using common sense therefore dont think need following standard normalization procedure correct wrong
8752 wondering implement sql get results sorted best match like predicate 100k articles database user call items part name want show results ordered best match asked query ill try describe pseudo code select articles item nale like user input order best match
8771 read oracle documentation key preserved table updating join views section however didnt find simple way understand hope receive simple conceptual details official oracle documentation
8774 several views used export data sql server csv files executed via ssis packages dba decided set max degree parallelism told use maxdop think makes sense seen many times maxdop really helps pull big data amounts especially results table scan partitions questions use maxdop view way around restriction
8790 used mysql sql server professional career company working uses postgresql someone similar situation please give insight biggest differences types client tools would use connect manage database thanks
8828 show sql currently executing oracle db extra information would useful would include user session id etc
8869 restore mysql database different name mysqldump file dontt want open dump file edit better methods
8885 im trying understand issue sql server moderately transactional website stored proc called sp getcurrenttransactions accepts customerid two dates depending dates customer query return anything zero 1000s rows problem weve experienced suddenly get number errors typically execution timeout expired similar particular client try execute stored proc examine query run ssms find takes 30s recompile stored proc bang runs 300ms ive spoken dba told database created query plan created stored proc said good plan set parameters throw certain set parameters plan best plan data see running slow options presented move problem query stored proc back dynamic sql execution plan created every run feels like step back feel like must way around way deal issue responses appreciated
8917 comes dbo schema best practice avoid using dbo schema creating database objects dbo schema avoided database user dbo schema
8938 using reporting database practical purposes read database created data dynamic reports generated viewed database thinking making database read things want ask regarding read databases data read still create indexes views database performance benefits using read database select queries using shared locks etc disadvantage using read database best practices follow using read databases
8978 actual difference row based statement based replication actually looking terms replications effect slave using row based replication effect slave using statement based effect please also take following parameters consideration replicate ignore db replicate db thanks
8994 found paper written hugh darwen avoiding nulls database link describes implement databases 6th normal form avoid nulls logic described language tutorial understand convert logic sql server end shows well implemented current database management systems see part need implement recomposition query done likely perform horribly might preferable store pers info single table covers tables resulting decomposition implemented mappings current technology give clean separation physical storage logical design perhaps something next generation software engineers grapple suggest storing pers info single table covers really mean would implement sql server
9011 im trouble figuring exactly place good boundaries use lookup tables database sources ive looked say never many point seems like database would broken many pieces may efficient longer manageable heres thrown together example im working lets say table called employees id lname fname gender position doe john male manager doe jane female sales smith john male sales pretend moment data complex contains hundreds rows obvious thing see could moved lookup table would position could create table called positions stick foreign keys positions table employees table position column id position manager sales far continue break information smaller lookup tables becomes unmanageable could create gender table correspond male correspond female separate lookup table could even put lnames fnames tables john entries replaced foreign key points fname table says id corresponds john go rabbit hole far like though employees table reduced mess foreign keys id lname fname gender position might might efficient server process certainly unreadable normal person may trying maintain makes difficult application developer trying access real question far far best practices sort thing good set guidelines somewhere cant find information online really nails good useable set guidelines particular issue im database design old hat good database design new overly technical answers may head help would appreciated
9015 im looking portable sample database created script simple er model little data database administration practicing purposes know adventureworks northwind pubs sample databases im looking something smaller idea find kind database
9047 undergrad databases course professor mentioned dbms software advanced detect long running query would benefit index dbms create index duration query increase performance however dont think thats possible initial googling seems agree anyone know dbms actually implements strategy
9109 attempting use sql case order stored procedure passed orderby parameter tinyint orderby date column asc orderby date column desc question get date column sort desc passed parameter string column sort asc case order statement case order order case orderby convertnvarchar30 ccd certenddate tp lastname tp firstname end case orderby convertnvarchar30 ccd certenddate tp lastname tp firstname end desc codes parses returns result set without error 2nd case order desc sort order would prefer ccd certenddate desc tp lastname asc tp firstname asc thanks advance
9124 using sql server looking closely concept key lookups http blog sqlauthority com sql server query optimization remove bookmark lookup remove rid lookup remove key lookup key lookup create index include columns cover non index columns select statement instance select id firstname oneindex city las vegas go index include key lookup create nonclustered index ix oneindex city dbo oneindex city asc primary go one remove key lookup create nonclustered index ix oneindex include dbo oneindex city include firstnameid primary go mean much impact performance key lookup operator cost really mean know need second index point become case trying add many indexes worth seems queries include index scans key lookups still seem perform fast
9143 getting confused could somebody kindly explain circumstances would want use group coalesce guess would use wanted conditionally group set data column null column otherwise sound right
9196 trying understand indexes managed common data types numeric integer decimals string varchar char datetime questions indexes stored different data types example numeric data like string data like aaabbbcccaaaabc numericcolumn stringcolumn index store data disk different retrieval numeric string indexes example try select statements numericindexed column sringindexes columns retrieved indexes stored different sql server oracle use logic regards
9197 im running postgres postgres database linux filesystem quite full ive run vacuum vacuum full yet none space returned os observe size table postgres shows table using considerably less space 80mb form 800mb something else run
9249 run mysqldump get error mysqldump got error user specified definer root foobar exist using lock tables makes sense foobar legacy machine longer exists change definer tables root localhost
9265 need primary key database function correctly every tutorial read need make id key primary key primary key differently regular cells
9268 possible recalculate row size sql server take example declare counter int declare statement nvarcharmax set counter drop table kua2 create table kua2id int counter begin set statement nalter table kua2 add id cast counter nvarcharmax nvarcharmax exec statement set statement nalter table kua2 drop column id cast counter nvarcharmax exec statement set counter counter end alter index kua2 rebuild dbcc cleantable 0kua20 alter table kua2 add id0 int alter table kua2 add id1 int alter table kua2 add id2 int alter table kua2 add id3 int add id3 column got warning bytes table int columns still count dropped nvarcharmax columns row size thing helps recreate table several reasons dont want way tell sql server recalculate row size somehow
9293 slightly unimportant piqued curiousity ive logged oracle 10g database first time using oracle sql developer tools used generic user login isnt name nottstest2 machine called something isnt name courgette name nowhere database isnt associated login yet server logs show connection jon hopkins know pulled windows login way though im using single sign
9302 simple query showing activity monitor statistics logical reads entire db server select maxresult date tablex mm nolock join tablex results mr nolock mr id mm id days null mm order id tablex million rows tablex results million rows reduce number logical reads query im kind confused simplistic query massive number logical reads thanks index definition comment tablex indexname pk type key1 key2 idx mp meds aa order id medpass date idx mp meds id order id medpass date ix mp meds root order id da root order id medpass date pk mp med pk medpass meds id tablex resulsts
9306 dump specific table set tables without including rest db tables
9352 postgresql matrix different high availability options represent many different ways building replication rdbms postgresql high availability load balancing replication feature matrix questions approaches postgresql high availability matrix supported oracle oracle high availability techniques available postgresql
9356 student developing several projects part academia developing database one projects came across situation thought whether erd necessary right every one us agreement developing erd first developing database majority people prefers developing database fly verbally according system requirementd paper directly strict follower database principles think database developed erd want know following industry following principles wasting time developing erd benefits developing erd
9406 log logitem tables im writing query grab data thousands logs log logitems query question complicated im skipping someone thinks important probably post ran ssms estimated query plan told new non clustered index would improve performance existing index non clustered key colums logitem parentlogid datemodified name databasemodified query plan recommendation create nonclustered index logreportindex dbo logitem parentlogid databasemodified fun created new index ran query much surprise takes second query run seconds assumed existing index would cover new query question creating new index columns used new query improve performance index unique combination columns used clauses note dont think sql server caching results ran query times created index consistantly took seconds index consistantly less
9441 guess predefined named system exceptions ora rewrite following catch error ora begin execute immediate create sequence test start increment exception others null end btw syntax catch errors providing error codes
9494 legacy database lot time schema needlessly allows null entries particular columns help find columns particular need querying sql server beyond level expertise aim tighten schema bit save dealing null case code crude way option help solve problem get records select contain least one null entry eye scan columns contain null entries could course use columna null columnb null columnc null gets tedious tables lots columns tables database contain twenty columns also theres tables total general solutions best three options answers would satisfy option get records least one columns null eyescan columns null entries option even better answer would script gets list column names contain least one null entry see nullable columns list manually option best answer would get list column names marked nullable schema even though records exist null entry columns thanks
9518 running scripts php cli linux script updating loop data mysql database typed mysqladmin proc terminal see lot rows locked seconds mostly update queues improve performance faster using innodb engine top command top days users load average tasks total running sleeping stopped zombie cpus us sy ni id wa hi si st mem 4138464k total 1908724k used 2229740k free 316224k buffers swap 2096440k total 16k used 2096424k free 592384k cached pid user pr ni virt res shr cpu mem time command mysql 903m 459m mysqld etc cnf mysqld set variable max connections safe show database max user connections key buffer size 16m query cache size 350m tmp table size 200m max heap table size 200m thread cache size table cache thread concurrency innodb buffer pool size 400m innodb log file size 128m query cache limit 500m innodb flush log trx commit server spec intel core quad q8300 ghz 4gb ram mysqladmin proc id user host db command time state info user localhost xxxxxxxxxxxxxx query updating update data set status error unknown error number 0xxxxx user localhost xxxxxxxxxxxxxx query updating update data set status error invalid number 0xxx user localhost xxxxxxxxxxxxxx query updating update data set status 0xxxx user localhost xxxxxxxxxxxxxx query updating update data set status error unknown number 0xx user localhost xxxxxxxxxxxxxx query updating update data set status error invalid number 0xxxx user localhost xxxxxxxxxxxxxx query updating update data set status error unknown number 0xxxx user localhost xxxxxxxxxxxxxx sleep null user localhost xxxxxxxxxxxxxx query updating update data set status error unknown number 0xxx user localhost xxxxxxxxxxxxxx query updating update data set status number 0xxxx explain id select type table type possible keys key key len ref rows extra simple data index merge processstatus processstatus null using intersectprocessstatus using mysql server using multiple cores edit information data table create table data number varchar50 null dob varchar50 null varchar50 null status tinyint1 unsigned null error varchar150 null process varchar50 null key process process key status status key number number engine innodb default charset latin1 number rows data table indexed process status number data table size mib according phpmyadmin hard drive gb sata rpm raid loop offset xx limit xx data select data status process limit limit offset offset loop rows error errorcheck data number error update data set status error error number data number else update data set status number data number end loop rows end loop limit select query return limited amount rows select remaining rows next iteration using offset limit read rows select query array variables iterate array numbers update every row continue first step mysql explain select data number 0xxxxxxxxxx id select type table type possible keys key key len ref rows extra simple data number null null null using iostat root host iostat linux el5pae xxxxxxx xxxxxxxxxxxx com avg cpu user nice system iowait steal idle device tps blk read blk wrtn blk read blk wrtn sda sda1 sda2 sda3 sda4 sda5 sda6 sda7
9587 one setup two identical servers automatic failover postgresql os centos postgresql compiled source postgres user account exists machines ssh passwordless key connect machines current setup master server configuration postgresql conf listen address wal level hot standby max wal senders checkpoint segments wal keep segments archive mode archive command cp opt pgsql91 archive pg hba conf host replication trust host replication trust standby server postgresql conf pg hba conf identical configured master server recovery conf standby mode primary conninfo host trigger file opt pgsql91 data trigger txt thanks hzroot understand switch server standby master using following commands synchronize new slave new master get replication backup running new master su postgres touch trigger txt opt pgsql91 data recovery conf becomes recovery done psql select pg start backupbackup true rsync ssh opt pgsql91 data opt pgsql91 data exclude postmaster pid psql select pg stop backup new slave create recovery conf cp recovery done recovery conf vi recovery conf change ip address primary conninfo host start postgresql questions correct way switch roles anyone automated process synchronous replication enabled noticed new master server wont commit transactions waiting slave respond slave however server old master correct need temporarily disable synchronous replication new slave
9638 following query return infinite rows would expected except clause terminate recursion cte select values12345 select cte union select select cte except select select came across trying answer question stack overflow
9662 following table create table test id smallint unsigned auto increment age tinyint null primary keyid check age problem check constraint work age column example insert age field mysql accepts
9689 want insert adminaccounts name select name matrix dont want create duplicates ie ran weeks ago need update data
9746 innodb table want alter table 80m rows quit indices want change name one columns add indices fastest way assuming could suffer even downtime server unused slave plain alter table fastest solution time care speed
9759 table like following create table table id int8 null id int8 null id int8 null id int8 null constraint pk table primary key id constraint constrainte unique id id id want id id id distinct situation following two inserts must result error insert table values null insert table values null doesnt behave expected according documentation two null values compared inserts pass without error guarantee unique constraint even id null case actually real question guarantee kind uniqueness pure sql implement higher level java case
9762 lets say table called dbo groupassignment groupid rank pk groupid rank normally ranks within group contiguous sequence integers starting possible groupassignment get removed leaving gap new assignment made group want fill first gap available could calculate sql server
9765 interest would transition sql server dba oracle major learning unlearning would would assume concepts difference merely programming language seen side door
9798 following table create table trans id serial primary key trans date date trans time time want following view create replace view daily trans select trans date maxtrans time first mintrans time last calculate statusmintrans time maxtrans time status group trans date columns specify ids max min trans time
9829 white paper compares performance individual select insert delete update range select statements table organized clustered index vs table organized heap non clustered index key columns ci table generally clustered index option performed better tests one structure maintain need bookmark lookups one potentially interesting case covered paper would comparison non clustered index heap vs non clustered index clustered index instance would expected heap might even perform better nci leaf level sql server rid follow directly rather needing traverse clustered index anyone aware similar formal testing carried area results
9852 developing mysql really miss able fire profiler find sqlyog good enough replacement query analyzer found tool works like sql profiler mysql folk seen microsofts sql profiler screenshot previous job tool trumped sql profiler even gave us stack traces anyone know tools like ones mentioned works mysql fyi get altiris profiler work mysql involve running windows furthermore really symantec sku licensing really tricky
9953 develop cms support two language english arabic cms sort article publishing site designing analysis found articles characters length table column pageid int pagetitleenglish nvarchar200 pagetitlearabic nvarchar200 pagedescenglish nvarchar500 pagedescarabic nvarchar500 pagebodyenglish nvarcharmax pagebodyarabic nvarcharmax keep pagebody nvarchar4000 limited characters store arabic version need bytes arabic unicode take time space ascii left option defining pagebody nvarcharmax downside performance point view actual question data pagebody column less characters ms sql store data inline column separately database looked google also didnt find relevant answer improve performance scenario suggestions best practice design multilingual cms welcome need support two languages arabic english
9962 suppose user table site around million users records table speeding login process good approach split user table one information one login run query similar one one table select usernamepassword users username test password necessary split speed sites login process
10005 question issue somewhat complicated one already addressed old questions duplicates one another suggestion database structure multilanguage jun whats best database structure keep multilingual data feb best practices multi language database design may schema multilanguage database nov popular database scheme backing multilingual user interfaces seems translated texts languages one table columns text id language code text text id language code together make primary key thats fine consider complication suppose texts need searchable suppose example multi language shop means every product category entered database shop owner enter name product category every one supported languages shopper able search product category name language problem collation different languages different collation sequences collation sequence works one language work another texts languages single column collation sequence going going query database find text id specific text web product search accuracy performance might awfully important purposes discussion let us assume really matter database administrators familiar concept collation sense collation database luckily thats default collation used collation information present exist places collation specified sql create index command supports collation specification though rumors microsoft sql server support anyone know sql select statement also supports collation case collation specification works function causing index scan instead index lookup something might impermissible want performance thats best might better nothing also hear microsoft sql server non persisted computed columns specify collation create filtered index though never heard microsoft sql server feature id rather refrain using matter cool well thought light structure database perform queries goal updatable searchable multilingual database question inspired discussion took place nvarcharmax store data database fast data less characters
10034 question dbas go learning skills become dba without hands job training experience db work messing mysql via myphpadmin something similar ton depth work classes sql books
10057 basically ms sql developerand relatively new oracle even great deal research unable find way copying entire database one server instance another ms sql usually done backup database restore database sql query even use external tools management studio create scripts done oracle 11g express ideas
10113 whats efficient way retrieve date ranges table structure like create table somedatetable id int identity1 null startdate datetime null enddate datetime null go say want range startdate enddate words startdate falls startdatebegin startdateend enddate falls enddatebegin enddateend something know ways probably go advised
10146 recently using query find tables database didnt clustered indexes found one results reported back sys sysfiles1 table running sql server impression table wasnt used anymore answers pointed seems misconception table exists databases upgraded sql server furthermore im able directly select anything sys sysfiles1 table though able select directly sys sysfiles view running following create fresh database local installation sql server version microsoft sql server r2 sp1 x64 though weve seen production instance sql server well illustrates mean create database sysfilestesting returns row select sysfilestesting sys objects name sysfiles1 throws invalid object name error select sysfilestesting sys sysfiles1 sys objects reporting existence sysfiles1 table
10167 supervisor hesitant use trigger process network interruption right time process would complete sql server include trigger calling procedures transaction best way implement
10199 friend store values ab ba one enough advantages disadvantages methods observation keep update receive request friend dont keep found difficult multiple join table currently keep relationship one way case advice
10208 one postgresql servers hosts several databases receive constant stream data data particularly structured amounts current time variety observed data particular instant data rate fairly high works gigabyte day one database tenth another one dont expect rate increase read performance much lower priority currently acceptable logs message log checkpoints occurring frequently seconds apart hint consider increasing configuration parameter checkpoint segments value currently set courtesy pgtune settings consider improve write performance would prefer keep much safety possible considering volume data coming could accept losing recent data failure long bulk data intact edit im using postgresql plan upgrade posting hardware details acknowledge importance ultimately needing make optimization several machines diverse hardware hardware essential answer please give general information apply answer machines different hardware configurations
10215 given simple three table join query performance changes drastically order included even rows returned actual problem scenario take seconds return zero rows instant order included select tinytable one narrow row join smalltable id tinyid one narrow row join bigtable smallguidid guidid million narrow rows foreignid doesnt match order createdutc try without order understand could index bigtable smallguidid believe would actually make worse case heres script create populate tables test curiously seems matter smalltable nvarcharmax field also seems matter im joining bigtable guid guess makes want use hash matching create table tinytable id int primary key identity1 foreignid int null create table smalltable id int primary key identity1 guidid uniqueidentifier null default newid tinyid int null magic nvarcharmax null default create table bigtable id int primary key identity1 createdutc datetime null default getutcdate smallguidid uniqueidentifier null insert tinytable foreignid values7 insert smalltable tinyid values1 make million rows declare int set insert bigtable smallguidid select guidid smalltable begin insert bigtable smallguidid select smallguidid bigtable set end ive tested sql 2008r2 results
10277 developers given permission query select read production databases previous place worked development team db datareader role work development team cant even connect production instance one test instances copy production restored production backup week arent problems developers actually seeing data good reasons allowing developers query production except simply wanting access read sensitive data
10383 ive tired explain every new junior developer team use primary keys decided write small whitepaper every new developer read draft disclaimer know understand difference clustered index primary key following question primary key means primary key clustered without primary key means without pk clustered index note whitepaper junior sql programmers things reviewed entering main development branch im going explain benefit using clustered index nonclustered primary key else fall premature optimizations hell question else add document may change explain detail comes draft primary keys constrain table within database without pk table considered heap sql server limited uses type data thing say suitable buffer fast bulk loading data outside sql servers engine avoid using natural primary keys primarily natural gauss distributions example phonebook table primary key based family name many smiths wilsons much fewer zimmerbergs states pages containing smiths wilsons splitted often pages queried also often multiplies performance impact leads performance degradation primary keys page fullness searches hit pks sparsed pages moreover even using ssn id number hope flat distribution pk solve problem pks page splitting numbers organized order secondary natural pks often composite creates composite foreign keys wide indexes result hurts performance avoid using composite pks better using simple surrogate pk composite unique index one composite pk leads composite fk wide indexes due statement every secondary index table pk include whole pk within avoid using surrogate primary keys integer uniqueidentifier types database design phase important identify entities corresponding tables may perspective zillions rows tables keys table wide unique db even world unique joined tables key several hop tables tables better uuid pk others ordinary integer sql server well fine tuned use integer pks two types guarantee vector distribution identity newsequentialid monotonous sequence main database design rule twenty minutes spent well thought design save days even weeks production databases maintenance
10396 say table clustered primarykey cases want results ordered primarykey additionally always order primarykey queries order affect performance way ignored profiler rows already order instance using sql server database
10409 first know squat oracle databases vendor looking converting data older piece software oracle db back end wants dump database see need bring data new software ms sql server based know ms sql server right click database say backup create backup database file ftp backup vendor would equivalent oracle appears like might version 10g oracle
10474 copy public schema database full table structure data functions fk pk etc version postgres need copy schema database
10492 im currently experimenting bit pl pgsql want know elegant way something like select data data doc doc id id group cur group cur order id desc limit exception data found select data data doc doc id id global cur global cur order id desc limit exception data found return null
10496 using innodb tables less 1mb mysql startup said innodb initializing buffer pool size 0m mean even using small size server still use 128m ram
10535 user never runs rebuild reorganize database sql server still somehow defragment indexes msdn suggests index fragmented recommended run rebuild instead reorganize would running reorganize multiple times things rebuild wonder client highly fragmented index run reorganize index every weekend time seems like index becomes defragmented make sense
10587 way query owner jobs sql server r2 discovered maintenance plans edited owner gets changed want make sure owned sa
10655 report developer wants make queries efficient possible used work dba told believe always dealing reports production server use nolock every single query work dba banned nolock circumstance even report mine due considerable lack indexes couple tables stopping replication system updates opinion case nolock would good thing since sql training come various dbas different opinions wanted ask wide variety dbas
10657 created stored procedure mysql using following syntax drop procedure exists sp set comment count delimiter create procedure sp set comment count id int begin ac allcount declare ac int default select count ac ac usergroups ug left join usergroup comments ugm ugm gid ug id left join mediagallery dm ugm mid dm id dm status ug id id update usergroups set allcount ac usergroups id id end delimiter fyi ive greatly simplified stored procedure know works without issues id like able set trigger usergroup comments works like drop trigger exists usergroups comments insert create trigger usergroups comments insert insert usergroups comment row begin call sp set comment countnew gid end reason every time mysql throws error thats less helpful stating theres syntax error line ive combed mysql documentation found information restrictions triggers found fairly convoluted http dev mysql com doc refman en stored program restrictions html ideas would helpful
10694 write simple query go looking peoples name start select name spelers name like name like order wondering way rewrite become performant avoid like
10716 something bad happened yesterday view created sometime back ago modified someone eventually broke reports unfortunately somebody knowingly unknowingly modification production database question way script software freeware etc come know username modification revoke access production database user question unclear please comment
10729 table fields auto increment primary key hard look table many columns frequently use select statement look fields mentally categorize group fields categorize group would face performance hit reads writes split table two tables one fields another fields would auto increment primary key could joined primary key need look fields
10776 one scale sql server basic understand two options scale cpu bound clearly see going cpu core ram usage rockets adding ram sql server actually pick slack scale way assuming application level changes minimize speculation lets assume im something dumb like burning cpu cycles cross joins etc scale clear scaling would work mean added another sql server right next first one query know server run load balancer front come sql server software entail application level changes scaling work shard data custom code calls correct database server depending data sharding key would appreciate input experienced folks
10818 comparing execution time two different queries important clear cache make sure execution first query alter performance second google search could find commands dbcc freesystemcache dbcc freesessioncache dbcc freeproccache fact queries taking realistic time complete several executions however im sure recommended technique whats best practice
10852 use root account created account cant use account connect mysql server specify host parameter successfully connect without parameter please see transcript hope someone help explain thanks mysql grant identified error error sql syntax check manual corresponds mysql server version right syntax use near line mysql grant identified query ok rows affected sec mysql show grants grants grant privileges identified password 667f407de7c6ad07358fa38daed7828a72014b4e row set sec mysql exit bye root localhost mysql localhost enter password error access denied user localhost using password yes root localhost mysql enter password error access denied user localhost using password yes root localhost mysql enter password error access denied user localhost using password yes root localhost mysql welcome mysql monitor commands end mysql connection id server version mysql community server gpl copyright oracle affiliates rights reserved oracle registered trademark oracle corporation affiliates names may trademarks respective owners type help help type clear current input statement mysql mysql status mysql ver distrib linux x86 using readline connection id current database current user localhost ssl use current pager stdout using outfile using delimiter server version mysql community server gpl protocol version connection localhost via unix socket server characterset utf8 db characterset utf8 client characterset utf8 conn characterset utf8 unix socket var lib mysql mysql sock uptime days hours min sec threads questions slow queries opens flush tables open tables queries per second avg mysql edit yes mysql listening port root localhost nmap localhost starting nmap http www insecure org nmap cst interesting ports localhost localdomain shown closed ports port state service tcp open ssh tcp open smtp tcp open rpcbind tcp open ipp tcp open unknown tcp open mysql nmap finished ip address host scanned seconds root localhost
10873 two database servers connected via linked servers sql server 2008r2 databases linked server connection made via regular sql server link using current logins security context linked servers datacentre connection shouldnt issue use following query check values column identifier available remotely locally select identifier linkedserver remotedb schema tablename except select distinct identifier localdb schema tablename tables non clustered indexes column identifier locally around 6m rows remotely yet looking query plan execution time devoted executing remote query also studying complete query plan number estimated local rows instead number estimated rows selecting query coming except executing query takes long time indeed makes wonder estimation way remote queries linked servers really expensive
10901 im researching defragmenting databases seems following sql statement im looking alter index mytablename rebuild withonline pull info sys dm db index physical stats see percents high percent tells want rebuild reorganize question executing rebuilds ran processes using database online tells yes want confirm wont crash anything better run use read rebuild makes things run slower indexes rebuilt forever long take rebuild indexes rather one side effects info need aware production live database edit finally best way go rebuilding looping objects percentage greater thank
10931 ages using mysql recently noticed version longer supported repository need upgrade mysql assume changing version complicated process changes cnf may changes code questions version stable preferred version use
10950 usually weekly full backups finish minutes daily diff backups finishing minutes since tuesday dailies taken almost hours complete way required coincidentally started happening right got new san disk config note server running production overall issues running smoothly except io issue thats primarily manifested backup performance looking dm exec requests backup backup constantly waiting async io completion aha disk contention however neither mdf logs stored local disk backup drive activity iops plenty memory disk queue length well cpu hovers around issue either san dell md3220i lun consisting 6x10k sas drives server connected san two physical paths going separate switch redundant connections san total four paths two active time verify connections active task manager splitting load perfectly evenly connections running 1g full duplex used use jumbo frames ive disabled rule issues change another server os config r2 connected luns shows issues however running sql server sharing cifs top however one luns preferred path san controller troublesome luns ive ruled well running couple sqlio tests 10g test file seems indicate io decent despite issues sqlio kr t8 o8 s30 frandom b8 bn ls fparam txt ios sec mbs sec min latencyms avg latencyms max latencyms histogram ms sqlio kw t8 o8 s30 frandom b8 bn ls fparam txt ios sec mbs sec min latencyms avg latencyms max latencyms histogram ms sqlio kr t8 o8 s30 fsequential b64 bn ls fparam txt ios sec mbs sec min latencyms avg latencyms max latencyms histogram ms sqlio kw t8 o8 s30 fsequential b64 bn ls fparam txt ios sec mbs sec min latencyms avg latencyms max latencyms histogram ms realize arent exhaustive tests way make comfortable knowing isnt complete rubbish note higher write performance caused two active mpio paths whereas reading use one checking application event log reveals events like scattered around sql server encountered occurrences requests taking longer seconds complete file xxx mdf database xxx os file handle 0x0000000000003294 offset latest long 0x00000033da0000 theyre constant happen regularly couple per hour backups alongside event system event log post initiator sent task management command reset target target name given dump data target respond time scsi request cdb given dump data also occur non problematic cifs server running san controller googling seem non critical note servers use nics broadcom 5709cs date drivers servers dell r610s im sure check next suggestions update running perfmon tried recording avg disk sec read write perf counters performing backup backup starts blazingly basically stops dead crawling slowly towards taking 20x time shouldve shows san paths utilized dropping backup initiated around notice looking good theres series peaks im concerned writes reads seem hang note little action though blazing performance end note 12sec maximum though average overall good update backing nul device isolate read issues simplify things ran following backup database xxx disk nul results exactly starts burst read stalls resuming operations update io stalls ran dm io virtual file stats query jonathan kehayias ted kruegers book page recommended shawn looking top files one data file results data files would seem like reads worse writes perhaps writes go directly san cache whereas cold reads needs hit disk guess though update wait stats three tests gather wait stats wait stats queried using glenn berry paul randals script confirm backups done tape iscsi lun results similar done local disk results similar nul backup cleared stats ran minutes normal load cleared stats ran minutes normal load normal backup running didnt complete cleared stats ran minutes normal load nul backup running didnt complete update wtf broadcom based mark storey smiths suggestions kyle brandts previous experiences broadcom nics decided experimentation weve got multiple active paths could relatively easily change configuration nics one one without causing outages disabling toe large send offload yielded near perfect run processed pages database xxx file xxx file processed pages database xxx file xxx file backup database successfully processed pages seconds mb sec culprit toe lso toe enabled lso disabled didnt finish backup took forever original problem toe disabled lso enabled looking good processed pages database xxx file xxx file processed pages database xxx file xxx file backup database successfully processed pages seconds mb sec control disabled toe lso confirm issue gone processed pages database xxx file xxx file processed pages database xxx file xxx file backup database successfully processed pages seconds mb sec conclusion seems enabled broadcom nics tcp offload engine caused problems soon toe disabled everything worked like charm guess wont ordering broadcom nics going forward update goes cifs server today identical functioning cifs server started exhibiting io requests hanging server wasnt running sql server plain windows web server r2 serving shares cifs soon disabled toe well everything back running smooth confirms wont ever using toe broadcom nics cant avoid broadcom nics
10952 saw ansi warning message today running colleagues script dont know many statements caused warning shown past ive ignored avoid nulls anything would eliminate good thing book however today word set literally shouted realised dont know meaning word supposed context first thought based fact upper case referring set keyword means assignment update table set delete set null set identity insert table according sql server help ansi warnings feature based iso ansi sql spec makes one use term set operation subsection title hence title case data assignment section however quick googling error message see examples select queries seemingly assignment involved second thought based wording sql server warning mathematical meaning set implied however dont think aggregation sql strictly speaking set operation even sql server team consider set operation purpose putting word set capitals googling noticed sql server error message table identity property perform set operation words set operation case refer assignment identity insert property brings back first thought anyone shed light matter
10975 currently use mixed mode sql server authentication ive tried convince dba allow us use windows authentication use team foundation server however absolutely refuses allow us accord windows authentication since planning become pci compliant eventually pci requires mixed mode see online opposite pci standard actually prefers windows authentication mixed mode someone give information preferably url states correct information direct department head
10990 often use ssms test slow stored procedures missing indexes whenever see missing index impact xxx kneejerk reaction create new index results faster query every time far tell reason shouldnt continue
10991 testing stored procedures ssms sometimes says missing index sometemptable 000000000000005b somefield etc etc add like sp create nonclustered index name missing index sysname dbo sometable somefield go never seem see speed improvement often add indexes adding indexes
11005 possible query last successful backup date perhaps type backup database sql sever r2
11031 added indexes table used searching result showing results asc desc order column index indexes table performance affect making making index column
11032 query found queries one table wasnt able modify see tablename column type
11043 large mysql db 150gb ive noticed innodb file per table set causes entire db hosted one single file ibdata1 want activate innodb file per table retroactively split db several files whats best way
11046 possible disable trigger momentarily one table example table tablea insert update delete trigger also table triggers affect certain columns table update query uses tables know updates table need fire triggers updates table definitely need fire triggers would like disable triggers updates done possible im using mysql addendum trigger table essentially begin old status new status old geo lat null old geo long null delete geo datatype foreignid new id end elseif old status new status new geo lat null new geo long null insert geo datatype foreignid long lat hostid morton status values ifnew grouptype new id new geo long new geo lat new hostid new status end elseif new status old geo lat null old geo long null new geo lat null new geo long null delete geo datatype foreignid new id elseif old geo lat null old geo long null new geo lat null new geo long null insert geo datatype foreignid longitude latitude hostid morton status values ifnew grouptype new id new geo long new geo lat new hostid new status elseif old geo lat new geo lat old geo long new geo long old status new status update geo set lat new geo lat long new geo long status new status datatype foreignid new id end end end triggers table essentially create trigger usergroups comments insert insert usergroups comment row begin call sp set comment countnew gid end stored procedure thats fired table delimiter create procedure sp set comment count id int begin ac count oldac old count declare ac oldac int default select count ac ac usergroups ug left join usergroup comments ugm ugm gid ug id left join mediagallery dm ugm mid dm id dm status ug id id select allcount oldac usergroups ug id id oldac ac update usergroups set allcount ac usergroups id id end end
11101 im mostly application developer find front database work current project btw ms sql server first decision im trying figure whether divide state using seperate databases using seperate schemas database ive done little reading sql server schemas seems like natural way seperate object domains like im sure may hidden costs pattern practical things consider selecting two approachs avoid dbo mytable favor myschema mytable creating challenges problems architecture side note point handed real dba maintain support im trying make sure dont make lives harder
11124 sql server flagship editions enterprise edition business intelligence standard full comparison three http www microsoft com sqlserver en us future editions sql2012 editions aspx business intelligence edition implies purpose data warehousing covers seems key concerns self service business intelligence alerting power view powerpivot sharepoint server advanced corporate bi tabular bi semantic model advanced analytics reporting vertipaq memory engine advanced data integration fuzzy grouping lookup change data capture advanced data mining enterprise data management data quality services master data services however enterprise edition version data warehousing columnstore index compression partitioning functionality entail seperated bi enterprise editions
11233 sql server r2 database suspect mode tried fix running query exec sp resetstatus yourdbname alter database yourdbname set emergency dbcc checkdb yourdbname alter database yourdbname set single user rollback immediate dbcc checkdb yourdbname repair allow data loss alter database yourdbname set multi user repair output message warning must recover database prior access msg level state line check terminated failure detected collecting facts possibly tempdb space system table inconsistent check previous errors warning log database servedb rebuilt transactional consistency lost restore chain broken server longer context previous log files need know run dbcc checkdb validate physical consistency database put dbo mode ready make database available use need reset database options delete extra log files msg level state line check terminated failure detected collecting facts possibly tempdb space system table inconsistent check previous errors repair database fully repair made works days database goes suspect mode
11292 need read data database given backup file issue restore database command creates two files database mdf file log ldf file possible restore database without creating ldf file
11341 defining schema new set resources using sql server case record row need store xml fragments time time although frequently ill need query xml find element attribute values left devises would tend use xml data type although led believe wrought issues leads questions given scenario factors considering trying decide storing xml xml column vs varcharmax column helps additional details decision made regarding use schema fragments xsd sizes fragments range small large xml well formed course day fragments collected online query support needed months queries xml happen throughout day remain light concurrent queries type
11396 two purposes offsite backup case region wide problem amazon web services copy production data production billing account beta billing account currently appear amazon supports either two use cases box seen mysqldump xtrabackup see form post mentioned also seen complicated process documented new rds server source billing account prod spun recent backup new ec2 instance spun access rds server step mysqldump used make backup database backup copied offsite location s3 separate account region fresh rds server spun database dump imported tips suggestions appreciated
11405 given version oracle find current scn maximum possible scn
11430 non clustered index million leaf level rows currently included columns would like add one included column site online significantly affect performance ssms gui
11444 im setting test environment development need export static data tables production ideally exported product would take form script required insert statements reset development environment quickly test anyone tell accomplish using sql server sql management studio visual studio note none tables foreign keys full permissions source database number rows per table dozen
11475 given declare type array table varchar22000 index binary integer array array count integer would like begin code filling array array obviously count elements exists im looking count count elementsmy array dbms output put linemy array containts count elements end something better creating procedure basic loop incrementing counter maybe pl sql native function already count elements
11527 database developers working large lot database objects control db objects changes change management company person would responsible db changes need source safe database objects something like version control standard code related database synchronize database scripts best one reliable cheap functional choose two ones
11531 im looking table listing oracle standard character sets example oracle standard weiso98859p1 iso al32utf8 utf etc etc kind resource exist couldnt find
11631 colleagues discussion normalization descriptive traits database status type lets call central table discussion order regular design approach would define another table orderstatus describe status order create foreign key relationship orderstatusid order table would give referential integrity id able join status times possible values always present orderstatus table colleague doesnt like degree normalization hell instead define varchar field orderstatus order table field would contain values directly possible values status defined application specifically enum orderstatuses available unless access source code said application im used entire context database exist database relationships tables write orderstatus sold opposed orderstatusid bugs think im looking pros cons approaches im primarily concerned performance readability maintainability
11638 ive found big nasty data extraction query runs daily needs updated stats avoid making horrible query plans based incorrect rowcount estimates lets worry whether stats updating automatically question noted title concerned incorrect query plans sticking around query plan happens prepared given set statistics updated time desisions made optimizer turned wrong stats updates automatically cause dependent query plans flushed plans stick around way figure plans depend given indexs statistics know could go digging dmv docs hoping someone already answer
11657 asked create something tracks daily cost collect accounts trying figure database table schema would support heres know company million accounts currently work average per month changes staffing levels currently low different cost types theyd like track warned might add future want costs tracked daily costs split across entire inventory either split across accounts worked per month users enter account identifiers apply cost group accounts could simply specify accounts apply cost first thought normalized database accountid date costtypeid amount issue math table going get huge quickly assuming cost types get applied worked accounts current month thats 200k days month somewhere around million records per month close billion records per year second thought denormalize bit accountid date totalcost costtype1 costtype2 costtype3 costtype4 costtype5 costtype6 costtype7 costtype8 costtype9 costtype10 costtype11 costtype12 costtype13 method denormalized create million records per month 200k days month 72million per year lot less first method however company decides new cost type future another database column need added two methods prefer another alternative think would handle better interested reporting performance summerized detailed reports job spread costs accounts run nightly one around secondary concern database size existing database already almost 300gb believe space disk around 500gb database sql server
11664 table holds basic info title date fields theres one field called comments varchar4000 time leave blank times enter large amount data really bad design slightly inefficient would assume creating separate table column would better note sql server
11670 working new project requirement use databases arguing performance stability optimization easier implemented dont agree im trouble collecting good arguments use single database databases splits tables logical domains one argument far data integrity cant use foreign keys databases good pros cons using single multiple databases summary far arguments losing data itegrity cant use foreign key databases losing restore integrity gaining complexity db user roles small odds server database go solutions use schemas seperate domains poc use dummy data proof point dbs execution plans
11697 faster select inner join record id forignkey notindexed notunique select inner join forignkey notindexed notunique record id
11701 measure time frame execution plan inline queries cached
11719 sensitive information names people looking put place script scrub names anybody come good algorithm something making last names test something thanks
11758 ive trying figure lets say person example attribute person social security number right person also social security number er diagram could draw square box person square box ssid could connect diamond alternatively could draw circle ssid could connect square person box isnt true ssid though possible draw either concrete things like car pet phone number conceptual things like phone number friendship mood draw lines object design get everything paper looking nice using guide
11806 new centos installation running import large db 2gb sql file problem ssh client seemed lose connection import seemed freeze used another window login mysql import appeared dead stuck particular 3m row table tried drop database huge db minutes later nothing another window etc init mysqld restart drop db window messaged server shutdown actually restarted physical server logged back mysql checked db still ran drop database huge db im waiting already minutes fresh installation huge db db system dbs swear ive dropped dbs large quickly maybe im wrong ive successfully dropped database took something like minutes also note think mistaken thought mysqldump import dead terminal connection lost think process still running likely killed import mid table 3m row table probably way whole db misleading top showed mysql using memory seemed like using dropping db ended taking min might restart server possibly could waited drop finish dont know mysql would react getting drop query db importing via mysqldump still question remains take 30min drop 2gb database delete db files remove references db information schema whats big deal
11893 need remove database postgresql db cluster even active connections need sort force flag drop connections db implement im using dropdb currently tools possible
11906 know best practices would regarding ssas real time reports sure pulling data live database using ssis move data periodically data warehouse database processing cube advice best approach would greatly appreciated
11912 lets say myisam table data length 8gb index length 2gb total data size eleven gig much memory would require convert memory table gig
11925 table structure create table dbo order details2 orderid int null productid int null unitprice money null default quantity smallint null default discount real null default constraint pk order details2 primary key clustered orderid asc productid asc pad index ignore dup key primary primary table values orderid productid uniteprice quantity discount required output orderid productid uniteprice quantity discount table two primary keys want get unique record table required output contain column orderid max productid row one row need helping hand solve issue query please ask
11956 customer site complaining seriously slow performance took one look obvious problem somebody else grrrr designed table holding million plus records without clustered index want create clustered index table test environment create index command running hour still done customer site shop floor works afford hour time create index less brute force method creating index either finish job quickly smart way totally kill servers performance busy using sql server enterprise edition
11962 im currently uploading one wikipedias dump files 1gb compressed 7gb uncompressed importing hours already size imported table mysql moment 5gbdata indexes continue import size table reach 7gb note data directory database external hdd considering development im concerned real performance
12024 situation developer workstations typically use client tools connect non local sql servers however rare times full version sql server local development beneficial effort waste system resources running sql server time would like know best way turn still allowing usage client tools management studio etc
12061 set max connections around cnf file max connections upgraded see following line error log warning changed limits max open files max connections table cache mysql changed max connections value mysqladmin variables grep max connections max connections soft hard open files restricted os ulimit sa grep open files open files ulimit ha grep open files open files number actually used max connections mysql show status like used connections variable name value max used connections
12080 simple table classes students class student math alice math bob math peter math anne music bob music chis music debbie theres classes every student attends classes bad analogy know testing theres students db rows db handle several million students thats im using mysql ndbcluster anyway query like select student countclass common classes classes table class subject list group student order common classes desc resulting something like student commonclasses brad melissa chris bob takes second innodb engine one server ok ndbcluster datanodes query takes seconds far much dont know statement treated internally guess lot communication nodes makes slow due latency someone tell happens cluster perform query make faster note question came posted question https stackoverflow com questions compute ranking mysql stored procedures informations look
12082 im migrating 15gb database sql server new server running sql server along need create new maintenance plans take care backup stuff table maintenance baffles anyone input often often would suffice following tasks check database integrity rebuild indexes reorganize indexes update statistics shrink database missing anything share often tasks would great share general information approach table maintenance would helpful lastly matter order run tasks setting job oh im open links might help
12150 table postgres database table bloated almost 25gb running vacuum full cluster table size dramatically smaller well 1gb weeks later back 5gb climbing table frequent deletes im loss causing bloat happens single table separate structurally identical database serving software table database shown bloat ideas
12185 imagine stream data bursty could events arrive quickly followed nothing minute expert advice write insert code sql server guarantee sql caches everything immediately ram without blocking app takes feed data said ram achieve know patterns setup sql server patterns set individual sql tables im writing course could version involves constructing queue ram dont want reinvent paleolithic stone axe speak
12250 usually warm database run similar queries every table db select ip log order id select ip member id ip log order ip member id best way something cooler
12258 run job tracking service part company software reports generated sql server standard reporting services usually daily often needed meetings etc jobs progress status changes details reports change due legacy front end application database store many milestones needed managers look back historical reports managers quite often ask see xyz last week things like let look project1 performing last june running reports project1 database backup show complete finished best way enable historical reporting daily level sql server standard ideally like keep months different reports stored daily possible
12271 ive read forum database capacity 1g buy license true much cost
12337 following setup multiple production database containing private data used desktop software web database public website needs data private databases intermediary database contains views stored procedures pull data private databases currently website logs web database web database connects intermediary database pull data execute stored procedures production databases databases sql instance entire process uses user account user account full access web database intermediary database access specific views stored procedures private database really secure making public database connect directly private ones seems like intermediary database complicates things since login used access data databases already limited views sps needs private databases hoping remove
12376 object called cot ntn pi told synonym doesnt appear synonyms table looks like view table cant find objects table select cant drop doesnt exists cant create new table name name already used another object going mad something really stupid
12388 im confusing problem changing computer name remote server hosting local sql server instance basically remote server moved one site another order facilitate backed restored old database new database name clearing data could used fresh database client software also changed computer name always identify server site number database connected client software fine log directly sql server fine however one sql server agent jobs fails error event log sql server scheduled job nightly reset 0x4f76fdfff6dffe4ea0de4a70252ad3bd status failed invoked message job failed unable determine owner site admin job nightly reset server access reason could obtain information windows nt group user site admin error code 0x534 sqlstate error site old computer name changed server reset connect manually using site new site number shows connected sql server site admin however look properties agent job shows owner site admin attempt browse users change site admin doesnt show option site admin script new job one manually change owner site admin new job created owner site admin looking sys servers via sp helpserver one entry current computer name however select servername returns original development machine name two name changes ago short cant run important sql server agent job belongs user longer exists cant figure change create correct user
12437 im trying use restore headeronly get date backup im restore made command restore headeronly disk path bak file works fine query analyzer gives resultset something like columns problem actually accessing code get temp table declaring every single one ish columns inserting exec getting value want problem really want avoid declare entire resultset temp table seems like brittle solution ever add columns future versions way get single column resultset without declaring columns
12453 net console app exe connects various sql databases using sql server authentication appropriate credentials change required exe use windows authentication use network credentials log sql server sql servers diffrent locations network credentials confused connect remote sql server using retrive data please help
12474 best practices configuring maintenance plan sql server currently im removing database backups transaction logs greater hours old backing problem ive seen transaction log still large including shrink database plan task
12512 added computed column table showing int id like make bit possible im hard time finding info computed column isactive case datedecommissioned null else end persisted
12564 reason specify tablename schema tablename instead schema tablename allow spaces tablename
12569 im new kind following scenario many tables sake simplicity represented view mysql database problem need value view representing one kind event another simple boolean tried achieve gu stoppinguniteventme ese monitoringelement isstopingevent result represented int read entity framework problem really need boolean return value tried achieve castgu stoppinguniteventme ese monitoringelement boolean isstopingevent resulted error one displayed mysql workbench receive annoying error guys please help tried solve application really preffer solved database since used software later
12580 imagine two different tables queries supposed return identical data want verify whats easy way show unmatched rows table like example comparing every column assume columns tables many nullable pk could duplicates per pk joining pk columns isnt enough would disaster full join join conditions properly handle nulls plus nasty condition exclude matched rows usually im writing new query unscrubbed fully understood data problem worst likelihood pk logically available extremely low cook two different ways solve problem compare results differences highlighting special cases data unaware result needs look like col1 col2 col3 col30 tablea cat mismatch tableb cat mismatch tableb cat mismatch tablea cat corresponding row tableb lizard null corresponding row col1 col2 happen composite key order final result easily see one row different one row example seeing first row twice desirable heres ddl dml set sample tables data create table dbo tablea col1 varchar10 col2 int col3 int col4 varchar10 col5 varchar10 col6 varchar10 col7 varchar10 col8 varchar10 col9 varchar10 col10 varchar10 col11 varchar10 col12 varchar10 col13 varchar10 col14 varchar10 col15 varchar10 col16 varchar10 col17 varchar10 col18 varchar10 col19 varchar10 col20 varchar10 col21 varchar10 col22 varchar10 col23 varchar10 col24 varchar10 col25 varchar10 col26 varchar10 col27 varchar10 col28 varchar10 col29 varchar10 col30 varchar10 create table dbo tableb col1 varchar10 col2 int col3 int col4 varchar10 col5 varchar10 col6 varchar10 col7 varchar10 col8 varchar10 col9 varchar10 col10 varchar10 col11 varchar10 col12 varchar10 col13 varchar10 col14 varchar10 col15 varchar10 col16 varchar10 col17 varchar10 col18 varchar10 col19 varchar10 col20 varchar10 col21 varchar10 col22 varchar10 col23 varchar10 col24 varchar10 col25 varchar10 col26 varchar10 col27 varchar10 col28 varchar10 col29 varchar10 col30 varchar10 insert dbo tablea col1 col2 col3 col4 col5 col6 col7 col8 col9 col10 col11 col12 col13 col14 col15 col16 col17 col18 col19 col20 col21 col22 col23 col24 col25 col26 col27 col28 col29 col30 values cat cat porcupine null tapir null null insert dbo tableb col1 col2 col3 col4 col5 col6 col7 col8 col9 col10 col11 col12 col13 col14 col15 col16 col17 col18 col19 col20 col21 col22 col23 col24 col25 col26 col27 col28 col29 col30 values cat cat lizard null porcupine null tapir null null
12581 im using classic time based partitioning using triggers found need separate trigger runs original table create table twitter interactions create replace function insert twitter interactions create trigger insert twitter interactions trig insert update twitter interactions row execute procedure insert twitter interactions create replace function maintain data pointers create trigger maintain data pointers trig insert update twitter interactions row execute procedure insert twitter interactions havent fully verified suspect partitioning logic runs maintain trigger since row doesnt end parent table 2nd trigger never fires happens want run insert update well since row doesnt make original table im loss implement logic
12596 ms sql supports tvp useful feature bulk uploading data stored proceedure processing rather create user defined type possible leverage existing table definition example possible create stored proceedure following signature create procedure usp insertproductionlocation tvp locationtable readonly documentation seems suggest possible sample code sample code http msdn microsoft com en us library bb510489 aspx use adventureworks2008r2 go create table type create type locationtabletype table locationname varchar50 costrate int go create procedure receive data table valued parameter create procedure usp insertproductionlocation tvp locationtabletype readonly set nocount insert adventureworks2008r2 production location name costrate availability modifieddate select getdate tvp go declare variable references type declare locationtvp locationtabletype add data table variable insert locationtvp locationname costrate select name adventureworks2008r2 person stateprovince pass table variable data stored procedure exec usp insertproductionlocation locationtvp go following part original source code create table locationtable locationname varchar50 costrate int go
12611 turned innodb flush log trx commit get fast write speed safe used production web site
12619 oracles document query optimizer view merging found following information view merging optimization applies views contain selections projections joins mergeable views contain set operators aggregate functions distinct group connect emphasis mine yet guess projection actually refers
12650 case identity insert set one database table time since identity columns arent globally unique cant think dangerous situation could caused inserting identities one table time least dangerous generally fudging identity insert identity insert rarely used reason hard limit
12655 sql server statistics updated automatically auto update statistics true default reason update statistics manually circumstances
12698 lets say following code please ignore awful begin tran declare id int select id id tablea update tablea set id id tablea must one row apparently commit tran id returned client used somewhere else eye managing concurrency properly transaction doesnt mean someone else wont read value get update statement leaving code realize better handled single statement even better using autoincrement identity column sure ways make handle concurrency properly prevent race conditions allow two clients get id value im pretty sure adding updlock holdlock select trick serializable transaction isolation level would seems work well since denies anyone else read tran update false see martins answer true work equally well one preferred imagine something legitimate id update calculation based read need update could many tables involved youll write others wont best practice written question think lock hints better locking tables need id appreciate anyones input dont know best answer really want get better understanding
12715 would like use two different tables one hold object active hold object becomesnon active id therefore unique per tables combined create constraint id id appears tables using sql server
12739 many times need write something like following dealing sql server create table table name column1 int column2 varchar200 insert table name execute stored procedure create table exact syntax result stored procedure tedious task example result sp helppublication columns want know whether easy way thanks
12769 would ever make sense application enforce database integrity instead foreign keys check constraints etc much performance improvement one expect enforcing database integrity internal database tools
12779 found handful rows db violate active constraint possible constraint active cant manually add row bypasses constraint however run checkconstraintsfiles find bypassed handful occasions test runs rows question created within half second one another suggesting kind race condition heres constraint applied table rule meant ensure name uniqueness given parent folder alter table files add constraint uniquenameinparentfolder check checkuniquenameinfolderparentfoldersid name constraint calls function looks like first check new name folders table select count folders parentfoldersid foldersid name name begin check files table select count files parentfoldersid foldersid name name return end return individual rows added inside transactions im hard time understanding duplicate rows sneaking past constraint
12809 question sql server index performance varchar2000 include covering index trying improve performance slow unstable database application cases data accessed large varchar strings queries including multple string operations like substring space datalength simplified example access update fattable set col3 substringcol3110 substringcol312datalengthcol3 fattable substringcol3101 col2 schema looks like create table dbo fattable id bigint identity11 null col1 nchar null col2 int null col3 varchar null following index defined covering field large text column create nonclustered index indexcol2col3 dbo fattable col2 asc include col3 read bad put large data fields index reading several articles including http msdn microsoft com en us library ms190806 aspx discuss impact paging disk size index performance said query plan definitely uses covering index enough information determine much actually costing terms system load know overall system performing poorly concerned one issues questions putting varchar2000 column index include ever good idea since include fields stored leaf nodes much impact index performance update thanks excellent replies unfair question ways guys say absolute right answer without actual statistics profiling like many performance issue guess answer depends
12810 demonstrated recent question mine locking concurrency hard suggest good resources intermediate advanced sql professionals thorough study would properly learned enable better navigation inherent pitfalls area im thinking kinds resources tutorials blogs manual pages pass sessions anything
12913 let preface saying total control db design lot aspects current system changed purposes scenario comments rethink aspects design likely correct unhelpful large table approx fields wide 600m rows drives large number processes data warehouse situation dont updates inserts outside scheduled load process heavily indexed decision made try partitioning table concerns indexing partitioned table dont experience partitioning input links appreciated couldnt locate specifically bol msdn currently cluster field well call incidentkey varchar50 unique could records ik comments please often get new data old incidentkey records sequential either understand need include partition field incidentdate clustered index key partition work correctly im thinking would incidentkey incidentdate question mechanics clustered index work part key partitioned table record new partition record old partition clustered index example records incidentkey date abc123 abc123 abc123 xyz999 xyz999 get new record abc123 need clustered index xyz999 work im assuming fragmentation pointers cant find info physical storage configuration non partitioned clustered indexes partitioned tables dual part keys
12941 im using sql coalesce function first argument null times ran first argument null second argument quite lengthy process select coalescec firstname select top firstname tablea join tableb example firstname john would sql server still run sub query know vb net iif function second argument true code still reads third argument even though wont used
12977 raid suitable mysql installation let explain application application socket programming connect gps device receive gps string processing socket programming another server db another server processing query db guess lots rite minimally processing minimum select insert minimum times even minimum also number updates hope clearer
12991 find ready use database models dont need database data schemas uml diagrams perhaps something like data models link much complex real world
13075 want connect oracle database located another host using sqlplus page suggested adding item tnsnames conenct database local sid description address protocol tcphost hostname networkport connect data sid remote sid use sqlplus sqlplus user pass local sid however circumstances modifying local tnsnames possible possible connect remote database using sqlplus argument without change tnsnames something like sqlplus user pass remote sid hostname network know one valid
13083 testing stuff added grant usage statistics cptnotsoawesome localhost identified password show grants cptnotsoawesome localhost see one grants cptnotsoawesome localhost grant usage cptnotsoawesome localhost identified password somepew pewstring want remove think security hazard revoke usage cptnotsoawesome localhost identified password flush privileges still shows usage grant grant list grants cptnotsoawesome localhost grant usage cptnotsoawesome localhost identified password somepew pewstring ideas wrong
13093 ran problem replication server essentially databases database1 database2 master server slave database1 replicate db database1 set change master configuration happened using code igniter one programers created database2 started inserting info code igniter sets default database database1 result every query produced get error show slave status error table database2 tbl40 doesnt exist query default database database1 query insert database2 tbl40 date day values essentially fixed problem afterwards replication doesnt work around queries produce error replication server question way clear queries like binlog need write script set global sql slave skip counter every query produces error
13112 difference common table expression cte temp table use one cte cte column1 column2 column3 select column1 column2 column3 sometable select cte temp table select column1 column2 column3 tmptable sometable select tmptable
13118 im seeing behavior right sql server r2 cant decide server underperforming ive set test insert integer table defined times dbo test1 id int identity11 text varchar2000 timestamp datetime null defaultgetdate application code inserting data sql server instance physical box results process taking almost minutes loop insert data really sure possible int using sqlconnection connection new sqlconnection server connection open using sqlcommand command new sqlcommand insert dbo test1 text select connection command executenonquery connection close edit update question per aaronbertrands response big specified integer loop dont care text may may go text column kind drives sata http www seagate com ww index jspvgnextoid 2ee06c02c732f110vgnvcm100000f5ee0a0arcrd database tiny yes possible issue database remote please read question closely everything physical box right front issues two boxes across network though im trying debug network issues right sql server insert issues good moneys autogrow issue right edit update machine vm application connection method researching since everythings box im sure connects triggers none resource governor set profiler profiler doesnt show delays whatsoever bugging hell blocking thing happening shouldnt blocking waits perhaps excluding log waits box everythings physical disk however big however boxes problem case pursue problem time
13167 weve number issues indexes lately dba team attributed statistics run recently made wonder check statistics recently updated via sql management studio apologize question isnt explaining well ive introduced statistics prior would look indexes whenever ive performance related issues edit im using following receiving syntax error use databasename exec sp autostats schema tablename error im receiving msg level state line incorrect syntax near
13190 im using red gate sql compare create release script based differences svn database results script containing bunch table procedure changes works fine however one thing puzzles using transaction isolation level serializable know dml statements im sure means ddl someone enlighten perhaps example
13243 understanding sql server generates undo files applying restore database using restore standby msdn documentation emphasis mine standby file used keep copy write pre image pages modified undo pass restore standby standby file allows database brought read access transaction log restores used either warm standby server situations special recovery situations useful inspect database log restores restore standby operation undo file automatically deleted next restore operation standby file manually deleted next restore operation entire database must restored database standby state treat standby file care database file unlike database files file kept open database engine active restore operations standby file name specifies standby file whose location stored log database existing file using specified name file overwritten otherwise database engine creates file size requirement given standby file depends volume undo actions resulting uncommitted transactions restore operation undo pass referred beginning understand operations written log file havent committed correct operations log file havent committed first place restore standby operation need store someplace able bring database read access words cant thrown away
13349 lets assume following situation oracle schema user user test create session privilege sys sysdba creates couple tables schema user test possible forbid access user user test tables schema
13455 learned school sql saves data tables right working project data stored xml files additionally every xml contains reference visual files jpeg xml contains one thousand coordinate points plus additional information data opinion would make sense store information tables besides couldnt store jpeg files sql either would appropriate solution error reasoning side see pretty new databases constructive suggestions links advice welcome
13468 ive read different upsert implementations postgresql solutions relatively old relatively exotic using writeable cte example im psql expert find immediately whether solutions old well recommended well almost toy examples appropriate production use thread safe way implement upsert postgresql
13470 database structure sql server types products requires different information order created one customers table three different orders tables ordersforproductas ordersforproductbs ordersforproductcs orders table one many relationship customers table also another table payments hold payment details inside doubts structure multiple product types customer may orders multiple products time need relate three order tables payments table issue customer may order one type product fk columns payments table needs nullable question whether nullable fk columns would headache long run generally speaking would considered bad practice nullable fk columns table
13518 running postgresql database server psql terminal front end ubuntu lucid lynx would like span single transaction several sequential psql sessions connect database psql new connection established server backend process connection created disconnect connection released backend process terminates non xa transaction bound scope connection obviously straight forward way span single transaction several psql sessions would like achieve following sequence commands run within single transaction therefore return transaction timestamp call tscho test sudo postgres psql align tuples select tscho test sudo postgres psql align tuples select database log cet log connection received host local cet log connection authorized user postgres database postgres cet log duration ms statement select cet log disconnection session time user postgres database postgres host local cet log connection received host local cet log connection authorized user postgres database postgres cet log duration ms statement select cet log disconnection session time user postgres database postgres host local clearly really want want able execute several bash scripts connect database execute sql statements scripts psql within single transaction afaik xa protocol would allow begin transaction prepare transaction different connections postgresql support first shot solve problem setup pgbouncer connection pool configure simple proxy exactly one connection target database session pooling mode reasoning pgbouncer would establish connection start connect disconnect proxy psql connection database keeps open tscho test sudo postgres psql pgproxy pgbouncer align tuples select tscho test sudo postgres psql pgproxy pgbouncer align tuples select actually works quite well database log shows cet log connection received host local cet log connection authorized user postgres database postgres cet log duration ms statement select cet log duration ms statement select cet log duration ms statement discard cet log duration ms statement select cet log duration ms statement discard little problem approach soon begin transaction proxy connection disconnect tscho test sudo postgres psql pgproxy pgbouncer align tuples start transaction start transaction connection released pgbouncer cet log duration ms statement start transaction cet log disconnection session time user postgres database postgres host local course makes perfect sense connection pool job provide shared connections several clients isolate transactions clients use case shared transaction exactly would need question way configure pgbouncer another connection pool release connection upon disconnection begin start transaction another way achieve would like questions post comments course answers appreciated
13522 creating stored procedure sql server allowed refer tables exist table exist column refer procedure must exist table deferred name resolution possible instruct sql server defer name resolution tables referenced procedure irrespective whether exist want keep general syntax checking even possible hacking stored procedure definition system table isnt option expect asking might seem little bit weird heres background auto generate table definitions stored procedures application written difficult change code order changes sql needs code guarantees schema consistent within transaction currently cant guarantee table columns defined define stored procedure references canonical example sql created illustrates problem im trying solve say table already exists create table mytable nvarcharmax go code creates something like begin tran go stored procedure gets generated first create procedure mysproc begin select ab mytable end table update alter table mytable add nvarcharmax commit tran possible fix code im hoping simple magic tweak pull sql save lot time
13523 database product write heavy bought new server machine ssd help surprise insertions faster old machine much slower storage benchmarking noticed io rate exhibited sql server process low example ran script found page except added begin tran commit around loop best could see disk usage reach 7mb cpu barely touched server 64gb installed using total run time minutes seconds first call around minute subsequent calls database simple recovery idle test dropped table call simple script slow hardware barely used dedicated disk benchmarking tools sqlio indicate ssd performs correctly speeds upward 500mb reading writing understand random writes slower sequential writes would expect simple insert like table without clustered indexing much faster ultimately scenario much complex feel need understand simple case first nutshell application deletes old data uses sqlbulkcopy copy new data staging tables performs filtering finally uses merge insert depending cases copy data final tables edit followed procedure linked martin smith got following result wait type wait count total wait ms resource wait ms signal wait ms network io logbuffer pagelatch sos scheduler yield writelog pageiolatch latch sh find weird network io takes time considering result display data transfer anywhere sql files network io type includes io edit created 20gb ram disk mounted database best time ssd 48s ram disk went seconds network io still biggest wait maximum write speed ram disk 250mb able multi gigabytes per second still wasnt using much cpu whats holding sql
13600 currently college student taking introduction oracle 10g seem make class time curious ask virtual oracle server something along lines would allow nutshell virtual database connect via sql plus enter commands learning running windows home premium thank much
13650 sql server execute queries parallel words run heavy query takes seconds execute time start another heavy query takes seconds second query actually start seconds start time
13668 poking around ssms noticed size int columns bytes expected bit shocked see bit columns whole byte misunderstand looking
13698 difference connection session related
13703 simple mysql table save highscores looks like id name score far good question get whats users rank example users name id want get rank rows ordinal ordered descending score example id name score ida boo lala bash assem case assems rank would got 3rd highest score query return one row contains required rank
13730 name tables creating new database singular client plural clients
13742 3gb database constantly modified need make backups without stopping server postgres pg dump runs minutes data modified process get consistent backups dont want find disaster strikes postgres documentation http www postgresql org docs static app pgdump html doesnt say anything
13744 looking various database types dbmss new project wanting start summer built systems mysql postgresql wanting expand knowledge experience databases project type social network aggregate knowledge thing still havent developed term describe yet looking cassandra use type query language seems good feature rich content delivering high performance query execution however keen requires java environment work would prefer nothing oracle mongodb nosql type dbms great scalability however lose capabilities already available proven sql language like business information queries requirements system data text dates times xml small ints blob structure behavioir normalised 3nf non realtime relational scalable robust environment unix linux java preferably run wondering could point database systems research also look object relational databases quite like idea working php objects pdos however performance seems bit poor seeing dbas feedback systems operated would appreciated thanks
13757 make sure app consistent state rollback uncompleted transactions case ok detach database need log file im particularly talking highly controlled environment real question explicitly force everything alright order avoid possible data loss anyone experience kind operation update reason im fan immense log files highly controlled environment pc running single app single user mode im developer app complete control code changes id prefer delete rather shrink please suggest simply shrink file udate practice ive process production half year without issue
13840 im trying understand software vendors decision keep date time separate columns example row created updated time date datetime columns using sql server database holds erp systems data believe largest tables contain million rows tables roughly rows would personally default choose single datetime single timestamp would allow easier time difference calculations date time parts could easily extracted timestamp would also consume less space separating date time bad practice something brilliant design dont understand
13851 basic knowledge sql sql server components goal master skills learn everything sql server eventually become dba future would like understand deep sql server internals exactly everything works could please suggest good place start imho possible programming work
13859 assuming multiple relations database example store employee sale want connect pairs simple binary relationship personally would create tables named employee store employee sale natural key composed foreign keys colleague insists creating one table multiple relationships example could table called employeelinks employeelinks idlink int pk idemployee int fk null idstore int fk null idsale int fk null linktype int null please help good reasons good idea arguments would like keep private hear unbiased opinions edit initially table would primary key foreign keys allow null surrogate key option
13882 background network approximately sensors data points collect minute intervals data points typically int values strings floats data stored days possible still efficient database design originally tasked project wrote app wrote comma separated files sensor time many someone wanted look trends would open csv excel graph needed things grew switched mysql database created table sensor yes know lots tables working well limitations many tables obviously impossible write query find data among sensors looking particular value next version switched microsoft sql server express put sensor data one large table also works lets us queries find values among sensors interest however ran 10gb limit express version decided switch back mysql rather invest sql server standard question happy mysql performance scalability uncertain sticking data one table approach best 10gb single table seems asking different design mention need query data graphing still im concerned performance issues query graphs example temperature data one sensor full days words graph something quick produce without waiting sql sort piles data isolate sensor interest split table way increase performance unusual large table indexes sensor id timestamp columns pretty much defining boundaries query get data sensor time time ive read little bit sharding partitioning dont feel appropriate case edit based comments answers far additional info may helpful indefinite storage currently store data past days daily run query removes data older days becomes important future store sufficient helps keep size check performance higher engine type original mysql implementation used myisam creating tables time new implementation one data table instead many theyve defaulted innodb dont believe requirement one normalization course tables besides data collection table support tables store things network information sensors login information users etc isnt much normalize far know reason data table many columns many variables sensor multiple temperatures light levels air pressure etc normalization means redundant data repeating groups least 1nf given sensor storing values particular time requires one row data relationships involved see could break apart table functionally making example temperature related values one table air pressure related values another might improve efficiency someone making temperature query still insert data still efficiency gain might worthwhile select operations obviously would better breaking apart table vertically based often users request data perhaps suppose asking question looking confirmation would worthwhile edit data usage ultimately much data never looked needed typically focus items problems attempting find problems use various tools search data determine items zoom example noticed correlation memory usage value customer specific proprietary software program reboot crash one data points collect relates memory usage able look historical data show devices become unstable particular memory usage exceeded today subset devices running software check value issue reboot command high discovered think collecting data value reason ive maintained data points collected stored even value questionable normal day day usage users typically examine perhaps dozen parameters user becomes interested particular geographic area may using software generate graphs spreadsheets data perhaps dozen sensors uncommon look day graph two three plot lines showing things temperature air pressure light levels would run query similar select sensor id location data timestamp temp1 air1 light1 data data timestamp sensor id original mysql version sensor table three separate queries would issued results combined software create graph data table contains many rows million despite indices id data timestamp performance notably worse multiple table scenario rows returned seconds opposed less one second example ability find sensors meet certain criteria practically zero multiple table schema thus reason moving single table type query done multiple users quick succession select different groups data compare graphs result quite frustrating wait nearly seconds per graph spreadsheet data discarded days could archived currently requirement hopefully information helps adequately show data used collection storage
13891 set scripts need run certain order would like create master file lists files correct order basically like include file asp vbscript
13911 tempdb server sql server increases 500gb several times every month possible find sql statements caused problem problem usually caused create table temp insert temp select temp complex joins initial size tempdb files also automatically set much bigger values every time prevent sometime cached plans prevent resizing shrinking files find one hold tempdb
13931 often repeated big data problem relational databases scale process massive volumes data created scalability limitations big data solutions like hadoop bound cant oracle rac mysql sharding mpp rdbms like teradata etc achieve feats interested technical limitations aware financial costs clustering rdbms prohibitive
14047 im creating database around tables every table containing tens millions rows table containing single important column primary foreign key column order maximise query efficiency face heavy updates insertions make heavy use clustered indexes two tables contain variable length textual data one containing hundreds millions rows rest contain numeric data really want squeeze every last drop performance hardware available 64gb ram fast ssd cores thinking allowing table file matter im joining tables table always read using separate thread structure file closely aligned table contents would hopefully minimise fragmentation make faster sql server add contents given table one caveat im stuck sql server r2 web edition means cant use automatic horizontal partitioning rules performance enhancement using one file per table actually maximise performance overlooking built sql server engine characteristics would make redundant second using one file per table advantageous create table give option allocate table file group specific logical file would require create separate file group every file scenario suggests perhaps sql server isnt envisioning advantages assuming would come im proposing
14155 database structure create table country name varchar40 null primary key name engine innodb default charset utf8 create table city name varchar40 null primary key name engine innodb default charset utf8 create table map country varchar40 null city varchar100 null primary key countrycity foreign key country references country name delete cascade foreign key city references city name delete restrict engine innodb default charset utf8 expect delete parent city leaving corresponding value child intact three equal commands foreign key city references city name delete action foreign key city references city name delete restrict foreign key city references city name using action restrict omitting delete mysql allow delete parent column error error delete update parent row foreign key constraint fails test map constraint map ibfk foreign key city references cityname delete restrict wrong isnt responsibility sqls action delete parent leave child orphan
14172 developing application oracle database havent documenting data model auditor wants entity relationship diagram database many tables creating erd visio manually question know toad database export er diagram option result exactly presentable ugly layout difficult edit know alternative way create presentable er diagram preferably nice resulting diagram editable also tool free
14246 couple questions familiar instances running antelope despite support barracuda looking play around compresses innodb tables understanding available barracuda format see innodb file format dynamic switch bounce implications aware tell means new tables subsequently altered created format correct hoping go convert tables kosher antelope barracude tables coexisting tablespace even works gotchas look ive read gathered tests answers yes yes im sure update ive running dynamic compressed tables various instances since post issue neglected read http dev mysql com doc refman en innodb file format identifying html time enable given innodb file format change applies newly created tables rather existing ones create new table tablespace containing table tagged earliest simplest file format required tables features example enable file format barracuda create new table compressed use row format dynamic new tablespace contains table tagged using file format antelope tables created antelope even allow barracuda mixing unavoidable unless specify every table row format dynamic compressed table indication complete dump reload introducing first barracuda table recommended upgrading major versions mysql
14327 installed oracle fdw successfully create extension oracle fdw foreign table shows following error server configuration problem env oracle postgresql create foreign server skytf create server oracle srv skytf foreign data wrapper oracle fdw skytf options dbserver manua create server skytf grant usage foreign server oracle srv skytf grant create mapping user skytf create user mapping skytf skytf server oracle srv skytf options user read password read create user mapping create foreign table skytf create foreign table ft test skytf id integer skytf name character varying20 skytf server oracle srv skytf options schema ocp table test create foreign table skytf skytf skytf skytf select ft test error error connecting oracle ocienvcreate failed create environment handle detail
14372 optimizing server application task uses database querying complex calculations data insertions execution task spends minutes tested times predictable time executed script alter index dbo tablename rebuild every table database see time execution task increased minutes whats going external influences task waiting increasing performance due rebuilding fragmented indexes got degradation
14388 suppose table foreign key constraint like create table foo fooid bigint primary key parentfooid bigint foreign key parentfooid references foo fooid insert foo fooid parentfooid values null update foo set parentfooid fooid table following records fooid parentfooid cases kind design could make sense typical employee boss employee relationship case im situation schema kind design unfortunately allows circularity data records shown example question possible write constraint checks feasible write constraint checks needed certain depth part question may relevant mention expect hundreds perhaps cases thousands records table normally nested deeper levels ps ms sql server update march 14th several good answers ive accepted one helped understand mentioned possibility feasibility several great answers though implementation suggestions well landed question look answers
14402 need keep track deleted items client synchronization needs general better add tombstone table trigger tracks row deleted server database basically adding new row tombstone table data deleted item keep items original table flag deleted typically column type bit indicate row deleted another column track delete occurred
14418 normal exact uses kb occasionally shoots query takes long total system memory 3gb running winxp specific amount ram recommended sql servers reason asking question could database problem uses much ram dont dba programmer also running multiple instances sql servers affect performance running multiple databases hit peformance use databases running old ones using sql server express huge database records
14490 msdn unlike derived table cte self referencing referenced multiple times query im using ctes quite lot ive never thought deeply benefits using reference cte multiple times query performance benefit im self join sql server scan target tables twice
14511 see code developers using implicit date conversion would like definitive answer select dba objects created mar
14535 requesting conceptual schemas government agencys information system research request denied grounds security risk dont really extensive database experience cant verify claim disclosing schema really big security risk mean pretty abstract divorced hardware software implementations explanation attacker could exploit conceptual schemas would appreciated thanks
14544 im confused tablespaces postgresql something like lvm mean disk getting full add another disk format create tablespace tblspace location media disk2 data enough manually alter databases tables indexes take benefit
14565 query select distinct email mybigtable account id takes 1s query select count total mybigtable account id email include result takes 2s query select count total mybigtable account id email select distinct email mybigtable account id takes minutes preparing state take much time table innodb 2mil rows mysql
14570 need add priority column table gets hit times second approx selects inserts updates column simple number1 priority matter inserts updates part primary key ill enforce separately basically dont want order range scan times second number executed drop massively index organised table guarantee priority always come priority running following query select table rownum slightly context typical query would select table modto numberto chartstampss1 done null country gbr rownum pk constraint iot would become priority rest pk separate constraint pk solely structure done null approximately table isnt selective anyway main index used think country done numberto chartstampss tested combinations came top long way completely unwilling add time queries 01s day added select minutes day wed much rather settle good enough perfection
14600 ive seen lot material covering business aspect ssas really much important aspects administration management point view administering instance sql server analysis services working dba know ssas manage correctly efficiently
14661 report shows count events past hours grouped hour sounds easy enough struggling include records cover gaps example table event eventtime datetime eventtype int data looks like need create result set one record every hour past hours regardless events hour assuming current time report would show roughly hour eventcount came solution uses table one record every hour day managed get results looking using union convoluted case logic clause hoping somebody elegant solution
14730 company facing decision whether purchase sql server denali sql server r2 new database server looking objective reasons choose one requirements standard edition financial reasons lack need enterprise features oltp workload means dont need new windowing functions column store indexes database size gb business intelligence features needed relational engine required synchronous database mirroring currently following reasons known sql server denali newest version available sql server r2 proven technology cant seem find lot technical reasons prefer one basically comes choosing proven technology running successfully vs newest greatest version available objective reasons make decision
14740 wrote script reindex indexes database one echo nreindex unq vbvdata vehicle started date log file psql username hostname dbname reindex index scm main unq vbvdata vehicle eq echo reindex unq vbvdata vehicle finished date log file else echo reindex unq vbvdata vehicle failed log file exit fi problem run script standalone mode psql prompting password every time runs also two limitations create user database password reindex locks tables use sleep num reindex automatic solution
14757 learn advanced sql programming improve ability sql reviewed database adventureworks need
14774 sql server tinyint stored 9b row reason seems additional one byte end null bitmap mask use tempdb go create table tbl tinyint null go insert tbl values go dbcc ind tempdbtbl go dbcc traceon page dump go console go dbcc page tempdb11683 go results reversed bytes due dbcc pages showing least significant byte first record size 9b taga 0x10 1b tagb 0x00 1b null bitmap offset 0x0005 2b integer column 0x01 1b column count 0x0001 2b null bitmap 0x0000 2b
14775 core mysql server gb ram holding myisam tables total 4gb data since databases size several times smaller available memory make full usage servers resources settings attempt configure cnf force data indexes stay memory
14789 researching something else came across thing generating test tables data running different queries find different ways write queries affects execution plan script used generate random test data exists select sys objects object id object idt type nu drop table go create table c1 int identity11 null c2 int null go insert select top select t1 number t2 number newid master spt values t1 cross join master spt values t2 t1 type t2 type order go update set c2 null c2 go create clustered index pk c1 go create nonclustered index c2 go given data invoked following query select c2 c2 null great surprise execution plan generated query sorry external link large fit someone explain whats constant scans compute scalars whats happening nested loopsinner join outer references expr1010 expr1011 expr1012 merge interval sorttop order expr1013 desc expr1014 asc expr1010 asc expr1015 desc compute scalardefine expr1013 expr1012 null expr1010 expr1014 expr1012 expr1015 expr1012 concatenation compute scalardefine expr1005 null expr1006 null expr1004 constant scan compute scalardefine expr1008 null expr1009 expr1007 constant scan index seekobject seek c2 expr1010 c2 expr1011 ordered forward
14791 need list columns table table definition order select syscolumns id object idmytable order colid examining syscolumns tables two columns look relevant colid colorder msdn article syscolumns says colid smallint column parameter id colorder smallint identified informational purposes supported future compatibility guaranteed tried run select syscolumns colorder colid yielded rows makes think columns values time look safest bet use colid however would curious know difference two columns difference also msdn article confirm colid reflects order table definition reasonable assume case could please let know sure case know
14864 im trying figure easy query test large table list entries least one blank null empty value column need something like select table anyt null dont want select table c1 null c2 null c3 null would huge query
14875 possible set database mysql use separate datadir im running userdir development sandbox server would like put mysql data files databases user home user mysql directory linux ubuntu server mysql server version storage engine type innodb would
14989 run following code select policynumber maxdecpageid decpageid risk statriskdecpages policynumber ar group policynumber risk get following results policynumber decpageid risk ar ar ar really want retrieve though policynumber maximum decpageid case would along risk numbers query also returning decpageid even though maximum decpageid policynumber different risk results would like returned policynumber decpageid risk ar ar figured different queries use return desired results dont think efficient queries came select policynumber maxdecpageid decpageid risk statriskdecpages policynumber ar decpageid select maxdecpageid statriskdecpages policynumber ar returns desired results dont want specify policy number query way call policynumber sub query outer query query came select t1 policynumbert2 decpageid t2 risk select policynumber maxdecpageid decpageid statriskdecpages policynumber ar group policynumber t1 left join statriskdecpages t2 t1 policynumber t2 policynumber t1 decpageid t2 decpageid like query specify policynumber time also expand query return info multiple policynumbers need know efficient way writing query seems little redundant might wrong think might better efficient way writing query suggestions
14996 get list partitioned tables database system tables dmvs looking
15063 column data type nvarcharmax wold like index however since big possible figured could create persisted computed column based column formula leftisnull fieldvalue however column also gets data type nvarcharmax cant create index possible index somehow without using full text index
15108 week resolve blocking chain sql server database caused long lived read lock access front end lock taken whenever user opens certain form released user finished scrolling form closes since many users open form reference locks stay around update table causes blocking suddenly nobody select table since theyre waiting first lock quite problem us since lots apps rely data understand locking behavior part access works linked tables ive solving problem activity monitor killing whichever select process head blocker whenever find problem takes time manually also reactive time hear already problem lot people id like know automatic way check long lasting blocking chains either emailed problem resolved automatically logic seems straightforward enough process matching select query blocking longer minute notify kill dont know implement sql server worth think proper solution fix rewrite app however due departmental politics option next months im looking stopgap
15186 audit tables useful came across reading article
15199 im building inventory database store enterprise hardware information devices database keeps track range workstations laptops switches routers mobile phones etc im using device serial numbers primary key problem im attributes devices vary dont want fields inventory table unrelated devices link erd part database fk relations shown im trying set example device workstation device type cant put phones table seems require use lot triggers validate device type class new tables anytime different device different attributes tracked mention one one relationships make joins nightmare one one relationships shown looked setting attribute tables mapped serial numbers would allow attributes apply device type assigned device someone could assign phone number attribute workstation wanted found explanation site gave following structure structure would work great attributes applicable items storing example database storing mobile phones attributes could things like touchscreen trackpad keyboard 4g 3g whatever case apply phones database would attributes like hostname circuittype phonenumber apply specific types devices want set attributes apply given device type assigned device type suggestions setup database im sure proper use one one relationships better way thank advance taking time look threads read gave good insight dont think really apply https stackoverflow com questions structure database inventory unlike items https stackoverflow com questions database structure items varying attributes https stackoverflow com questions product inventory multiple attributes https stackoverflow com questions question setting inventory database https stackoverflow com questions best represent items variable attributes database
15231 working back envelope calculation 100tb reporting database setup seeking thoughts experts proposed environment storage capacity 100tb tables sizes ranging 1gb 5tb mean size could lie 100gb 200gb etl jobs may require join tables 10s millions rows join keys ranging bytes bytes joins finish minutes live selects initially interested select speeds support selects second updates second relatively much smaller number ignored exercise need 24x7 availability independent db servers available serve select calls data replicated questions present looking oracle experience commercial opensource solutions large databases hardware os seen work best planning linux dell network storage netapp must issues foresee using commercial shelf disks hardware os ready much time would set aside setup configure db storage etc team compositions worked best environments observed mean various admins os admin oracle db admin required manage operate setup many might needed achieve 24x7 uptime approximation range db licenses network storage costs know dont environment details looking exact details approximation sufficient though questions might best answered managers interested admins perspective appreciate input
15241 question non clustered index included columns db ms sql server read blog optimized non clustered index maintenance gives information query plans update statements executed clustered index non clustered index defined table question non clustered index included columns im referring example provided blogger create table pk int int int int int int create unique clustered index tpk tpk create index tb tb create index tcd tcd create index te te new non clustered index included columns create index tf te includea insert values0 update set index tf defined update clustered index performed nonclustered index insert delete operations performed happen tf defined
15250 want case sensitive search sql query default mysql consider case strings idea case sensitive search sql query
15276 sql server user particular database ive asked grant access non system views database believe done editing securables type view granting select one many many views efficient way accomplish
15312 ive used full outer joins get desired results maybe dont fully understand concept able accomplish simple join tables il call t1 t2 fields t1 policy number premium t2 policy number loss trying get sum premium sum losses tables also policy number code using select sumpremium prem sum sumloss loss sum t1 policynumber t1 full outer join t2 t1 policynumber t2 policynumber group t1 policynumber code return correct sum totals group records isnt policy number match null policy number would like result look like policy number prem sum loss sum null null etc want result shows null policy number shown since thing null policy number total policy number tables dont match policy number prem sum loss sum null null select group t2 policy number instead t1 policy number get something like record policy number prem sum loss sum null null dont mind seeing null prem sum loss sum dont want null policy number would like results something like policy number prem sum loss sum null null ect thought full outer join would accomplish guess missing something thinking maybe could select group t1 policy number t2 policy number sub query maybe case outer query something dont think complicated ideas advice
15326 created database schema 11g express edition however apex tables dummy data safe delete also would like know apex means dollar sign thanks apex acl table apex ws files table apex ws history table apex ws links table apex ws notes table apex ws rows table apex ws tags table apex ws webpg sections table apex ws webpg section history table used sys create new user new user created along workspace database schema please see images
15335 explored clustered tree index system innodb think presence many null small columns significant effect innodb performance presence excess columns slow mysql performance tried practically test significant effect however think compared heavy load reason curious learn technical reasoning matter
15342 database called fdb created database pc sql server express edition added one table made backup database sql server version server copied backup server tried restore get message media family device program file microsoft sql server mssql mssql bacup fdb bak incorrectly formatted sql server process media family restore headeronly terminating abnormally microsoft sql server error
15350 using sql server later want add rowversion column large table however simply alter table tablename add rowversion rowversion null table unavailable updates long strategies use reduce downtime ill consider anything simpler better course ill consider strategy thinking last resort could maintain copy staging table maintained triggers sp rename staging table original table im hoping something simpler easier
15371 schema number views need check execution plans make sure appropriate indexes place used id rather copy paste output show create view viewname explain especially views built top views would quite pain
15388 better define foreign keys database code part application
15403 consider large set statistical data record int columns better keep entire set one table belong record creating another table connected one one relationship advantage former avoid join quick access statistical data corresponding record advantage latter keep column tidy first column read intensive second write intensive course think significant effect performance use innodb row level blocking general want know practical useful separate different sets data single record
15463 trying create following table mysql giving errors create table customer cus id int null auto increment cus name varchar cus dob date cus addr varchar cus email varchar cus tel varchar cus pw varchar cus joindate datetime cus lastaccess date error sql syntax check manual corresponds mysql server version right syntax use near cus dob date cus addr varchar cus email varchar cus tel varchar cus pw line
15506 ive got table holds two types notes collection notes delivery notes identical data structures hence using table create table notes id int identity11 null type int null customerid int null etc migrating data legacy system table requirement collection delivery notes sequential numbers previously implemented two sequence tables create table collectionnotesequence id int identity11 null noteid int null id column unique sequential id collection notes noteid foreign keys notes id getting towards time final real data migration setup seems hard work way could bin two sequence tables add noteno field notes table noteno would sequential depending note type composite key something new table might look like create table notes id int identity11 null noteno int null type int null customerid int null etc data would look like id noteno type customerid im using ms sql server
15530 create foreign key constraint table photos phpmyadmin later see constraint named photos ibfk next constraint called photos ibfk etc gathered tablename ibfk constraintindex convention db constraints mysql correct ibfk stand
15531 convenient myisam used store table corresponding file innodb made advancements many aspects wonder innodb stores databases one file ibdata1 default understand innodb map location data file individual index files tables understand mixes data one file importantly mix data databases server interesting feature myisam one copy paste database folder another machine use database without dump
15572 major differences unique key primary key mysql
15583 sql server using rank partition col2 order col3 desc return data set rank hundreds records partition get values rank want ranks partition example id name score subject joe math jim math tim math joe history jim history tim history joe geography tim geography jim geography want result select subject name rank partition subject order score desc table subject name rank math joe math jim history jim history joe geography tim geography jim want rank category
15595 percona differ mysql consider switching upgrading stock mysql percona add specifics situation almost exclusively use innodb understand percona done lot optimizing extensive foreign key constraints stored procedures finding present mysql poorly optimizing queries query goes joins build explicitly straight joins improve performance
15632 suppose table stuff column city indices including column populate table decide create index create index stuffoncityindex dbo stuff city asc database confirms create index succeeded newly created index immediately include existing entries table slowly built background words think creating index improve performance see improvement immediately upon create index completion
15682 number clients sql server thats server use backup files send databases back forth clients office read create backup sql server way restore onto instance assumed compatibility level would take care problem doesnt therefore loss upgrade upgrade clients impossible think clean way need send database client well receive database client first version upgrade sql server im new problem ideas proceed
15720 postgres table million rows ran update stops select id rank order offense timestamp defendant dl offense street number offense street name stop consistent master citing jurisdiction update consistent master set arrest id stops stop stops master id stops id query took hours run running physical core i7 q720 laptop processor plenty ram nothing else running vast majority time hdd space constraints table recently vacuumed analyzed reindexed whole time query running least initial completed cpu usage usually low hdd use hdd used hard app ran considerably slowly normal laptops power setting high performance windows x64 heres explain update master cost rows width cte stops windowagg cost rows width sort cost rows width sort key consistent master offense timestamp consistent master defendant dl consistent master offense street number consistent master offense street name seq scan master cost rows width filter citing jurisdiction hash join cost rows width hash cond stops id consistent master id cte scan stops cost rows width hash cost rows width seq scan master cost rows width citing jurisdiction excludes tens thousands rows even clause im still operating million rows hard drive whole drive encrypted truecrypt 1a slows things bit enough cause query take many hours part takes minutes run arrest id field index foreign key indexes foreign keys table fields query indexed arrest id field constraints except null table columns total arrest id type character varying20 realize rank produces numeric value use character varying20 rows citing jurisdiction use non numeric data field arrest id field blank rows citing jurisdiction personal high end year ago laptop user queries operations running locking seems unlikely triggers anywhere table anywhere else database operations database never take abornmal amount time proper indexing select queries usually quite fast
15729 using sqlite need store prices sqlites real data type says uses floating point unacceptable storage prices data type besides text use store prices numerically sort correctly
15730 ive got update trigger table watches specific column changing one specific value value happens updates related data another table via single update statement first thing trigger check see updated rows value column changed value question simply joins inserted deleted compares value column nothing qualifies bails early update statement doesnt run exists select top custnmbr inserted inner join deleted custnmbr custnmbr custclas misc custclas misc return case custnmbr primary key underlying table large update table say rows statement takes ages even havent touched custclas column watch stall statement several minutes profiler execution plan bizarre shows inserted scan executions million output rows runs filter custclas column joins via nested loop deleted scan also filtered custclas executes output rows idiotic thing cause note trigger absolutely must properly handle multi row updates edit also tried writing like case exists something unpleasant still terrible declare custnmbr varchar31 select top custnmbr custnmbr inserted inner join deleted custnmbr custnmbr custclas misc custclas misc custnmbr null return
15846 way deny drop permissions specific table user role
15859 payment table agents get commission payments commission based different factors long took get payment calculations involved figuring commission rate agent gets nothing obscenely complex example probably never complex select payments amount case datediffyear client received payments datepaid rates rate1 datediffyear client received payments datepaid rates rate2 else rates rate3 end would make sense build 2nd table hold data instead querying anytime needed stick run time queries pull data whenever requested importantly factors use determining query run anytime data needed data stored separate table
15860 anyone know ms sql server text queries optimised upper lower case strings read somewhere uppercase cant seem find reference course entierly wrong optimisation takes place would also useful know thanks help cm
15878 table producers table products form id int primary key name nvarchar producer carry multiple products going create table called producerdetails would producerid int foreign key producers id productid int foreign key products id started question thought id ask experts would better database design additional id int primary key column producerdetails table unnecessary im using sql server r2 make difference edit relationship tables would many many believe sorry didnt make clear producer carry multiple types products product could produced multiple different producers apologize question overly simple referential integrity database design strongsuit although im trying improve
15906 application one table growing million lines rest million advice go innodb file per table leave one ibd read articles say go need disk access joins performed join table others reporting generation purposes
15994 thought writing simple tail like utility trace progress figures within database create replace function tail return varchar2 tab pipelined number begin loop exit select count pipe rowsysdate dbms lock sleep60 end loop return end tail id like select tabletail sql plus order fetch rows one one set arraysize yet records except first one fetched pairs explanation get records soon one piped
16002 im conceptual model survey database goal store answers given users going android app three entities user question option question one options example many employees options text value value selected user user select one options conceptual design dont know associate answer user represent relation another entity represent option value model store questions pre made answers offered answers allows used different surveys represent question like one question related one survey database design first version errors
16127 need manually retrieve rows sql server database backup normally create new database restore database backup new database run queries database huge however takes forever restore easier way get older data
16201 trying figure nice way hard time finding right pieces guessing must possible put simple terms would like accomplish php front end socket locally hosted pooler pool persistent tcp ip connections externally hosted mysqld tool way things exist would basically like implement persistent mysql connections without using mysql pconnect respectfully ask start discuss persistent connections needed etc running time wait ports issues would solved type system implemented yea summarize would implement mysql connection pooler socket based local end persists connections made lan externally hosted mysql server use transactions anything else would affected mysql connections recycled running linux front end master master percona cluster thanks
16208 many articles exaggerating imho course need innodb file per table understand innodb file per table better control individual tables like backup table separately however claim better performance questionable test difference performance innodb file per table ibdata1 database 60gb course simple test normal queries situation different complicated queries real life reason asked question bit linux ext4 effectively handle large files innodb file per table disk operations needed significant complicated joins foreign key constraints tablespace shared single ibdata dedicated tablespaces separate tables save disk space course easier free table space table alter still expensive process table lock question innodb file per table effect better performance mysql yes
16211 getting interested nosql technology read several posts se works different products available however wonder canonical references books articles site research paper example read good overview benefits disadvantages works
16372 creating tables multiple joins use analysis preferred use views versus creating new table one reason would prefer use views database schema developed administrator within ruby familiar ruby request tables created requires additional step would like flexibility developing testing new joins started using views following answer related question use use sql top voted answer begins data manipulations sql data single table rest started using views run issues views queries much slower views get dumped production backup database use analysis views appropriate use expect performance penalty way speed queries views
16397 problems decided create users except root localhost works fine newly created user right anything want simply give rights root local ip root localhost tried create user root grant root first command works second one fails message error access denied user root localhost dont get root localhost cant everything im sure didnt mess privileges show grants root localhost get grants root localhost grant select insert update delete create drop reload shutdown process file references index alter show databases super create temporary tables replication slave replication client create user root localhost grant option grant privileges root localhost grant option whatever means missing needed privilege fixed im working mysql ver distrib debian linux gnu x86
16433 nvl stand im talking oracle informix perhaps others function used filter non null values query results similar coalesce databases
16436 alright feel like terrible idea need help understanding bad im still working implementing disaster recovery business continuity solution datacenter running mssql enterprise plan running passive instance cloud currently im suggesting log shipping ive asked explore using rsync something similar push mdf ldf file deltas cloud instead using internal tools goal would reduce footprint run cloud sql instance time due licensing issues passive dr license already use current datacenter center goes license becomes available ive found solution uses vss create push deltas even files locked im wondering sorts issues could show get insight would pushing deltas every minutes database question roughly 2gb maybe mb logs generated minute window
16461 table stores unix timestamp query date im attempting convert timestamp datetime type view unfortunately seem get date portion link describes conversion requires changing nls date format include time portion default currently shows date portion need date time unfortunately solution works session level developer id rather go running managed service provider ask change value database level especially since may impact applications way convert timestamp sql datetime without modifying system
16484 need change procedures packages database due migration accomplish weekend migration one server exadata however database developed sloppy way bank carries number text files written directly disk nobody uses directories exadata path writing files different due use dbfs must change calls via utl file let give example currently code file utl file fopen file folder documents filename want create directory create replace directory directory name file folder documents change procedures file utl file fopen directory name filename migration change directory create replace directory directory name dbfs documents real question way make search replace changing procedures database mean theres way change file folder documents directory name
16493 besides using sql server profiler way track stored procedures used least last executed
16554 following question normal form surrogate key violate thought 3rd normal form im quite sure assumption making could someone explain
16587 application intermittently break connection sql server instance requires function good way go troubleshooting type problem kind log sql server logs something drops connection purpose understand anything application database could causing connection lost dont think network connectivity issue client server application served via citrix xenapp instances running host trouble around point time saw problem matters sql server enterprise edition application visual foxpro based application served client machines via citrix xenapp problem rare intermittent times day hundreds clients also sql server citrix running virtualized server infrastructure tl dr troubleshoot intermittent database connectivity loss update message application error log problem happens connectivity error microsoft odbc sql server driver communication link failure time ive seen message sql server completely overloaded actual network connection problems disconnected dont think either two things case instance
16612 following table index definitions create table munkalap munkalap id serial primary key create table munkalap lepes munkalap lepes id serial primary key munkalap id integer references munkalap munkalap id create index idx munkalap lepes munkalap id munkalap lepes munkalap id none indexes munkalap id used following query explain analyze select ml munkalap join munkalap lepes ml using munkalap id query plan hash join cost rows width actual time rows loops hash cond ml munkalap id munkalap id seq scan munkalap lepes ml cost rows width actual time rows loops hash cost rows width actual time rows loops buckets batches memory usage 115kb seq scan munkalap cost rows width actual time rows loops total runtime ms even add filter explain analyze select ml munkalap join munkalap lepes ml using munkalap id lezarva query plan hash join cost rows width actual time rows loops hash cond ml munkalap id munkalap id seq scan munkalap lepes ml cost rows width actual time rows loops hash cost rows width actual time rows loops buckets batches memory usage 4kb seq scan munkalap cost rows width actual time rows loops filter lezarva total runtime ms
16616 taught use name id identity column tables lately ive using anyways simple short descriptive data actually ive seen people suggest prefixing id table name seems make work person writing sql queries programmer youre using orm like entity framework particularly longer table names customerproductid agencygroupassignementid one third party vendor hired create something us actually named identity columns ident avoid using id first thought id keyword looked found id isnt keyword sql server using people recommend using name id identity column edit clarify asking naming convention use arguments use one naming convention want know recommended use id identity column name im single programmer dba database place store data since usually build small apps typically use orm data access common field name identity field much easier work want know missing really good reasons
16725 taught mssql classes join two tables select firsttable join secondtable id id professional life came across join queries like select firsttable secondtable id id know second option norm perhaps abandoned find complex queries join tables number sub queries second form lot easier understand short pretty questions one use advantage one
16763 question script around thousand insert select statements try run get error message stating run memory get script run context added new data fields make app play nice another app client uses got spreadsheet data client full data mapped current data items values new fields converted spreadsheet insert statements run statements works entire script typos different way loading data feel free chastise let know
16809 ive read article mentioned achieve inserts per second using load data file statement reads csv files inserts data database differ normal inserts edit reduced round trip calling one insert statement insert tblname values null2some text here0null2some text here1 null2some text here2null2some text here3 null2some text here3000
16846 setting mysql database accounting software one fields save currency used transaction field type would recommend details different currencies used currencies three letter iso names currency column sometimes used case statement sometimes statement table quite large want make optimal choice storage size issue speed lesser extend ease use considering using char field saving currencies usd cad etc using enum field defining currencies options using tinyint field relating another database holds iso code currency using tinyint field instead relating database joins save list static non changing currencies php array saves joining still allows use tinyint anybody suggestions would best
16875 previously saved copy var lib mysql ddms directory ddms schema name installed new mysql freshly installed ubuntu lts running apt get install mysql server believe version installed copy ddms directory var lib mysql tables work fine tables associated set three files frm file myd file myi file however two tables different set files frm file ibd file two tables didnt show table list phpmyadmin look error log says error find open table ddms dictionary item internal data dictionary innodb though frm file table exists maybe deleted recreated innodb data files forgotten delete corresponding frm files innodb tables moved frm files another database table contains indexes version engine doesnt support please help restoring two tables thanks
16884 im oracle dba also sybase experience major architectural conceptual differences two rdbms platforms answer similar sql server oracle question would use
16895 writing stored procedure takes database name argument returns table databases indexes fragmentation level stored procedure live dba database db contains tables dbas use monitoring optimizing things systems question sql server r2 makes difference basic query worked stuck trying provide indexes actual names best knowledge information contained individuals sys indexes view specific problem trying reference view programmatically another databases stored procedure illustrate portion query issue sys dm db index physical stats db idnullnullnullnull inner join sys indexes object id object id index id index id index id query works fine executed database identified db id using proper sys indexes view try call dba database however comes null sys indexes view wrong database general terms need able something like declare db name nvarchar255 database select db name sys indexes use db name tried switching databases referencing databases using combinations string concatenation object name object id db id functions nothing seems work id appreciate ideas community might suspect retool stored procedure reside individual database thanks advance suggestions
16956 anyone point good sql sniffer watch sql commands run database real time free would great
16969 cpu intensive opening closing db connection web app mysql db software localhost db software another machine
16993 cant believe make hard loss view data database easy way see data tables pgadmin iii alternatively program could use suck
16999 sure whether less appropriate place ask question originally posed stack overflow sql server view tables looks roughly like create view select union select reading causes query take intent shared locks base tables also takes intent shared lock view object clear need locks tables see lock view prevents concurrent modification tables underlying view thats fine query plan contains mention view completely compiled resulting plan case simple concatenation rows two base tables indeed mention view query plan xml statement text add second view tables reading cause lock taken rules engine takes lock views database engine know take lock view statement text parsed channel information query planner underlying execution pass information latter details mechanism storage engine knows lock view fairly considered internal however fact user visible would expect documented somewhere
17030 im trying add column database query running 25mins locking web access table breaking website alter table mytable add mynewcolumn varcharmax null default table contains binary data different column quite large cancelling using red cancel executing query button cause additional problems im trying figure attempt cancel query point happen since running long
17057 one table taking close hd space server decided drop columns free space need return space os problem though im sure happen run vacuum full enough free space make copy table understand vacuum full used figured best option scenario ideas would appreciated im using postgresql
17069 sql server possible primary key set columns without either clustered nonclustered indexes set columns aware fact primary key clustered index key separate concepts create primary key without clustered index see alter table dbo sample add constraint pk sample seqguid col1 primary key nonclustered seqguid col1 question see possible create primary key table without clustered nonclustered index
17092 purely theoretical question lets say application deployed multiple servers load balancer multiple scalable applications servers single database server moment two first parts know look database server kind hardware look cpu frequency relevant database server multiple core cpus relevant ram important cpu ps supposing chosen database mysql postgresql
17103 possible sql server r2 standard automatically execute stored procedure given database restored attachced instance ive got close solution creating server level trigger executes stored procedure given database ddl event create database alter database fired unfortunately work databack backup restores elaborate clean stored procedure exists every database restore im looking way get executed automatically whenever backup restored instance googling pointed configuring either audits policies sql server get functionality features quite overwhelming first glance cant tell audits polices avenue start investigating
17197 im working accounting system transaction need save either debit credit think two ways mysql database method amount decimal type enum debit credit method debit decimal credit first setup save type transaction second way rather save amounts debit credit column pros method easily sum debit credit totals method wondering common way
17217 child table something like cust date table customer id date balance would like able get result set like one record client latest date customer id date balance know individual customer id following sql sql server syntax select top date customer id balance cust date table customer id order date desc customer id date balance im sure get three records want im sure situation calls sub query something else please note max date different given customer id example customer 3s maximum date whereas records max date tried select customer id max date latest date balance cust date table group customer id balance problem doesnt return one row customer returns multiple rows
17265 connected production server sql server powerful machine select statement takes seconds spitting back fields mb data total select top person withnolock box network connecting using sql authentication windows authentication query takes minute seconds testing simple statement illustrate indexing problem query related problem performance issues queries moment rows come chunks get first rows instantly wait minute batches rows come client statistics query ran remote box query profile statistics number insert delete update statements rows affected insert delete update statements number select statements rows returned select statements number transactions network statistics number server roundtrips tds packets sent client tds packets received server bytes sent client bytes received server time statistics client processing time ms seconds total execution time ms wait time server replies see client processing time equal total execution time anyone know steps take diagnose transfer actual data taking long time sql configuration parameter restricts limits data transfer speed machines
17267 need aggregate function mysql doesnt provide would like mysqls flavor sql im stuck creating aggregate function docs dont seem mention done examples desired usage product function mysql select productcol table row set sec mysql select col productcol table group col col rows set sec
17277 know shrink devil reverses page order responsible skin cancer data fragmentation global warming list goes said say gb database delete gb data one table general pruning old data database wide level covering tables constitute appropriate use case shrinking database appropriate steps take clean house removing high percentage data database think two rebuild indexes update stats else
17302 anybody using hierarchyid real production tables reasonable size thousand rows reliable performant far found anyone affiliated vendor recommend paul nielsen advises experience using hierarchyid actual production systems criteria used choosing hierarchyid alternatives
17339 copied database working could change key elements design new version want delete totally tables database however due foreign key constraints view foreign key constraints exist table delete foreign keys table viewing doc 2008r2 understanding sys foreign keys
17367 importing gb foobar sql restore table local database mysql localhost root data foobar sql mysql version usr local mysql bin mysql ver distrib apple darwin9 i386 using readline monitor progress
17398 powerful machine gb ram created one oracle instance gb sga target able create another oracle instance sga target 10g even keep first database set sga target 10g gives error startup ora system defined limits shared memory misconfigured free shows enough memeory available though total used free shared buffers cached mem buffers cache swap need increase swap space pointer regard highly appreciated also gb memory creating many instances would best value swap space way caluculate objective least two instances sga target 20g keep one instance time missing concept output ipcs im shared memory limits max number segments max seg size kbytes max total shared memory kbytes min seg size bytes
17431 myisam faster innodb myisam needs disk reads data innodb uses buffer pool indexes data myisam index
17439 project could benefit using database experience databases dont access server relatively little experience working things living server side im going tackle learning curve id prefer learn something broad applicability sql would settle learning something like access sufficiently powerful task im currently trying tackle course id also rather drop access helped since im tinkering ive downloaded libreoffice base well something called sqlitebrowser wanted check first invest time learning particular applications flavors sql whether tools sufficient want want able import data csv excel run queries equate select contains contain write new field indicates results match given query im willing learn would nice learn bunch intermediate stuff focus learning databases necessary particulars given application
17529 mysql servers say abc want want make master well slave update mysql servers replicated servers studied circular replication found implemented anybody please give steps accomplish replication stated three servers one point want ignore tables database also also caveats type replication
17533 wonder know necessary write commit insert delete update function procedure example create replace function test fun return number begin delete return end procedure create replace procedure aud clear pro begin delete end need commit delete understand following situation call function procedure sql window requires commit schedule function procedure using dbms scheduler run job delete statement automatically committed
17615 suppose parent table parent referenced child table child table parent populated child attempting truncate parent results ora unique primary keys table referenced foreign keys way hint dbms child empty foreign key constraint doesnt need disabled
17653 want update tables 10s millions records problem taking much time update process also time cpu usage also goes high want way use much cpu processing data processing time increased problem use limited cpu resources processing updating table using postgresql database server operating system linux sample query mine like update temp set customername select customername user user customerid temp customerid
17691 checking propaganda page postgresql found little piece art turtle style postgresql logo old postgresql ever officially use turtle instead elephant story
17711 need store bit array record table supporting following operations testing bit set setting bit using sql querying setting value using ado ado net indexing order benefit covering index feature maximum number bits stored array fixed may exceed simple int column doesnt always work ive seen far options use several int columns use bigint works long number bits use binary first option would work require quite bit refactoring code accesses data second option temporary relief searches far im sure ado works well bigint experience binary im aware options data type would choose given requirements
17761 take look following sqlfiddle http sqlfiddle com dacb5 create table contacts id int auto increment primary key name varchar20 network id int network contact id int insert contacts name network id network contact id values john alex bob jeff bill walter jessie basic table contacts network id network contact id fields contain id numbers link tables want able run insert ignore queries table want use combination network id network contact id unique key match example tried insert contact network id network contact id insert ignore query would see entry already exists ignore error thrown basically network id unique network contact id unique combination two unique set would single field concatenated values two fields way setup keys table need
17790 must missing something regards setting postgresql id like create multiple databases users isolated specific user access databases specify however determine created user access databases without specific grants given ubuntu server apt get install postgresql sudo postgres createuser drsp mike1 specifying password new user sudo postgres createdb data1 psql localhost mike1 data1 specifying password user mike1 login seems new user mike1 problem connecting database data1 creating tables etc without running grant command owner data1 postgres since didnt specify owner step really supposed work id like grant mike1 full access data1 repeat users databases making sure users access one possibly several databases choice
17808 two tables deal dealcategories one deal many deal categories proper way make table called dealcategories following structure dealcategoryid pk dealid fk dealcategoryid fk however outsource team stored multiple categories deal table way dealid pk dealcategory store multiple deal ids separated commas like feel wrong dont know clearly explain right explain wrong maybe im one whos wrong acceptable
17853 inspired django modeling question database modeling multiple many many relations django db design something like create table book bookid int null booktitle varchar200 null primary key bookid create table tag tagid int null tagname varchar50 null primary key tagid create table booktag bookid int null tagid int null primary key bookid tagid foreign key bookid references book bookid foreign key tagid references tag tagid create table aspect aspectid int null aspectname varchar50 null primary key aspectid create table tagaspect tagid int null aspectid int null primary key tagid aspectid foreign key tagid references tag tagid foreign key aspectid references aspect aspectid issue define bookaspectrating table enforce referential integrity one add rating book aspect combination invalid afaik complex check constraints assertions involve subqueries one table could possibly solve available dbms another idea use pseudocode view create view bookaspect view select distinct bt bookid ta aspectid booktag bt join tag tagid bt tagid join tagaspect ta ta tagid bt tagid primary key bookid aspectid table foreign key view create table bookaspectrating bookid int null aspectid int null personid int null rating int null primary key bookid aspectid personid foreign key personid references person personid foreign key bookid aspectid references bookaspect view bookid aspectid three questions dbms allow possibly materialized view primary key dbms allow foreign key references view base table could integrity problem solved otherwise available dbms features clarification since probably satisfying solution django question even mine im interested general strategy possible attack problem detailed solution answer like dbms done triggers table perfectly acceptable
17893 given optimizer take time needs minimize execution time contribute explore possible execution plans sometimes get cut wondering overridden give optimizer time needs certain amount milliseconds dont need atm imagine scenario complex query executed tight loop want come optimal plan cache hand course tight loop rewrite query goes away bear question curiosity also see sometimes difference short circuited optimization full one turns give optimizer time trace flag exactly asking comes close best information found query processor modelling extensions sql server sp1 ian jose use trace flag care useful coming better plans see also articles tagged optimization level grant fritchey upgrade sql server brent ozar tuning options sql server running high performance workloads microsoft support thinking queries lots joins solution space join order explodes exponentially heuristics sql server uses pretty good wondering optimizer would propose different order time range seconds even minutes
17904 sql server varchar column value may may may may may convert column datetime column real datetimes possible create new column copy values datetime values
17921 ive got customer comments split multiple rows due database design report need combine comments unique id one row previously tried something working delimited list select clause coalesce trick cant recall must saved cant seem get work case either seems work single row data looks like id row num customer code comments dilbert hard dilbert worker wally lazy results need look like id customer code comments dilbert hard worker wally lazy row num theres really one row results comments combined order row num linked select trick works get values specific query one row cant figure make work part select statement spits rows query go whole table output rows im combining multiple columns one row pivot doesnt seem applicable
17926 everyone knows tables use innodb engine queries like select count mytable inexact slow especially table gets bigger constant row insertions deletions query executes understood innodb doesnt store row count internal variable reason problem question would hard store information important information know many situations difficulty see internal count would implemented transactions involved transaction uncommitted count rows inserted ps im expert dbs im someone mysql simple hobby asked something stupid dont excessively critical
18024 large tens millions records database going perform full database backup however database large enough transactions start well commit backup takes place example t0 transaction start t1 full database backup start t2 transaction start deadlock t3 transaction commit rollback matter t4 full database backup end t5 transaction commit rollback matter t0 t1 t2 t3 t4 t6 understanding locks used backup although performance problems may arise due say high im sure guarantee committed also concern isnt database inconsistent state rather state even deterministic theres set rules consistently applied got example much data file used along transaction log create backup file
18042 sql server database datetime column good way create new column represents long value datetime column long would represent number seconds thought convert longs would make easier group queries time periods could divide long number fixed amounts table static wont updating deleting data
18059 using methods create copy table lose indexes pk fk etc example sql server say select dbo table2 dbo table1 simple copy table indexes constraints missing copy table structure without using backup primarily looking manually thats possible ill accept solution
18208 past weeks ive raging old firebird database database crappy sorts reasons one thing noticed every single field every single table two indexes one single segment one asc order one desc order apart wtfness index every field every table got thinking advantage single segment indexes two indexes index segments one desc one asc anything gained would modern dbms simple use asc index start end work way backwards required
18215 added new column table column cn unique mandatory old data dont value update existing records sequecely random unique data thank
18239 better way rewrite select clause multiple columns use case conditions conditions checked see example select case teststatus authorized completed progress cancelled end status case teststatus authtime cmpltime strttime canctime end lasteventtime case teststatus authby cmplby strtby cancby end lasteventuser test non sql psuedo code code might look like case teststatus statuscol authorized lasteventtimecol authtime lasteventusercol authuser statuscol completed lasteventtimecol cmpltime lasteventusercol cmpluser end note aware obvious normalization issues implied query wanted demonstrate issue
18300 asking question specifically postgres good supoort tree spatial indexes following table tree structure nested set model words frequencies lexikon id integer primary key word text frequency integer lset integer unique key rset integer unique key query select word lexikon lset low high order frequency desc limit suppose covering index lset frequency word would useful feel may perform well many lset values high low range simple index frequency desc may also sufficient sometimes search using index yields early rows match range condition seems performance depends lot parameter values way make perform fast regardless whether range low high wide narrow regardless whether top frequency words luckily narrow selected range would tree spatial index help adding indexes rewriting query designing table limitation
18315 context developing system large ish database bottom ms sql database running sql server r2 total size database gb approximately gb single table binarycontent name suggests table store simple files kind directly table blob recently weve testing possibility move files database file system using filestream necessary modifications database without problems system still working fine migration binarycontent table looks roughly like create table dbo binarycontent binarycontentid int identity11 null filename varchar null binarycontentrowguid uniqueidentifier rowguidcol null primary filestream filestreamcontentfg alter table dbo binarycontent add filecontentbinary varbinary max filestream null alter table dbo binarycontent add constraint dfbinarycontentrowguid default newsequentialid binarycontentrowguid everything residing primary file group except field filebinarycontent separate file group filestreamcontentfg scenario developers point view would often like fresh copy database production environment able work latest data cases rarely interested files stored binarycontent using filestream almost working wed like back database without file stream like backup database filestreamdb filegroup primary disk backup filestreamdb withoutfs bak init restore like restore database filestreamdb disk backup filestreamdb withoutfs bak seems working ok system works long avoid parts use filebinarycontent field instance run following query without problem select top binarycontentid filename binarycontentrowguid filecontentbinary dbo binarycontent naturally un comment line including filecontentbinary query get error large object lob data table dbo binarycontent resides offline filegroup filestreamcontentfg accessed system handles files content set null would like something like update dbo binarycontent set filecontentbinary null course gives error point im stuck question way restore database without also restore everything filestreamcontentfg file group either updating values null im trying default null file missing something perhaps approaching problem wrong way im developer nature much knowledge dba excuse im overlooking trivial thing
18339 believe understand reasons behind fenced unfenced stored procedures fenced run outside database case db2 prevent possible corruption database engine issues things like pointers unfenced runs inside database means performance better also researched sql pl always basically unfenced sql therefore access memory like programming languages java procedures run fenced unfenced since possibly access memory consideration running fenced unless certainty quality code crash needs performance first correct understand next generally best practice start stored procedures even defined sql pl fenced first best practices stored procedures especially related fencing security edit research shown sql pl procedures run fenced since contain code could harm database engine pointers file db2 knows safe runs inside engine ie unfenced said still looking best practices regarding stored procedures
18372 used alter index rebuild remove index fragmentation cases rebuild seem remove fragmentation reasons rebuild remove fragmentation seems happens especially small indices
18399 suggested repost stackoverflow currently table need start adding new data columns every record even going forward new data adding new data columns data wondering suited new table since really extension data rows applicable every row words since lot unused columns new data elements seems like would suited new table first table record page views currently 2million records id ip address times viewed created timestamp date every ip address record made per day consecutive pageviews added times views per day additional fields would point origin tracking ie google analytics source medium campaign every visit info im would assume rows data usually attributed first visit main use data would attribute people came may wind used frequently seems lend single table appreciate feedback add needed
18433 master slave replication setup looks like running fine result show slave status command show slave status row slave io state waiting master send event master host master user repliv1 master port connect retry master log file mysql bin read master log pos relay log file mysqld relay bin relay log pos relay master log file mysql bin slave io running yes slave sql running yes replicate db data1 replicate ignore db replicate table replicate ignore table replicate wild table replicate wild ignore table last errno last error skip counter exec master log pos relay log space condition none log file log pos master ssl allowed master ssl ca file master ssl ca path master ssl cert master ssl cipher master ssl key seconds behind master master ssl verify server cert last io errno last io error last sql errno last sql error would like understand relay log file relay log pos relay master log file questions true relay log file one read stored locally replication run relay master log file different master log file values viz read master log pos relay log pos showing even though replication complete sync true files binary format hence view
18463 possible view delete statements recently occurred transaction log
18495 following solution https stackoverflow com questions howto clean mysql innodb storage engine comment14041132 tried increase innodb buffer pool size 4g later 1g also 1024m addition log file size mysql wont start values put back 512m mysql starts fine solve server 16gb one according webmin sysinfo real memory gb total gb used meanwhile found error log well mysqld safe mysqld pid file var run mysqld mysqld pid ended mysqld safe starting mysqld daemon databases var lib mysql note plugin federated disabled innodb innodb memory heap disabled innodb mutexes rw locks use gcc atomic builtins innodb compressed tables use zlib innodb using linux native aio innodb initializing buffer pool size 0g innodb completed initialization buffer pool innodb error log file ib logfile0 different size bytes innodb specified cnf file bytes
18593 embark migrating database files new san old san abd couple options implement suggested look level effort restoring full backup new database server however original plan copy files old san new san detaching reattaching database gut tells id rather detach copy attach since seems fail safe may na vety dont want miss transaction somehow break something process renaming databases guess question whether justified skepticism backup restore replay option merits risks option
18610 today troubleshooting service broker problem discovered database owner windows login employee left company login removed thus query notifications failing supposedly best practice dealing make sa database owner changed cleared queue elementary question database owner purpose
18637 ive got query like following delete tblfestatsbrowsers browserid select distinct browserid tblfestatspaperhits nolock browserid null tblfestatsbrowsers got rows tblfestatspaperhits got rows tblfestatsbrowsers create table dbo tblfestatsbrowsers browserid smallint identity11 null browser varchar null name varchar null version varchar null constraint pk tblfestatsbrowsers primary key clustered browserid asc tblfestatspaperhits create table dbo tblfestatspaperhits paperid int null created smalldatetime null ip binary null platformid tinyint null browserid smallint null referrerid int null userlanguage char null theres clustered index tblfestatspaperhits include browserid performing inner query thus require full table scan tblfestatspaperhits totally ok currently full scan executed row tblfestatsbrowsers meaning ive got full table scans tblfestatspaperhits rewriting exists doesnt change plan delete tblfestatsbrowsers exists select tblfestatspaperhits nolock browserid tblfestatsbrowsers browserid however suggested adam machanic adding hash join option result optimal execution plan single scan tblfestatspaperhits delete tblfestatsbrowsers exists select tblfestatspaperhits nolock browserid tblfestatsbrowsers browserid option hash join isnt much question fix either use option hash join create temp table manually im wondering query optimizer would ever use plan currently since qo doesnt stats browserid column im guessing assuming worst million distinct values thus requiring quite large memory tempdb worktable safest way perform scans row tblfestatsbrowsers foreign key relationship browserid columns two tables qo cant deduct info tblfestatsbrowsers simple sounds reason update give couple stats option hash join logical reads scans option loop join hash group logical reads scan per browserid options logical reads scan per browserid update excellent answers thanks tough pick one though martin first remus provides excellent solution give kiwi going mental details
18664 im using postgresql ubuntu scheduled vacuum analyze still recommended autovacuum enough take care needs answer depends largish database gib compressed dump size gib data directory etl database importing close million rows per week tables frequent changes inherited master table data master table data partitioned week create hourly rollups daily weekly monthly reports im asking scheduled vacuum analyze impacting reporting runs hours ive kill twice week impacting regular database imports check postgres doesnt report significant bloat database thats really issue docs autovacuum take care transaction id wrap around well question stands still need vacuum analyze
18669 anybody knows google yahoo perform searches keywords huge amounts data sort database technologies employ takes milliseconds billion pages indexed
18700 lot discussion question database technologies big search engines use much discussion made confused database anyway relational databases databases object oriented databases databases system allows store retrieve information like map list etc database database store retrieve information also administration features like users privileges dbase iii plus database since wasnt really relational
18864 fairly simple question probably answered somewhere cant seem form right search question google number columns particular table affect performance query querying subset table example table foo columns query selects columns versus say columns affect query performance assume simplicity anything clause included columns im concerned usage postgres buffer cache addition operating systems disk cache lose understanding postgres physical storage design tables stored across several pages defaulting 8k size per page dont quite understand tuples arranged smart enough fetch disk data comprises columns
18877 insert tables using instead triggers identity ident currenttable scope identity return null get last identity inserted row
18887 im working table date time event stored char format yyymmddhhmmss need compare current timestamp see minutes since event happened seems difficult anticipated possible different approach works
18934 process improving performance database application dba pretty comfortable sql book help understand queries written different ways affect performance also understanding things like table scans indexes statistics dont want blindly add everything tuning advisor says looking knowledge required assess recommendations context environment fully utilise tools available working mssql2008 book utilises environment specific would good thanks advance
18943 want create best indexes table database query tool sql server help process
19077 today issue stored procedure timing took longer seconds run asp net web page executed quickly run ssms took seconds suspecting parameter sniffing culprit masked input parameters query executed faster question happen system production years first time weve seen anything like stored procedures database wear tear weve resolved issue isnt big deal im curious happening
19111 need able pull column names allow null value know show columns table give show table properties whether column allows null values way return columnnames allow null show columns table null yes doesnt work explains need accomplish course easy pull everything sort later way im asking id like learn
19130 ive inherited maintenance plans following cleanup old data checks db integrity performs database transaction log backups reorganizes indexes updates statistics delete old backups maintenance plan files minute maintenance plan updating statistics takes staggering minutes minute period access database blocked least replication db others paused question updating statistics seems like kind thing less frequently every day im trying get us mind set unnecessary maintenance
19135 mysql error logs see quite warnings like warning aborted connection db db name user user name host webapp hostname got error reading communication packets havent noticed loss data per se wondering warning means causes one might address issue causing rhel mysql enterprise
19159 im storing sensor data table sensorvalues table primary key follows create table dbo sensorvalues deviceid int null sensorid int null sensorvalue int null date int null constraint pk sensorvalues primary key clustered deviceid asc sensorid asc date desc fillfactor data compression page pad index statistics norecompute sort tempdb ignore dup key online allow row locks allow page locks mypartitioningscheme date yet select sensor value valid specific time execution plan tells sort would thought since store values sorted date column sorting would occure index isnt solely sorted date column cant assume result set sorted select top sensorvalue sensorvalues sensorid deviceid date order date desc edit instead since table sorted deviceid sensorid date select specifying one deviceid one sensorid output set already sorted date desc wonder following question would yield result cases select top sensorvalue sensorvalues sensorid deviceid date according catcall sort order storage order cant assume returned values already sorted order edit ive tried cross apply solution luck martin smith suggested id try outer apply result partitions found blog post aligned non clustered indexes partitioned table describing similar problem tried somewhat similar solution smith suggested however luck execution time par original solution boundariesboundary id select boundary id sys partition functions pf join sys partition range values prf pf function id prf function id pf name pf prf value union select maxboundary id sys partition functions pf join sys partition range values prf pf function id prf function id pf name pf prf value top1sensorvalue select top sensorvalue boundaries cross apply select top sensorvalue sensorvalues sensorid deviceid date partition pfdate boundary id order date desc order date desc select sensorvalue top1
19164 170gb innodb index data readjust innodb buffer pool size better performance max table size innodb tableindex data 28gb optimal size innodb buffer pool update going migrate local database ec2 set ram according current statistics innodb thats need size buffer pool available ram file per table enabled using linux machine
19165 anyone know ready made1 command line tool would allow connect linux client sql server want able run arbitrary queries time want able take database dump restore scriptable integrate automated build environment 1fyi alternative write something ill probably use perl dbi
19240 curious business tables think create separate table location table separate table myisam would cant innodb store points
19242 realized company uses elt extract load transform process instead using etl extract transform load process differences two approaches situations would one better would great could provide examples
19291 im running plpgsql script postgres would like pass arguments script via psql im currently executing script like psql database user update file sql came across link explains pgoptions environment variable doesnt work custom arguments receive error setting isnt listed postgres conf file bash export pgoptions pretend true bash psql db update database sql psql fatal unrecognized configuration parameter pretend ideas ideally id like avoid environment variables
19344 issue come periodically yet found good solution supposing following table structure create table int primary key char1000 null char1000 null requirement determine whether either nullable columns actually contain null values ones also assume table contains millions rows column statistics available could peeked interested generic solution class queries think ways approaching weaknesses two separate exists statements would advantage allowing queries stop scanning early soon null found columns fact contain nulls two full scans result single aggregate query select maxcase null else end maxcase null else end could process columns time worst case one full scan disadvantage even encounters null columns early query still end scanning whole rest table user variables think third way begin try declare int int int select case null else end case null else end divide zero error might happen next row guarantee order assignments option maxdop end try begin catch error number divide zero begin select bc contain nulls return end else return end catch select isnull b0 isnull c0 suitable production code correct behavior aggregate concatenation query undefined terminating scan throwing error quite horrible solution anyway another option combines strengths approaches edit update results get terms reads answers submitted far using ypercubes test data exists case kejser kejser kejser ypercube 8kb maxdop hash group maxdop nulls one null two null thomass answer changed top top potentially allow exit earlier got parallel plan default answer also tried maxdop hint order make number reads comparable plans somewhat surprised results earlier test seen query short circuit without reading whole table plan test data short circuits plan ypercubes data adds blocking sort operator plan also tried hash group hint still ends reading rows key seems get hash match flow distinct operator allow plan short circuit alternatives block consume rows anyway dont think hint force specifically apparently general optimiser chooses flow distinct determines fewer output rows required distinct values input set ypercubes data row column null values table cardinality estimated rows going operator making predicate bit opaque optimiser generated plan flow distinct operator select top select distinct case null null else foo end case null null else bar end test leftb1 leftc1 null dt edit one last tweak occurred query could still end processing rows necessary event first row encounters null nulls column continue scanning rather exiting immediately one way avoiding would unpivot rows scanned final amend thomas kejsers answer select distinct top nullexists test cross apply valuescase null end case null end vnullexists nullexists null would probably better predicate null null nullexists null previous test data one doesnt give plan flow distinct whereas nullexists null one plan
19360 tables structure tbdoc id int tbdocactions id int docid int date datetime col1 int col2 int want indexed view get last tbdocactions columns tbdoc record result view must docid col1 col2 get result view use query select docid select docid maxid maxactionid tbdocactions group docid inner join tbdocactions id maxactionid want indexed view better performance indexed view cant use max aggregate function
19456 trying delete principal database cant owns schema go edit user however box uncheck schemae blue unremovable remove principal schemas
19491 enough entire index memory ram mongodb even try allocate much ram possible store even data fast reads id like run mongodb applications looks like mongodb one allow define range ram lets say max memory allocated reserved 8gb way explain oom killer mongod bad process best practise opinion
19525 requirement tracking usage table getting retired next year feel could get pertinent data stored procedures line sql used transaction logs ive see expensive purchased options reading logs wondering anybody knew opensource solutions sample code parse logs
19544 profiling instance sql server via perfmons sqlserver sql statistics sql compilations sec metric see average whipped sql profiler looked sp compile sql compile events apparently exist find stored procedure sp recompile tsql sql stmtrecompile events amount data see profiler suggests wrong events look though sure questions answers would great see exactly compiling sql server pick wrong metrics look either perfmon sql profiler regards stored procedure sp recompile tsql sql stmtrecompile events sql profiler include duration metric gauge impact events system provide way see timing impact system
19564 possible pass name table stored procedure example suppose several views table exact structure want stored procedure run views something like create procedure myprocedure tablename varchar50 select blah tablename blah blah2 try get must declare table variable tablename ideas
19632 create column db table postgresql default value random string possible please let know
19670 im running search query mysql return items products pricelist table user search query need get products products table left joined authorized unlocked sellers 2nd table number sellers basic search query working cant get dynamic left join work told prep statement im struggling mightly first time dont know put working search query look like select articles art need left join bigtable bt lot criteria prep statement came set sql text declare strcount int default select sid ifnullpricelist base count recs buyerlist left join sellerlist sid sid pass pass bid set string left join preislisten lj loop set string concat string iln iln preisliste sid ean ean iln pricelist set strcount strcount strcount recs leave lj end end loop lj set string concat string set param iln param iln prepare stmt sql text execute stmt using param iln deallocate prepare stmt im basically finding sellers pricelist name default base try construct string like left join pricelists sid sid pricelist foo ean ean iln sid sid pricelist bar ean ean iln questions sellers loops correct seller pricelist inserted string like insert actual search query execute may get string back cant put string query thanks easy first time prep statement 2nd week mysql edit came bigtable query select counta id gesamt datensaetze nos nos anzeige artikelstammdaten join colors left join farbenzuordnung zu farbe zu farbe param filter zu iln param filter new part left join preislisten iln iln ean ean preisliste new get pricelists select ifnullklhs preisliste standard pricelistid kundenliste haendler klhd left join kundenliste hersteller klhs klhs iln klhd iln verkaeufer klhs plz klhd plz klhs cid klhd cid klhd iln kaeufer param iln group pricelistid iln get seller select klhd iln verkaeufer sellerid kundenliste haendler klhd left join kundenliste hersteller klhs klhs iln klhd iln verkaeufer klhs plz klhd plz klhs cid klhd cid klhd iln kaeufer param iln group pricelistid active aktiv ja criteria stil trying find works correctly anyone shed insights whether combine identical nested selects single nested select would greatly appreciated
19719 unable see copy database option sql server management studio r2 anyone tell whats going please
19749 normally create stored procedure use following template sort create procedure procedurename param1 type param2 type etc begin procedure end way include granting execute permission stored procedure im instance like grant execute user execute stored procedure ive seen similar questions seem refer stored procedures one seen one specify permissions inside create procedure script even answers set permissions without gui specific stored procedures would welcome edit top answer certainly pointed right direction essentially looking didnt think batching commands ended batching command along stored procedure anyway think pretty slick create procedure procedurename param1 type param2 type etc begin procedure end go grant execute procedurename username go
19870 would like know identify exact query stored proc actually filling transactional log tempdb database
19894 looking alternative create index long column create table line field key integer null value varchar4000 create index key value idx line field key value results db2 sql error sqlcode sqlstate documentation says sum stored lengths specified columns must greater cases mysql syntax create index key value idx line field key value1000 hsqldb works without limitations analogue db2
19912 ive brought old school learned design database schema applications business layer using ooad everything else ive pretty good designing schemas imho normalized remove unnecessary redundancy impacted speed joins performance hit redundancy left place mostly wasnt advent orm frameworks like rubys activerecord activejdbc others cant remember im sure plenty seems prefer surrogate key every table even primary keys like email breaking 2nf outright okay understand much gets nerves almost orms programmers dont acknowledge stipulate better everything one big table matter ton nulls todays systems handle comment ive heard often agree memory constraints bear direct correlation normalization benefits todays time cheap memory quad core machines concept db normalization left texts dbas still practice normalization 3nf bcnf matter dirty schema design good production systems one make case normalization still relevant note im talking datawarehouses star snowflake schemas redundancy part need design commercial systems backend database like stackexchange example
19924 problem application works dev sql server developer edition production sql server easy way export settings production server compare server configuration found export facets sql server management studio xml files compare diff tool better way export compare settings two sql server instances
19959 question expected actual behaviour following scenario scenario one database table table1 cleared reloaded every day table id column reference several tables using foreign keys set foreign key delete action cascade obviously delete rows tables issue single delete table1 command table however would happen delete rows insert rows ids transaction trigger cascade mid transaction foreign key reconciliation happen ive called commit obviously im thinking sql server im wondering behaviour consistent across dbs well event cascade triggered even middle transaction would best way go managing foreign keys relationships table completely cleared loaded every day
20068 way temporarily suppress sql server management studios auto complete typing query dont want disable auto complete completely say hold key typing particular word doesnt get way example say following query select foo foo2 sometable type foo hit space bar sql server management studios auto complete kicks completes foo foobar
20070 sql server table called brittney spears marriages following columns marrigeid tinyint husbandname varchar500 marrigelength int another table brittney spears marriage stories storyid int marriageid tinyint storytext nvarcharmax problem want update marrigeid column int tinyint feel brittney going lots marriages everything said done brittney spears marriage stories table million rows hey girl issues go update transaction log fills sql server box dies get around anyway say hey sql server im going update column make bigger trust sql server please dont fill transaction log attempt validate everything
20099 issue face every time decide build cube havent found way overcome yet issue allow user define range things automatically without need hardcode dimension explain problem example table called customers data table want display data pivot style group salary age defined ranges like wrote script defined ranges select custid custname age salary salaryrange case castsalary float castsalary float castsalary float castsalary float end agerange case castage float castage float castage float castage float castage float end customers go ranges hard coded defined copy data excel view pivot table appears like problem want create cube converting customers table fact table create dimension tables salarydim agedim salarydim table columns salarykeysalaryrange agedim table similar agekeyagerange customer fact table customer custid custname agekey foreign key agedim salarykey foreign key salarydim still define ranges inside dimensions every time connect excel pivot cube see hardcoded defined ranges question define ranges dynamically pivot table directly without creating range dimensions like agedim salarydim dont want stuck ranges defined dimension range defined might want change users request different ranges every time every time change change dimension improve process would great solution implemented cube whatever bi client tool connects cube define ranges wouldnt mind good way using excel
20117 background construction views well using reporting table locations key fields location parent structure two fields create level wise along lines company name campus name building name floor name room name company name remains campus name remains case structure locations generally looks like org name campus name bldg bldg bldg grounds floor basement room room every location links back parent location ultimately organization name currently one organization one campus goals would like able query locations beneath given location building level return things like many workorders performed location within given building would like able determine sub location belongs building essentially reverse would like go level beneath building level trace back building would like view means would like table every item building level lists building left hand column possible locations building right hand column way id list could query time find locations part building attempts right ive attempted horribly constructed views union queries etc seemed like bad idea know oracle possesses mechanism connect im sure make use
20145 basically part postgresql table used keep server access logs sometimes production get pretty large way setting postgresql maximum number records table push oldest record
20217 set timestamp column whose default value current utc time mysql uses utc timestamp function utc timestamp mysql select utc timestamp utc timestamp row set sec ive tried create table blah creation time timestamp default utc timestamp variations like utc timestamp without success
20275 existing setup sql server standard eav table users want slice dice bi tool cognos hope transform data format report google led believe hope id like believe kind solution
20283 one developers written sql function works like vb net function lastindexof wants publish question would reason put central database versus putting user database developer trying put sys schema master db wouldnt qualify calls user databases sigh wasnt sure valid excuse would centralize obviously master database versus user database
20335 planning storing scans mass spectrometer mysql database would like know whether storing analyzing amount data remotely feasible know performance varies wildly depending environment im looking rough order magnitude queries take days milliseconds input format input file contains single run spectrometer run comprised set scans scan ordered array datapoints bit metadata majority file comprised arrays bit ints floats host system os windows bit mysql version x86 cpu 2x xeon e5420 cores total ram 8gb ssd filesystem gib hdd raid tib services running server using negligible processor time file statistics number files total size tib min size bytes max size gib mean mib median mib total datapoints billion total number datapoints rough estimate proposed schema im planning things right normalizing data like crazy would runs table spectra table foreign key runs datapoints table foreign key spectra billion datapoint question going analyzing across multiple spectra possibly even multiple runs resulting queries could touch millions rows assuming index everything properly topic another question trying shuffle hundreds mib across network remotely plausible mysql handle additional info scan data coming files xml based mzml format meat format binarydataarraylist elements data stored scan produces binarydataarray elements taken together form dimensional array form data write update performance transaction safety concerns na plan database schema runs table column name type id primary key start time timestamp name varchar spectra table column name type id primary key name varchar index int spectrum type int representation int run id foreign key datapoints table column name type id primary key spectrum id foreign key mz double num counts double index int reasonable may able infer programmer biologist lab dont know science nearly well actual scientists heres plot single spectrum scan kind data ill dealing goal software figure significant peaks use proprietary software package figure want write analysis program know heck going sheets see vast majority data uninteresting dont want throw potentially useful data algorithm missed list probable peaks satisfied rest pipeline use peak list rather raw list datapoints suppose would sufficient store raw datapoints big blob reanalyzed need keep peaks distinct database entries case would couple dozen peaks per spectrum crazy scaling stuff shouldnt much issue
20355 working documenting databases would like create list indexes database reason want track changes indexes overtime currently spreadsheet indexes changed since created spreadsheet doesnt indexes instead script index would like able generate list played system views wasnt able figure generate list indexes create statement index
20410 experienced sql server sybase oracle understand products well ive asked look ways reduce server estate running oracle understand instance oracle maps database hosting many tablespaces fairly good grasp fundamentals however wanted consolidate server1 server4 running oracle database one server would best way physically considering virtual well using dbaas database service model curious done physically possible four separate instances point four separate databases one machine would merge four databases one database consolidated server manage schemas ensure name conflicts would one instance four read documentation im still sure area
20416 starting learn memory usage sql server using query answer question sql server r2 ghost memory discovered single database taking lions share space buffer pool looking using sys allocation units sys indexes confirmed likely caused heavy use indexes database indexes clustered another database developer believes memory issues server queries starting run long available memory question use indexes existence buffer pool take away memory available processes
20419 continuation indexes consume memory fellow database developer believes memory issues seen increased run times standard queries going seconds two half minutes looked task manager server found high memory usage wants take memory currently allocated os free sql server sql server bit machine awe enabled minimum mb max mb found brent ozars sysadmin guide microsoft sql server memory indicates task manager reliable also found page life expectancy indicating memory pressure checked via pinal daves query else look else check id like report back database developer either confirm suspicions prove incorrect edit modified actual question appreciate agree queries overwhelming likely slower reasons memory problems situation however need prove memory culprit across board proving handful queries slower reasons wont accomplish task id like understand get information metrics check
20455 using sql server r2 write sql server error log rollback statement id like couple statement written error log external monitoring example begin tran insert table1 select table2 error begin rollback tran write log return end commit tran edit id like clarify want write sql server logs current log management folder object explorer
20499 need update million records single table effect normalizing table replacing varchar value column simply id say replacing really im writing id another column im trying achieve normalize dataset yet normalized data indexing thought would build indexes raw values waiting instead index foreign keys replacing varchar values tinyint values update completes update set autoclassid autoclassid autodataimportstaging dbo automobile join autodata dbo autoclass autoclassname autoclassname background using mssql r2 server r2 server gb ram server one raid10 rpm sata great know production read data write data plus recent hd shortage made necessary cost server dual quad core xeon cpu machine anything else currently dedicated dev process simple logging turned still log rollback note query references two different dbs thats worth width record table getting updated bytes resources execution physical ram maxed disk maxed cpu hardly anything choke point run time hours counting suspect things like need index raw data even though dropping column autoclassname normalization updates also wonder loop table one record time instead join seemed ridiculous time started seems would faster change methodology remaining normalization updates similar one quickly
20566 something mysql console drives nuts hit ctrl cancel current command typed terminal exits every terminal know nix terminals python postgresql ctrl cancels current command ctrl exits terminal issue reported bumped several times since way change behaviour convince mysql dev team really annoying
20583 records one details stop clock stopped started one date value record im trying work difference stop start dates im looking pointers thought something like select e1 id mine1 eventtime stoptotalminutes maxe2 eventtime starttotalminutes event e1 join event e2 e1 id e2 id would able work something im failing table sample data id eventtime action stop start stop stop start stop
20619 maintenance job im trying get list fragmented indexes query extremely slow takes minutes execute think due remote scan sys dm db index physical stats way speed following query select object namei object id tablename name tableindexname sys dm db index physical statsdb id null null null detailed phystat inner join sys indexes object id phystat object id index id phystat index id phystat avg fragmentation percent object namei object id null order phystat avg fragmentation percent desc im dba could making obvious mistake query maybe indexes statistics would help maybe size database around 20gb tables reason ask small window maintenance night taking time
20706 windows login mixed mode configure sql server use internal logins block windows logins solution add potential windows logins set restricted privileges preventative reactive procedure
20714 duplicate question asked stackoverflow advised someone could better idea happening sporadic problem upgrading sql server single user mode using net sqlconnection application somehow logs database sql code executed kicks process sqlconnection closed disposed way application somehow ends connected database kicks connection run sp could see process took control database command task manager anyone could tell process purpose world could get database single user mode active connection
20734 two things id like know safely move tempdb minimal downtime many tempdb files need file per core quad core tempdb files creating three new ones
20759 process routine data feed client refactored database form seems familiar one row per entity one column per attribute one seems unfamiliar one row per entity per attribute one column per attribute id ht cm wt kg age yr one column attributes id metric value ht cm wt kg age yr ht cm wt kg age yr ht cm wt kg age yr name database structure relative advantages old way seems easier place validity constraints specific attributes non null non negative etc easier calculate averages see might easier add new attributes without refactoring database standard preferred way structuring data
20832 tables mysql innodb one million records used command back things mysqldump username dbname gzip path file dbname sql gz command import things new server use dbname source path file dbname sql pain afflicted time going query speed things something wrong mysqldump command
20867 googling couldnt find answer question recent years ago thought id ask oracles rac feature offers load balancing read write transactions well scale high availability without downtime least understand deploy first databases use rac well see goes sql server feature set third party component could install top delivers equivalent functionality weve always used windows clustering failover event causes seconds sql downtime always tolerable ideal alwayson sql sql server shrinks seconds adds concept read secondary databases still require write transactions choked single connection point much improved since many transactions read still really load balancing case node failure need patch theres still downtime suppose curiosity feel like area sql server falls behind oracle least among features ive personally seen used wanted see options close gap possibly improve sql server deployment wait microsofts equivalent feature added maybe sql
20959 im trying set openstreetmap server ubuntu machine using ubuntu packages listed switch2osm org initially installed set everything using northeast us map extract want install entire planet maps downloaded planet latest osm bz2 ran osm2pgsql slim planet latest osm bz2 user write permission database command worked install us northeast osm pbf earlier came back next day find command appeared finish successfully reason rendering daemon wasnt generating new tiles new data tried restarting renderd effect tried restarting postgresql server sudo etc init postgresql restart however server startup failed following errors log utc warning page relation base uninitialized utc warning page relation base uninitialized lines like utc warning page relation base uninitialized utc panic wal contains references invalid pages utc log startup process pid terminated signal aborted pastebin entire log isnt much information kinds errors internet find seems mean either indexes corrupted write ahead log way fix corrupted indexes though start database single user mode rebuild cant even get fatal errors even start single user mode indexing disabled way delete write ahead log force server start scratch fix kind corruption doesnt require first starting database successfully alternatively way delete database import planet data given cant start server execute drop database command update following craig ringers suggestion went looked database logs wal errors started occurring see could find suspicious behavior log immediately first instance wal errors found suspicious looking lines utc log received fast shutdown request utc log aborting active transactions utc fatal terminating connection due administrator command utc fatal terminating connection due administrator command utc fatal terminating connection due administrator command utc fatal terminating connection due administrator command utc fatal terminating connection due administrator command utc statement create table planet osm polygon tmp select planet osm polygon order way utc fatal terminating connection due administrator command utc statement create index planet osm ways nodes planet osm ways using gin nodes fastupdate utc fatal terminating connection due administrator command utc statement create table planet osm line tmp select planet osm line order way utc log received immediate shutdown request utc warning terminating connection crash another server process utc detail postmaster commanded server process roll back current transaction exit another server process exited abnormally possibly corrupted shared memory utc hint moment able reconnect database repeat command utc log could send data client broken pipe utc warning terminating connection crash another server process utc detail postmaster commanded server process roll back current transaction exit another server process exited abnormally possibly corrupted shared memory utc hint moment able reconnect database repeat command utc log could send data client broken pipe pastebin entire log says terminating connection due administrator command assume command restart database server looks like shutdown somehow failed horribly resulting corruption shared memory doesnt make sense restarted cleanly using etc init postgres restart script abrupt kill manually logging postgres interpreting log incorrectly actually problem using etc init postgres restart restart postgresql server please note since question moved database admin im new user longer ability upvote answers doesnt mean dont appreciate help
20973 sql server could look task manager least get cursory look much memory allocated sql server sql server working set commit size never really goes mb even though sqlserver memory manager total server memory kb perf counter states setting actually show server memory task manager result changing memory used sql server
20974 according postgresqls docs theres performance difference varchar varcharn text add arbitrary length limit name address column edit dupe would index lookup noticeably faster char vs varchar values chars know char type relic past im interested performance pros cons like erwin stated amazing answer
21014 parts question way specifying initial size database postgresql isnt deal fragmentation database grows time ive recently migrated mssql postgres one things mssql world creating database specify initial size database transaction log reduced fragmentation increased performance especially normal size database known beforehand performance database drops size grows example workload im putting normally takes minutes database grows time increases vacuum vacuum full vacuum full analyse appear solve issue solve performance problem stopping database de fragmenting drive vacuum full analyse takes performance test back original minutes leads suspect fragmentation whats causing pain ive able find reference reserving tablespace database space postgres either im using wrong terminology thus finding nothing different way mitigating filesystem fragmentation postgres pointers solution supplied answers helped confirm id begun suspect postgresql stores database across multiple files allows database grow without worry fragmentation default behaviour pack files brim table data good tables rarely change bad tables frequently updated postgresql utilizes mvcc provide concurrent access table data scheme update creates new version row updated could via time stamp version number knows old data immediately deleted marked deletion actual deletion occurs vacuum operation performed relate fill factor table default fill factor fully packs table pages turn means space within table page hold updated rows updated rows placed different table page original row bad performance experience shows summary tables get updated frequently rows sec opted set fill factor table inserted row data update data may seem excessive large amount space reserved updated rows means updated rows stay within page original theres table page isnt full time autovacuum daemon runs remove obsolete rows fix database following set fill factor summary tables creation time passing parameter create table fact via alter table issued following plpgsql command alter table summary table set fillfactor issued vacuum full writes completely new version table file thus implication writes new table file new fill factor rerunning tests see performance degradation even database large need many millions rows tl dr file fragmentation wasnt cause table space fragmentation mitigated tweaking tables fill factor suit particular use case
21031 currently im trying delete objects name column null temp table following delete pulleddata pulleddata name0 null ive also tried null null etc nothing seems work id appreciate help matter
21044 concatenate two psql postgresql client variables want generate absolute path concatenating directory path variable filename variable ive tried set path tmp set file foo echo path file psql puts space path file outputs tmp foo
21065 ive considering quite long time basic question unit test stored procedures see set unit tests relatively easily functions classic sense mean get zero arguments return value consider real life example seemingly simple procedure inserting row somewhere triggers insert even defining boundaries unit quite difficult test insert thats fairly straightforward think relatively low value test result whole chain events apart question whether unit test designing suitable test quite strenuous job lots additional question marks arising way comes problem constantly changing data case update affecting rows every potentially affected row must included somehow test cases difficulties deletes unit test stored procedures treshold complexity gets completely hopeless resources needed maintenance edit one small question based alexkuznetsovs answer treshold completely useless
21075 weve encountered problem moving database customer extra server positive effects sites performance problem table locking myisam ive heard using innodb instead myisam change engine near future could spot update query performed moderator activates comment articlesite process update query processed set status id index set cached files page deleted point whole page becomes slow database busy minutes fetched processlist times saw entries different select queries state waiting table level lock dont unterstand update table article comments affect select statements table article wait table level lock processlist almost waiting queries table ive read fact updates inserts preferred selects cause problems articles table isnt updated comments become activated selects shouldnt wait missunterstand something besides changing innodb prevent behaviour least get better balance im irritated fact problem appear moving database new server guess misconfiguration dont know identify
21087 master slave configuration master failed ive able reset old slave master old master slave fine cant seem remove master information old slave new master see mysql show slave status row slave io state master host master user replicationslave master port slave io running slave sql running ive read lot mysql documentation still havent found way clear slave information new master ive tried reset slave seem clear settings actually remove master info file memory settings see change master master host spits error since deprecated recently checking cnf master information since added programmatically reset master mysql docs recommended resets bin logs poking around internal mysql tables see find fields clear proper way mysql thanks help edit turns reset slave removes master info file rolandomysqldba implied however still need restart server slave information removed way remove slave information without restart mysqld
21152 table name ips create table ips id int10 unsigned null default begin ip num int11 unsigned default null end ip num int11 unsigned default null iso varchar3 default null country varchar150 default null engine innodb lets assume countryid field table country table create table country countryid tinyint3 unsigned null auto increment name varchar50 character set utf8 collate utf8 unicode ci null ordering smallint5 unsigned null default iso char2 null primary key countryid engine innodb records ips table query following scenario check ips iso equal country iso equal add country coutryid record couldnt think way idea
21181 single row insert table auto increment column id like use last insert id function return new auto incremented value stored row many microsoft sql server devs admins doubt aware equivalent functionality sql server scope identity identity hasnt without problems know mysql docs state id generated maintained server per connection basis means value returned function given client first auto incrementvalue generated recent statement affecting auto increment column client value affected clients even generate auto increment values behavior ensures client retrieve id without concern activity clients without need locks transactions source even go far say using last insert id auto increment columns simultaneously multiple clients perfectly valid source known risks scenarios may cause last insert id return correct value im using mysql centos x64 fedora x64 innodb engine
21186 aware adding new fields large tables recommended add end fields rather somewhere middle wondering something like applies changing field types table million records several varchar type fields would like change nvarchar understand take time resources fields middle table sql server bunch copying ordering efficient way accomplishing
21189 running sql server need back udf scripts queries created done timely manner tried right clicking folder icon udf saved table valued functions copy folder bale thing think using modify command every single one udf scrips copying pasting separate text files even simple way save scripts one text file instead separate txt files would happy instead copy paste every single file one time suggestions
21220 unique compound key like frfromidtoid table run query explain get following result impossible noticed reading const tables query ran explain select rid relationship fromid toid help edit1 use query explain select rid relationship fromid toid approved approved approved see using instead previous message use query explain select rid relationship fromid toid approved approved approved get first impossible message parenthesis edit2 create table relationship rid int10 unsigned null auto increment fromid mediumint8 unsigned null toid mediumint8 unsigned null type tinyint3 unsigned null approved char1 null primary key rid unique key fromid fromidtoid key toid toid constraint relationship ibfk foreign key fromid references user uid delete cascade update cascade constraint relationship ibfk foreign key toid references user uid delete cascade update cascade engine innodb edit3 mysql site say impossible noticed reading const tables mysql read const system tables notice clause always false query get result want part false someone could explain shed light subject
21226 trying make following sql statement work get syntax error select countb foo table1 left join table2 pkey fkey group wide table columns would like avoid listing column name group clause possible many tables run similar query write stored procedure whats best way approach using ms sql server
21302 one production server log files following message observed daily basis mean serious issue sql server encountered occurrences cachestore flush sql plans cachestore part plan cache due database maintenance reconfigure operations
21319 created basic sql table following create table dbo tickdata date varchar null time varchar null symbol varchar null side varchar null depth varchar null quote varchar null size varchar null primary performed gig bulk insert bulk insert tickdata sumo csv go ram usage sql server went skyrocking eating 30go ram prefer think abnormal behavior action taken avoid edit ok seems default behavior fair enough however isnt memory freed long bulk insert finished couple extra considerations comments concerning sql server freeing memory told os hands experience core gb xeon server proves inexact memory voracious bcp extract pool net instances data processing application need process extracted data left choking fighting share remaining memory try perform jobs take faaaaar longer sql server turned memory available applications share stop sql server agent make everything go smoothly prevent apps crashing articiallt caused outofmemmroy exception artificial brutal memory capping limitation free memory available use ideally would rather dinamically set adapt available rather forcibly limited randomly guess design case closed last point
21342 follow previous question perf troubleshooting sharepoint site wondering could something cxpacket waits know knee jerk solution turn parallelism setting maxdop sounds like bad idea another idea increase cost threshold parallelism kicks default cost execution plan fairly low wondering theres query already written would find queries highest execution plan cost know find highest duration execution execution plan cost retrievable somewhere would also tell query executed parallel anyone script hand point direction relevant dmv dmf system catalog views find
21414 using sql enterprise edition following instructions restoring backup http msdn microsoft com en us library ms186390 aspx restrictions need able rename database second copy instance testing purposes rename change folders restore mdf ldf files whatever reason relocate files folder checkbox available restoring form sql backup
21426 googled found old web page said change name directory tried didnt work pg lsclusters version cluster port status owner data directory log file main postgres var lib postgresql main var log postgresql postgresql main log main online postgres var lib postgresql main var log postgresql postgresql main log pg ctlcluster main stop pwd var lib postgresql ls main mv main oldmain pg ctlcluster oldmain start error specified cluster exist postgresql ubuntu
21434 understand order view least sql server working also understand correct way sorting view putting order around select statement querying view relatively new practical sql usages views would like understand done design ive followed history correctly possible explicitly removed sql server dont quote exact version however best reason come microsoft removed feature view unsorted collection data assuming good logical reason view unsorted cant view flattened collection data specifically un sorted doesnt seem hard come situations least imho seems perfectly intuitive sorted view
21443 mysql slave got stuck error built seconds behind master rebuild start scratch let catch
21480 ive wondering lately improvements available mariadb conventional mysql understand platform interoperability backwards compatibility may issue sticking tried trusted mysql best stand alone db stand alone web site application benefits using maria maria work common web platforms wordpress drupal joomla etc expect going come choice preference storage engines honest still dont know half time use myisam innodb others better faster whatever thing get want true table relationships foreign keys etc use innodb thanks help clarity people offer
21483 large myisam table mysql 5windows xp x64 run delete low priority queries delete low priority make rows invisible select statements immediately actually delete rows disk clients accessing table point delaying removal visibility
21542 im situation want get minimum value columns ive found three ways far accomplish concerns performance methods would like know would better performance first method use big case statement heres example columns based example link case statement would much longer since looking columns select id case col1 col2 col1 col3 col1 col2 col3 col2 else col3 end themin mytable second option use union operator multiple select statements would put udf accepts id parameter select id dbo getminimumfrommytableid mytable select mincol select col1 col mytable id id union select col2 mytable id id union select col3 mytable id id 3rd option found use unpivot operator didnt even know existed cte id col1 col2 col3 select id col1 col2 col3 testtable select cte id col1 col2 col3 themin cte join select id minamount themin cte unpivot amount amountcol col1 col2 col3 unpvt group id minvalues cte id minvalues id table size frequency table queried updated concerned performance impact queries would database query actually used join table million records however records returned reduced around hundred records time get run many times throughout day columns querying frequently updated contain daily stats think indexes columns querying methods better performance trying get minimum multiple columns another better method dont know using sql server sample data results data contained records like id col1 col2 col3 col4 col5 col6 end result id value
21567 question regards proper use null utilizing check constraints business logic vs stored procedures following tables setup normalized tables avoid using nulls problem tables depend due business processes devices must sanitized tracked another system devices eventually disposed disposal table issue need perform checks boolean field requiressantization true disposaldate entered sanitize fields entered also boolean value istrackedinother true officialoutofservice fields must entered disposaldate entered merge columns archive device table null fields able manage business rules using check constraints alternative leave tables manage business logic stored procedure selecting tables check records exist throw appropriate errors case null used appropriately boolean fields istrackedinother requiressanitization basically give meaning null fields istrackedinother false device tracked system sectionid specialdevicecode null know null becuase tracked system likewise officialoutofservicedate ooslogpath know null aswell disposaldate entered time istrackedinother true sectionid specialdevicecode required officialoutofservicedate ooslogpath null know officially removed system yet thus disposaldate entered question separate tables nulls enforce rules stored procedures vs combined table nulls enforce rules check constraints understand querying nulls picture complex somewhat undefined behavior separate tables stored procedures seem beneficial sense alternatively able use check constraints rules built table seems equally beneficial thoughts thanks reading please ask clarification needed update example table merged allowed nulls allow null archive device table deviceid serialnumber devicetypeid istrackedinother sectionid specialdevicecode officialoutofservicedate ooslogpath oosremarks requiressanitization sanitizemethodid sanitizelogpath sanitizedate sanitizeremarks location originalinventorydate archivedate lastupdated reasonid storagelocation archiveremarks categorycode example check istrackedinother sectionid null specialdevicecode null officialoutofservicedate null ooslogpath null oosremarks null istrackedinother sectionid null specialdevicecode null seem natural way handle design problem
21587 recently updated machine mac os lion mountain lion think borked postgresql installation installed originally via homebrew im dba hoping someone tell troubleshoot unable connect able pre mountain lion psql rails myapp development psql could connect server file directory server running locally accepting connections unix domain socket var pgsql socket pgsql postgres still clearly running ps aux grep postgres meltemi ss wed01pm postgres rails myapp development local idle meltemi ss wed12pm postgres stats collector process meltemi ss wed12pm postgres autovacuum launcher process meltemi ss wed12pm postgres wal writer process meltemi ss wed12pm postgres writer process meltemi wed12pm usr local bin postgres usr local varpostgres usr local var postgres server log responding queries test db development db local rails app user load 2ms select users users rendered users index html haml within layouts application 3ms appears var pgsql socket directory let alone var pgsql socket pgsql socket file mentioned maybe install mountain lion wiped ls var grep pg drwxr postgres postgres jun pgsql socket alt troubleshoot
21650 title says even tried select convertnumeric also returned using sql server
21724 assuming following query legitimate executes successfully way speed select foo t1 t1 huge 5e6 rows table indexes union select bar t1 union select baz t1 union select qux t1 four columns shown type nvarchar128 non sparse nullable using sql server thanks edit provided info add indices stage table also removing distincts totally forgot phil consolidate single query
21749 fairly simple question cant seem find answer im working unions differences would like perform count results currently im pipe file wc file minus postgres printing theres got way include count select tbl1 id except select tbl2 id union tbl3 id would like know number results set difference thanks input
21779 drag columns folder editor window full list columns added without brackets drag columns individually brackets anyway turn im unable find anything options theyre really distraction
21837 sql server introduced concept contained databases everything well mostly everything database needs contained within database offers big advantages moving databases servers would like know default strategy designing new database msdn lists several disadvantages contained databases big ones lack support change tracking replication others im going use features reason use contained databases
21895 im quite new sql server would grateful someone help restored copy huge database sql server tried run simple queries im trying run select query database table lines select query simple clause every time run query fails system disk partition windows installed run space partition 6gb free space dont understand defined tempdb different drive terabytes free space course database located different drive makes system partition run space page file
21897 postgresql database one table three columns first name last name display name possible set default value display name first name last name
21913 hope question shorter answer read page book thats real situation hit real dba im software developer realizing need dba yet shop work zero dbas however ms sql database design including several core stored procedures giant mess stored procedures slow suspect bugs dont even know expected work dont know fix start ive decided well document supposed work well start unit testing building set unit tests help prove stored procedures actually work logic perform key part application could say crown jewels companys main product way works completely undocumented im looking specific technical documentation professional dba might expect existing might write understand giant web stored procedures call usual format documenting large stored procedure description expected values parameter ie preconditions postconditions ie boolean parameters changes turn etc one usually document sql comments external tooling specific purpose external documentation sql tools ms sql management studio wondering tool would make understanding documenting testing environment better maybe better way ask question tool need solve mess goal able use documentation generate whatever tools add environment help understand procedures supposed work go create unit test coverage stored procedures show client app developers properly call complex stored procedures unit test stored procedures
21925 currently tables db stores products product id store id question db design keep track products store example store products store products store products etc column stores table ids stored string separated column possibility thousands entries string another table id storeid productid possibility storesxproducts table
21962 current project involves lot database shuffling upgrade sql task hardware repeat one minor annoyance connection dialog ssms shuffling server order put recent top given particular day im connecting db servers want quickly find specific one list behavior much hindrance help way disable behavior servers listed alphabetically order added anything doesnt change every time connect server barring entirely different way better manage connecting specific server list farm im using ssms sql though im curious solutions well
21965 trying write query found hard way sql server parses wheres query long parsing selects executing query msdn docs say general logical parsing order select parsed nearly last thus resulting object alias errors trying use column alias clauses even suggestion allow aliases used anywhere shot microsoft team citing ansi standards compliance issues suggests behavior part ansi standard programmer dba found behavior somewhat confusing since seems largely defeats purpose column aliases least column aliases could made significantly powerful parsed earlier query execution since place actually use aliases order programmer seems like missing huge opportunity making queries powerful convenient dry looks like glaring issue stands reason reasons deciding column aliases shouldnt allowed anything select order reasons
22002 development machine ive installed sql server express instance name sqlexpress want default instance im pretty sure selected default instance option setup apparently didnt work way change instance name added seems known bug installer fixed pcu public update comes theres telling thats gon na happen mean time two workarounds installing choose named instance option enter mssqlserver install named instance install another instance time default instance option work still question remains way rename instance without reinstalling setup slow pain xd
22026 would possible suppress sqlcmd messages output cmd window running large script seems slowed lot processed xxxx total records messages script 4gb large amount data
22067 ive created user forgotten password mysql create user blayo identified right linux command line tool encrypt password way mysql mysql select passworduser mysql user 920018161824b14a1067a69626595e68cb8284cb blayo sure use right one tool right 920018161824b14a1067a69626595e68cb8284cb
22148 select counttitle idas algodata titles pub id select counttitle idas binnet titles pub id select counttitle idas newmoon titles pub id database used pubs sql server use single query show count records publisher publishers single record
22189 query uses three lookup tables get information need need distinct values one column however also need rest data associated sql code select acss lookup id acss lookupid acss lookup product lookupid acssproduct lookupid acss lookup region lookupid acssregion lookupid acss lookup document lookupid acssdocument lookupid product id product id product parent productid productparent product id product label product label product displayheading product displayheading product displayorder product displayorder product display product display product ignorenewupdate product ignorenewupdate product directlink product directlink product directlinkurl product directlinkurl product shortdescription product shortdescription product logo product logo product thumbnail product thumbnail product content product content product pdf product pdf product language lookupid product language lookupid document id document id document shortdescription document shortdescription document language lookupid document language lookupid document document note document document note document displayheading document displayheading acss lookup inner join product acss lookup product lookupid product id inner join document acss lookup document lookupid document id order product displayheading asc want get products query want get im populating drop menu search application want user able select products table thats need complicated use simplified approach
22250 im trying execute following script sql server management studio use master go create database test1 primary name ntest1 filename nc program files microsoft sql server mssql10 sqlexpress mssql data test1 mdf size 70656kb maxsize unlimited filegrowth 1024kb log name ntest1 log filename nc program files microsoft sql server mssql10 sqlexpress mssql data test1 log ldf size 164672kb maxsize 2048gb filegrowth im getting error msg level state line create file encountered operating system error access denied attempting open create physical file program files microsoft sql server mssql10 sqlexpress mssql data test1 mdf msg level state line create database failed file names listed could created check related errors already role permissions user ideas whats wrong
22362 im looking precise piece information database knowledge 3rd party product slow answering questions know data lying inside db want little retro engineering given one table possible list names columns table example sqlserver possible dump table reusable create statements textually lists columns table composed
22385 seems company hosting sql servers trouble replication production server backup server believe tables replicating correctly though replication done daily hours way compare tables backup vs production server see last nights replication worked way could find run following query servers seeing result matched might mean tables contain information select checksum aggbinary checksum select table compare t1 using code seems table replicate successfully checksum values im sure reliable method anyone know better method check good way im running sql server windows server computer thanks
22459 database using inline tvfs table value functions instead views example might two tables called car model car manufacturer im joining together inside tvf fncarbrands tvfs called tvfs processing reporting might take function fncarbrands join table purchase year form function fncarbrandhistory several layers tvfs could probably get functionality using views since inline tvfs really joins tables tvfs performance inline tvfs written way compare views
22460 would like use code developed clr used databases system dont set trustworthy turn clr keep bunch code inside one best way administrative security standpoint clr functions basic like string breakers email validation url en decode base64 etc would like dbo schema database able access functions simple way also clear clr dll embedded move database tags along move dll well thanks
22512 would like able generate random bytea fields arbitrary length 1gb populating test data best way
22638 sql server r2 would determine partition record currently lives
22697 whenever user updates profile conduct set queries like delete user likes id id insert user likes values default id interest id interest name way one step way interest ids different user keep mind data never actually deleted set always growing
22726 following customers table customer id int company name nvarchar street nvarchar city nvarchar comments nvarchar app used part one small country something like cities friend told seperate city different table cities use city id customers table personally didnt see much benefit except saving space customers table seems insignificant case cost creating another table also mentioned duplicate columns city foo city bar city foo customers city considered normalized true whos right enlightenment issue
22771 microsoft sql server ok shrink log file online database cause interruption service
22779 subscriber transactional replication subscription control publisher read following article schema changes publication database make schema changes publication databases however trying change schema subscription end possible wondering transactional replication supports addition persistent computed columns subscriber tables would much prefer solution versus adding new view every table requires computed value
22799 planning use postgresql application concerned crash safety recovery cant find database crash recovery method process postgresql know must something postgresql advice anyone help find would great
22803 know check logins users defined using gui sql server wondering check using script ran query shows principal id im sure map get permission level select sys login token built stored proc list logins users permission level thank
22809 rebuilding index used option sort tempdb order avoid unnecessary growing user database files exactly means complete process done tempdb grow mdf ldf file size example reindex database simple recovery mode largest index size database 25gb mdf size 100gb allocated used freespace ldf size 20gb tempdb 200gb freespace approximate size mdf ldf files grow
22833 would like update development machine sql server still manage old sql server machines wil ssms able connect sql server machines sql server r2 works fine
22909 dont know question better suits script id like launch code function copied question mydb create replace function truncate tablesusername varchar returns void declare stmt record statements cursor select tablename pg tables tableowner username begin stmt statements loop execute truncate table quote identstmt tablename cascade end loop end language plpgsql get following error error syntax near line1 query context sql statement pl pgsql function truncate tables near line new postgres pl pgsql dont know error message means
22962 rows im needing update information column column example customers need arrival time match departure time understand one row work nested select statement update statement trying update multiple rows though believe im getting stuck unique key identifiers used update records im using oracle sql update patient set discharge dt select admit dt patient pat seq xxxxxx facility id pat seq xxxxxx apologize confusing description really database administrator help would greatly appreciated
22979 query used getting internet traffic statistics certain ip addresses separate ip address fields hosts blocks ips called assignments data stored minute intervals query results grouped time column total sums minute intervals used plot graph table called traffic contains end month around million records show create table traffic create table traffic type enumv4 assignmentv4 hostv6 subnetv6 assignmentv6 host null type id int11 unsigned null time int32 unsigned null bytesin bigint20 unsigned null default bytesout bigint20 unsigned null default key basic select type idtimetype engine innodb default charset latin1 select traffic time sumtraffic bytesin sumtraffic bytesout traffic traffic type v4 assignment type id ids265 traffic type v4 host type id lot ids traffic time traffic time group traffic time order traffic time following explain output query id select type table type possible keys key key len ref rows extra simple traffic range basic select basic select null using using temporary using filesort show indexes traffic table non unique key name seq index column name collation cardinality sub part packed null index type comment traffic basic select type id null null btree traffic basic select time null null btree traffic basic select type null null btree query takes seconds minutes complete hope improve things using better indexes maybe using different query im unable figure update following advise helpful commentors ive created primary key added index traffic pk time type type id id unfortunately turns cardinality new index equal lower original index basic select mysql still uses original key update dropped original index basic select explain shows higher rows value less steps extra fields also query execution time went minute still bit slow major improvement mysql show create table traffic test row table traffic test create table create table traffic test traffic id int10 unsigned null auto increment type enumv4 assignmentv4 hostv6 subnetv6 assignmentv6 host null type id int11 unsigned null time int32 unsigned null bytesin bigint20 unsigned null default bytesout bigint20 unsigned null default primary key timetypetype idtraffic id key traffic id idx traffic id engine innodb auto increment default charset latin1 indexes table mysql show index traffic table non unique key name seq index column name collation cardinality sub part packed null index type comment traffic test primary time null null btree traffic test primary type null null btree traffic test primary type id null null btree traffic test primary traffic id null null btree traffic test traffic id idx traffic id null null btree also simplified query using select sql cache traffic time sumtraffic bytesin sumtraffic bytesout traffic traffic type like v4 host type id traffic time traffic time group traffic time asc old execution query rows set min sec new executiontime rows set sec explain output id select type table type possible keys key key len ref rows extra simple traffic range primary primary null using rows value still quite high think improve switching order type type id index since types possible many type ids correct assumption
22989 sql select kill tbl pvporderview problem end incorrect syntax near keyword kill kill sql command way bypass cant change column name used software lot cant change software thats using database simply fails use sqlserv select data column wont help complete statement would sql select serialkill tbl pvporderview kill order kill desc
23036 im attempting import csv file database via copy command however get seems common error need superuser use copy instead however using copy get syntax error error syntax error near line copy caret pointing heres query copy tablenamecolumn2 column3 column4 column5 home uploads data csv delimiter csv header tried copy copy first giving superuser error latter giving syntax error idea fix make work im executing command via mypgadmins sql input field question concerning importing columns via tablenamecolumn2 column3 correct syntax
23041 id like able predict whether delete run constraint violation without actually performing delete options simple way dry run delete
23053 migrating server application existing system another system unfortunately existing system also database server data stored possible copy data system copy table schemas idea proceed using postgresql
23058 lets say principal server mirroring server one serves failover backup witness server matter bring mirroring server principal offline short five minutes lets say going break mirror anything need turning mirroring temporarily mirrored databases take server offline plenty resources online explain needs happen principal goes nothing find scenario
23068 count records queries like select countcol1 table1 col1 like something select countcol1 table1 col1 like another select countcol1 table1 col1 like word count mysql needs walk thoughout table big problem long table numerous queries wonder way make counts one query case mysql walks row process counts need scanning entire table
23124 lets imagine web site directory people person may profile photo biography ill admit sql queries could better general would faster use less processing power check file exists open check mysql see bio exists display im pretty sure case filesystem smoke mysql database make database read delimited txt file whats faster case certain point txt file many records better use mysql
23129 mysql create queries without backtick symbol example select test select test works fine mysql console technical difference benefit using simple queries
23135 apply static data clause faster applying sub query example query returns records result set select startdate enddate test startdate faster select startdate enddate test startdate select startdate test2 limit case sub query executes time comparison perform query record time
23147 project need estimate db size im going use oracle project lot transactions data presentation need specify years much expect db grow pdf way calculating row size another stuff sql server want oracle pdf estimation formula without real db cant queries db check actual size thats ive seen posts googled formula sql server row row size fixed data size variable data size null bitmap formula works oracle also size header row dont know translate meaning english oracle value oracle things think think ive solved
23163 correlated subquery like bol select distinct lastname firstname businessentityid person person join humanresources employee businessentityid businessentityid select bonus sales salesperson sp businessentityid sp businessentityid go rewrite query using joins select lastname firstname businessentityid bonus person person inner join humanresources employee businessentityid businessentityid inner join sales salesperson businessentityid businessentityid bonus look actual execution plan looks exactly queries thinking correlated subquery much slower nested loop execution plan looks different much data tables
23192 table stores sequence counter data received devices field rate sequences need order within configurable time span come system order device reset sequence number set back create table dbo tapgapdetail id bigint null fk another table deviceesn varchar collate sql latin1 general cp1 ci null tapdateutc datetime null date event occurred device createddateutc datetime null counter int null create clustered index cx tapgapdetail dbo tapgapdetail deviceesn createddateutc counter primary go ive tried switch order cx deviceesn createddateutc system doesnt seem make much difference io millions rows table example insert would insert tapgapdetail 00am 10am insert tapgapdetail 05am 15am order insert date insert tapgapdetail 00am 05am back order insert tapgapdetail 00am 05am missing insert tapgapdetail 00am 05am order outside tolerance insert tapgapdetail 00am 05am device reset report needs report gap occurred data also detail one step time want get run less seconds seems take least minutes local stat io needed proc created get gaps like create proc dbo getvalidatortapgapsummary validator varchar100 filterdateutc datetime tolerancehours int temp table select rowid row number order deviceesn createddateutc counter deviceesn tapdateutc createddateutc counter taps tapgapdetail createddateutc filterdateutc order cx create clustered index cx1 tapsrowid results select deviceesn validator sum case sequence t2 counter counter reset occured t2 counter counter gap exists find difference else t2 counter counter end tapgaps case gets last tap date per validator maxt tapdateutc maxt2 tapdateutc maxt tapdateutc else maxt2 tapdateutc end maxtapdate case gets last tap date per validator maxt createddateutc maxt2 createddateutc maxt createddateutc else maxt2 createddateutc end maxcreateddate taps inner join taps t2 deviceesn t2 deviceesn t2 rowid rowid t2 counter counter t2 counter counter createddateutc filterdateutc t2 createddateutc filterdateutc deviceesn validator validator exists edge case gap end tried left join stats easier read think select top null tapgapdetail tgd tgd deviceesn deviceesn counter tgd counter tgd createddateutc dateaddday tolerancehours createddateutc tgd createddateutc dateaddday tolerancehours createddateutc group deviceesn order maxcreateddate desc deviceesn go example statio would table tapgapdetail scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected rows affected table taps scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected table taps scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table tapgapdetail scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads ive tried various indexes temp table suspect even filling taking long suggestions appreciated
23203 im trying store lot large numbers truncate stored int values unfortunately large type im thinking using base36 encoding accomplish ways go fixing problem
23259 remember correctly last time microsoft sqlcmd require command end hit enter key execute command however currently need type go time execute command alternative hit enter key ending command execute command
23265 mysqls show grants shows permissions current user way log root show permissions users
23280 im new oracle databases understood correctly materialized view view result set saved physical table database view table refreshed bases parameter view saved physical table store data table first place benefit using materialized view instead table
23305 monitoring file growth via data collector sql server r2 two weeks database growing consistently around 35mb day db yet hit initial size gb db files auto growth set 5mb would like try different approach looking suggestions comments tuning task runs every week sunday night task check database integrity shrink log file ok logging mode simple shrink database reorganize index rebuild index update statistics clean history would like add two steps weekly tuning plan grow database file mb used space reaches certain threshold total size grow log file mb shrink used space reaches certain threshold total size placing growth burden offline hours hope gain performance reducing number auto growth events heavy loads two questions relating auto growing files best place put file grow steps would prior current steps use alter database modify file grow file determine spaceusedinfile totalfilespace allowancethreshold
23335 im problems database run basic queries albeit much slower normal attempt view hierarchy trees tables views procedures ssms object explorer get lock request time period exceeded ssrs reports run objects database longer completing jobs associated procedures stored database also run tried using sp who2 find kill connections database however solved problem going resolve
23355 possible using pgadmin plsql get hold query plan sql statement executed inside user defined function udf using explain get hold query plan particular invocation udf see udf abstracted away single operation pgadmin looked documentation couldnt find anything currently im pulling statements running manually isnt going cut large queries example consider udf udf even though ability print query string work copy paste local created temporary table exist paste execute create replace function get paginated search results forum id integer query character varying date timestamp without time zone default null date timestamp without time zone default null categories integer default returns setof post result entry declare join string character varying date character varying date character varying query string character varying begin date null date fp posted date end date null date fp posted date end create local temp table un catid commit drop select unnestin categories categories join string inner join forum topics ft fp topic id ft id inner join un cat uc uc id ft category id end query string select indexposted atpost textnamejoin datequotes forum posts fp inner join forum user fu fu forum id fp forum id fu id fp user id join string fu forum id forum id tsvectorenglishfp post text tsqueryenglish query date date raise notice query string return query execute query string end language plpgsql
23371 looking post stackoverflow aaron bertrand proposes using cte instead numbers table elegant way performing task hand question first line cte begin semi colon select top select row number order s1 object id sys objects s1 cross join sys objects s2 order select order look gaps ensure statement get parsed previous select something see nothing sql server bol using semi colon prior
23399 ive got tdf sql server profiler trace template someone wants run template targeting ss r2 ssms r2 server need trace ss attempting trace server server type locked generated actual server cant select template need marked different ss version change server type trade template targeting ive tried file templates edit templates doesnt seem option change possible change target server version whole trace made scratch
23456 want force appdomain used sqlclr reset besides restarting sql server instance
23465 query currently taking average 2500ms complete table narrow million rows options improve performance good gets query select top cia wiz dbo heartbeats dateentered table create table dbo heartbeats id int identity11 null deviceid int null ispup bit null iswebup bit null ispingup bit null dateentered datetime null constraint pk heartbeats primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary index create nonclustered index commonqueryindex dbo heartbeats dateentered asc deviceid asc pad index statistics norecompute sort tempdb ignore dup key drop existing online allow row locks allow page locks primary would adding additional indexes help would look like current performance acceptable query run occasionally im wondering learning exercise anything make faster update change query use force index hint query executes 50ms select top cia wiz dbo heartbeats withindexcommonqueryindex dateentered adding correctly selective deviceid clause also hits 50ms range select top cia wiz dbo heartbeats dateentered deviceid add order dateentered deviceid original query 50ms range select top cia wiz dbo heartbeats dateentered order dateentered deviceid use index expecting commonqueryindex suppose question way force index used queries like size table throwing optimizer much must use order hint
23467 following procedure sql server r2 create procedure usp savecompanyuserdata companyid bigint userid bigint datatable tt couserdata readonly begin set nocount xact abort merge companyuser holdlock using select companyid companyid userid userid mykey myvalue datatable newdata companyid newdata companyid userid newdata userid mykey newdata mykey matched insert companyid userid mykey myvalue values companyid userid newdata mykey newdata myvalue end companyid userid mykey form composite key target table companyid foreign key parent table also non clustered index companyid asc userid asc called many different threads consistently getting deadlocks different processes calling statement understanding holdlock necessary prevent insert update race condition errors assume two different threads locking rows pages different orders validating constraints thus deadlocking correct assumption best way resolve situation deadlocks minimum impact multi threaded performance view image new tab readable sorry small size rows datatable traced back code see anywhere start transaction foreign key set cascade delete deletions parent table
23475 using postgresql figure top end dbs must similar capabilities moreover solutions may inspire solutions dont consider postgresql specific know first try solve problem figure worth asking trying evaluate costs modelling accounting data every transaction fundamentally balanced accounting data append overall constraint written pseudo code might look roughly like create table journal entry id bigserial null unique artificial candidate key journal type id int references journal typeid reference text source document identifier unique per journal date posted date null primary key journal type id reference create table journal line entry id bigint references journal entryid account id int null references accountid amount numeric null line id bigserial null unique check sumamount partition entry id wont work obviously check constraint never work operates per row might check entire db always fail slow question best way model constraint basically looked two ideas far wondering ones someone better way leave app level stored proc could borrow page accounting worlds concept difference book original entry book final entry general journal vs general ledger regard could model array journal lines attached journal entry enforce constraint array postgresql terms select sumamount unnestje line items trigger could expand save line items table individual column constraints could easily enforced indexes etc could useful direction leaning could try code constraint trigger would enforce per transaction idea sum series 0s always weighing current approach enforcing logic stored procedure complexity cost weighed idea mathematical proof constraints superior unit tests major drawback types tuples one areas postgresql one runs inconsistent behavior changes assumptions regularly would even hope behavior area might change time designing future safe version easy ways solve problem scale millions records table missing something tradeoff missed response craigs point versions minimum run postgresql higher maybe higher probably go straight
23509 follow question increasing query performance id like know way make index used default query runs seconds select top cia wiz dbo heartbeats dateentered one runs 33ms select top cia wiz dbo heartbeats dateentered order dateentered deviceid clustered index id field pk non clustered index dateentered deviceid first query uses clustered index second query uses non clustered index question two parts since queries clause dateentered field server use clustered index first second make non clustered index used default query even without orderby would want behavior
23532 trying compare features sql server express oracle xe db2 express find difficult compile differences one place especially current differences constantly shifting battle field anyone information hand know someone tracks best knowledge db2 express cores mem 16g 4g size terabytes user data per database oracle express edition 11g cores mem 1g size 11g sql server express cores lesser socket cores mem 1g size 10g obvious measures missing know could go open source well mysql postgresql certainly viable solutions sake argument lets limit options view db2 clear cut winner another article subject found
23547 found table clustered non clustered indexes different columns leaf level non clustered pages instead pointing data row point node clustered index another search instituted find data row point extra level indirection clustered index say levels indirection nci leaf page ci root would traverse levels reach data store normal rid nci leaf page access data without going ci index structure
23566 need write select query results csv file done using sql sql server r2 know done ssis reasons dont option tried use suggested proc article run proc sql complains cant run sys sp oacreate sys sp oadestroy called proc know turn components know better way write file using sql thanks advance
23637 found writing following select yes existsselect foo val existsselect foo val wondering concise way without sacrificing much readability found one way posting answer im entirely happy would interested alternatives case val unique within foo duplicates
23704 troubleshooting purposes would like able check client connect sql server instance independent application possibly cant connect sql server easy way means install 3rd party software using default windows system tools perhaps using scripts network applications
23718 instance oracle 10g one schema used web application internet facing user reading information adding modifying data rest schemas used archived redo logs activated strange us archived files generated every day including sundays holidays nobody comes work thought archived redo logs generated inserting deleting updating data never select statements correct
23747 test mysql credentials command line linux server
23772 cant seem find option set server property enable compression sql database backup default dont manually set every time anyone point please
23782 one products supports oracle sql server database backend customer wishes switch oracle backend microsoft sql server isnt typical transition us easiest way get data entire oracle schema sql server database schema contains plain old tables nothing fancy might one two stored procedures well problem migrating hand could use oracles sqldeveloper export table data create insert statements wont match syntax used sql server looking forward manually fix syntax errors
23786 best practice data obfuscation sql server wed like use masked production data uat system want quickly higher level obsfucation approach taken im thinking character scrambling peoples given name family name create function predefined functions available use dont want spend time inventing wheel date fields example date birth randomly picked whole table assigned record better way
23794 anybody please summarize differences http www postgresql org docs static xfunc sql html http www postgresql org docs static plpgsql html main points conceptional differences given problem family convenience use political issues
23879 postgresql table select slow whereas select id nice quick think may size row large taking transport may factor need fields nearly selecting subset isnt quick fix selecting fields want still slow heres table schema minus names integer null default nextvalcore page id seq regclass character varying255 null character varying64 null text default text character varying255 integer null default text default text text timestamp time zone integer timestamp time zone integer size text field may size still kilobytes worst case questions anything screams crazy inefficient way measure page size postgres command line help debug
23908 suppose need encrypt certain table fields mysql database additionally need search fields encrypt would one search fields anyway decrypting record step step option suppose multiple thousands records would take much time space decrypt record check single record matches search update adding details database schema would ok since im implement new application furthermore need extend applications currently running production even application adding details would ok update encryption kernel question access restrictions proposed answers already apply fit formal requirement encrypt data formal requirement payment card industry data security standard pci
23983 created table testtable inside database testbase following structure product int null product name varchar30 null price money null expire date date null expire time time7 null used microsoft sql server management studio created stored procedure testtable pricesmaller follows use testbase go create procedure testtable pricesmaller pricelimit money select testtable price pricelimit go able view stored procedures object explorer microsoft sql server management studio listed following tree structure object explorer databases testbase tables dbo testtable programmability stored procedures dbo testtable pricesmaller find strange receive following error could find stored procedure dbo testtable pricesmaller execute following sql statement execute dbo testtable pricesmaller could missing
24014 innodb table idtimes mysql log columns id int11 null time int20 null compound unique key unique key id time idtime multiple timestamps per id multiple ids per timestamp im trying set query get entries plus next greater time entry exists return id time nexttime null null right far select id time time idtimes left join idtimes id id time time order id asc time asc course returns rows time time first one guess ill need subselect like select outer id outer time select time idtimes id outer id time outer time order time asc limit idtimes outer order outer id asc outer time asc dont know refer current time know valid sql single query id prefer use variables depend stepping though table one row time remembering last value
24091 senior dba told sql query execution default doesnt lock table issues sql server reporting services ssrs report seems getting issues locking getting errors googling fell short finding anything ssrs reports lock tables queried msdn documentation document behavior specifically
24165 connecting sql server r2 net client application different server lan one set three different network protocols tcp named pipes dont set anything connection string use default best practice choose additional information tcp named pipes enabled server client application using database mirroring client server communicate fast lan investigating rare spurious connectivity timeout problems regardless id like know best practice article subject msdn generic vague advise recommend anything useful
24280 trying duplicate business logic embodied intranet web application database databases access work rules rule seems difficult implement without using hacks create table case stage id number9 primary key null stage id number9 null case phase id number9 null date created timestamp6 default current timestamp null end reason id number9 previous case stage id number9 current number1 null date closed timestamp6 default null create table case recommendation case id number9 null recommendation id number9 null order number9 null date created timestamp6 default current timestamp null case stage id number9 null alter table case recommendation add constraint sys c00000 primary key case id recommendation id business logic summed inserting case stage case stage stage id case stage previous stage id must found case recommendation case stage id logic embodied check constraint ugly trigger way edit values case stage stage id value previous stage id must found case stage id application allow deletions case recommendation longer current ie value case stage current stage closed longer changed stage row active changed edit using excellent ideas comments working solution problem create materialized view log case stage tablespace users storage buffer pool default nocache logging noparallel rowid create materialized view log case recommendation tablespace users storage buffer pool default nocache logging noparallel rowid create materialized view case recommendation mv refresh fast commit select cr rowid cr rowid necessary fast refresh cs rowid cs rowid necessary fast refresh cr case id cs stage id cr recommendation id cr case stage id cs previous case stage id case recommendation cr case stage cs cs previous case stage id cr case stage id cs previous case stage id null extract year cs date created covers non conforming legacy data cr recommendation id null cs stage id last line excludes everything problem cases due outer join alter table case recommendation mv add constraint case recommendation ck check previous case stage id null case stage id null inserting stage using existing packages without recommendation error ora error materialized view refresh path ora check constraint appbase case recommendation mv c01 violated ora line job done materialized view intended better trigger
24326 performing parallel testing upgraded legacy batch jobs new framework need test existing batch jobs existing setup web application creates updates records based user input batch jobs process records plan databases primary secondary existing batch job connected primary database server new batch job connected secondary database server web application populate data primary secondary databases would like perform replication tables database however would like replicate dml changes done specific database account used web application possible
24386 hi im trying create login role user fairly minimal ability modify database able select delete create triggers insert update would like multiple accounts members user permissions log edits individual users im using pgadmin database design program accesses qtsql error message get caught qt trying select data test run code database owner superuser problems bool run queryconst qstring qsqldatabase db qsqldatabase database default qsqlquery querydb query execq query isactive qmessagebox warning0 qobject tr database error query lasterror text return false query next qstring title query value0 tostring std cerr qprintabletitle std endl return true run query select forename contacts error permission denied relation contacts qpsql unable create query far ive created role user role user drop role user create role user login encrypted password md54d45974e13472b5a0be3533de4666414 nosuperuser inherit nocreatedb nocreaterole noreplication comment role user low level user gave previous problems tried adding permissions public database didnt work either ive idea look solution help much appreciated thanks
24410 two tables one paymentdetail another ledger want prioritize paymodetype manner cash considered first ra fundtype credit card dd cheque want amount received cash first considered lastly fundtype another example sqlfiddle well solved sql dont want use cursor edit updated sqlfiddle tried trying use join due multiple rows obtained result respect payment detail want span amount one row payment detail ledger second row used achieve result current sqlfiddle
24496 one perplexing issues ive deal stored procedure groups given stored procedure usp dosomethingawesome create proc another group calling usp dosomethingawesome discovered troubleshooting replication issues publisher sql ent dist sub r2 ent arose system generated insert update delete replication stored procedures purpose thought behind grouping ability
24507 database application connects using db owner permissions effectively determine minimum set requirements actually needed user application run without causing service interruption ie without trial error
24518 lets consider following example start psql script db run truncate important table tried avoid similarities anything exists run command psql connection details db run dev database runs user happy decides specify db run production database lets assume happen like people run rm rf dont try home ocassionally hopefully fresh backup table question arises check variables passed script stop processing based value
24531 way create index mysql exist mysql support obvious format create index exists index name tablecolumn error error sql syntax mysql version mysql think mysql lacks create index exist ability versions whats right way create index already exist mysql
24583 structure tables category table create table category catid bigint20 null auto increment title varchar60 null created timestamp null default current timestamp primary key catid engine innodb auto increment default charset latin1 second table projects create table projects id int11 null auto increment catid int11 null industryid int11 null dsid int11 null countryid int11 null title varchar255 null primary key id key catid catid key industryid industryid key dsid dsid key countryid countryid engine innodb default charset latin1 add fk tables query keep getting error cant create table errno alter table projects add constraint fk catid foreign key projects catid references category catid
24617 im fixing performance issues multistatement stored procedure sql server want know parts spend time understand read query cost always percentage even ssms told include actual execution plan query cost relative batch figures still based cost estimates far actuals understand measuring query performance execution plan query cost vs time taken surround invocation stored procedure set statistics time statements get list like messages pane sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms etc sql server execution times cpu time ms elapsed time ms one output message statement easily though conveniently associate time statistics output statement statement execution plans execution plan pane counting fourth sql server execution times message output corresponds query execution plan pane better way
24711 note work mssql guess valid many others db engines table users userid user countryid user user user user user user table countries countryid country mx usa england see every user belongs country want know different countries least one user users table right query select distinct country users inner join countries users countryid countries countryid achieve next result set england mx usa indeed different countries least one user muy table users doubt possible achieve result set using distinct mean using joins conditions de ddl scripts use test go object table dbo users script date set ansi nulls go set quoted identifier go create table dbo users userid int null user nvarchar null countryid int null primary go insert dbo users userid user countryid values nuser insert dbo users userid user countryid values nuser insert dbo users userid user countryid values nuser insert dbo users userid user countryid values nuser insert dbo users userid user countryid values nuser insert dbo users userid user countryid values nuser object table dbo countries script date set ansi nulls go set quoted identifier go create table dbo countries countryid int null country nvarchar null primary go insert dbo countries countryid country values nmx insert dbo countries countryid country values nusa insert dbo countries countryid country values ncan insert dbo countries countryid country values nengland insert dbo countries countryid country values nbrazil
24714 writing dynamic sql identify perhaps im feeling crazy enough automatically convert nonclustered indexes clustered indexes line order desc sql designed output drop index statements alter table statements order drop nonclustered index first add clustered index add desc column get drop first followed alter backwards unless im losing declare server nvarcharmax declare database nvarcharmax declare cmd nvarcharmax declare indextype int set indextype clustered nonclustered set server myserver set database mydatabase set cmd declare cmd nvarcharmax set cmd set nocount declare indexinfo table tablename nvarchar255 indexname nvarchar255 indexcolumnname nvarchar255 insert indexinfo tablename indexname indexcolumnname select name tablename name indexname name indexcolumnname create date ic sys tables left join sys indexes object id object id left join sys index columns ic object id ic object id index id ic index id left join sys columns object id object id ic column id column id primary key type cast indextype nvarcharmax order create date desc declare t1 nvarcharmax declare t2 nvarcharmax declare t3 nvarcharmax declare cmd nvarcharmax declare cur cursor select tablename indexname execorder drop index indexname tablename indexinfo union select tablename indexname execorder alter table tablename add constraint pk tablename indexcolumnname primary key clustered indexcolumnname indexinfo order desc open cur fetch next cur t1 t2 t3 cmd fetch status begin print cmd fetch next cur t1 t2 t3 cmd end close cur deallocate cur exec server database sys sp executesql cmd print cmd
24748 learned normalization recently understand important implementing new schema check database 2nf 3nf compliant manual review sure option im looking automated tool im looking point click tool something would highlight possible optimizations make table 3nf compliant guess might use statistics based good sample data semantic analysis columns names
24758 create primary key foreign key constraints create table script named constraints created fk recentlyvi scid 2764765d constraints predictable ie run creation script another server constraint name ask entity framework multiple references secondary table get properties like foreign foreign1 foreign2 etc sometimes generating entity model order different ive come following work around want know default constraint names work even though im using named constraints workaround included need future may refactor getting property entity based foreign key object type name private contact getcontactmatchforforeignkeystring foreignkeyname var props typeoforder getproperties whereprop attribute isdefinedprop typeofedmrelationshipnavigationpropertyattribute foreach var prop props var attrs prop getcustomattributestypeofedmrelationshipnavigationpropertyattribute true foreach var attr attrs var edmrelationshipnavigationpropertyattributeattr relationshipname foreignkeyname targetrolename contact return contactprop getvaluethis null return null private void setcontactmatchforforeignkeystring foreignkeyname contact value var props typeofcontact getproperties whereprop attribute isdefinedprop typeofedmrelationshipnavigationpropertyattribute foreach var prop props var attrs prop getcustomattributestypeofedmrelationshipnavigationpropertyattribute true foreach var attr attrs var edmrelationshipnavigationpropertyattributeattr relationshipname foreignkeyname targetrolename contact prop setvaluethis value null return public contact purchaser get return getcontactmatchforforeignkey fk set setcontactmatchforforeignkey fk value public contact seller get return getcontactmatchforforeignkey fk set setcontactmatchforforeignkey fk value
24774 installed postgresql ec2 machine want change password user postgres sudo postgres psql psql type help help postgres alter user postgres password newpasswd alter role exit shell try login new password psql postgres password user postgres psql fatal peer authentication failed user postgres postgresql version psql version psql postgresql contains support command line editing wrong thank update made changes pg hba conf looks database administrative login unix domain socket local postgres peer type database user address method local unix domain socket connections local peer local md5 ipv4 local connections host md5 ipv6 local connections host md5 restarted postgres sudo etc init postgresql restart restarting postgresql database server ok tried logging failed psql postgres password user postgres psql fatal peer authentication failed user postgres
24832 moderately complex query trying optimize noticed removing top clause changes execution plan would guessed query includes top database engine would run query ignoring top clause end shrink result set number rows requested graphical execution plan seems indicate case top last step appears going question top clause impact execution plan query simplified version going case query matching rows two tables without top clause optimizer estimates 19k rows table 46k rows table actual number rows returned 16k 13k hash match used join two results sets total rows sort applied query happens quickly add top optimizer use hash match instead first sorts results table estimate actual 19k 16k nested loop table estimated number rows table strange thing top directly affects estimated number executions index seek appears always 2n case estimate changes accordingly change top course since nested join actual number executions 16k number rows table slows query actual scenario bit complex captures basic idea behavior tables searched using index seeks sql server r2 enterprise edition
24883 alter table statements running work result running sql data compare want group transactions roll back statements something goes wrong possible data rolled back
24894 address belong either mailing billing categories user adds address table address category independent integer value set constant somewhere source code foreign key table lists categories available im concerned performance best practice chances adding removing categories slim none
24937 im new oracle databases used sql server description fields ms description tables columns documentation purposes equivalent oracle best practice documenting oracle database
24991 asking chat secure sql server backup files im told attacker access bak file unencrypted access data lets look scenario open symmetric key mysymetrickey decryption certificate mycertificate notice password encrypt tables update tbl1 set namepass encryptbykeykey guidmysymetrickeyname go lets say hacker got bak file order view data computer sql server select convert nvarcharmax decryptbykeynamepass tbl1 would still able access data
25047 rely sql server database engine tuning advisor creating indexes statistics find often generates overly complex indexes think would costly index maintenance benefit index solely rely database engine tuning advisor straightforward method book article perhaps missing index dmvs particularly useful trying think indexes brand new tables
25103 want able script schema given database sql file windows command prompt basically want execute generate scripts feature management studio programmatically know possible using net smo something built background question meant simple auditing instrument want capture schema every night primitive low tech solution works us
25124 traditional sql server cluster failover occurs clients connected sql server failed instance lose connections client must establish new connection failover cluster instance alwayson availability group mitigate problem failover case sql server alwayson availability group transparent clients connecting sql server
25161 cases oracle advanced queuing preferred mechanism implementing functional requirements example money transfer bank account bank account might theoretically considered two different operations might implemented separately first enqueue money transfer account update enqueue money trasfer account update however obvious cant done like two operation done one consistent operation transaction maybe advanced queuing considered developing stored procedures functions perform logic done internally dml operations calling local stored proc fnc externally calling webservices using calls webservices cant wrap consistent transaction way use queuing mechanism real life detailed examples would appreciated im curious details technology rather real life cases using messaging havent done like need pass data message payload around
25177 according site http www dbspecialists com oracle11glinux html oracle supported following linux distributions oracle enterprise linux red hat suse asianux technical reason oracle would perform poorly debian based install ubuntu dealing oracle enterprise support standpoint
25226 tools comparable ssms tools pack licensing per machine number machines months leaves lot desired wasnt sure options available example one thing really miss save every query run tinkering researching invaluable running backup different versions queries run realize dont backup query working months ago clarification sql server management studios official addon support tools ssms tools pack one ive fond versions licensing fee horrible would pay reasonable license thats question ive found ssms boost example cool additions ssms seem worth addins available sql server id love something saves query hit f5 like ssms tools pack anything besides two tools listed
25291 tickets table id need associate lookup table counterpart data another id controlled outside source tickets id sutff lookup outside data id ticket id need know association exists hence lookup table one many relationship know nothing else outside data id except id related ticket id also dont want alter tickets table affect small amount ticket ids example outside data id related ticket id ticket id ticket id would lookup table structure work better way create table lookup outside data id integer ticket id integer
25304 use sql server r2 standard edition cant afford enterprise edition production database servers periodically maintain critical indexes rebuilding reorganizing production servers problem since using standard edition dont access rebuild index online option dont limit access database critical indexes rebuilt get many timeout errors index essentially disabled rebuild ive used scripts ola hallengrens index optimize script however doesnt seem solve problem im thinking work around problem instead rebuilding index index fragmented create separate index copy ix name temp done drop original fragmented index finally rename copy index back original name im hoping new index built sql server use original somewhat fragmented index new temp index built start using one drop fragmented index rename back original state next time run scheduled job question approach make sense sql server able utilize new temp index copy im dropping original fragmented index tips possibly strategies appreciated
25305 tablespace parameter optional creating tables upon execution create table statement oracle assigns default one defined default database users tablespace several tablespaces defined one would assigned
25382 trying figure store formula method table could create category formula table category different way formula method calculate point need assign formula method category best way example cpucategory id calculate point formula would commision fulfilment bonus cost hard drivecategory id calculate point formula would commision cost formula would different categories mysql select category id name cpu hard drive mysql select items id category id name cost commision fulfilment bonus intel cpu core i7 3770k 160gb samsung spinpoint rows set sec update would use php calculation example admin website select formula setting category save formula setting could saved category formula table category formula table designed create table structure table category create table exists category id int11 null auto increment name varchar100 null primary key id engine innodb default charset latin1 auto increment dumping data table category insert category id name values cpu hard drive table structure table items create table exists items id int11 null auto increment category id int11 null name varchar100 null cost decimal62 null commision decimal62 null fulfilment float null bonus float null primary key id engine innodb default charset latin1 auto increment dumping data table items insert items id category id name cost commision fulfilment bonus values intel cpu core i7 3770k 160gb samsung spinpoint
25425 recently discovered large swath finance department using excel connect sql server instance account sysadmin role current risks immediately communicate powers
25448 query create new table existing table takes long time ive set remote database office ram connect database home usual psql tell remote server execute query terminal without wait response postgresql linux enviroment edit im open solutions necessary use psql
25461 well hypothetical scenario im trying understand path go post morten log say sql server profiler trace identify code orm situation make vague consider scenario like sql server entity framework orm scenario common path dba also vb net developer make log diagnosing codes case linq queries creating trouble case app ok affecting apps response time using db server would absurdly different java hiberate process edit want understand path trace culprit metaquery app sql means find files session maybe regex extreme cases could reduce inspect task targets dozen suspects instead tenths even hundreds source files using orm get stage using orm case ef
25472 high traffic website possible 1000s new records inserted every hour one error crippling site pdoexception sqlstate serialization failure deadlock found trying get lock try restarting transaction insert location instance nid vid uid genid lid values db insert placeholder db insert placeholder db insert placeholder db insert placeholder db insert placeholder array db insert placeholder db insert placeholder db insert placeholder db insert placeholder cck field item location db insert placeholder would surprised mysql could handle type load questions database issue configure mysql able handle much traffic copy website set development server scripts simulate load content added website running ubuntu lamp stack 16gb ram admittedly knowledgeable databases fact starting default cnf comes apt get install finishes tables innodb starting configuration settings approach would recommend begin solving problem let know information may need thanks
25513 im difficulty finding lay explanations indexes cached postgresql id like reality check assumptions postgresql indexes like rows live disk may cached index may entirely cache whether cached depends often used defined query planner reason sensible indexes going cache time indexes live cache buffer cache rows therefore cache space used index available rows motivation understanding follows another question asked suggested partial indexes used tables majority data never accessed undertaking id like clear employing partial index yields two advantages reduce size index cache freeing space rows cache reduce size tree resulting faster query response
25531 found script sql server reaching table row size limit seems return row size per defined data type lengths need script would give rows table max data size recommended whatever ms recommends
25627 problem definition users need ability query database mostly date data stale hours acceptable would lowest cost approach getting keeping second database date production copy approach im thinking workload third party application use monitor stock trading activity day lots little changes occur part various work flows yes trade valid suspicious etc night perform large set based operations load previous days trades current solution problem make use database snapshots drop recreate snapshot etl processing begins obviously taxing disk allows users ability query database without locking database use access front end use late night early morning notice downtime problem approach two fold first event nightly processing fails thats terribly uncommon get restore database results snapshot dropped problem processing times slipping past sla attempting address working vendor identified poorly written queries lack indexing database snapshot also culprit slowdown evidenced speed difference present versus shocking know approaches considered clustering database clustering turned didnt address needs making data available generally complicated admins lives since turned sql server replication started looking replication last week theory get second catalog stood synchronized production database prior etl beginning well sever connection enable etl process completed admin started snapshot replication hes concerned taking multiple days high cpu usage generate snapshot well disk consumption required indicates appears write data physical files prior ever shipping subscriber 6tb database cost 8tb storage costs also itll take multiple days generate snap wouldnt fit desired sla reading fine article seems like snapshot might way initialize subscribers wed want switch transactional replication keep sync assume turning transactional replication wont force full reinitialization otherwise well blow time window database mirroring database full recovery mode database mirroring option know even less replication find answer indicated database mirroring prevents data accessed directly mirrored data accessible database snapshot log shipping sounds like log shipping might also option another things know nothing would lower cost solution implementation maintenance anything else based remuss comment log shipping allows read access replica copy disconnect users applying next backup log received eg every minutes im sure long downtime would translate might cause users angst ms sync heard using sync past weekend yet investigated id hate introduce new technology something high visibility like problem best approach ssis plenty ssis generating hundred ssis packages keep secondary synchronized option us albeit ugly one fan thats lot maintenance overhead id rather team take san magic snapshot past ive heard admins using san technology make instant backups entire disks perhaps theres emc magic could used make uberquick copies mdf ldf detach attach target database backup restore think take full backups week differentials nightly tlogs every minutes users could live hour outage full restore suppose might approach constraints windows r2 sql server r2 enterprise edition vmware v5 enterprise edition emc san storage drives mapped vmdk files commvault handling backups 6tb data source catalog third party application host house modifying structure generally frowned upon users go without querying database refuse constrained proactively identifying tables monitor work dbas purely contractors moment full timers set sail replaced yet application admins well versed sql server matters team storage vm admins could help hinder effort development teams currently involved enlisted based approach simpler implement maintain solution would preferable im development side hosue propose approaches deal administration side things time admin saddle im hesitant say one approach would superior another looks great according papers im fully willing run direction yall suggest see going make valuable db professional wheelbarrow holocaust cloak available related questions https stackoverflow com questions scenarios using mirroring log shipping replication cluste https stackoverflow com questions mirroring vs replication https stackoverflow com questions sync databases mirroring replication log shipping https stackoverflow com questions sync databases mirroring replication log shipping http nilebride wordpress com log shipping vs mirroring vs replication edits address onpnts questions data latency acceptance users currently view data hours behind data current amount data change given minute hour day sure quantify business hours maybe hundreds changes per hour nightly processing millions rows per business day connectivity secondary internal network separate virtual host dedicated storage read requirements secondary instance windows group read access secondary tables time secondary instance strong definition time requirement users want always available willing pay probably much realistically id say hours day would suffice alterations existing schema objects infrequent modifications maybe per quarter table objects maybe per month code objects security special security needs production permissions would match copys permissions although think could revoke users read access prod allow read copy requirement though darin strait reverting snapshot could option think reason didnt pursue ill check admin cfradenburg assumption wed use one approaches good point restores would break sync technologies investigating using emc snapshot magic admin described would take snapshot migrate image secondarys zone complete theyd perform detach reattach secondary database wrap evaluated emc snapshot magic replication options dbas decided could best figure mirroring upvoted answers helped gave plenty options well homework investigate
25642 sql server r2 nonclustered covering index multiple tables 100m rows table thousand insertion points new inserts happen means regardless fill factor ill quickly end page splits fragmentation every insertion point fragmentation splits anywhere else table unfortunately queries always include new rows hence fragmented areas index happens theres page split inserts continue sequentially split way tell sql server split lots extra room subsequent inserts without wasting space existing pages large fill factor pages never filled good index maintenance strategies use indexes like good automated way identify tables like fragmentation severe uniform tables dont show fragmented overall index schema changes considering heres info problem indexes look like pattern simplifying clarity create table foo id int identity11 primary key clustered foreign key int log time datetime create nonclustered index foo foreign key log time include queries table always form log time getdate foreign key select facts foreign key values 10000s rows average row size bytes meaning around rows per page filter usually includes foreign key values rows date filter includes rows average total rows selected index covering index queries clustered index access needed
25667 looking best way disable access sys tables information schema user group sql server found thread shows way deny access sys something like deny select sys columns denysystemtableselectrole go deny select sys tables denysystemtableselectrole go deny select sys syscolumns denysystemtableselectrole go deny select sys sysobjects denysystemtableselectrole go way disable access information schema deny select information schema tables denysystemtableselectrole seems work disable access information schema easier way disable access sys information schema update actually run ot following statements deny select sys reduceddbo go deny select information schema reduceddbo go tried run specific db user exists also tried master still run select information schema tables still returns results select sys tables results anymore including schema query made possible create securables deny select schema sys reduceddbo go deny select schema information schema reduceddbo go still select information db look securables tab users property window management studio looks like entry block selecion sys tables schema sys name tables type view permissions sys tables permission select grantor dbo deny checked entry block selection schema name information schema type schema permissions information schema permission select grantor dbo deny checked tried check chance permission select grantor information schema deny checked tried set permissions gui get error setting permissions would possible master db user login added master dbs security solution way could make deny work information schema add user master db run deny select master deny select sys tables reduceddbo go deny select information schema tables reduceddbo go code executed single tables
25683 log table captures datetime stamp certain files exported another system exportedlog table currently three fields id primary key messageid int exporteddatetime datetime reviewing found id field serves purpose joins table thing working table insert batch job processes messages inserts log table remove id field primary key either messageid exporteddatetime
25730 current setup principal database used production manual failover mirrored database ha need setup reporting database well would best approach shall setup sql job drop create snapshot mirrored database refresh every night anyone suggestions thanks
25809 lets say table bookingsperperson person id arrivaldate departuredate need achieve view following person id arrivaldate departuredate jan jan jan jan jan jan jan system events hotel booking could take anything days ideas would much appreciated
27045 ive writing basic web apps year oracle db since functions pretty simple us stick regular loops get data select students loop htp prni student last name student first name student dob end loop cursors seem right way things find lots information cursors different ways loop cant find solid reason use regular loops dependent needs procedure inherent advantages aware
27100 two queries logically equivalent declare datetime datetime getdate query select mytable datediffday loginserttime datetime query select mytable loginserttime datetime logically equivalent give logical equivalent first query clause effectively use index eliminate function wrapping
27153 popular mysql postgres database system handle altering tables live production databases like adding deleting changing type colums know correct way backup everything schedule downtime changes current database system support things line without stopping anything maybe delaying queries reference column changed deleted happen alter table live running database everything stop happens data get corrupted etc im mostly referring postgres mysql encounter yes anytime right way backing things scheduling downtine etc want know possible sort things quick dirty db system actually support quick live dirty schema changes someone suggested online schema change mysql facebook script tutorial source seems like nice way automate set hacky ways anyone ever used something resemblig production
27255 need know enable disable history table trigger natively tracked sql server ive reviewed system views sys triggers contains modify date field sys trigger events focuses trigger insert update delete events recommend sources information trigger history
27265 sorry confusing title wasnt sure write table hundred records need assign record table much smaller dynamic table users users alternate records get assigned example tablea row number id tableb row number id need end result set userid recordid ive managed something bit messily using mod operator curious query could run without temp table variable temp table used tablea actually user defined function converts comma delimited string table need count objects udf converts comma delimited string table select num userid row number order select rowno tmptest dbo stringtonumset231 declare test int select test count tmptest select tmptest t1 inner join select top id row number order somedatetime rowno tablea nolock t2 t1 rowno t2 rowno test important userids alternate assign top records user1 second records user2 3rd records user3 also userids need maintain order originally entered row number order select users table way joining tables single query wont need use temp table variable im using sql server
27310 count aggregate sql query speed execution time database systems im sure many things could speed hardware one im novice dba im sure ill getting answers migrated million rows sql server database query taking forever source netezza database takes seconds example netezza select count databasename mytable oracle 11g select count mytable sql server select count databasename dbo mytable
27328 busy database solely innodb tables 5gb size database runs debian server using ssd disks ive set max connections sometimes saturate grind server halt average query per second 5k need optimize memory usage make room maximum possible connections ive seen suggestions innodb buffer pool size total memory hand get warning tuning primer script max memory ever allocated configured max per thread buffers configured max global buffers configured max memory limit physical memory current innodb variables innodb adaptive flushing innodb adaptive hash index innodb additional mem pool size innodb autoextend increment innodb autoinc lock mode innodb buffer pool instances innodb buffer pool size innodb change buffering innodb checksums innodb commit concurrency innodb concurrency tickets innodb data file path ibdata1 10m autoextend innodb data home dir innodb doublewrite innodb fast shutdown innodb file format antelope innodb file format check innodb file format max antelope innodb file per table innodb flush log trx commit innodb flush method direct innodb force load corrupted innodb force recovery innodb io capacity innodb large prefix innodb lock wait timeout innodb locks unsafe binlog innodb log buffer size innodb log file size innodb log files group innodb log group home dir innodb max dirty pages pct innodb max purge lag innodb mirrored log groups innodb old blocks pct innodb old blocks time innodb open files innodb purge batch size innodb purge threads innodb random read ahead innodb read ahead threshold innodb read io threads innodb replication delay innodb rollback timeout innodb rollback segments innodb spin wait delay innodb stats method nulls equal innodb stats metadata innodb stats sample pages innodb strict mode innodb support xa innodb sync spin loops innodb table locks innodb thread concurrency innodb thread sleep delay innodb use native aio innodb use sys malloc innodb version innodb write io threads side note might relevant see try insert large post say 10kb drupal sits separate web server database lasts forever page return correctly regarding im wondering innodb buffer pool size optimal performance appreciate suggestions set parameters optimally scenario
27383 much index need narrow results search order useful speeding queries examples across spectrum column storing true false values obviously two unique values last name column probably many unique values although may primary key column unique values think goal index quickly narrow search rows therefore last case best second ok first useless correct roughly line usefulness example index narrow results rows useful
27450 getting following sqlexception calling stored procedure attempt fetch logical page database failed belongs allocation unit system data sqlclient sqlexception occurred message attempt fetch logical page database failed belongs allocation unit source net sqlclient data provider errorcode class linenumber number procedure ispdisplaycount server state exception mean resolution issue although database referenced error indicates tempdb similar errors referencing message may fixed using answers msg level state line attempt fetch logical page database failed belongs allocation unit
27467 consider sql query select name row number overorder name asc footable observe results returned sorted name change sort column defined row number function another column results become sorted column expecting row number assigned rows expecting rows come back sorted criteria simply side effect query executed case sql server r2 behaviour guaranteed could find reference guarantee
27477 table stores historical temperatures past days stored integer column based city question query entries value great less specified value heres example table city temps seattle miami lets say want query cities experienced temp higher example miami experienced temps higher row returned ive tried queries success looked intarray doesnt seem solve problem either thanks much im running postgresql
27558 relates counting number records match certain condition invoice amount tend prefer countcase invoice amount end however valid sumcase invoice amount else end would thought count preferable reasons conveys intention count count probably involves simple operation somewhere whereas sum count expression simple integer value anyone specific facts difference specific rdbms
27637 dbconsole configured started navigate internet explorer shows page stating internet explorer display webpage error means ie received response server firewall completely disabled ive tried deconfig config avail thoughts could possibly lead path fixing appreciated os windows server bit db 11gr2 enterprise edition em whatever comes db 11gr2 update im using link automatically created run emctl config dbconsole db url https corp svr xxxxxx xxxxx em represents alphanumeric character removed privacy reason configures port 10g instance server already port recently updated 11g havent uninstalled 10g yet ive tried changing url use localhost network ipv4 address avail
27659 table looks like name kode jum aman kode1 aman kode2 jhon kode1 amir kode2 make view like mysql kode1 kode2 count aman jhon amir
27725 equivalent mysql show databases statement possible find databases cluster databases present network system could analyze files present oracle installation find given complete access credentials oracle system would go enumerating databases exist
27732 possible rename default f1 f2 f3 names using row json function columns row jsoncustomers returning id customer first name bla last name second bla want names without id customer use row jsonrowfirst name last name get f1 bla f2 second bla would like get result either default column names know create composite type use row jsonrowfirst name last name custom type isnt possible right query without creating type
27759 suppose table friends columns friend1id friend2id chose represent friendship two records say john jeff jeff john thus pair friends show exactly twice table sometimes constraint violated pair friends shows table write query identify cases ideally using reasonably standard sql words would like query return list rows table corresponding row swapped fields additional question way enforce referential integrity mysql
27879 system stored procedure sp dboption available sql server anymore could replaced
27893 postgresql instance running rhel core machine 16gb ram server dedicated database given default postgresql conf quite conservative regarding memory settings thought might good idea allow postgres use memory surprise following advice wiki postgresql org wiki tuning postgresql server significantly slowed practically every query run obviously noticeable complex queries also tried running pgtune gave following recommendation parameters tuned didnt change anything suggests shared buffers ram size seems line advice elsewhere pg wiki particular default statistics target maintenance work mem 960mb constraint exclusion checkpoint completion target effective cache size 11gb work mem 96mb wal buffers 8mb checkpoint segments shared buffers 3840mb max connections tried reindexing whole database changing settings using reindex database didnt help either played around shared buffers work mem gradually changing conservative default values 128k 1mb gradually decreased performance ran explain analyzebuffers queries culprit seems hash join significantly slower clear give specific example following query runs 2100ms default configuration 3300ms configuration increased buffer sizes select count contest left outer join contestparticipant cp id cp contestid left outer join teammember tm tm contestparticipantid cp id left outer join staffmember sm cp id sm contestparticipantid left outer join person id cp personid left outer join personinfo pi pi id cp personinfoid pi lastname like pi firstname like explain analyzebuffers query default buffers http explain depesz com xahj bigger buffers http explain depesz com plk question observing decreased performance increase buffer sizes machine definitely running memory allocation shared memory os shmmax shmall set large values problem im getting errors postgres log either im running autovacuum default configuration dont expect anything queries run machine seconds apart changed configuration restarted pg edit found one particularly interesting fact perform test mid imac osx also postgres 16gb ram dont experience slow specifically set work mem 1mb select running time ms set work mem 96mb select running time ms exactly query one exactly data server get ms work mem 1mb ms mb mac ssd understandably faster exhibits behavior would expect see also follow discussion pgsql performance
27949 use postgresql table million rows columns table change replace year users query table kinds filters columns select table null select table null performance plan create index every column table feeling stomach tells ask experts first good design described use case create index every column update speculate real use cases cant measure exact queries yet design phase server well equipped ram ssd storage queries already fast feel effect caching fire similar queries sequence columns types double integer timestamp geometry explicitly gets gist index queries include columns usually results usually 20k rows queries column never relate another column thanks explanations select 4th columns think used create indexes wait testing usage start measuring analysing queries use cases thank
27950 say want query database discover types trigger contains one way use objectproperty function trigger objects database sometimes objectproperty function produces confusing result output seems depend database context following example query returns row sysmail triggers msdb select object id name objectpropertyobject id execisinserttrigger isinserttrigger objectpropertyobject id execisupdatetrigger isupdatetrigger objectpropertyobject id execisdeletetrigger isdeletetrigger msdb sys objects type tr name like trig sysmail go intent find dml action fire trigger example isinserttrigger column contains trigger defined insert otherwise execute query context msdb result set contains computed columns looks like object id name isinserttrigger isupdatetrigger isdeletetrigger trig sysmail profile trig sysmail account trig sysmail profileaccount trig sysmail profile delete trig sysmail servertype trig sysmail server trig sysmail configuration trig sysmail mailitems trig sysmail attachments trig sysmail log execute query context master result set contains null computed columns looks like object id name isinserttrigger isupdatetrigger isdeletetrigger trig sysmail profile null null null trig sysmail account null null null trig sysmail profileaccount null null null trig sysmail profile delete null null null trig sysmail servertype null null null trig sysmail server null null null trig sysmail configuration null null null trig sysmail mailitems null null null trig sysmail attachments null null null trig sysmail log null null null msdn notes objectproperty function returns null property name valid object id valid id unsupported object type specified property caller permission view objects metadata rule reasons query returns correct result context msdb first thought might cross database permissions issue reason sysadmin server leaves reason leaves questions object id invalid cross database query databases objectproperty function called
28055 truncate table statement hang sometimes reasons type issue migrating mysql mariadb problem doesnt happen mysql mariadb hanging statement simply truncate table sampledb datatable cause happen could fix another one observation table data may one two rows truncate query works successfully else table lot data query becomes hang
28187 currently use following get local datetime utc datetime set offset datediffminute getutcdate getdate set localdatetime dateaddminute offset utcdatetime problem daylight savings time occurs getutcdate utcdatetime localdatetime ends hour easy way convert utc local time date current date im using sql server
28213 profile sql server database see code thats executed particular database remember using sql server profiler dont see sql server management studio downloading sql server r2 express download tool install need full version sql server order see option
28326 installed oracle 11g connect sysman oracle database tnsnames ora file find need generate tnsnames ora file place oracle generate need generate appropriate syntax file
28360 im good sql ive got database maintain theres almost place left ive decided delete data lets say year executing delete query rows cleaned cleaning transaction log ive found actions effect database size anything else
28370 currently data imports legacy system discovered system use single clustered index quick google search introduced concept heap tables curious usage scenarios heap table preferred clustered table far understood heap table would useful audit tables inserts happen far often selects would save disk space disk since clustered index maintain additional fragmentation problem rare reads
28406 want count two columns need get results first column one row select country count table1 group country type query gives country type count canada first canada second canada third australia second australia third need get country type first type second type third canada australia want update another table values row structure update country table row row get query update country set first second third note type column enum predefined values
28431 two tables foreign key t1 t2 one many relationship tuple table t1 associated tuples t2 create simple example lets say t1 cars t2 table imperfections car imperfections store imperfections t2 integers would like select cars cars contain imperfections i1 i2 performing instead pretty easy select cars t1 exists select imperfection imperfections t2 t1 uid t2 uid imperfection imperfection ive trying set logic using intersection point im wondering im complicating
28459 modify user interface language sql server management studio instance installed english wish view japanese name one possible example running environment non english first language environment would prefer windows read natural language particular natural language isnt really important
28512 first im dba im software engineer building applications database backed entire career one things remember maybe incorrectly designing erd take real world account serves context design situation concept customer two two phone numbers customer zero many addresses well address two phone numbers flag indicating number mobile number numbers address would used contact someone particular address numbers customer used contact customer whos address may system design came phone1 phone2 columns customer table well address table ive others suggest isnt good design created phonenumber table instead im sure suggesting relate numbers records certainly see valid well either still need phone1id phone2id customer address table something phone table tells record owns number issue though course makes appliction logic complex since need add remove update record phone table instead blanking nulling value respective tables design also acceptable one preferable valid
28544 want following db related patients patient inserts birthday shows age category infants children adult elderly etc help classify patients translate birthday age category design age category
28584 think would need help simplify problem lets assume two tables first called topics structure idtopic author deleted false false second callledd texts looks like idtopic idtext dateposted need select data every topic data newest text topic output like idtopic author deleted idtext dateposted false false sql query looks trying inner join second table grouped idtopic didnt work thanks
28730 stored procedure takes seconds im trying understand want execution plan run sql server management studio execution plan enabled takes minutes get tab says execution plan tab empty attempts run sql even select foo longer works broken sql server management studio app must shut try ive done three times wasted minutes ready learn alternatives first reliable command line way generate sqlplan file particular sql script maybe command line could investigate using tool ssms generate plans secondly isnt built reliable command line way generate store sql execution plan text xml id like know exists third party tools would good job large sqlplans particular choking dying gui drawing parts get overwhelmed ssms wont generate show execution plan im using sql r2 standard included ssms version dont extra plugins update im invoking stored procedure creates cursor subqueries great evil loop generating excess 10k individual subquery statements looks like really need refactor generate less storm output update2 really looks like server side tracing zero problem areas return profiling return query plans might required zoomed far deep big picture need zoom heck bit
28751 application generates lot data needs inserted quickly something around 13million records use jpa hibernate postgres managed achieve quite good performance around 25k inserts per second multi threading batching inserts every thousand inserts completing whole run around 8mins however noticed foreign keys index missing would really wish analysis point view drill data also delete data specific run unfortunately added indexes table getting inserts performance dropped drastically around 3k per second way avoid performance slow know one option drop indexes run recreate end another clumsy option generate data biggest table file instead use copy guess largest table relation due foreign key values would need know generated sequences alternatives seem hacks solution maybe bit less intrusive application setting tell postgres defer indexing something sort ideas welcome
28801 windows r2 running sql server r2 imporatant ntfs allocation unit size disk io performance appears server admin built servers mission critical app left ntfs allocation unit size cluster size default kb instead kb sql server already installed worth take pain uninstall sql format drive kb cluster size reinstall sql server
28926 using aws cloud environment installed postgresql drive root instance volume attached mounted second drive instance want move postgresql data different drive still development mode delete old data makes transfer easier point time best way postgresql tablespace something look
29055 sql server im getting following error query canceled estimated cost query exceeds configured threshold contact system administrator result execution stored procedure pretty complex havent run stored procedures one possible change query cost one procedure somehow stored procedure upon execution define server im using ado net command execute stored procedure thanks
29064 customer switching san storage directly attached storage sql server database several filegroups deployed lun order determine best setup filegroups directly attached storage want test loading existing file groups directly attached storage would normally tested loading looking performance counters like disk queues etc assumes file groups setup separate arrays sans would normally got io throughput lun san vendor however filegroups lun test heavily filegroup loaded way sql profiler thanks chris
29116 need run sql server logging db main tables seperate datacentres writing time idea restoring db new datacentre reseeding identity column setting increment way would never chance duplicate ids data needs combined datacentre1 would positive integers datacentre2 negative integers would increment cause issues
29194 mysql official rpm shipping files usr share mysql innodb heavy 4g cnf usr share mysql medium cnf usr share mysql huge cnf usr share mysql large cnf usr share mysql small cnf files gone one left usr share mysql default cnf im mysql tuning expert used always start innodb heavy 4g cnf left single configuration option remove leading set amount ram important data cache mysql start total ram dedicated server else innodb buffer pool size 128m tuning variable magic key optimizations relevant parameters tune installing new server case find equivalent file would contain sensible defaults innodb 4gb ram dedicated mysql server
29284 using sql server wondering profile stored procedures instance profiler capture individual sql statement stored procedure long takes run etc trying diagnose merge replication stored procedures must captured part full run merge agent doesnt seem possible grab stored procedure performance issues run point slow
29289 context first wrote reports straight without locking hints queries larger reports would sometimes cause locking problems first remedied using nolock hint tables query quite obtrusive easy forget hint one tables moved second approach setting transaction isolation level read uncommitted fine top datasets query may guess still easy forget hint one datasets leads question question options sending nolock hints along report queries ps realize extent xy problem lot options optimizing query reporting operational database etc tried make valid question nonetheless options options mentioned added options im curious would work set nolock hint table obtrusive easy forget set isolation level read uncommitted entire query still easy forget possible specify report level make sure dataset queries one report run without locking possible specify ssrs level perhaps set certain report folder utilizing extension possible specify data source connection string level relevant reports use certain lock data source related previous option perhaps possible specify default locking hint specific lock sql user one thats used connection options viable options ive missed
29309 take following code declare integer set set cast binary set cast binary select cast integer shouldnt output code integer set binary 0s becomes binary become decimal output actually get edit clarity im trying accomplish tsql following code include stdio include iostream using namespace std int main int cout 0b100 cout endl
29328 working sql server since sql server old advice still rings head never place upgrade im currently upgrading r2 dev test systems sql server need use hardware thought restore reporting services configuration attractive im really wall time wise analysis services involved anything unusual non standard database engine reporting services installed anyone experienced serious issues place upgrades reevaluate position place upgrades
29352 field meta value current value like want change string thought could get value update characters correct order ie update wp postmeta set meta value meta value meta value meta value meta value
29363 database set use full recovery guess reasoning prevent data loss failure happened full backups make daily full backups database need recover point time previous last full backup data files log files hard drive experience programmer im dba database failures ive seen related disk failures wonder setup makes sense imagine hard drive fails wouldnt able recover using transaction logs question twofold likely cause database failure hard drive failure common reasons would justify setup would make sense switch simple recovery model convince business worst case scenario would input data day
29403 many systems configuration one server virtual physical running sql server sql sql server analysis server multiple cores 16gb ram night sql server hours processing followed hours processing throughout day queried assuming dedicated server apps concern two sets processing completely synchronous overlaps always one best set sql server memory limits reason asking dont set limit sql grab memory however understanding sql happily relinquish memory using another service program requests logical perspective believe allow sql take much needs im sure totalmemorylimit im sure relinquish memory fact reading leads believe wrong let take mean need actually set limits im confused best practises need measuring considering processes dont overlap hope makes sense
29415 table called slot follows default data 1st table day time venue free rm rm rm rm rm rm rm rm another table booking data might come go anytime column header fixed 2nd table day time venue user rm jill rm jill rm jack rm mary rm mary rm jill rm ken rm ken based example data table booking derive following table 3rd table wanted day time venue free used rm rm rm rm rm rm rm rm able retrieve following table 4th table day time venue used rm rm rm using following command select day time venue count used booking group day time venue order day asc time asc time asc find hard merge get 3rd table wanted
29468 process creating test environment sql server development staff production sql servers sql01 contains several databases mirrored sql02 sql03 acts witness high safety automatic failover synchronous configuration ive used vmware p2v virtualize three machines onto separate hardware reconfigured sids machines blackholed ip addresses production servers new machines initially forgotten blackhole production witness machine databases test machines still using sql03 machine witness noticing issue decided reconfigure databases test point newly virtualized test witness call test03 reconfigure database use new witness entered following command primary server test01 alter database testdb set witness tcp test03 domain inet response unexpected alter database command could sent remote server instance tcp test03 domain inet database mirroring configuration changed verify server connected try perplexed error message since configuration work production machines modified way test machines order get work needed create login test witness create login domain sqlserviceaccount windows default database master grant connect rights endpoint question grant connect endpoint mirroring domain sqlserviceaccount able successfully point mirrored databases test environment new test witness inspect production witness endpoint see security associated assume must system catalog inspect however books line seem anything specific endpoints bing well bingless additional info select ep endpoint id class desc permission name ep name sp name sys server permissions inner join sys endpoints ep major id ep endpoint id inner join sys server principals sp grantee principal id sp principal id class returns endpoint id class desc permission name endpoint name principal name endpoint connect tsql local machine public endpoint connect tsql named pipes public endpoint connect tsql default tcp public endpoint connect tsql default via public select name endpoint id protocol desc type desc role desc sys database mirroring endpoints returns name endpoint id protocol desc type desc role desc mirroring tcp database mirroring witness appears entry sys server permissions mirroring endpoint object major id minor id matches also none system databases contain reference endpoint im loss
29489 table million tuples looks like table public methods column type attributes id integer null default nextvalmethodkey regclass hash character varying32 null string character varying null method character varying null file character varying null type character varying null indexes methods pkey primary key btree id methodhash btree hash want select values query incredibly slow db explain select hash string countmethod methods hash select hash nostring group hash string order countmethod desc query plan sort cost rows width sort key countmethods method groupaggregate cost rows width sort cost rows width sort key methods hash methods string seq scan methods cost rows width filter subplan subplan materialize cost rows width seq scan nostring cost rows width hash column md5 hash string index think problem whole table sorted id hash takes sort first group table nostring contains list hashes dont want need tables values option delete additional info none columns null fixed table definition im using postgresql
29522 table 64m rows taking gb disk data row bytes integer columns plus variable nvarchar255 column text added nullable column data type datetimeoffset0 updated column every row made sure new inserts place value column null entries ran command make new field mandatory alter table tblcheckresult alter column dtodatetime datetimeoffset null result huge growth transaction log size 6gb 36gb ran space anyone idea earth sql server r2 simple command result huge growth
29532 sql queries combine one result set end guessing since operating tables sql sections cool way get results one unified sql query currently like select date convertdate crdate tally sent smc attachment count total mb size sumcastad size decimal tmp attachments sent smc attachmentdetail ad inner join messageattachment ad attachmentid attachmentid inner join messagerecipient mr messageid mr messageid inner join message mr messageid id ad isinline mr recipienttypeid leftmr emailaddress4 smc group convertdate crdate order date desc select tmp attachments sent smc select date convertdate crdate tally sent smc attachment count total mb size sumcastad size decimal tmp attachments sent smc attachmentdetail ad inner join messageattachment ad attachmentid attachmentid inner join messagerecipient mr messageid mr messageid inner join message mr messageid id ad isinline mr recipienttypeid leftmr emailaddress4 smc group convertdate crdate order date desc select date convertdate crdate grand total sent smc count total mb size sent smc sumcastsize decimal tmp sent smc message messagesourceid group convertdate crdate order date desc select date convertdate crdate grand total sent smc count total mb size sent smc sumcastsize decimal tmp sent smc message messagesourceid group convertdate crdate order date desc select tally sent smc attachment total mb size grand total sent smc total mb size sent smc grand total sent smc total mb size sent smc tmp attachments sent smc join tmp attachments sent smc date date join tmp sent smc date date join tmp sent smc date date drop table tmp attachments sent smc drop table tmp attachments sent smc drop table tmp sent smc drop table tmp sent smc
29543 using databases total application share 4tb space among auto grow databases via san storage id like write query report single database indicating currently allocated space available free space attributes tasks shrink database option sql server management studio id like convert numbers tb total database get rough estimate much space left fields accessed via sql query would query look like
29544 working sql server r2 trying rollback set ddl statements group think upgrade script database running trouble take following code begin try begin tran create table foo int alter table foo add dog insert foo select insert foo select commit tran end try begin catch rollback tran print error end catch im expecting try fail alter table statement drop catch rollback transaction print error message however check objects tables youll see foo still create table didnt rollback properly select sys objects name foo wrong
29596 test network database created sql server update sql server sql server data base used sql server moved best way transfer database sql server update
29613 message sql server log file viewer shows login failed user user error severity state actually means failed open explicitly specified database question list somewhere variations errors login failed combination severity state helpful description text ive google cant find anything specific combinations
29636 need make heavy statistical analysis deliver data users currently catch data mysql process via php arrays however mysql temporary tables quite better extremely efficient faster php arrays obviously due mechanism tentative solution form temporary table upon request connection import process data however sure drawback creating many temporary tables simultaneously make problem mysql server use alternative php arrays numerous simultaneous requests
29668 alright im trying make query library show students never borrowed book done following select leerlingen llnr leerlingen voornaam leerlingen tussenvoegsel leerlingen achternaam leerlingen klas count aantal uitleningen inner join leerlingen uitleningen llnr leerlingen llnr group leerlingen llnr leerlingen voornaam leerlingen tussenvoegsel leerlingen achternaam leerlingen klas count doesnt seem work reason create empty table click execute wrong
29712 8gb ram server run instances sql server express total memory limit used sql server 1gb 4gb would advisable run multiple instances like enable database make better use resources assuming server plenty resources
29723 sql server user ability drop database ive running code check rights user sql server able identify user ability drop databases sql script help identify user drop dbs command deny dropping databases ssms showing user part dbcreator role select user namep grantee principal id principal name dp type desc principal type desc class desc object namep major id object name permission name state desc permission state desc sys database permissions inner join sys database principals dp grantee principal id dp principal id order principal name output query provides following three records user helpful class desc object name permission name permission state desc object column xp cmdshell execute grant database null connect grant database null create database grant
29767 try use file psql exe folder says permission denied example file sql command users work desktop school work load database sql type users work desktop school work load database sql says permission denied fix found work around copy sql file folder psql exe way stand import
29775 input table containing number user supplied strings value table user details userid username tom ann dina mark need query return records users table username partial string match value record input table expected output case userid username tom ann
29801 want make alter table expression adds new column sets default value additionaly defines allowed values column text column allowed value1 value2 value3 default value1 according following syntax diagrams im getting point alter table exampletable add column new column varchar20 default value1 im absolutely sure set allowed values possible make somethin like constraint check new column value1 value2 value3 must admit search condition diagram quite confusing
29829 one seems common question forums web asked many formats typically sound like sql server reasons transaction log grows large log file big ways prevent problem occurring get track underlying cause want put transaction log file healthy size
29903 servers alwayson group user accounts within synchronized database exist servers database instance level logins exist one servers ie dbinstance security logins missing one server therefore failover get login failures second server doesnt corresponding instance level logins overcome issue supposed set user account special way
29913 im graduate school student researching olap mondrian olap want insert data innodb mysql faster initial loading environment user think allow loose settings insertion speed moment im using following techniques disable log bin enable skip innodb doublewrite set transaction isolation read committed read uncommitted actually read commited set innodb flush log trx commit actually set innodb buffer pool size 5gb system 6gb ram techniques faster insertion innodb modify innodb io read thread innodb io write thread need information please tell
29961 using pgadmin iii right click database navigate variables tab put variable name value property database way customize saw application name variable id like application version variable
29963 related question help get better performance innodb tables according mysql manual innodb flush log trx commit global dynamic variable thus change using set global command seems working mysql set global innodb flush log trx commit query ok rows affected mysql show variables like innodb flush log trx commit variable name value innodb flush log trx commit row set make actual mysql setting changed updated cnf restarted mysql server work change global variable run time prefer default value innodb flush log trx commit need change run restore process large database get faster process done want change value back possible run time dont access cnf shared hosting server
29985 table following structure id int identity pk fooid int fk barid int fk quxid int fk fields following indexes defined pk id clustered index1 fooid index2 fooid barid index3 fooid barid id quxid redundant keep index1 index2 considering id pk make sense third column index3 quxid would make sense one index fooid barid quxid would benefit including id sidenote im developer dba
30019 index one attribute speed gained select statement whose clause uses one attributes index example take table index attributes index useful query select foo ask book im reading following statement trouble understanding key multiattribute index really concatenation attributes order even use index find tuples given value first attributes
30061 list tables schemas using dt also lists system tables greatly outnumber tables care id like tables possibly views created public schema schemas ive defined im hoping find way without explicitly add schemas search path create described https stackoverflow com edit based accepted answer ive created following view create view tables select table catalog table schema table name table type information schema tables table schema pg catalog information schema following command gives wanted select tables
30091 im using sql server r2 logged ssms turn connects remote sql server machine im writing query writes file need know windows permissions grant myfolder select query provide windows account actually finally writes file
30119 sql server instance linked server oracle server table oracle server called personoptions contains following data personid optionid need pivot data results personid optiona option option suggestions
30210 new offset fetch model introduces sql server offers simple faster paging differences considering two forms semantically identical common one would assume optimizer recognizes optimizes trivially fullest simple case offset fetch 2x faster according cost estimate select objects sys objects select select row number order object id objects order object id select objects order object id offset rows fetch next rows one vary test case creating ci object id adding filters impossible remove plan differences offset fetch always faster less work execution time
30317 start object id database id inside user defined function want get full name id database schema object get schema id without using dynamic sql prohibited inside udfs note get database name db name get object name using object name accepts db id second parameter get schema name using object schema name also accespts db id second parameter easy get schema id using dynamic sql select db name want sys schemas allowed udf update purpose possible solution db id context farther call stack im adapting call stack functions gabriel mcadams work accross multiple databases version pushes proc id call level onto context info stream ive modified also push db id could push schema id well things start get crowded context info limited bytes hoping able reconstruct schema id db id object id function creates view call stack callstackview code db id proc id saved logging function declare db name nvarchar128 db name db id ok declare obj name nvarchar128 object name proc id db id ok declare schema name nvarchar128 object schema name proc id db id ok declare schema id int
30374 several databases legacy applications run vms currently someone needs look history set databases used applications offline wanted know performance benefit unused databases offline state instead sitting online unused without connections queries run
30383 im administrator simply run command sqllocaldb start v11 result start localdb instance v11 failed following error error occurred localdb instance startup sql server process failed sta rt event viewer log event id windows api call waitformultipleobjects returned error code windows system error message application error application unable start correctly 0x lx click ok close application reported line tried another user administrator accounts problems uninstalled reinstalled version sqllocaldb msi luck idea fix
30477 found deadlock appears show something thought impossible two processes involved deadlock process8cf948 spid performing alter table temporary table pb cost excp process invoices work owns ix lock table pb cost excp process invoices work object id process4cb3708 spid performing update temporary table pb cost excp process invoices work supposed unique copy table owns sch lock pb cost excp process invoices work object id supposed impossible missing something temporary table really get reused two spids sql server r2 service pack cumulative update version full unaltered deadlock trace note two processes operating object id table name pb cost excp process invoices work snip 0000000d8519 03spid23sunknownwaiter id process8cf948 mode requesttype wait 03spid23sunknownwaiter list 03spid23sunknownowner id process4cb3708 mode sch 03spid23sunknownowner list 03spid23sunknownobjectlock lockpartition objid subresource full dbid objectname tempdb dbo pb cost excp process invoices work 0000000d8519 id lock371705d00 mode sch associatedobjectid 03spid23sunknownwaiter id process4cb3708 mode sch requesttype wait 03spid23sunknownwaiter list 03spid23sunknownowner id process8cf948 mode ix 03spid23sunknownowner list 03spid23sunknownobjectlock lockpartition objid subresource full dbid objectname tempdb dbo pb cost excp process invoices work 0000000d8519 id lock3139b4780 mode ix associatedobjectid 03spid23sunknownresource list 03spid23sunknownproc database id object id 03spid23sunknowninputbuf 03spid23sunknownexec pb processexc costs submit sp sitekey pwdate 03spid23sunknownframe procname pdicompany dbo dr submitpaperwork sp line stmtstart stmtend sqlhandle 0x03000800cb72be6e500434018da000000100000000000000 03spid23sunknownexec pb processexc costs create sp clean work table 03spid23sunknownframe procname pdicompany dbo pb processexc costs submit sp line stmtstart stmtend sqlhandle 0x03000800428c1f1950f833018da000000100000000000000 03spid23sunknownupdate pb cost excp process invoices work set pbceprcinv rtlpkg item quantity rtlpkg item quantity pb cost excp process invoices work inner join item packages nolock pbceprcinv itempkg key itempkg key inner join retail packages nolock itempkg rtlpkg key rtlpkg key lookup pricebook cost 03spid23sunknownframe procname pdicompany dbo pb processexc costs create sp line stmtstart stmtend sqlhandle 0x030008003a082846321f46018da000000100000000000000 03spid23sunknownexecutionstack 03spid23sunknownprocess id process8cf948 taskpriority logused waitresource object waittime ownerid transactionname update lasttranstarted 14t13 xdes 0x3c4502930 lockmode schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 14t13 lastbatchcompleted 14t13 clientapp pdi wcf services pdidb01 pdimaster cfg hostname pdiweb01 hostpid loginname pdiuser isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 03spid23sunknownproc database id object id 03spid23sunknowninputbuf 03spid23sunknownexec pb processexc costs submit sp sitekey pwdate 03spid23sunknownframe procname pdicompany dbo dr submitpaperwork sp line stmtstart stmtend sqlhandle 0x03000800cb72be6e500434018da000000100000000000000 03spid23sunknownexec dbo pb processexc costs createinvoiceworktable sp 03spid23sunknownframe procname pdicompany dbo pb processexc costs submit sp line stmtstart stmtend sqlhandle 0x03000800428c1f1950f833018da000000100000000000000 03spid23sunknownalter table pb cost excp process invoices work drop column pbceprcinv filler 03spid23sunknownframe procname pdicompany dbo pb processexc costs createinvoiceworktable sp line stmtstart stmtend sqlhandle 0x0300080025d75a14ffff4701969f00000100000000000000 03spid23sunknownexecutionstack 03spid23sunknownprocess id process4cb3708 taskpriority logused waitresource object waittime ownerid transactionname alter table lasttranstarted 14t13 xdes 0x5f48bce80 lockmode sch schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 14t13 lastbatchcompleted 14t13 clientapp pdi wcf services pdidb01 pdimaster cfg hostname pdiweb01 hostpid loginname pdiuser isolationlevel read committed xactid currentdb locktimeout clientoption1 clientoption2 03spid23sunknownprocess list 03spid23sunknowndeadlock victim process4cb3708 03spid23sunknowndeadlock list update machine question shows processors task manager device manager lock partitioning enabled two locks different lock partitions dont know lock partitioning contributing cause also found intriguing post css sql server engineers blog update temporary tables dropped end every stored procedure created pattern create table modify schema insert update select drop multiple entry points common procedure uses temp table central proc sets columns needed call common proc otherwise wed replicate table definition entry point procs process invoked frequently multiple client applications client applications call process multiple threads others run one time think inventory accounting software home office processing data thousands stores parallel stores also run process rare issue lock partitioning enabled going rare larger customer databases update another customer issue sql server build see mention fix issue cumulative update descriptions researching update microsoft released fix bug following updates cumulative update package sql server r2 sp2 cumulative update package sql server sp1
30551 trying add new column table query giving error rds instance size small gb memory ecu virtual core ecu table trying modify million rows 7gb size disk size instance 15gb free critical time us stuck aws rds allowing access parameters mysql configurations get rid problem
30609 established replication broken requested wal segment already removed downtime easily stop master pg start backup rsync pgdata master slave pg stop backup master postgresql still full load pg start backup lead table locks blocks inconsistencies fire alarm slow db response words pg start backup affect application
30621 last release app added command tells wait something arrives service broker queue waitfor receive convertint message body message myqueue dbas tell since addition log sizes gone roof could correct looking elsewhere
30626 disclaimer admittedly havent tried yet im sure would know wasnt working correctly wanted ask would like run nightly backup job via pg dumpall hot standby server running streaming replication avoid putting load primary ive seen mention gotchas people run little guidance okay backup lags behind primary slightly long consistent questions really want backup done primary server dump standby settings need procedure use correctly must stop replication duration backup
30637 old computer oracle 8i dead daily backup database oradata unable install old oracle version anywhere dont install cds read database example oracle express yes
30692 weve reports queries running slowly timing early morning job see running think could affect database backup job database 300gb backup job starts 30am doesnt finish little 00am current syntax backup job backup database databasename disk ne database backups databasename bak init nounload name ndatabasename bak noskip stats noformat partition server holds databases database backups also probably noted virtual server dedicated standalone server started getting complaints slowdowns backup process right switched virtual server think may related way run backup job doesnt affect query performance running using sql server
30696 following sql query select event id event iata device name eventtype description event data1 event data2 event plctimestamp event eventtypeid event inner join eventtype eventtype id event eventtypeid inner join device device id event deviceid event eventtypeid event plctimestamp event iata like order event id also index event table column timestamp understanding index used statement question way make index particular statement speed query also tried adding event eventtypeid filter index timestamp looking execution plan doesnt appear using index suggestions insight would greatly appreciated graphical plan link sqlplan file
30734 im currently working project bulk import data flat files csv different files linking specific table stored procedure followed steps advised data loading performance guide database bulklogged recovery mode minimize logging executing stored procedure file containing rows get error msg level state procedure sp import declarationclearancehistory fromcsv line transaction log database full find space log reused see log reuse wait desc column sys databases testing purposes full backup starting import looking log reuse wait desc see following log reuse wait desc checkpoint import get imported successfully input solving would welcomed procedure dbo sp import declarationclearancehistory fromcsv filepath nvarchar begin creating temproary table importing data csv file dbcc traceon610 create table declarationclearancehistory itemid int identity1 null cmsdeclarationid bigint null statuscode nvarchar null substatus nvarchar null departmentcode nvarchar null startdate datetime null enddate datetime null primary key clustered itemid asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary inserting csv temproary table using bulk insert exec bulk insert declarationclearancehistory filepath fieldterminator rowterminator firstrow keepidentity codepage acp order itemid asc using merge statement inserting record present updating exist merge dbo declarationclearancehistory targettable inserting updating table using declarationclearancehistory sourcetable records temproary table records csv file targettable itemid sourcetable itemid defining condition decide records alredy present matched target insert itemid cmsdeclarationid statuscode substatus departmentcode startdate enddate values sourcetable itemid sourcetable cmsdeclarationid sourcetable statuscode sourcetable substatus sourcetable departmentcode sourcetable startdate sourcetable enddate matched matched update update set targettable itemid sourcetable itemid targettable cmsdeclarationid sourcetable cmsdeclarationid targettable statuscode sourcetable statuscode targettable substatus sourcetable substatus targettable departmentcode sourcetable departmentcode targettable startdate sourcetable startdate targettable enddate sourcetable enddate dbcc traceoff610 end
30787 answering stackoverflow question found strange result select pg timezone names name europe berlin name abbrev utc offset dst europe berlin cet next query select id timestampwithtimezone timestampwithtimezone time zone europe berlin berlin timestampwithtimezone time zone cet cet data id timestampwithtimezone berlin cet im using postgresql ubuntu checked result according documentation doesnt matter use name abbreviation bug something wrong someone explain result edit comment cet europe berlin im selecting values pg timezone names select pg timezone names abbrev cest name abbrev utc offset dst select pg timezone names abbrev cet name abbrev utc offset dst africa tunis cet africa algiers cet africa ceuta cet cet cet atlantic jan mayen cet arctic longyearbyen cet poland cet winter europe berlin summer edit2 timezone change summer time winter time two records value europe berlin suggest use one abbreviations cet cest big data range summer time winter time result wrong records good use europe berlin changed system time pg timezone names changed also select pg timezone names name europe berlin name abbrev utc offset dst europe berlin cest
30788 two tables sources sname sid apple1 apple2 banks banksb bankerly prefixes pname pid app bank banker goal find longest prefix matches sources results would look like sname sid pname pid apple1 app apple2 app banks bank banksb bank bankerly banker constraints using sql server upgrade know solve problem using analytic functions available sql server far know
30824 sql server newbie im mysql guy im look something client sql server need advice whoever designed database chose log insane amounts stuff never flush log tables largest table stores complete xml documents transactions app apis sites like ebay assume database gigabytes hurts performance im guessing tables queried app even dont like idea huge database purging log tables would anticipate total remaining size 30gb id like advice go little ive read subject deleting bunch data database file automatically shrink size also read shrinking indexing bad large database hurting performance tables something safely something yield performance increase
30862 executing query pull deadlock events default extended events session select cast replace replace xeventdata xevent value data value varcharmax victim list deadlock victim list process list victim list process list xml deadlockgraph select cast target data xml targetdata sys dm xe session targets st join sys dm xe sessions address st event session address name system health data cross apply targetdata nodes ringbuffertarget event xeventdata xevent xeventdata xevent value name varchar4000 xml deadlock report takes minutes complete machine stats reported table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads sql server execution times cpu time ms elapsed time ms slow plan xml remove clause completes less second returning rows similarly add option maxdop original query speeds things stats showing massively fewer lob reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads sql server execution times cpu time ms elapsed time ms faster plan xml question anyone explain whats going original plan catastrophically worse reliable way avoiding problem addition ive also found changing query inner hash join improves things extent still takes mins dmv results small doubt join type responsible though presume something else must changed stats table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads sql server execution times cpu time ms elapsed time ms plan filling extended events ring buffer datalength xml bytes contained events testing cut version original query without maxdop hint select count select cast target data xml targetdata sys dm xe session targets st join sys dm xe sessions address st event session address name system health data cross apply targetdata nodes ringbuffertarget event xeventdata xevent xeventdata xevent value name varchar4000 xml deadlock report select sys dm db task space usage session id spid gave following results fast slow internal objects alloc page count internal objects dealloc page count elapsed time ms lob logical reads clear difference tempdb allocations faster one showing pages allocated deallocated amount pages used xml put variable slow plan page allocation counts millions polling dm db task space usage whilst query running shows seems constantly allocating deallocating pages tempdb anywhere pages allocated one time
30932 since im dba many cases de facto sysadmin sql server installed pretty much every server work regularly realized recently ive using sql agent job scheduler pretty much every case rather native windows task scheduler perspective sql agent number advantages native windows task scheduler remote workstation start stop monitoring tasks shared schedules rather task multiple steps control flow different types tasks alerts failure completion configured act different users moderately descriptive error messages rather error code however cant escape feeling bad practice sql agent reserved database related tasks leave os level tasks running windows task scheduler despite dislike usability okay rely sql agent way consider third party windows task scheduler get functionality im looking
31018 database accessed around clients via tds tcp seem releasing log space number processes stays around expected quite long lived days database gb log space gb data gb free due space limitations drive would like shrink something reasonable 10gb ish execute dbcc shrinkfiledb log returns error end log use order free access end log attempted place database single user mode following alter database db set single user rollback immediate go alter database db set multi user go script returning following message repeated hundreds times nonqualified transactions rolled back estimated rollback completion leads believe somewhere leaving transactions uncommitted aware process would intentionally open many transactions one time think must accumulate time never closed question locate offending process script log released sys dm tran active transactions showing reasonable transactions understandable purposes sp shows processes aware sql server version microsoft sql server r2 rtm x64 apr copyright microsoft corporation enterprise edition bit windows nt x64 build service pack hypervisor server version windows server r2 x64 datacenter vcpus 16gb memory pass disk data log os disk vhd hyper windows server r2 sp1 x64 datacenter dual intel x5650 core thread 67ghz gb memory hypervisor three vms show high resource use sql server vm shows cpu load cache hits
31045 table 106k rows 11k rows values columns swapped want run query fix dont think update game set homescore awayscore awayscore homescore awayscore homescore winner hometeam awayscore homescore winner awayteam im worried scores end value also please validate query intend need swap home away scores rows recorded winner correct doesnt match scores recorded accidentally swapped coding mistake fixed saying winner team points
31087 developed java program works sql server database installed sql server enterprise edition windows designed database via sql server management studio example designed tables set backup schedule takes backup every 24hs features version sql server express installed users windows computer program connect local db work also proscribed database features like backup schedule would work database java program going computer criteria chosing database edition database tables java program going insert update delete select add columns tables ireport used report data addition java application database file set deleted scheduled backup nothing else
31104 possible call sql server job run within another job know add steps job job prefer first job already quite big second couldnt find copy paste option copy steps jobs would time consuming add steps manually suggestion appreciated
31348 question regarding transaction log let call ldf short contents assuming database full recovery model read ldf file contains logs every operation database full recovery mode different logging begin tran commands commit asking apparently roll back transactions roll back standard commands full recovery mode guess transaction contents logged ldf file different regular full recovery logging right different inclusion undo operations action related note heard commercial tools rollback undo standard queries using full recovery ldf file analyze ldf contents try come inverse undo operations
31366 realize somewhat subjective question looking community guidance company fairly new dbas used use db2 ibms iseries servers really wasnt need dba least operationally os pretty much managed everything us within last years started move db2 luw aix thus need dbas born three us interested making career change developers dbas one aix defaulted using ksh scripting language database management functions creation deployment operations etc found ksh quite powerful yet functions need perform get rather complex example question unix linux stackexchange based question well reading blogs db2 administrators see general suggestion perl better suited administration scripting ksh realize unix linux forum would thoughts thing wish approach database administration viewpoint regardless dbms scripting language seems better suited administration unix linux platform perl ksh perhaps strengths weaknesses use scripting languages encounter dba pick language dont want highly subjective flame war language better language kind stuff like used see development community regarding say java vs ruby etc looking honest objective possible information regarding best suits needs database administrators
31368 two questions database full recovery mode lets call transaction log ldf file short sql server allows restore point time past restoring database even make sense tried yield expected results even allowed work practical purposes playing ldf files discovered curiosity consider database simple mode switch full recovery mode insert rows database check ldf find ldf file size increase take full backup insert rows database ldf file increases sort optimization note ldf file shrinked operations thanks explanations
31378 scenario time data inserted updated deleted table multiple unrelated items business logic need executed question given solution use database triggers option better single trigger per operation insert update delete table executed insert table executed update table executed delete trigger would handle multiple unrelated items business logic multiple triggers per operation segregated concern table logging logging insert table ri enforcing referential integrity insert table bl executing business logic insert table logging logging update table ri enforcing referential integrity update table bl executing business logic update table logging logging delete table ri enforcing referential integrity delete table bl executing business logic delete prefer option single unit code single concern dba know enough sql server make dangerous architecture schema database must changed several places schema enforced explicit relationships unfortunately changed yet reason need manually enforce referential integrity instead relying explicit relationship compelling reasons handle concerns single trigger im specifically concerned performance order execution rollback
31383 anyone explain main differences help appreciated
31460 moving records one database another part archiving process want copy rows destination table delete rows source table question efficient way check first insert successful deleting rows idea feel better way num records select countid source table criteria eligible rows insert destination table criteria eligible rows select countid destination table criteria numrecords delete source table criteria better possible combine raiserror function thank
31511 copied code create table records email text references usersemail lat decimal lon decimal depth text upload date timestamp comment text primary key upload dateemail create table samples date taken timestamp temp decimal intensity decimal upload date timestamp email text primary keydate takenupload dateemail foreign key upload dateemail references recordsupload dateemail first thing caught eyes use natural composite keys primary keys tables things able extract piece code users table shown uses email primary key type text records table uses composite key text timestamp samples table uses composite key fields type text timestamp timestamp case wouldnt surrogate key better identification mean performance wise indexing int better indexing text something could make surrogate key bad choice
31514 way figure best way know indexes create table
31561 run pre existing sql im hard time uderstanding select maxi symbol symbol maxi ticker cusip maxi name name sumh quantity totalquantity sumh marketvalue totalmarketvalue maxh pricelc price maxi categorycode5 buy sell maxi equivfactor1 pricetgt maxp lastprice currprice maxi assetclass target maxi industry industry maxi categorycode1 risk holdings secure investments price symbol symbol product stock quantity categorycode5 symbol symbol group symbol symbol ticker name categorycode5 assest class industry categorycode1 varchar fields remaining fields decimals best educated guess somehow max used avoid multiple grouping columns return correct results
31593 two databases database1 database2 databases contain table similar structure exemplified follows id name phonenoformat dialingcountrycode internationaldialingcode internettld however due reason one tables one databases data exactly contained table another database compare database1 table1 database2 table1 tried using following query nothing happened wondering rewrite select mintablename tablename id name phonenoformat dialingcountrycode internationaldialingcode internettld select table tablename id name phonenoformat dialingcountrycode internationaldialingcode internettld database1 mdf dbo table1 union select table tablename id name phonenoformat dialingcountrycode internationaldialingcode internettld database2 mdf dbo table1 tmp group id name phonenoformat dialingcountrycode internationaldialingcode internettld count order id
31701 encountered new issue yesterday one mysql slave dbs runs ec2 aws db created snapshot another slave data correct least one table secondary index returning incomplete results querying child table parent id returning rows returned querying missing rows primary key worked correct parent id returned problem secondary index problem highly concerning since presumably even data slave matches master still get incorrect results queries run slave brute force solution rebuild entire table like alter table table engine innodb resolved issue specific table im left following questions determine tables similar index corruption whats efficient way fix corrupt indexes ive found good resources online finding fixing innodb data corruption havent found anything relevant innodb index corruption looked mysql error log didnt find smoking gun find troubling innodb errors im assuming separate issue could related innodb unable find record delete mark innodb tuple data tuple fields len hex 04af1f21 asc len hex 0a1c03bd asc innodb record physical record fields compact format info bits len hex 04af1f21 asc len hex 0a052a77 asc
31720 want way establish columns given database joined via pk fk relationships return pk fk information given table via select information schema key column usage cu exists select tc information schema table constraints tc tc constraint catalog mydatabase tc table name mytable tc constraint type primary key tc constraint name cu constraint name go pk returned query establish associated fk assuming one know also get referenced tables via select constraint name name foreign schema object schema nameparent object id foreign table object nameparent object id referenced schema object schema namereferenced object id referenced table object namereferenced object id sys foreign keys object namereferenced object id mytable go struggling get explicit column references creating script generator qlikview generate script need constraints associated links need constraint information given column want construct database class holds information given database class structure database table column constraints used get matches different columns pk fks clearly columns fks case also want retrieve pk information corresponding key pks want reverse course
31752 im loading 100gb file via load data infile ive good success myisam hours done im trying using innodb load starts fast 10mb sec watching table file growth file per table turned 5gb data slows 4mb sec range get 20gb around 2mb sec innodb buffer pools size 8g ive done following prior running load data infile command set session sql log bin set autocommit set unique checks set foreign key checks alter table item load disable keys run load data infile cant see reason starting well slowing time also using settings ran load data infile command table using innodb myisam 5gb test dataset myisam 20x faster innodb mysql load data concurrent local infile tmp item replace table item load query ok rows affected warnings min sec records deleted skipped warnings myisam mysql load data concurrent local infile tmp item replace table item load query ok rows affected warnings min sec records deleted skipped warnings anything else consider trying myisam engine able keep load rate much better additional details ive tried loading files individually difference incidentally files 500mb within file keys sorted getting 40gb overnight 12h later load rate 5mb sec meaning operation practically speaking impossible havent found answers similar questions forums seeming innodb doesnt support loading large amounts data tables gb size
31773 inherited table contains column used chain various related rows within table instance id bar reference id foo foo foo idea call structure order search deal idea table maintains sort living history within problem may row need get row somehow agnostic number levels need traverse
31805 rather innocuous question adding dates times sql server set rather fascinating taxonomic debate differentiate related terms use properly row record
31823 2m rows inserted using load data infile innodb takes 5min profiling shows time system lock tell anything useful mysql set profiling query ok rows affected sec mysql load data concurrent local infile tmp item replace table item load query ok rows affected warnings min sec records deleted skipped warnings mysql show profile query status duration starting checking permissions opening tables system lock waiting query cache lock query end closing tables freeing items logging slow query logging slow query cleaning rows set sec
32906 im still struggling understand sqls backup jobs currently sql server instance using full recovery model full database backup every week backup database mydatabase disk ne database backups mydatabase bak init name nmydatabase bak differential backup day backup database mydatabase disk ne database backups mydatabase diff bak init differential name nmydatabase diff bak trying figure schedule transaction log backups every hour would lose hours worth work backup log mydatabase disk ne database backups mydatabase log bak problem storage space limited dont want log file grow large use init transaction log backup force create new file every hour need transaction log backups since last differential backup restore specific point time day need keep copies since last differential way tell reset anytime backup
32919 working migrating database tables sql r2 sql azure currently proof concept stage figuring process well following process think solid id like perform validation diffs schema data confirm successful migration ive never done sql azure looking good way perform verification effort schema data ultimately one time migration well times real migration done
32975 trying run sql command select array select column name information schema columns table name gis field configuration stage get error error could find array type datatype information schema sql identifier
33021 easier way group records range percents try accomplish select top percents mytable order pki way felling cloud much much easier select top25 percent mytable id select top25 percent id mytable order pki order pki top percents table better nicer way
33074 ive seen several people call set transaction isolation level read uncommitted reading system dmvs ever reason assuming arent mixing calls dmvs tables transaction
33085 ive found lot resources mention adding index table makes searches faster inserts slower table large creates tradeoff design decision approximate table size using index absurd rows example probably way beneath limit anybody know limit would know resource would point right direction
33196 table multicolumn index doubts proper sorting indexes get maximum performance queries scenario postgresql table one million rows values column c1 different values assume values evenly distributed rows every possible value column c2 different values rows every possible value searching data condition always includes values two columns table multicolumn index combining c1 c2 read importance properly ordering columns multicolumn index queries using one column filtering case scenario question one given fact one filters selects much smaller set data could improve performance first index selective one one allows smaller set never considered question saw graphics referenced article image taken referenced article multicolumn indexes queries use values two columns filtering queries using one column filtering c1 parametera c2 parameterb also conditions like c1 abc c2 like ab
33285 give user account postgresql ability create drop databases way grant
33297 running sql server r2 need create new job basically run query start month 1st month query insert supporttracker dbo dashboardrecords select bg id bg short desc bg reported date bg status updated date us firstname us lastname lastupdateduserfirstname lastupdateduserlastname st name pr name ct name pj name assigneduserfirstname assigneduserlastname bg project hours bugtype subtype device pj parent id supporttracker dbo viewissuelistwbugtypendevice bg reported date bg id select bg id supporttracker dbo dashboardrecords order bg reported date asc problem clause two dates change every month need dates need dates basically need capture parts database save table end month thanks
33319 function postgresql called fun test composite type input parameter keep getting casting error call create replace function netcen fun testmyobj netcen testobj returns boolean body declare tmp code smallint cur member refcursor begin check member exists first open cur member execute select testkey netcen test testkey myobj testkey fetch cur member tmp code close cur member case tmp code coalescetmp code0 record found insert new record skip user defined validation insert netcen test valuesmyobj testkey myobj tes myobj testname else record found update record update netcen test set test myobj test testname myobj testname testkey myobj testkey end case end body language plpgsql type testobj create type netcen testobj testkey smallint tes text testname text call function select netcen fun test3khaendra comkhaendra netcen testobj get following error message error operator exist smallint boolean line select case variable coalescetmp code0 hint operator matches given name argument types might need add explicit type casts query select case variable coalescetmp code0 context pl pgsql function fun test line case cast definition table netcen test create table netcen test testkey smallint null default tes netcen dom email validation testname text constraint key primary key testkey erwin thanks links read modified function please go tell work well several clients calling function concurrently create replace function netcen fun test modifiedmyobj netcen test returns boolean body declare myoutput boolean false begin update netcen test set tes myobj tes testname myobj testname testkey myobj testkey found myoutput true return myoutput end begin insert netcen test valuesmyobj testkey myobj tes myobj testname myoutput true exception others update netcen test set tes myobj tes testname myobj testname testkey myobj testkey myoutput true end return myoutput end body language plpgsql done away type test used table test didnt know could work
33333 mysql workbench possible search specific column name tables writing string look field top right nothing thank
33357 im attending free db course stanford online frankly one exercises gave trouble feeling horribly simple dba im obviously good sql working simplified scenario rating movies cases reviewer rated movie twice gave higher rating second time return reviewers name title movie heres schema movie mid title year director reviewer rid name rating rid mid stars ratingdate go
33448 article sql server tempdb best practices increase performance suggests split tempdb number files equal number cores cores get files larger number files increase number physical operations sql server push disk one time sql server push disk level faster database run standard databases sql server cache large amount data needs memory high write nature tempdb data needs written disk cached back memory though sounds good theory really good general optimisation something may apply specific systems io high
33553 made draft remote application top libpq postrgresql behaves well profiled general functioning application final business result produce happens call something like select clause tcpip reminiscences sql server reminding minimize number interactions remote application database analyzed selects think could reduce number select clauses using joins dont remember syntax using result select another select select individual inner join publisher individual individual id publisher individual id individual individual id would like use results another select select would simply kind select identifier another table something something simplified tables layout declined number times different item types totally different types hence sql queries optimized table passage id passage pk business field passage bytea table item id item pk id passage fk business field item text table item detail id item detail pk id item fk business field item detail text image content bytea several id item one id passage several id item detail one id item would write name describing action redirecting one select another
33561 table rows stickers id title keywords ts vector sticker case 580h 580h cas stick sticker case 580l 580l cas stick sticker case cas stick sticker case plus cas plus stick well search using script row return return row select stickers keywords tsquerycase
33564 database gb transaction log caused fact database full recovery mode used years prior first backup want truncate shrink log file following command backup log dbname truncate go dbcc shrinkfilelogicalfilename100 want know ran command future able restore point time future full backup time line pre truncate backup truncate shrink future full backup future full backup thanks
33596 running fairly hefty query execution plan gave missing index suggestion form timestamp include customerid eventid id employeeid seems covering index include column either primary keys id foreign keys however querys clause filtering timestamp customerid eventid dont know werent included main part index question difference using suggested index think better alternative timestamp customerid eventid include id employeeid understanding still allow timestamp index seeking also assist query customer event ids filtered main part think something width main part fyi timestamp datetime20 customerid int eventid byte testing moment huge table rows taking time compare indexes id like learn thanks
33624 wondering example create table cities city varchar80 primary key location point create table weather city varchar80 references citiescity temp lo int temp hi int prcp real date date definition city varchar80 duplicated postgresql syntax allows duplicate varchar80 basing references citiescity create weather table
33669 seen heard multiple sources good idea performance wise write db journal data files separate disks whats recommended way ec2 write data files raid ebs drives would people write journal use completely separate raided set drives use single non raid drive leave data journal raid
33698 long running proc causing problems morning sec run time decided check see parameter sniffing blame rewrote proc set incoming parameters variables defeat parameter sniffing tried true approach bam query time improved less sec looking query plan improvements found index original wasnt using verify didnt get false positive dbcc freeproccache original proc reran see improved results would surprise original proc still ran slow tried recompile still slow tried recompile call proc inside proc even restarted server dev box obviously question parameter sniffing blame get slow query empty plan cache shouldnt parameters snif instead affected table stats related plan cache would setting incoming parameters variables help testing also found inserting option optimize unknown internals proc get expected improved plan folks smarter give clues whats going behind scenes produce type result another note slow plan also gets aborted early reason goodenoughplanfound fast plan early abort reason actual plan summary creating variables incoming parameters sec recompile sec dbcc freeproccache sec option optimize uknown sec update see slow execution plan https www dropbox com cmx2lrsea8q8mr6 plan slow xml see fast execution plan https www dropbox com b28x6a01w7dxsed plan fast xml note table schema object names changed security reasons
33700 large table million rows im trying bulk insert sql server get error could allocate space object mydb database stroke primary filegroup full create disk space deleting unneeded files dropping objects filegroup adding additional files filegroup setting autogrowth existing files filegroup another table database around million rows database used single machine designed mine data already exists circumstances ever grow beyond current size situation whats best way tackle sql server doesnt complain solution matter db wont exposed multiple users
33703 sql query shows last restore datetime certain database
33737 developing platform prepaid cards basically holds data cards balance payments etc card entity collection account entity account amount updates every deposit withdrawl debate team someone told us breaks codds rules updating value payment trouble really problem fix
33760 came across puzzle comments create table int select sql server postgresql return row mysql oracle return zero rows correct equally valid
33894 postgresql database part handles agent commissions agent formula calculation much commission get function generate amount commission agent get becoming impossible use number agents grow forced extremely long case statements repeating code made function big formulas constant variables days worked month new nodes accuired loyalty score subagent commission base rate revenue gained formula something like agent negotiates payment formula hr dept store formula agents table like small function gets formula table translates values computes amount
33937 given question reddit cleaned query point issue query use comma first make modifying queries easier queries generally end like select companyname shippeddate od unitprice productname customers inner join orders customerid customerid inner join order details od orderid od orderid inner join products productid od productid shippeddate productname tofu order companyname someone basically said generally lazy bad performance given dont want prematurely optimize want follow good practices ive looked query plans generally find indexes add adjust make queries run faster question really cause bad things happen tell minor edit ive always assumed well would optimized worst negligible never hurts question mantra like gotos evil premature optimization assumed facts wasnt sure would realistically affect query plans subqueries ctes procedures im one optimize unless needed im something actually bad id like minimize effects change applicable
33943 im new postgres trying migrate mysql databases mysql grant select update insert delete privileges low privileged user enable grants apply tables specified database must missing something postgres looks like grant privileges table one time many databases hundreds tables per database seems like daunting task get ground addition database operation adding tables happens frequently enough wouldnt want grant permissions time unless absolutely necessary best accomplished
34047 sql server date datatype added casting datetime column date sargable use index datetime column select castdatetimecol date option use range instead select datetimecol datetimecol queries equally good one preferred
34079 tracking made change identified cdc along lines datetime hack tried approach adding suser sname new field default value cdc change track table seems return owner cdc process user initiated change base table also tried original login returns sql service account login likely associated cdc process user initiated change found similar question stack overflow answer tracking changes front end via trigger seems defeat purpose using cdc wouldnt repost since original stackoverflow thought id give try especially r2 introduced better way short know made change change data capture
34132 want export database diagram pdf image types worked sql server r2
34136 ive got postgres pgbouncer version came stack builder net application connecting via npgsql version win7 machine application happily connect straight postgres server always fails connect via pgbouncer connection string npgsql substitution sslmode prefer timeout server port user id password database pooling false ive also tried connect pgbounce protocol explicitly didnt work database line pgbounce ini databases something host localhost port dbname somethingelse user someone password aaa userlist txt someone aaa required app runs npgsql says connection forcibly closed pgbouncer error log says log file descriptor limit max client conn max fds possible log listening log listening log process pgbouncer libevent stable win32 adns evdns2 log something someone fe80 997b 396e eacc dd2b login attempt db somethingelse user someone log something someone new connection server log something someone fe80 997b 396e eacc dd2b closing client close request age log nodb nouser fe80 997b 396e eacc dd2b closing bad packet header age warning nodb nouser fe80 997b 396e eacc dd2b pooler error bad packet header npgsql exception says log file app topmost exception follows nested exceptions exception message unable read data transport connection established connection aborted software host machine exception source npgsql exception stacktrace npgsql npgsqlclosedstate opennpgsqlconnector context projectdirectory npgsql2 src src npgsql npgsqlclosedstate cs line npgsql npgsqlconnector open projectdirectory npgsql2 src src npgsql npgsqlconnector cs line npgsql npgsqlconnectorpool getnonpooledconnectornpgsqlconnection connection projectdirectory npgsql2 src src npgsql npgsqlconnectorpool cs line npgsql npgsqlconnectorpool requestconnectornpgsqlconnection connection projectdirectory npgsql2 src src npgsql npgsqlconnectorpool cs line npgsql npgsqlconnection open projectdirectory npgsql2 src src npgsql npgsqlconnection cs line snip thing code goes opens connection snip exception message unable read data transport connection established connection aborted software host machine exception source system exception stacktrace system net sockets networkstream readbyte buffer int32 offset int32 size system io stream readbyte npgsql npgsqlclosedstate opennpgsqlconnector context projectdirectory npgsql2 src src npgsql npgsqlclosedstate cs line exception message established connection aborted software host machine exception source system exception stacktrace system net sockets socket receivebyte buffer int32 offset int32 size socketflags socketflags system net sockets networkstream readbyte buffer int32 offset int32 size also window firewall anti virus turned temporarily hba conf file postgres host md5 host md5 ipv6 local connections host md5 host fe80 md5 ive googled around found solution help thanks peter
34151 want one many relationship parent one zero children marked favorite however every parent child think parents questions site children answers favorite accepted answer example tablea id int primary key tableb id int primary key parent int null foreign key references tablea id way see either add following column tablea favoritechild int null foreign key references tableb id following column tableb isfavorite bit null problem first approach introduces nullable foreign key understand normalized form problem second approach work needs done ensure one child favorite sort criteria use determine approach use approaches considering using sql server
34173 wondering sql server management studio express mainly microsoft sql server installed standalone machine without sql services stuff connect remote database run sql server told one managers wish create web ui specified users run queries update database within ability php thinking ease could make proposition scrap need web ui cost lot time server administrators install smse network machines connect manage databases possible would go painful task creating webui displays schemas tables etc
34313 need create alert notify query blocked seconds example someone transaction open table forgets run commit rollback possible get system tables
34356 etl process said done bunch tables identical quickest way verify tables two different servers fact identical im talking schema data hash table self like would able individual file filegroup compare one red gate data compare since tables question contain millions rows id like something little performant one approach intrigues creative use union statement id like explore hash idea little possible post answer update future vistors exact approach ended taking worked well every table database thanks answers pointing right direction create procedure dbo usp databasevalidation tablename varchar50 begin set nocount parameter table name passed otherwise check one create temp table lists tables target database create table chksumtargettables fullname varchar250 name varchar50 chksum int insert chksumtargettables fullname name chksum select distinct mydatabase name name fullname name name chksum mydatabase sys tables inner join mydatabase sys schemas schema id schema id name like isnull tablename create temp table lists tables source database create table chksumsourcetables fullname varchar250 name varchar50 chksum int insert chksumsourcetables fullname name chksum select distinct mylinkedserver mydatabase name name fullname name name chksum mylinkedserver mydatabase sys tables inner join mylinkedserver mydatabase sys schemas schema id schema id name like isnull tablename build dynamic sql statement populate temp tables checksums table declare targetstmt varcharmax select targetstmt coalesce targetstmt update chksumtargettables set chksum select checksum aggbinary checksum fullname name name chksumtargettables select targetstmt declare sourcestmt varcharmax select sourcestmt coalesce sourcestmt update chksumsourcetables set chksum select checksum aggbinary checksum fullname name name chksumsourcetables execute dynamic statements populate temp tables checksums exec targetstmt exec sourcestmt compare two databases find checksums different select tt fullname tables whose checksum match chksumtargettables tt left join chksumsourcetables st tt name st name isnullst chksum0 isnulltt chksum0 drop temp tables tempdb drop table chksumtargettables drop table chksumsourcetables end
34358 sql server weekly full backup nightly incremental backups want know possible restore single table backup either source database different one find clear answer online thanks advance
34381 table contains posts another table contains meta options post first table meta options table key value pare table lets say posts tables look like posts id columns data data data data data meta options table look like meta id post id meta key meta value views maxviews views maxviews publison auhor myuser auhor another author question get post id equals making comparison meta key values views maxviews example like retrive post id id views lower masviews meta table help please
34484 difference sql batch sql statement remote procedure call tell part sql code batch statement
34525 work host webservers amazon ec2 usually used mysql databases installed box apache webserver communicated localhost face need migrate database server one systems choice two solutions use amazon rds launch new amazon ec2 box install mysql rds dedicated database service provided company ec2 seems like ought obviously better option however look pricing two options see http aws amazon com ec2 pricing http aws amazon com rds pricing seems rds server costs almost twice much ec2 server box specs given im capable handling backups ec2 offers ability scale instance required rds cant see reason use rds instead ec2 seems like im probably missing something big though right nobody would use rds exactly missing advantages rds installing database ec2 instance
34603 database designer data warehouse environment used dealing tables maximum millions rows faced tables half billion rows significant differences tools efficiency toolbox trust previous knowledge indexes partitions like specific tools hindrance help large data tips dealing tables already found great post updating million rows value
34633 using xp cmdshell quite helpful sometimes possibly answer scenarios ive read posts internet enabling xp cmdshell might jeopardize security database server question anything reduce risk example set restrictions applying users role etc providing safeguards mitigate risk thanks
34730 servers default collation latin1 general ci determined query select serverpropertycollation collation surprised discover collation match non digit characters strings using predicate like default collation happen cant think case would useful know work around behavior using binary collation seems like strange way implement default collation filtering digits produces non digit caracters demonstrate behavior creating column contains possible single byte character values filtering values digit matching predicate following statement creates temporary table rows one code point current code page p0 select union select p1 select p0 cross join p0 p2 select p1 cross join p1 p3 select p2 cross join p2 tallynumber select row number order select p3 select number codepoint charnumber symbol codepage tally number number row contains integer value code point character value code point character values displayable code points strictly control characters selective sample output select codepoint symbol codepage would expect able filter symbol column find digit characters using like predicate specifying range characters thru select codepoint symbol codepage symbol like produces surprising output codepoint symbol set code points thru ones expect surprises symbols superscripts fractions also included result set might mathematical reason think exponents fractions numbers seems wrong call digits using binary collation workaround understand get result expect force corresponding binary collation latin1 general bin select codepoint symbol codepage symbol like collate latin1 general bin result set includes code points thru codepoint symbol
34754 find legal copy iso sql standard
34765 potential customer wants evaluate storage system run windows 2008r2 x64 4kb ntfs virtual test machine theyve sent us seem know hand think reasonable assume environment tweaked tests inserting indexing searching deleting tool known given windows ntfs block size 4kb sql write 64kb chunks safe assume block size 64k san good choice run sql server perhaps standard
34766 vague understanding transactions means help server understand series queries related scenario suppose series queries creates user inserts user info record creates empty profile record initialises records etc whatever reason script fail half way need ensure everything creating user queries gets undone understand reading mysql documentation simple using start transaction commit statements many cmss neglect suppose common argument might unnecessary short scripts dealing record updates right thinking also highly beneficial dealing replication environments
34947 stored procedure users run manually get updated numbers report thats used constantly throughout day second stored procedure run first stored procedure runs since based numbers obtained first stored procedure however takes longer run separate process dont want make user wait 2nd stored procedure gets ran way one stored procedure start second stored procedure return immediately without waiting results im using sql server
34955 creating restful api struggling decide best way design database tables around resources initially though table per resource would good way go im worried result exponentially bigger tables resource chain go example imagine three resources users clients sales users subscribers api clients users customers sales purchases made client users account sale resource accessed follows get users userid clients clientid sales salesid users customers customer sales table size gets larger resource chain go im fairly confident sql cope large tables im sure read writes slow things example maybe doesnt illustrate api progressively writes reads resource chain go therefore scenario biggest tables database read written times smaller tables also necessary join tables running queries reason allow user client name avoid getting wrong client data users table clients tables joined userid also case sales joining large tables running reads writes slow things
34976 sql server way find users either dont exist server level account deleted server level wasnt disassociated databases deleted accounts arent linked account may deleted server level db level readded db level never cleaned ive got messy server would awesome query run find
34979 im process testing populating specific table leverages sequence object process im testing populating table tens thousands insert lines im unfamiliar program problem im seeing specific table start another population test sequence reset back first number want wish run new test delete table question run following drop sequence foo fee go drop schema foo go want run test run following schema sequence commands fired order create schema foo go create sequence foo fee start increment cycle cache go create table create table foo sample table data order number bigint primary key null sample column one nvarcharmax null sample column two nvarcharmax null sample column three nvarcharmax null go completed run following insert command times insert foo sample table data order number sample column one sample column two sample column three values next value foo fee blah blah blah blah blah blah absolutely problem data entering table challenge im encountering delete table drop schema sequence create table sequence schema sequence picks last number previous database incarnation reset back one example last number sequence say next sequence number new table deleting table dropping schema sequence run following verify removal sequence schema select information schema schemata go select sys sequences go im stumped happening another command im missing would help localize exactly going note table belongs database tables running sequence command correctly sql sp1 enterprise edition installation
35015 microsoft sql server r2 database applications different programming languages legacy would like modify way log server level query errors regardless application causing would like know error query causing error type ideally loginame hostname
35081 databases server want take databases backup using mysqldump ignore remaining databases mysqldump command option mysqldump ignore databases backup mysql know general mysqldump command lengthy want ignore databases need take remaining dbs backup
35177 best way automatically restart sql server regular basis read could create batch file net start net stop agent service batch file schedule curious better way please nevermind indicative larger problem operation ive arguing month weve ended thanks
35182 becoming somewhat involuntary dba work themoment really need help something 40gb database full recovery mode log backup configured huge log file 84gb plan thus far salvage situation run full log backup database shrink log file instigate maintenance plan run log backup every night database backup help keep control problem want log file shrink nothing spend first morning monday constantly growing rough estimate file database would like set get go ensure much contiguous space possible case changing initial size database properties files would guess well database would need offline occur thanks advance
35219 need create hash value nvarchar data comparison purposes multiple hash algorithms available sql one best choose scenario want ensure risk duplicate hash value two different nvarchar value minimum based research internet md5 seems best one right msdn tells us link available algorithms description one conditions hashbytes transact sql need join two tables two nvarcharmax columns imagine query takes along time execute thought would better keep hash value nvarcharmax data join hash values rather nvarcharmax values blobs question hash algorithm provides uniqueness dont run risk one hash value one nvarcharmax
35225 execute sql use aspstate go existsselect sys sysusers name r2server aaouser create user r2server aaouser login r2server aaouser go get following error login already account different user name know different user name login account
35271 im using built sp spaceused stored procedure performing operation software see tables row inserts size table changes im seeing tables get rows written handful show table increased side others show rows added show change size stored procedure case true first transaction performing truncate tables appears instead storing duplicate data sql server showing rows inserted must storing pointers previous identical rows anyone confirm please
35277 situations require really big query joining several tables together sub select statements produce desired results question consider using multiple smaller queries bring logical operations application layer querying db one calls better one go example consider following query select users user id select f2 friend user id friends f1 inner join friends f2 f1 friend user id f2 user id f2 page f1 user id f2 friend user id f2 friend user id select friend user id friends user id user id select user id friend requests friend user id user image null order rand limit whats best way
35292 data retrieved microsoft sql server compressed controlled connection string simple way tell particular app using im examining analysis tools volume data take minutes transmit network im wondering whether expect performance increase pull data compressed data store remote server long topic im curious data transmitted binary ascii example value queried int column transmitted five bytes 0x31 0x32 0x33 0x34 0x35 two bytes required value four bytes required column clear understand options regarding storing data compression backing im asking data transmitted
35316 im wondering newly created user allowed create table connecting database one database project2 core postgres list databases name owner encoding collate ctype access privileges postgres postgres sql ascii project2 core atm project2 utf8 de de utf de de utf project2 ctc project2 template0 postgres sql ascii postgres postgres ctc postgres template1 postgres sql ascii postgres postgres ctc postgres rows far good create user postgres create role dietrich encrypted password md5xxx login nocreaterole nocreatedb nosuperuser okay try connect database user allowed psql localhost dietrich project2 core password user dietrich psql fatal permission denied database project2 core detail user connect privilege expected strange stuff starts grant user connect postgres grant connect database project2 core dietrich grant postgres list databases name owner encoding collate ctype access privileges postgres postgres sql ascii project2 core atm project2 utf8 de de utf de de utf project2 ctc project2 dietrich project2 template0 postgres sql ascii postgres postgres ctc postgres template1 postgres sql ascii postgres postgres ctc postgres rows without grants user allowed create table psql localhost dietrich project2 core password user dietrich psql ssl connection cipher dhe rsa aes256 sha bits type help help project2 core create table adsf create table project2 core list relations schema name type owner public adsf table dietrich row would expected user allowed anything explicitly grant usageon schema grant select tables mistake wrong achieve want new user allowed anything explicitly granting appropriate rights im lost help greatly appreciated edit following advice daniel verite revok immediately creating database user dietrich allowed create table good also owner database project2 allowed create table even issuing grant privileges database project2 core project2 grant privileges schema public project2 get error error schema selected create specifically try create table public whatever get error permission denied schema public wrong
35325 postgresql choose elephant logo wasnt clear logo wiki update wiki updated thanks
35327 use software makes big postgresql database table million rows developers says vacuum analyze periodically postgresql database default autovacuum turned vacuum analyze benefits whats difference automatic manual vacuum example pgadmin3
35380 trying construct query postgresql gets longest sequence continuous rows specific column consider following table lap id serial lap int car type enum race id int fk lap unique race id car type would like query produce longest sequence given race id car type would return int long highest following data red red red red blue red blue green car type red race id query would return longest sequence lap field found similar question however situation bit straightforward would also like know longest sequence given car type races planning work
35424 using sql server small business server client using winxp added user active directory security group cant user immediately access database seems delay user recognized sql server using ad security groups permissions expressly dont need add individual users sql server effectively dont need anything add user ad security group order grant access reason sql server doesnt immediately recognize addition ive seen number times add user group user cant access data next day seems doesnt query active directory real time confirm need sql server refreshes list users active directory
35459 table like following annotation document term category document term id category integer couple document term unique could couple different category document id term id category document id term id category document id term id category would like design query return couple document term exists row category previous example couple document id term id returned becouse exist also two rows different values category give hints
35480 ive always seen written column aliases select columnname today came across query used select columnname difference two queries get executed standard among dbas one use personally think 2nd would easier read maintain longer column definitions good example article however ive never seen 2nd syntax used today wondering reason shouldnt using
35497 ive created new udts postgresql however two problems see udts defined see columns defined within udts unfortunately couldnt find anything postgresql documentation
35500 ive reading great articles regarding sql server plan caching kimberly tripp one http www sqlskills com blogs kimberly plan cache optimizing adhoc workloads even option optimize ad hoc workloads shouldnt always whether developers using ad hoc sql would option enabled every instance supports sql thereby reducing cache bloat
35529 tables database dont want use following sql table database select table name possible display first records table inside database using sql
35565 table called book create table book id smallint null default bname text btype text bprices numeric112 constraint key primary key id function save book create replace function save bookthebook book returns text body declare myoutput text nothing occured begin update book set bname thebook bname btype thebook btypebprices thebook bprices id thebook id found myoutput record pk thebook id successfully updated return myoutput end begin insert book valuesthebook idthebook bnamethebook btype thebook bprices myoutput record successfully added end return myoutput end body language plpgsql volatile cost call function select save book179the art warfiction book get error error malformed array literal sql state 22p02 character dont understand dont see error format array help
35579 migrated large website database older server windows sql server gb ram ghz quad core sas disks newer much better server windows r2 sql server sp1 gb ram ghz core processors ssd disks detached database files old server copied attached new server everything went well changed compatibility level updated statistics rebuild indexes huge disappointment noticed sql queries much slower times slower new sql server old sql server example table around 700k records old server query index took around 100ms new server query takes around ms happens queries would appreciate help let know check verify find hard believe better server newer sql server performance worse details memory set max table index create table dbo answer details id int identity11 null userid int null surveyid int null customerid int null default summaryid int null questionid int null rowid int null default optionid int null default enteredtext ntext null constraint answer details pk primary key nonclustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary textimage primary create nonclustered index idx answer details summaryid questionid dbo answer details summaryid asc questionid asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary executed query set statistics time select summaryid countsummaryid answer details group summaryid order countsummaryid desc set statistics time old server sql server execution times cpu time ms elapsed time ms new server sql server execution times cpu time ms elapsed time ms execution plans uploaded http tl arbpuvf9t8 later update amd 1ghz opteron core processors look much worse intel 5ghz quad core processors great improvement changing windows power options ballanced high power improvement changing max degree parallelism cost threshold sql server execution times cpu time ms elapsed time ms still worse old server bad suggestions local query optimizations please feel free comment
35596 write query like select table1 t1 join table2 t2 t1 id t2 id sql optimizer sure correct term translate select table1 t1 table2 t2 t1 id t2 id essentially join statement sql server easier way write sql actually used run time edit almost always almost always use join syntax curious happens
35616 working function allows add index exist running problem get list indexes compare thoughts similar issue column creation one solved code https stackoverflow com
35755 background web programming rather database administration please correct im using wrong terminology im trying figure best way design database application ill coding situation ive got reports one table recommendations another table report many recommendations also separate table keywords implement tagging however want one set keywords gets applied reports recommendations searching keywords gives reports recommendations results heres structure started reports reportid reportname recommendations recommendationid recommendationname reportid foreign key keywords keywordid keywordname objectkeywords keywordid foreign key reportid foreign key recommendationid foreign key instinctively feel like isnt optimal taggable objects inherit common parent comment parent tagged would give following structure baseobjects objectid primary key objecttype reports objectid report foreign key reportname recommendations objectid recommendation foreign key recommendationname objectid report foreign key keywords keywordid primary key keywordname objectkeywords objectid foreign key keywordid foreign key go second structure missing important concerns also go second use non generic name replace object update im using sql server project internal application small number non concurrent users dont anticipate high load terms usage keywords likely used sparingly pretty much statistical reporting purposes sense whatever solution go probably affect developers need maintain system line figured good implement good practices whenever thanks insight
35812 forms locking cause process wait correct copy record currently use another process pessimistic locking lock mechanism comes db native lock object whereas optimistic locking lock mechanism form row versioning like timestamp check whether record stale cause 2nd process hang ask optimistic locking generally considered faster superior pessimistic locking use cases pessimistic preferred optimistic thanks advance
35821 working mysql database table like table name myfield need make lot queries like strings list select myfield table name myfield something stuff bit longer around unique rows use fulltext index key varchar150 increase chars would make great difference way calculate said going unique myfield primary key isnt rare add primary key field already varchar index fulltext
35847 id like get clarification flush privileges option mysqldump heres description option mysql docs flush privileges send flush privileges statement server dumping mysql database option used time dump contains mysql database database depends data mysql database proper restoration says sends flush statement dumping database read mean data schema etc dumped backup file flush statement sent database dumped dumped wondering dumping data etc required privileges flushed started searching explanation sure use read various answers occurred would make sense flush statement included dump file contents file loaded database flush privileges statement run update settings new info imported work flush source database dumping data file necessary flush destination database importing contents dump file something possibilities ive described
35893 read error state help distinguish different states locations source code type error occur really clear useful msdn states error state returns state number error caused catch block try catch construct run really used one give example ones provided reference article dont really help explain things well
35910 please help understand statement database mysql schema oracle started use oracle find different rdbms softwares used like mssql mysql derby example create database use create database ghazals throws error error line ora create database failed ora database already mounted also commands like show databases work
35932 select dv name maxhb dateentered de devices dv inner join heartbeats hb hb deviceid dv id de group dv name get error msg level state line invalid column name de select name de select dv name maxhb dateentered de devices dv inner join heartbeats hb hb deviceid dv id group dv name tmp tmp de works expected someone explain need nest main query subquery limit data set also maybe better way achieve goal retrieve records one table single top related record ordered dateentered descending
36056 need update sql server database thats 18gb size change significant number text columns nvarcharmax problem im executing alter table commands database ends almost 26gb size understand using nvarcharmax alow db grow slowly way prevent bloating
36073 need write query insert row even query run multiple times new sql well new ish exists friend said preferred deleting row exists adding might advantages deleting exists vice versa another way
36081 currently sql server database using varchar wed like change nvarchar ive generated script question differences sql server writes varchar columns vs nvarchar columns number backend procedures im concerned edit sure helps columns dont indexes constraints
36163 im curious possible create table column never changed columns table instance could imagine createdbyuser column never changed built functionality sql server possible via triggers something else
36244 using sql server unique identifier weve noticed selects additional characters added onto end chars still returns match uuid example select table uuid 7da26ecb d599 91d4 f9136ec0b4e8 returns row uuid 7da26ecb d599 91d4 f9136ec0b4e8 run select table uuid 7da26ecb d599 91d4 f9136ec0b4e8extrachars also returns row uuid 7da26ecb d599 91d4 f9136ec0b4e8 sql server seems ignore characters beyond selects bug feature something configured massive issue validation front end length doesnt seem correct behaviour
36345 client ask migrate mysql db server doesnt free space also big table broken cant dump cant repair lacking free space question way physically move mysql db data files another server use new mysql
36432 visual studio designer right click ssis package designate entry point package search found page msdn states value signifies package meant started directly value signifies package meant started another package execute package task default value flag enabled disabled able execute package directly purpose enabling disabling flag merely document intentions ssis packages sql server ssis behave differently enabled disabled
36522 setting new sql server use following code determine good starting point maxdop setting recommend maxdop setting appropriate machines numa memory configuration need evaluate setting non production environment moving production maxdop configured using exec sp configure max degree parallelismx reconfigure instance hosting sharepoint database must specify maxdop url wrapped readability http blogs msdn com rcormier archive shall configure maxdop using sharepoint aspx biztalk versions including maxdop required biztalk message box database servers must changed servers hosting biztalk server databases may return value set http support microsoft com kb declare corecount int declare numanodes int set corecount select cpu count sys dm os sys info set numanodes select maxc memory node id sys dm os memory clerks memory node id corecount less cores dont bother begin declare maxdop int total cores machine set maxdop corecount maxdop greater per numa node core count set maxdop per numa node core count maxdop corecount numanodes set maxdop corecount numanodes reduce maxdop even number set maxdop maxdop maxdop cap maxdop according microsoft maxdop set maxdop print suggested maxdop cast maxdop varcharmax end else begin print suggested maxdop since less cores total print default setting likely need print anything end realize bit subjective vary based many things however im attempting create tight catch piece code use starting point new server anyone input code
36539 table schema like create table questions tags id false force true integer question id integer tag id end add index questions tags question id name index questions tags question id add index questions tags tag id name index questions tags tag id would like remove records duplicates tag id question id another record sql look like
36603 table used legacy application substitute identity fields various tables row table stores last used id lastid field named idname occasionally stored proc gets deadlock believe ive built appropriate error handler however im interested see methodology works think im barking wrong tree im fairly certain way access table without deadlocks database configured read committed snapshot first table create table dbo tblids idlistid int null constraint pk tblids primary key clustered identity11 idname nvarchar null lastid int null nonclustered index idname field create nonclustered index ix tblids idname dbo tblids idname asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks fillfactor go sample data insert tblids idname lastid values sometestid insert tblids idname lastid values someothertestid go stored procedure used update values stored table return next id create procedure dbo getnextid idname nvarchar255 begin description increments returns lastid value tblids given idname author max vernon date declare retry int declare en int es int et int set retry declare newid int set transaction isolation level serializable set nocount retry begin begin try begin transaction set newid coalesceselect lastid tblids idname idname0 select countidname tblids idname idname insert tblids idname lastid values idname newid else update tblids set lastid newid idname idname commit transaction set retry need retry since operation completed end try begin catch error number deadlock set retry retry else begin set retry set en error number set es error severity set et error state raiserror en es et end rollback transaction end catch end retry must deadlockd times begin set en set es set et raiserror en es et end else select newid newid end go sample executions stored proc exec getnextid sometestid newid exec getnextid sometestid newid exec getnextid someothertestid newid edit ive added new index since existing index ix tblids name used sp assume query processor using clustered index since needs value stored lastid anyway index used actual execution plan create nonclustered index ix tblids idname lastid dbo tblids idname asc include lastid fillfactor online allow row locks allow page locks edit ive taken advice aaronbertrand gave modified slightly general idea refine statement eliminate unnecessary locking overall make sp efficient code replaces code begin transaction end transaction begin transaction set newid coalesceselect lastid dbo tblids idname idname newid insert tblids idname lastid values idname newid else update dbo tblids set lastid newid idname idname commit transaction since code never adds record table lastid make assumption newid intention append new id list else updating existing row list
36612 installed oracle 11g server ubuntu cant start server start server following error occurs sql startup ora failure processing system parameters lrm could open parameter file u01 app oracle product xe dbs initxe ora solve issue think connect failed target host object exist target host specified running ls latr u01 app oracle product xe dbs initxe ora returns rw oracle dba mar u01 app oracle product xe dbs initxe ora running echo oracle sid displays nothing empty line
36815 ive running index usage reports im trying get definition leaf non leaf seem leaf non leaf inserts updates deletes page merges page allocations really dont know means one better someone could give simple definition also explain leaf non leaf matters would appreciated
36828 using sqlalchemy query postgresql database behind pgbouncer using transaction level pooling best pattern use kind set one engine per process using connectionpool create engine per request use nullpool one different pattern altogether using thanks much let know information needed ill update asap
36870 added user myuserto postgres added database mydatabase pgadmin iii gui restored backup file owner mydatabase superuser postgres tried give rights access modify mydatabase myuser logged psql user postgres psql template1 postgres ran query grant privileges database mydatabase myuser use myuser log try simple query get error error permission denied relation table name missing something help solve
36875 common need using database access records order example blog want able reorder blog posts arbitrary order entries often lots relationships relational database seems make sense common solution seen add integer column order create table table id title sort order values lorem ipsum dolor sit amet consect elit fusce sort rows order get proper order however seems clumsy want move record start reorder every record want insert new record middle reorder every record want remove record reorder every record easy imagine situations like two records order gaps order records could happen fairly easily number reasons approach applications like joomla take could argue interface bad instead humans directly editing numbers use arrows drag drop youd probably right behind scenes thing happening people proposed using decimal store order use insert record records order helps little arguably even messier end weird decimals stop better way store order table
36917 recently using database abstraction layer built python web framework called web2py click dal syntax include option include constraints within create table statement whilst taking stanfords introduction databases mooc sql standard mentioned supporting query within create table statement constraints essentially replacing major use case triggers best practice simple example including constraints create table statements rather alert table create trigger statements create table place address varchar240 constraint place pk primary key address create table company name varchar240 constraint company pk primary key name create table employee name varchar240 tax number salary number194 sex char birthdate date address varchar240 constraint employee pk primary key tax constraint address fk foreign key address references placeaddress check address null create table companyemployee employee id number company id varchar240 constraint unique employee id uniqueemployee id constraint employee id fk foreign key employee id references employeetax constraint company id fk foreign key company id references companyc name constraint company employees pk primary key employee id company id btw youll note im using caps keywords upper camelcase table names lower score attribute trigger names good practice feel free critique indentation whitespace usage styles also
36943 table numbers like status either free assigned id set number status assigned free assigned free free assigned assigned free free free assigned assigned assigned free assigned need find consecutive numbers query would return free free free return first possible group id set fact would executed id set per query checking window functions tried queries like countid number partition id set rows unbounded preceding thats got couldnt think logic postgres thinking creating virtual column using window functions counting preceding rows every number status free select first number count equal number maybe group numbers status one assigned another assigned select groups containing least numbers edit found query changed little bit select row number partition id set status order number rnd row number partition id set order number rn numbers select id set minnumber first number maxnumber last number status countnumber numbers count group id set rnd rn status order first number produces groups free assigned numbers would like numbers first group meets condition sql fiddle
36979 big database need extract primary keys foreign keys table pgadmin iii way automatically go table manually
37014 understand character email address valid implementations researched tend use varchar60 varchar80 equivalent example sql server recommendation uses varchar80 oracle example reason use full character maximum doesnt varchar definition use much storage needed hold data significant performance implications trade offs cause many implementations use less full possible characters
37034 database postgresql main schema around tables variable number identically structured per client schemas tables client schemas foreign keys referencing main schema way around started filling database real data taken previous version db reached gb expected grow several 10s gb within weeks bulk delete central table main schema concerned foreign keys marked delete cascade surprise would take long time hours became clear better starting dropping db launching migration need repeat operation later db live much larger alternative faster methods would much faster wrote script browse dependent tables starting table furthest central table deleting dependent rows table table important detail triggers tables
37038 recently struggling sql server performance although fixed huge multitude basic errors config still performing badly clarify overall performance rather fairly frequent time outs client application previously looked memory cause resolved still getting behaviour looking graphs management data warehouse see lck ix causing majority waits around time user experiences timeout everything reading states need look queries processes running yet find anything aimed level understand locks see picture seem spike coincides error users side clever dmv address try work query run creating lock case trawling trace find details guidance greatly appreciated apologies information clear
37058 bunch databases one sql servers owner generally speaking harmful give one example use dbname go exec sp changedbowner sa go know sa may best choice example primary concern whether creating owner none may cause issues software currently connect ok
37149 use sql server developer edition server class machines dev staging environments working large project passes proof concept stage several large geographically distributed enterprise class database servers running sql server enterprise edition production environment initially servers staging environment minimum servers development environment server hosting three instances impression would need acquire enterprise licences actual production servers could get developer edition developer staging environments production sources told need enterprise licence mentioned machines developer edition meant single developer workstation since developer edition sexy features enterprise cant really see value workstation class machine especially developing testing type high availability system building fork enterprise licences dev server kill proof concept stage thus killing project forcing enterprise licence staging environment make management want skip staging altogether
37162 fairly busy database server running sql server r2 following setup sata raid drives os programs sas raid drives sql database files data logs sas raid drives tempdb data logs assuming cant add additional drives server made best use configuration available consider another scheme logs isolated data files example update requested hardware details sata drives used os program partition wd rpm gb inch sata sas drives used arrays seagate 15k rpm gb inch sas raid controller used lsi 8i sas sata gb port update based upon feedback ive received looks like following viable options choose award bounty someone tell likely best environment ive outlined leave everything probably wont much better move sas raid drives existing raid array composed disks total move log files onto sas raid relocate tempdb data logs back raid
37252 machine tool application runs sql server backend tools run day every day looking way incrementally backup database without machine downtime ive seen mirroring solutions two servers solutions would work us cost size constraints possible programmatically service mirror database backup hard drive main pc data loss acceptable
37280 exactly qualified dba yes charge db use social app recently implemented master slave replication database obvious reasons wish know whether mysql replication kills performance db since every user writing master db creates additional write slave db might wrong lag slave master replication almost instantaneous
37354 im attempting set sandbox report developers work current plan reset database every evening im sure go mean reset want essentially drop user tables views stored procedures etc one database server suppose another option would drop recreate database well im pretty sure thatd mean regranting access appropriate ad groups people really dont know would best way go im hoping able provide good ideas suggestions thanks clarity essentially want database http try discourse org site sandbox reset every day difference dont want recreate users every day version sql server edition developer enterprise
37363 im update like update dbo table1 set birthdate birthdate table1 join table2 id id want use output clause back changes update dbo table1 set birthdate birthdate output inserted id inserted birthdate new birthdate deleted birthdate old birthdate outputtable table1 join table2 id id want know way output clause create table outputtable make sure already exists running statement
37379 app deploy production uses honor system security users connect db using sql user passwd credential app manages permissions latter part doesnt bother much fact connection object contains embedded credentials copied around freely im try find way limit connections limited set clients create firewall rules limit ip course way prequalify sql logins either machine account domain membership
37427 possible custom unique column constraint follows suppose two cols subset type strings though data types probably doesnt matter type true want combination type subset unique otherwise constraint im using postgresql debian
37491 got really weird annoying problem somehow instance sql server r2 running server gotten somewhat corrupted first noticed database created yesterday missing looked around found still detached tried attach mdf got message something like file currently use thought odd restarted sql server thing okay time drastic measures stopped service zipped mdf started service unzipped tried restore message gone got attach database name existing database ouch course showing database explorer idea whats going last resort drop database databasename course didnt work tells database exist im stuck one point sql server thinks database exist another point thinks db exist obviously state confusion anyone seen got ideas fix
37557 table millions rows growing following improve performance inserts database side dropped indexes constraints disabled logging application side switched jpa managed entities native insert queries added append oracle hint query tried commit batches per 1k 2k 3k rows tried write parallel multiple threads thread count core count server one table gave rows per second additionally tried write parallel batches multiple tables group back results using union gave 1k rows per second empty tables filled tables dummy data millions speed inserts dropped per second could anyone suggest else speed inserts basically want understand could bottleneck first upd table partitioned insert date table columns columns varchar22000 byte
37600 currently using tortoise svn source control net web application would best way bring sql server stored procedures source control currently using vs development environment connecting premise sql server r2 database using sql server data tools ssdt past saving procs sql file keeping files source control im sure must efficient way extension install vs2010 ssdt even sql server production machine
37609 recently upgraded sql server sql server sql server option create compressed backups attempt backup database compression file already initialized without compression backup database command fail following error message error message backup database terminating abnormally error code tell existing backup file initialized compressed backups
37627 would like able easily check unique identifiers exist table supplied query better explain heres would check ids list exist table select dbo table id lets say table contains row id dump results excel run vlookup original list searches list value result list vlookup results value occur table im thinking theres got better way im looking ideally something like list check query table check members list table
38708 database drop table exists books create table books isbn varchar255 null title varchar255 null default null primary key isbn comment books used school drop table exists classes create table classes class id int10 null auto increment teacher id smallint5 null default null primary key class id comment classes school drop table exists create table isbn varchar255 null class id int10 null primary key isbn comment books classes alter table add foreign key isbn references books isbn update cascade alter table add foreign key class id references classes class id update cascade issue im would like normalize data much possible dont want multiple entries relationship entered table would like store data absolutely pertinent first idea deal create compound primary key table consisting fields isbn class id would solve issue duplicate relationships table however heard strong opinions unique identifier every row table like justification unique identifier every row seems useful able specify specific row though dont see situation would become useful someone offer example another criticism ive heard using compound pks way make joins extremely taxing someone comment performance two different methods question boils worth add id field table use compound pks enough properly represent relationship books classes tables comments design directly pertaining question would love hear thank advance help
38722 script identifying indices rebuild select alter index name dbname dbo object namea object id rebuild sys dm db index physical stats db id dbname null null null null inner join sys indexes object id object id index id index id avg fragmentation percent generates alter index fooindex foodb dbo footable rebuild execute alter statement index still high fragmentation value execute dont get lower input could wrong would highly appreciated updated manually increased size db managed lower fragmentation indices still still couple around daniel
38758 messages table database include sender id message type course many columns relevant question try create query counts many messages type user send following table id user id message type private public private want get following id private public fact want group message type user id instead generating multiple rows per user want create multiple columns one message type achieve without hardcoding message types query
38793 looking developing tool capture analyze netflow data gather tremendous amounts day capture billion flow records would look like json format tcp flags src nexthop unix secs src mask tos prot input doctets engine type exaddr engine id srcaddr dst unix nsecs sysuptime dst mask dstport last srcport dpkts output dstaddr first would like able fast searches less seconds data set likely narrow slices time mintes intervals also want index majority data points searches quickly would also like date view data searches executed would great stay open source world opposed looking proprietary solutions project idea keep approximately one month data would billion records rough estimate record would contain bytes data would equate terabytes data month maybe three times indexes eventually would like grow capacity system store trillions records basically evaluated couchbase cassandra mongodb far possible candidates project however proposes challenges couchbase indexing done intervals insertion data views date cassandras secondary indexes efficient returning results typically require scanning entire cluster results mongodb looks promising appears far difficult scale master slave sharded candidates plan evaluate elasticsearch mysql sure even applicable column oriented relational databases suggestions real world experience would appreciated
38803 installed fresh copy ubuntu lts new machine logged mysql root david server1 mysql root p123 created new user called repl left host blank new user may access location mysql create user repl identified query ok rows affected sec checked user table verify new user repl properly created mysql select host user password mysql user host user password localhost root 23ae809ddacaf96af0fd78ed04b6a265e05aa257 server1 root 23ae809ddacaf96af0fd78ed04b6a265e05aa257 root 23ae809ddacaf96af0fd78ed04b6a265e05aa257 root 23ae809ddacaf96af0fd78ed04b6a265e05aa257 localhost server1 localhost debian sys maint 27f00a6baae5070bcef92df91805028725c30188 repl 23ae809ddacaf96af0fd78ed04b6a265e05aa257 rows set sec exit try login user repl access denied david server1 mysql repl p123 error access denied user repl localhost using password yes david server1 mysql urepl p123 error access denied user repl localhost using password yes david server1 access denied
38808 release sql server integration services ssis delivered ssisdb catalog tracks operations packages among things default package execution solutions using project deployment model logging ssisdb turned package executes system executioninstanceguid populated value one using explicit logging sys sysdtslog90 sys sysssislog would record events specific package execution id like know tie executioninstanceguid anything ssisdb catalog alternatively ssis package executing ssisdb privy value catalog executions execution id ultimately trying use existing custom audit table link back detailed history ssisdb catalog cant seem find link
38992 say following setup use tempdb go set nocount go create table mytest column1 varchar100 column2 text go insert mytest column1 column2 select replicatea replicatea sys syscolumns sys syscolumns id like convert columns varcharmax like processes every page alter table mytest alter column column1 varcharmax processes metadata alter table mytest alter column column2 varcharmax demonstrate first command processes whole table second command processes metadata thinking using set statistics io reports thousands logical reads first command nothing also thinking using dbcc log fn dblog wasnt sure interpret tie results queries issued
39058 best practice whether foreign key tables link natural key surrogate key discussion ive really found unless google fu lacking jack douglas answer question reasoning seems sound im aware discussion beyond rules change would something would need considered situation main reason asking legacy application makes uses fks natural keys strong push devlopers move nhibernate case fork already produced breaking changes im looking either push back track using natural key move legacy app use surrogate keys fk gut says restore original fk im honestly sure really right path follow majority tables already surrogate natural key already defined though unique constraint pk add extra columns non issue us insance using sql server id hope generic enough db
39081 standard sql result union guaranteed order something like select union select could return two rows order although practice database know come sql server turns execution plan using concatenation physical operation could easily imagine concatenation operation would scan inputs returning whatever input records available however found following statement web query processor execute plan order operators appear plan first top one last end one question true practice guaranteed true havent found reference microsoft documentation inputs scanned order first last hand whenever try running results suggest inputs indeed processed order way engine process one input time tests using much complicated expressions constants parallel enabled core machine queries take advantage parallelism
39128 sql server job steps steps must run regardless failures first four steps first four jobs set skip step fail however steps succeed whole job regarded success email notification set job failure receive email first four steps fail due overall job considered success would like happen would ideal split first four steps separate job must completed steps begin please anyone give advice solve problem steps run even steps fail steps begin strictly steps complete steps fail email notification sent indicating step failed thanks much advance help
39239 intend using uniqueidentifier access key users use access certain data key act password sense need generate multiple identifiers part insert select statement architectural reasons want generate identifiers server side case generate securely random uniqueidentifier note newid would random enough promise security properties im looking sql server equivalent system security cryptography randomnumbergenerator need unguessable ids anything based checksum rand getutcdate would also qualify
39344 simple voting system create table elections election id int11 null auto increment title varchar255 create table votes election id int11 user id int11 foreign keys getting list elections user voted following join used select elections join votes usingelection id votes user id get list elections user voted
39421 local development server middle east production server uk need show date user time zone example user saudi arabia need show time according saudi arabia format create new database table called timezone save time utc
39572 new sql server instance migrating database sql server stored procedures db moving reference another database back server best way handle would linked server help trouble creating link testing people recommend using odbc others seem use sql server client driver sqlncli10 using sql server client driver seems better issues installing sql server instance
39589 use postgresql ubuntu need select records inside range time table time limits two timestamp fields one integer property additional columns actual table involved query create table start date time timestamp end date time timestamp id phi integer primary keystart date time end date timeid phi table contains roughly 2m records queries like following took enormous amounts time select time limits id phi start date time timestamp2010 end date time timestamp2010 tried adding another index inverse pk create index idx inversed time limitsid phi start date time end date time got impression performance improved time accessing records middle table seems reasonable somewhere seconds still several tens seconds values middle time range twice targeting end table chronologically speaking tried explain analyze first time get query plan bitmap heap scan time limits cost rows width actual time rows loops recheck cond id phi start date time timestamp without time zone end date time timestamp without time zone bitmap index scan idx time limits phi start end cost rows width actual time rows loops index cond id phi start date time timestamp without time zone end date time timestamp without time zone total runtime ms see results depesz com could optimize search see time spent scanning two timestamps columns id phi set dont understand big scan 60k rows timestamps arent indexed primary key idx inversed added change timestamp types something else read little gist gin indexes gather efficient certain conditions custom types viable option use case
39596 way determine view longer used without removing ideally would like know views usage sql server upgrading databases suspect many views longer used also views difficult compile new server access multiple databases moved new server
39611 self taught ms access programmer main part job programming building larger databases still using ms access ui sql server store data work essence question subject matters need know sql server probably didnt learn need using access looking tell anything think important things go research theres lot subjects hell lot detail dont want find long way less valuable path brain dump maintenance important check database reduce database update statistics rebuild etc indexes dont know much good book blog etc teach basics upwards anything else missed theres probably lots said new sql server helps work mid sized retailer databases predominantly work cover things reporting platform summarises sales receipts inventory etc main system provides fast reporting reconciling tool third part stores put registers imports data third party cross references transaction logs stores data promotions product prices projections actual results etc
39652 im considering using cluster reorder table index understand recreation table data makes existing indexes either bloat useless ive seen indications reindex required cluster ive found references indicate cluster reindex official documentation says nothing reindex part cluster required although suggest running analyze cluster anyone definitively sort reference official docs say whether reindex required cluster
39689 dbcc freeproccache doesnt work azure sql db else force plan kick cache way wont hurt production system cant go alter tables willy nilly specifically sql created entity framework arent self managed stored procs effectively dynamic sql source bad indexes bad stats etc thats fixed bad plan wont go away update selected mrdennys solution got first however successfully using aaron bertrands script perform work thanks everybody help
39703 time time stored procedures looks like create procedure handle data fk int value varchar10 begin exists select table id fk begin update table set value value id fk end else begin insert table fk value select fk value end end probably fault design app calls stored procedure avoid making apps stored procedure methods inserting new data also updating old ones better way achieve updating inserting data one approach using sql server
39815 use case choose columns display select query postgres like select case val column val column else end update something similar possible performing update query postgres choose columns updated assume since couldnt find anything maybe someone clever alternative besides using procedure updating column using case determine value column assigned new value simply reassigned existing value easy alternative ill course accept answer well extra info case potential columns may updated one updated per matching row table updated joined another query amount rows update likely vary could dozens hundreds believe indexes place joining conditions
39833 constraint applied database flexible put code im reading beginners book implementing databases im asking beginner lets say designed database including entity model entity type sub types person employee student student graduate undergraduate employee teacher administrator current constraints registered person system student employee person entity requires uniqueness social number presume every person holds single unique one aka good enough primary key see later decide remove number one day college decides teacher employee sub type also student taking courses free time much harder change database design could thousands millions billions zillions entries rather changing logic code part didnt allow person registered student employee improbable cant think anything else right apparently possible care business rules database design rather code note years later real life example seen government mistake issued ssns duplicated multiple people ssn designing original db definitely made mistake applying uniqueness constraint database later bug original application multiple applications using shared database agreeing put check enforce constraint bug go live system system developed rely original systems database many many years come reading answers learned apply constraint many possible wisely blindly database represent real physical world good
39844 sql server agent jobs periodically perform checkdb defrag alter index reorganize rebuild index highly fragmented typical maintenance best practices im wondering system databases apply jobs right run checkdb master vaguely remember setting saw book somewhere following perform checkdb index defrag master model msdb tempdb
39936 new sql databases general use occasional homework havent even tried master seats theater seats divided main areas area number rows number seats per row database id like row seatnumber compound primary key one table area dont yet know ill selects want ask way selects doable want example select exact position within theater know area row seat number would tables hindrance could give example select might look first time site question belong please direct suitable site within stack exchange
39968 sql server single database full recovery model usually queue length less sometimes grows several thousands seconds time many write queries ends timeout error using resource monitor found moment sqlserver exe writes large amount data main database file mdf thoughh usually writes transaction log ldf using sql server profiler found heavy queries running moment think kind sql servers background operation wonder kind database also read commited snapshot mirroring synchronous mode enabled fact cause issue update found writing log data file default behavior full recovery mode log copied data file backup transaction log operation still dont understand sql server copying log every ten minutes
40045 using postgresql v9 list schemas using sql expecting something along lines select something pg blah
40141 dbcc showcontig scanning mytable table table mytable index id database id table level scan performed pages scanned extents scanned extent switches avg pages per extent scan density best count actual count logical scan fragmentation extent scan fragmentation avg bytes free per page avg page density full read scan density good logical scan fragementation also great extent scan fragmentation troubles internet says ignore im analyzing single table slow performing query runs seconds first execution ms second subsequent executions reset behavior dbcc dropcleanbuffers high extent scan fragmentation important clue ill likely add another question single table query
40221 following mysql query select table name like john limit mean query search mysql database table return top results match query condition want search top records database table match condition return first rows records table want search first records use wanted query human readable search top records table name like john return top records match corresponding mysql
40272 ive installed successfully configured sql server alwayson node servers new intranet coming ive gotten alwayson working great front end servers intranet using sharepoint glitch sharepoint configured add databases automatically sql server back end alwayson reading contacting microsoft msdn support default answer must manually find select back add new databases individually get alwayson wait quite task constantly checking sql server back end servers see databases created add alwayson im looking script process check new databases back new databases full mode added alwayson course add databases alwayson automatically run every hours without user intervention ive come far script actually identifies newly added databases yet alwayson backs shared location next task find newly added databases various processes needed get added alwayson involve sort looping action imagine im sql scripting guru solution script might access would add databases alwayson automatically please advise im sure im first person issue seen previous posts various internet sites including one solution either incorrect states something like sure go ahead script thanks need little detail thanks allen declare name varchar50 database name declare path varchar256 path backup files declare filename varchar256 filename backup specify database backup directory set path atel web be2 backups declare db cursor cursor select name sys databases group database id null replica id null name inmastermodelmsdbtempdb open db cursor fetch next db cursor name fetch status begin set filename path name bak backup database name disk filename fetch next db cursor name end close db cursor deallocate db cursor
40280 tl dr since question keeps getting views ill summarize newcomers dont suffer history join table member value1 member value2 slow hell join table member coalesce value1 value2 blazing fast note value1 value value2 null vice versa realize might everyones problem highlighting sensitivity clauses might help look right direction case original text future anthropologists original text consider following simple query tables involved select sku id productid primary isprimary v1 category name category1 v2 category name category2 v3 category name category3 v4 category name category4 v5 category name category5 category c4 join category voc v4 v4 category id c4 category id v4 language code en join category c3 c3 category id c4 parent category id join category voc v3 v3 category id c3 category id v3 language code en join category c2 c2 category id c3 category id join category voc v2 v2 category id c2 category id v2 language code en join category c1 c1 category id c2 parent category id join category voc v1 v1 category id c1 category id v1 language code en left outer join category c5 c5 parent category id c4 category id left outer join category voc v5 v5 category id c5 category id v5 language code lang join category link sku id select value ids category id c4 category id category id c5 category id c4 level c4 version id pretty simple query confusing part last category join way category level might might exist end query looking category info per product id sku id thats large table category link comes finally table ids temp table containing ids executed get following actual execution plan see almost time spent nested loops inner join heres extra information nested loops note table names dont match exactly edited query table names readability pretty easy match ads alt category category way optimize query also note production temp table ids doesnt exist table valued parameter ids passed stored procedure additional info category indices category id parent category id category voc index category id language code category link index sku id category id edit solved pointed accepted answer problem clause category link join however code suggested accepted answer slow slower even original code much faster also much cleaner solution simply replace current join condition following join category link sku id select value p1 category id coalescec5 category id c4 category id minute tweak fastest solution tested double join accepted answer also tested cross apply suggested valverij
40373 set mysql replication single slave whenever adding data master database automatically copied slave database add data slave database available master database wrong add slave database tell slave database redirect writes master possible application designed normal application replicated database change application code working replicated database
40441 want list partitions created dynamic triggers postgresql able generate count partitions using related answer frank heikens table foo insert trigger creates foo foo etc dynamically partition insert chosen based primary key id range based partitioning possible display partitions currently place table foo
40481 turned maximum memory sql server instance mb cant log increase increase maximum memory without logging version sql r2
40488 whenever create brand new database postgresql maestro creates following list default schemas understanding schemas like folders organization etc question schemas needed create new db used pg side wont ever use understand information schema default install mysql server though dont get database would need opposed entire server db type guess
40492 im trying find whether sql sql solution would better creating events database im creating ticketing system similar ticket master know either database type storage simple part deciding factor performance following queries select events location within specific date range select events given location city town etc sort date search events keyword within specific date range within specific location events basically id name location venue start date end date relational schema would events table dates table storing dates separately events occur one date repeatable venues table event location country city etc cross referenced experience sql databases vote sql please suggest see schema organized particular db hope question specific enough query performance deciding factor consideration realize question properly distills availability date time functions facilitate fast date range queries know mysql postgresql functions postgresql even looking little better point terms syntax dont know nosql solutions offer regarding know system certainly modelled comfortably relational database also aware sql solution different wondering anyone specific knowledge particular sql db could cite particular db good solution
40516 trying run sqlcmd exe order setup new database command line using sql server express windows bits heres command use sqlcmd mssqlserver08 dp0 aqualogydb sql dp0 databasecreationlog log heres pieceof sql file creation script create database aqualogy collate modern spanish ci trustworthy db chaining go use aqualogy go create table dbo baselayers code nchar100 null geometry nvarcharmax null isactive bit null default exec sp updateextendedproperty name nms description value ncapas de cartograf base de la aplicaic consideramos en galia vil la cartograf level0type schema level0name ndbo level1type table level1name nbaselayers well please check accents words tables description database created problems collate understood script see attached screenshot despite accents properly shown examining table id really appreciate help thank much edit hi changing sql file encoding using notepad worked fine thank much help learned something interesting problem
40567 process designing database new php mysql based application problem represent saved database unlimited changing problem example application shopping website many kind products shared attributes title price kinds specific details expiry date isbn non example really many kinds many different attributes create table kinds available kinds many kinds items unknown time way accommodate problem without head users side
40580 tasked writing update query update table million rows data table structures source tables create table dbo sourcetable1 prodclassid varchar null pricelistdate varchar null pricelistversion smallint null marketid varchar null modelid varchar null variantid varchar null varianttype tinyint null visibility tinyint null constraint pk sourcetable1 primary key clustered variantid asc modelid asc marketid asc prodclassid asc pricelistdate asc pricelistversion asc pad index statistics norecompute ignore dup key allow row locks allow page locks fillfactor create table dbo sourcetable2 id uniqueidentifier null prodclassid varchar null pricelistdate varchar null pricelistversion smallint null marketid varchar null modelid varchar null constraint pk sourcetable2 primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks fillfactor primary primary textimage primary sourcetable1 contains million rows data sourcetable2 contains rows data targettable structure create table dbo targettable chassisspecificationid uniqueidentifier null variantid varchar null varianttype tinyint null visibility tinyint null constraint pk targettable primary key clustered chassisspecificationid asc variantid asc pad index statistics norecompute ignore dup key allow row locks allow page locks fillfactor primary primary relationship tables follows sourcetable1 variantid related targettable variantid sourcetable2 id related targettable chassisspecificationid update requirement follows get values varianttype visibility sourcetable1 variantid maximum value pricelistversion column get value id column sourcetable2 values modelid prodclassid pricelistdate marketid match sourcetable1 update targettable values varianttype visibility chassisspecificationid matches sourcetable2 id variantid matches sourcetable1 variantid challenge update live production minimum locking query put together check temp table already exists drop exists select null tempdb sys tables name like cspec begin drop table cspec end create temp table assign sequence numbers create table cspec rowid int id uniqueidentifier pricelistdate varchar8 prodclassid varchar10 modelid varchar20 marketid varchar10 populate temp table insert cspec select row number order marketid rowid cs id cs pricelistdate cs prodclassid cs modelid cs marketid dbo sourcetable2 cs cs marketid null declare variables hold values used updates declare min int max int id uniqueidentifier pricelistdate varchar8 prodclassid varchar10 modelid varchar20 marketid varchar10 set minimum maximum values looping set min set max select maxrowid cspec populate variables loop min max begin select id id pricelistdate pricelistdate prodclassid prodclassid modelid modelid marketid marketid cspec rowid min use cte get relevant values sourcetable1 variant cte select variantid varianttype visibility maxv pricelistversion latestpriceversion sourcetable1 modelid modelid prodclassid prodclassid pricelistdate pricelistdate marketid marketid group variantid varianttype visibility update targettable values obtained cte update sv set sv varianttype vc varianttype sv visibility vc visibility spec variant sv inner join targettable vc sv variantid vc variantid sv chassisspecificationid id sv varianttype null sv visibility null increment value loop variable set min min end clean drop table cspec takes seconds set limit iterations hardcoding value max variable however increase limit iterations takes almost minutes complete concerned execution time taken iterations run multiple days production however might still acceptable targettable get locked preventing users accessing inputs welcome thanks raj
40656 go mysql shell type select users get userid name emailid password user type contact id fkusers company id fkusers cc com admin kshitiz ksharma aaa com asdf admin oracle sqlplus shows userid name emailid password user type contact id fkusers company id fkusers cc com admin cc com admin sqlite shell shows cc com admin kshitiz ksharma aaa com asdf admin way beautify output sqlite shell alternative shell thats better default distribution cli clients
40673 following tables staffname name income group educational level country jack jill jane june country id country country description america japan incomegroup id income range description us us us educationallevel id educational level country description phd master intention get values table main table display something like following intended result name income group educational level country john us us phd america koko us us master japan kane us us degree thailand ali us us college malaysia tried using following sql select name income group educational level country staffname country incomegroup ig educationallevel el income group id educational level ig id country el id return results foreign primary keys tables could missing
40703 temptable created using select temptable openrowsetmicrosoft ace oledb excel database myfilename xls select sheet1 easy way copy table structure temptable new physical table temp table contains lot columns contain numbers dates decimals strings want identify manually define every column using sql server
40738 forum example online always suggest allow snapshot isolation read committed snapshot set whenever someone asking snapshot row versioning similar question guess word snapshot setting get little confusing thought order database engine use row versioning instead locks read committed default behavior database read committed snapshot set regardless allow snapshot isolation setting allow snapshot isolation setting set allow snapshot isolation starting transaction set transaction isolation level snapshot regardless read committed snapshot setting reason two settings set needs read committed row versioning snapshot isolation question understanding incorrect way two setting always set together especially read committed row versioning
40830 recently moved sql server thats vps every get error trying update rebooting server fixes problem changed maximum server memory mb 4gb vps dont know whats causing error
40833 im somewhat new dba im managing sql server instance fair amount activity im running full recovery mode need point time recovery right im taking full backup databases logs every day 5am log files ballooned 300gb even taking backup dont reduce size get reduce size running something similar backup log db1 disk server share db1 log1 trn dbcc shrinkfile db1 log backup log db1 disk server share db1 log2 trn dbcc shrinkfile db1 log backup log db1 disk server share db1 log3 trn dbcc shrinkfile db1 log check lsns backup files see something like restore headeronly disk server share db1 log1 trn firstlsn secondlsn restore headeronly disk server share db1 log2 trn firstlsn secondlsn restore headeronly disk server share db1 log3 trn firstlsn secondlsn dont believe im breaking log chain shrinking log files reading believe im hurting performance shrunk log files grow questions doesnt log file shrink backups uncommitted transactions first thinking shrink log files every backup reading thats bad performance believe need take regular log backups every couple hours day correct normal full backup database logs happens every day sometimes takes hours schedule log backups happen every hour happen log backup collides backup
40980 facing problem connecting local system db connect server connects login failed user domain username microsoft sql server error help click http go microsoft com fwlinkprodname microsoft sql server evtsrc mssqlserver evtid linkid
40987 new sql server would like understand whether following simple select statement would take locks select student please consider case statement would running inside begin tran block
41067 consider select statement select query id players username foobar returns column query id value along players columns would one make sql return least query id even select finds rows match btw postgresql
41215 database mb data file mdf gb log file ldf recovery model set full try shrink log file shrinking know shrinking database good done still trying shrinking log file ran dbcc sqlperflogspace found log size mb log space used tried command use databasename dbcc loginfo almost vlfs status means use tried take log backup shrink log file shrinking didnt reduce size changed recovery model simple tried shrinking also didnt help checked open transactions dbcc opentran database found transaction open stopping shrinking log file solve
41223 weve dedicated server single quad core gb ram moving new dedicated server 2x hex core gb ram windows server sql server performance new server slightly worse old slower server testing asp net application runs slower running individual expensive queries statistics io statistics time shows greater elapsed time new server sql query profile shows higher cpu usage expensive queries task manager new server shows sqlserver exe consuming gb ram cpu values always stay low ive updated statistics rebuilt reorganized indexes etc execution plans stored new server point given amount testing ive done missing indexes dont think affect old new servers equally new restored backup data old id expected performance new server would better concern load old server performing better even load happen new slightly worse server take load else could missing edit maxdop set old server os databases tempdbs physical drives raid total 15k gb inch sas new server three drive sets os raid database raid tempdb raid total 15k gb inch sas old server intel xeon e5620 ghz quad core threads new server intel xeon e5 ghz six core threads edit heres final analysis power plan balanced high performance switched tempdb raid raid added another hd create two physically distinct raid configs one tempdb one everything else excluded sql related files mdf ldf ndf bak virus scanning rebuilt indexes following move new server fragmented possibly result backup copy restore realized processor jump big queries arent going execute much faster processors cores ram well scalable
41239 assuming following procedure create procedure foo table1 id table1 table1 id type table1 val table1 table1 value type sql update varchar2500 update table1 set table1 value table1 id begin execute immediate sql update using foo table1 val foo table1 id update table1 set table1 value foo table1 val table1 id foo table1 id end beside style readability performance penalty using dynamic query compared cases mean absolutely avoidable thank
41343 im using sql server r2 pseudo query sp select linkmode null mycolumn long running query problem query takes long time execute even execute sp linkmode noticed long running query executed linkmode null case case linkmode however change select mycolumn long time exeted query sp run fast ive heard sometimes optimizer optimize order criteria ask even optimizer chooses different route faster checking null mean think checking null much faster running long query force sql server run query ive written order
41413 ive given mysql 5gb memory use innodb insert lots data dumpfile 1gb hard drive still bottleneck cpu busy hard drive possible force mysql make hard drive bottleneck
41476 installation sql server collation tab choose french ci french ci mean one newer theres code newer older
41574 two tables user address user contains reference address address contains columns createdby modifiedby reference user design database avoid cyclic dependency
41577 db2 table containing large binary data purged whole table ran runstats reorg runstats amount disk space taken change could wrong table resides tablespace created follows create bufferpool bp size automatic pagesize create large tablespace tbs database partition group ibmdefaultgroup pagesize managed automatic storage extentsize prefetchsize bufferpool bp overhead transferrate file system caching deleted reorged follows delete tbl runstats table tbl distribution detailed indexes reorg table tbl runstats table table distribution detailed indexes alter tablespace tbs reduce table tbl took 5gb deleting reorging uses mb less fwiw im running db2 nt v9
41608 creating package exporting data database empty excel file added source destination components ran package got conversion error stating output column column convert unicode non unicode string data types fix added data conversion component converted columns unicode string dt wstr longer received error problem columns go select unicode string dt wstr drop list go destination component map newly converted columns excel file question anyone else come across better efficient way get around manual data type conversions convert map columns one one doesnt seem practical especially large number rows understand excel files best way go importing exporting data required particular case might look way export flat text file try convert excel last step package im hopping wont trigger unicode nonunicode conversion error
41709 im really trouble tracking blocking experiencing root blocking spids status sleeping cmd awaiting command sqltext set transaction isolation level read committed view top transactions blocked transactions count report blocking sql statement ive performed trace sql blocking happens tracing root blocking spid hasnt really led anywhere last trace statement sqltext set transaction isolation level read committed ive checked related stored procedures find make sure try catch begin tran commit tran rollback tran statements use stored procedures everything standalone statements ran issue started happening last hours one claiming made changes system solution one seldomly used stored procedures error insert number columns didnt match still confused exactly happening looking trace information exec statement stored procedure listed times never block happened blockking spid seemed starting blocking trace didnt record execution statements within either however times trace record execution blocking occurred stored procedure error report came user able find multiple exec statements traces run ssms time ran blocking occur hang ran expected catch block fired rolled back transaction error resolving fixing stored procedure seen issue
41754 using sql server j2ee web application need maintains audits updates column previous value new value one table heavy around columns 10k records increasing rapidly daily basis around users work application updates also occur frequently know handling via code require frequent connections database want know better approach handling code provide better performance using sql server trigger
41765 use following script search text stored procedures want find specific values select routine name routine type information schema routines routine definition like searchtext order routine name recently discovered routine definition stops characters procedures getting returned query full text stored procedure value
41854 two databases setup mirroring single sql server instance test database production database get mirrored another server using exact endpoints go database properties test database click failover button fail production database well since databases share mirror endpoint server network addresses properties concerned set mirroring 2nd database configure anything new used existing information use failover button database properties result failing databases use endpoint specific database viewing properties
41938 os ive install postgresql macports ive realized enough space system drive db populate data way create new database another drive partition system one postgres installed
41961 find positions patindex table variable declare name nvarcharmax set name ali reza dar yek shabe barani ba yek dokhtare khoshkel disco raft va ali baraye saat anja bud va sepas ali select patindex ali name pos returns want results pos
42180 two datasets fees payments crscode instno fee regno crscode instno payment ca1 r1 ca1 ca1 r1 ca1 ca1 r1 ca1 ca1 desired output regno crscode instno fee paid diff r1 ca1 r1 ca1 r1 ca1 r1 ca1 output getting regno crscode instno fee paid diff r1 ca1 r1 ca1 r1 ca1 null null null null null query using select regnoa crscodeb feea paymentb fee payment fees left join payments crscode crscode instno instno please find sqlfiddle
42214 tried backup ibm db2 luw database using command db2 backup database dbemp home user1 db2bkup got message sql1035n database currently use sqlstate tried db2 backup database dbemp online home user1 db2bkup got message sql2413n online backup allowed database recoverable backup pending condition effect mean alternative way backup database online cant stop database used
42290 system writes lots data kind big data system write performance good enough needs read performance really slow primary key constraint structure similar tables timestamptimestamp indexsmallint keyinteger table millions rows even billions rows read request usually specific period timestamp index tag common query returns around 200k lines currently read 15k lines per second need times faster possible note postgresql packaged software hardware different one client another vm used testing vms host windows server r2 x64 gb ram server spec virtual machine vmware server r2 x64 gb memory intel xeon w3520 67ghz cores postgresql conf optimisations shared buffers 512mb default 32mb effective cache size 1024mb default 128mb checkpoint segment default checkpoint completion target default default statistics target default work mem 100mb default 1mb maintainance work mem 256mb default 16mb table definition create table analogtransition keytag integer null timestamp timestamp time zone null timestampquality smallint timestampindex smallint null value numeric quality boolean qualityflags smallint updatetimestamp timestamp without time zone utc constraint pk analogtransition primary key timestamp timestampindex keytag constraint fk analogtransition tag foreign key keytag references tag key match simple update action delete action oids false autovacuum enabled true query query takes seconds execute pgadmin3 would like result seconds possible select analogtransition keytag analogtransition timestamp time zone utc analogtransition timestampquality analogtransition timestampindex analogtransition value analogtransition quality analogtransition qualityflags analogtransition updatetimestamp analogtransition analogtransition timestamp analogtransition timestamp analogtransition keytag analogtransition keytag analogtransition keytag analogtransition keytag analogtransition keytag order analogtransition timestamp desc analogtransition timestampindex desc limit explain limit cost rows width actual time rows loops buffers shared hit index scan backward using pk analogtransition analogtransition cost rows width actual time rows loops index cond timestamp timestamp time zone timestamp timestamp time zone filter keytag keytag keytag keytag keytag buffers shared hit total runtime ms explain latest test took minutes select data see limit cost rows width actual time rows loops index scan using pk analogtransition analogtransition cost rows width actual time rows loops index cond timestamp timestamp time zone timestamp timestamp time zone keytag total runtime ms
42532 format mysql query log particular lines like query commit query rollback stand true line represents round trip communication database batched
42539 database 16mb space left used truncate taught found links advise truncating http www sqlskills com blogs paul shrink data files http blog sqlauthority com sql server shrinking database bad increases fragmentation reduces performance anything else database reduce size deleting table records new dba forum probably looked around questions posting desperate worried database going
42553 looking execution plan slow running query noticed nodes index seek index scan difference index seek index scan performs better sql choose one realise questions think answering first one explain others
42561 several independent databases data code common sense accessed databases sense data means thing database code thing examples configuration settings error codes 50xxx boilerplate text company name etc procedures functions perform common tasks converting csv string table logging error formatting error message based error code table structures table database version history table logging errors well columns constraints triggers also common procedures functions read write data look tables date look table containing dates similar table structures quite often data across databases case date table start end dates configuration settings read function date data generated procedure operations common databases user defined types types passing tables functions maintenance support reasons think makes sense things like error codes procedures functions types single point truth across databases different truth database moment database copy everything including source repository maintain independently far ideal easy fix procedure forget put add error code one mean different things etc databases updated time dont necessarily reside hardware cases read data one exists standard way single point truth data code used across one database
42721 know memo structure pruned expensive alternative plans discarded optimization wondering way prevent let optimizer consider every possible plan select best alternatives
42837 case expression select case column end col linkedserver database dbo table produce result error message msg level state line statements could prepared msg level state line case expressions may nested level clearly isnt nested case expression though branches another oddity inline table valued function produces error alter function dbo fn myfunction var varchar20 returns table return select case column end col linkedserver database dbo table similar multi statement tvf works fine alter function dbo fn myfunction var varchar20 returns result table value varcharmax begin insert result select case column end col linkedserver database dbo table return end
42889 seen lot blogs stating shrinking good habit reduce performance system agree things lead side effects like fragmentation etc doubt scenarios use shrink option database never seen scenario stated useful one shrinking always evil
42998 conceptual question individual queries faster joins try squeeze every info want client side one select statement use many seems convenient tl dr joined query takes longer running individual queries fault expected first database savvy may noticed get information multiple tables often faster get information via multiple queries individual tables maybe containing simple inner join patch data together client side try write complex joined query get data one query tried put one extremely simple example together sql fiddle schema setup create table master id int null name varchar242 char null constraint pk master primary key id create table data id int null master id int null value number constraint pk data primary key id constraint fk data master foreign key master id references master id insert master values one insert master values two insert master values three create sequence seq data id insert data values seq data id nextval insert data values seq data id nextval insert data values seq data id nextval insert data values seq data id nextval insert data values seq data id nextval insert data values seq data id nextval query select name master id results name one query select id value data master id results id value query select name id value master inner join data id master id id results name id value one one one course didnt measure performance one may observe query returns amount usable information query return 2x3 data cells client return 3x3 data cells client join naturally include redundancy result set generalizing far fetched joined query always return data individual queries receive amount information since database cobble together data large datasets one assume database work single joined query individual ones since least return data client would follow observe splitting client side query multiple queries yield better performance way go would rather mean messed joined query
43099 postgresql documentation states function side effects must labeled volatile consider following function create replace function count items returns integer body declare result integer default begin select count id result table return result exception others perform error log insert sqlstate sqlerrm current query return end body language plpgsql stable cost since error log insert alters database performs insert upon exception mean count items function side effect albeit indirect thus declared stable must volatile words stability volatility function also depend functions calls within exception block case would create stable functions postgresql log exceptions database table
43254 bad practice always create transaction example good practice create transaction nothing one simple select cost creating transaction really necessary even using isolation level like read uncommitted bad practice
43352 sql server specifically case statement evaluate conditions exit finds clause evaluates true go entire set conditions mean last condition evaluating true overwrites first condition evaluated true example select case thenyes end results yes even though last condition make evaluate seems exits finds first true condition someone please confirm case
43452 kind curious one sql enterprise edition gb ram size database gb growing amount memory used locks objectstore lock manager memory clerk showing kb also confirm looking perf counter select sys dm os performance counters counter name lock memory kb however run query select count sys dm tran locks shows locks using gb locks way find mean memory locks allocated sql yet yet deallocated past hour see lock count exceeding lock memory stays edit max server memory gb use lock pages memory see memory pressure errors error log past hours avialble mbytes couter shows gb available memory edit activity monitor consistenly shows waiting tasks obviously blocking considering sql server lock take bytes memory gb lots memory trying find using edit run server dash board report top transaction lock count says currently locking transactions running system however lock memory still shows stated db busy overnight hours
43457 theres long winded debate going id like hear opinions many tables uniqueidentifier clustered pk whether good idea scope going change anytime soon database merge published devs advocating use separate rowguid column instead marking existing pk rowguidcol basically say application never bring domain something used replication dba stuff performance standpoint see reason add new column something could existing one moreover since dba stuff let dba choose kind understand devs point still disagree thoughts edit want add im minority debate devs questioning position people respect trust reason resorted asking opinions might also missing something could misunderstood point
43490 seen extensions used datafiles dat dbf creating altering tablespace im sure difference extensions dat incorrect examples oracle database sql reference 10g release dat create tablespace tbs datafile tbs f2 dat size 40m online dbf create tablespace tbs datafile tbs f03 dbf size 20m logging
43580 im experienced programmer im new sql databases please bare one current tasks involve editing refactoring needed dynamic generated sql statement stored procedure best practices design patterns follow writing stored procedures general better yet stored procedures generate long lines dynamic sql statements
43632 exploring new function format come across following issue would like know one else faced similar problem found fix bug select formatgetdatemm dd yyyyen us select getdate output
43772 would thought databases would know enough encounter often able respond demands theyre placed could decide add indexes highly requested data
43802 work sql server database microsoft sql server r2 serves back end two different user interfaces net web interface foxpro interface every month need apply updates web foxpro clients advised make sure one accessing database update process easiest way prevent access database update follow question best way prevent access update
43812 know mysql command line reset tables auto increment field alter table tablename auto increment curious way within phpmyadmin something like check box reset auto increment something else along lines anything wrong command line approach one curiosity things keep thinking thanks advance
43823 table currently duplicate values column remove erroneous duplicates would like prevent additional non unique values added create unique doesnt check existing compliance tried using nocheck unsuccessful case table ties licensing information companyname edit multiple rows companyname bad data cant remove update duplicates time one approach inserts use stored procedure fail duplicates possible sql check uniqueness would preferable data queried company name existing duplicates mean multiple rows returned displayed wrong acceptable use case goal prevent future seems comments logic stored procedures
43854 using sql server r2 quite working great need use sql server effect existing databases much risk involved installing sql server machine sql server r2 running
43910 table identity column developing delete rows time time add identity values always kept increasing didnt start added ids go crashes code reset identity value
43937 would like call stored procedure regular basis oracle would create job found postgresql mimic well using external tool cron etc pgagent know internal alternative wouldnt involve external tool want avoid security concerns password stored command line pgagent want avoid additional system configuration hiding password pgpass postgresql linux redhat 64bit
44084 im using open source rhel based machine running siem software run top command see postgres postmaster cpu usage way pin point see causing service stack
44188 ive multi tenant db setup need add columns im using schemas search path partition users im looking ubiquitous way apply ddl schema change databases initially id thought might able single query cursor pg catalog thinking command line invocation psql might preferred way
44498 tasked architecting solution large retail chain want allow million customers log web site see distribution recent purchases current month previous month year date categories data updated every day thinking putting sql server based olap cube letting website query cube directly leveraging features like proactive caching however developer heart next experience analysis services parts sql server quite concerned performance solution connecting web site directly olap cube sound like feasible solution systems react load multiple users roughly like sql server making reasonable solution act completely differently dont expect users check status often course using caching webserver etc
44507 exe file server say server1 run sql server job exists different server server2 done know local file use xp cmdshell job step run exe file case file exists different server doable security permissions set achieve
44533 ms sql server using cpu power server hardware restart sql service restart usage slowly increases course days depending much used every query extremely slow website dealing alot big queries takes seconds restart cpu usage less takes seconds query fix ive read online affinity masks adjust cpu usage affinity settings disabled change processor plenty tricks queries websites services quite big simply much change already pretty well optimized keep restarting sql service even though takes seconds alarm service allows people call record message selected group called hear recorded message system used hundreds search rescue teams sql service restarts alarm terminate person called notified searched place found nothing except stuff affinity masks change must way clear cpu cache without terminating current queries right sql microsoft sql server os windows server x64 processor ghz ram gb
44585 used sql server replication long time issues sometimes needed reinitialize subscriptions fix issues times needed destroy whole replication structure rebuild main concern replication issue almost time easy solution reinitialize replication accepted business requirements preparing release new big project trying look 3rd party software sql server replication setup includes servers distributed branches different countries mobile clients laptops local sql server databases need replicate data ability offer article filtering would somebody please suggest alternate solutions us
44657 manage big hundreds gigs database containing tables various roles holding millions records tables receive large number inserts deletes inserts large number updates database runs postgresql debian amd64 system gigabytes ram question sometimes autovacuum process table takes long time days complete want able roughly tell much time particular vacuum command take able decide whether cancel also progress indicator postgres vacuum operations would really helpful edit im looking bullet proof solution rough hint number dead tuples necessary bytes enough decide really annoying clue vacuum finish whatsoever ive seen pg catalog pg stat tables column number dead tuples possible estimation even means one analyze table hand autovacuum vacuum threshold autovacuum vacuum scale factor settings alone prove postgres knows something amount change tables probably puts hands dba im sure query run run vacuum verbose see tables indexes processed
44764 working customized maintenance solution using sys dm db index physical stats view currently referenced stored procedure stored procedure runs one databases want pulls listing records regarding database place different database pulls listing records relating db example code bottom query run database shows requested information databases query run database shows requested information database reason want procedure specifically database three id prefer keep maintenance objects within database id like job sit maintenance database work application database code alter procedure dbo getfragstats databasename nvarchar64 null tablename nvarchar64 null indexid int null partnumber int null mode nvarchar64 detailed begin set nocount declare databaseid int tableid int databasename null databasename tempdbreportservertempdb begin set databaseid db id databasename end tablename null begin set tableid object id tablename end select name databasename name tablename name indexname index id indexid avg fragmentation percent percentfragment fragment count totalfrags avg fragment size pages pagesperfrag page count numpages index type desc indextype sys dm db index physical stats databaseid tableid indexid partnumber mode join sys databases database id database id join sys tables object id object id join sys indexes object id object id index id index id avg fragmentation percent order databasename tablename indexname percentfragment desc end go
44784 table id value date many ids values dates table records inserted table periodically id always stay occasionally value change write query give id plus recent time value changed note value always increase sample data create table taco taco id int taco value int taco date datetime insert taco values result taco id taco date last time taco value changed
44785 ive got database tables need build join query get specific data two know one basically need something like select tables database exists table column name
44796 8tb sql database mostly data files 400gb log files currently takes around hours restore database used testing purposes must deleted restored backup run make sure always starting point question server currently cores 92gb ram raid disk subsystem database areas usually cause bottlenecks sql restore processes disk memory cpu
44908 could somebody provide better insight compatibility mode feature behaving different expected far understand compatibility modes availability support certain language structures various versions sql server affect inner workings database engine version would try prevent use features constructs yet available earlier versions created new database compat level sql server r2 created table single int column populated rows executed select statement row number function thought since row number function introduced would throw error compat mode surprise worked fine surely compat rules evaluated save something created stored proc row number statement stored proc creation went fine perfectly execute obtain results could someone help better understand working compatibility mode understanding obviously flawed
44956 dont design schemas everyday try setup cascade updates deletes correctly make administration easier understand cascades work never remember table example two tables parent child foreign key child references parent delete cascade records trigger cascade records get deleted cascade first guess would child records get deleted parent records deleted since child records depend parent records delete ambiguous could mean delete parent record child record deleted could mean delete child record parent deleted wish syntax parent delete cascade foreign delete cascade something similar remove ambiguity anyone mnemonics remembering
44992 exploring master database ssms noticed tables folder another folder called systems tables houses bunch tables possible us create structure akin systems tables within database looking organize tables stored procedures project specific folders new setup referring table object would use following syntax guessing dbname projectname dbo tablename also apart clearing clutter anybody foresee performance improvement degradation organization use microsoft sql server r2
45087 tried three method explained max allowed packet one changes value mysql use show variables like max allowed packet see current value always changing value ini effective wrong
45095 sql server database using full recovery model execute following commands alter database test set recovery simple alter database test set recovery full backup log test truncate try run log backup backup log test disk backupfile bak receive error message backup log performed current database backup question check able take log backup without running backup log command
45137 im looking best practice dealing scheduled sql server agent jobs sql server availability groups maybe missed something however current state feel sql server agent really integrated great sql2012 feature make scheduled sql agent job aware node switch example job running primary node loads data hour primary goes activate job secondary becomes primary schedule job always secondary fails secondary read
45179 table includes column decimal values id value size need accomplish little difficult describe please bear trying create aggregate value size column increments time preceding rows sum descending order according value result would look something like id value size bucket naive first attempt keep running sum ceiling value however doesnt handle case records size end contributing total two separate buckets example might clarify id value size crude sum crude bucket distinct sum bucket see simply use ceiling crude sum record would assigned bucket caused size records split across two buckets instead ideal solution reset sum time reaches increments bucket column begins new sum operation starting size value current record order records important operation ive included value column intended sorted descending order initial attempts involved making multiple passes data perform sum operation ceiling etc example create crude sum column select id value size select top sumsize table t2 t2 value t1 value crude sum table t1 used update operation insert value table work later edit id like take another stab explaining goes imagine record physical item item value associated physical size less one series buckets volume capacity exactly need determine many buckets need bucket item goes according value item sorted highest lowest physical item exist two places must one bucket cant running total ceiling solution would allow records contribute size two buckets
45296 table rownumber essence range clients running total client resets every time client changes client rownr amount runtotal company company company company reset customer previous row customer company reset customer previous row customer company reset customer previous row customer company company tried using partition always groups client together client together removes crucial part row numbers help please drop table checks create table checks client varchar32 rownr int amount decimal122 runtotal decimal122 part int insert checksclient rownr amount select company union select company union select company union select company union select company union select company union select company union select company gets first entries per client amounts base amounts entries tallied cte select c1 client c1 amount c1 rownr case c1 client c2 client c1 amount else null end amt checks c1 left join checks c2 c1 rownr c2 rownr select client rownr amount case isnullamt0 amt else total end runtotal cte cross apply select sumx amount total cte rownr cte rownr cte client client rt drop table checks
45302 suppose structure like recipes table recipeid name description recipeingredients table recipeid ingredientid quantity uom key recipeingredients recipeid ingredientid good ways finding duplicate recipes duplicate recipe defined exact set ingredients quantities ingredient ive thought using xml path combine ingredients single column havent fully explored work make sure ingredients uoms quantities sorted sequence proper separator better approaches 48k recipes 200k ingredient rows
45461 following table sql server create table mytable id uniqueidentifier null primary key default newid mygroup int null want output table form mygroup count max min example rows mytable mygroup rows mygroup rows mygroup mygroup count max min sort query would output information
45579 common product table db1 db2 want make one table one inventory stock products best solution share product table among two different database thoughts writing trigger update delete insert one table update another time creating view product table used second db dont know replication dont know guide best way
45589 cant seem find documentation describes valid formats postgresql schema name know schema name start number spaces start pg else look
45655 im new microsoft sql server business intelligence analysis servicebut im programming years sql server one describe measures dimensions cubes simple wordsif possible images thanks
45665 mysql master slave setup created another slave server stopped original slave dumped data copied reimported worked fine noted master log pos original slave used commands set new slave change master master host ipaddress master user username master password password master port master log file mysql bin master log pos master connect retry started new slave got last io error got fatal error master reading data binary log log event entry exceeded max allowed packet increase max allowed packet master however started original slave caught fine sync questions current value 16m know big go would rather avoid trial error production server need increase value master original slave coped fine could problem really new slave update increased max allowed packet rolando suggested master old slave new slave restarted set global max allowed packet reason didnt seem take last io error see last sql error relay log read failure could parse relay log event entry possible reasons masters binary log corrupted check running mysqlbinlog binary log slaves relay log corrupted check running mysqlbinlog relay log network problem bug masters slaves mysql code want check masters binary log slaves relay log able know names issuing show slave status slave mysqlbinlog masters file scrolls past commands quite happily ages file 722m slave relay log get error error log event read log event sanity check failed data len event type error could read entry offset error log format read error checked variables changes worked however mysql show variables like max allowed packet new slave showed max allowed packet slave max allowed packet master max allowed packet version check master mysql show variables like version variable name value innodb version protocol version slave type conversions version log version comment mysql community server gpl remi version compile machine x86 version compile os linux new slave mysql show variables like version variable name value innodb version protocol version slave type conversions version log version comment mysql community server gpl remi version compile machine x86 version compile os linux versions far apart
45708 user table column name email password etc would like create another user select name column select name user ok select email user ok done mysql
45712 want speed following piece code delete ssn sdo art id art id skl id skl id level art id art id skl id skl id level tip tip art id art id skl id skl id doc id doc id server ms sql server art idskl id doc id integers tip varchar10 type want make indexes ssn sdo table delete going faster considering make three indexes one every case doc id asc art id asc skl id asc skl id asc art id asc tip asc skl id asc art id asc better way make one index include three cases careful indexes want slow inserts table
45846 single server running net web application sql server database standard im planning move database onto separate server order provision network hardware id like benchmark data throughput web application database port monitored internally tool native windows r2 would need 3rd party application like wireshark connection string referencing database using server localhost still possible tap see bandwidth used port essentially im trying determine need gbit mbit connection web server database server thoughts would much appreciated update 8th july hashed realise largely irrelevant reason thought would big cost difference mbit gbit switch cheapo home user switches mbit others pointed wireshark pickup activity iis sql server box im putting 1gbit managed switch ill use either wireshark built monitoring switch see whats going later dont think anywhere close physical transfer limits imposed hardware
45870 trying hourly incremental backup single postgres server win7 following setup postgresql conf max wal senders wal level archive archive mode archive command copy postgres foo restart base backup pg basebackup postgres foo made big base tar file foo folder added kb files assume wals dont understand wals foo dont change wals data pg xlog change pg supposed copy decide perhaps need set archive timeout ive seen several sites pgs mailing lists baculas postgres page say need call pg start backup pg stop backup believe required true secondary questions often wals data pg xlog get written triggers write seems update wal dml psql edit table pgadmin close window figured would write commit best practices pg basebackup week archive wals machine pg remote machine
45876 saw sql server central thread full backup truncate log full backup truncate log neither full differential backups truncate transaction log lynn pettis full backup truncate log chad crawford difference full backup copy full backup log backup copy backup prevent log chain breaking without truncating log copy full backup
45926 im system testing product several tests severely changing data demo database data quite complex create queries undo changes done tests moreover tests subject change using backup restore option since restoring database takes seconds long context automated testing using insert select complex tests subject change affect tables dont affect copying whole database way option neither performance reasons microsoft sql server snapshots feature given dont enterprise version localhost cant use cant use transactions neither since system tests involve two applications complex interaction course dont share connection done quickly undo last changes database make problem easier database controlled environment localhost one access changes system tests changes expected lost recovery model chosen preparation example sort backup take long time even manual task since would performed rarely speed undoing changes point important since done every test affects database
45934 find version store clean versions older oldest active transaction question oldest transaction database specific sql server keep versions regardless database older transaction still active period backstory sql server sp4 enterprise hosting around databases tempdb currently gb version store around gb one applications hosted database instance open transaction days old based sys dm database transactions two separate large databases extremely heavy use last month saw consistent tempdb growth coinciding operations expected growth expect keep growing question versions stored tempdbs version store two separate databases still third independent database connection days old shows open transaction state perfmon counters version store continually growing hours tracked morning version generation rate avg around kb version cleanup rate kb plenty space left tempdb around gb total data files user databases tempdb grown average mb per day data files since last restart behavior abnormal investigation revealed large version store answers comment questions long running comment section auto growth tempdb tempdb set initialize size found appropriate time allow auto growth order handle abnormal database activity monitor auto growth well know transaction active active connection transaction state says active sys dm tran active snapshot database transactions stuff activity monitor says connection open transaction app stupid third party one many instance know behavior abnormal easily fixed resolution open transactions preventing version store cleanup jon right version store cleanup done independent databases closing offending transactions allowed version store cleanup commence current theory behind jon seigel version store clear versions based oldest active transaction within entire instance support use transaction level snapshot isolation across multiple databases simultaneously anyone knows certain prove please referenced question find transactions filling version store referenced documents tempdb wp teratrax tuning tempdb idera demystify tempdb
46009 use following query find performance improvements queries select top substringqt text qs statement start offset case qs statement end offset datalengthqt text else qs statement end offset end qs statement start offset qs execution count qs total logical reads qs last logical reads qs min logical reads qs max logical reads qs total physical reads qs last physical reads qs min physical reads qs max physical reads qs total elapsed time total elapsed time qs last elapsed time last elapsed time qs min elapsed time min elapsed time qs max elapsed time max elapsed time qs last execution time qs creation time qp query plan sys dm exec query stats qs cross apply sys dm exec sql textqs sql handle qt cross apply sys dm exec query planqs plan handle qp qt encrypted last execution time dateadd minute current timestamp order qs total logical reads desc order qs total physical reads desc issue ive found query appears thrown repeatedly time time requires enhancement im able determine comes could user program case login username get user track query apply improvements
46011 setting mysql master slave replication trying figure handle failover situation promote slave master event master goes application server needs direct writes current master use server level ha master slave heartbeat keepalived since two db servers completely different subnets different physical locations think something need handle application level query two servers ask one master perform queries one query mysql see current server master master slave replica
46074 experiencing memory issues sql server first realised problem started getting timeouts login errors connection successfully established server error occurred login process provider tcp provider error specified network name longer available looking event viewer sqlbox noticed multitude insufficient memory errors insufficient system memory run query information see help support center http go microsoft com fwlink events asp immediate warning prior following message appdomain alerts dbo runtime unloaded twenty minutes prior number perf related messages errors info microsoft operations manager agent computer received new rules configuration settings mom server management group ggc warning configuration information performance library windows system32 aspperf dll asp service match trusted performance library information stored registry functions library treated trusted error microsoft operations manager performance provider could access performance counters computer blah blah blah microsoft operations manager monitor performance counters computer become available info microsoft operations manager successfully loaded performance counters computer blah blah blah previous failures start monitoring doubt perf alerts errors anything two hours insufficient memory exceptions included messages case finally two hours red memory errors following info message heralded end insufficient memory alerts sql server encountered occurrences cachestore flush bound trees cachestore part plan cache due dbcc freeproccache dbcc freesystemcache operations freeprocache called dba point despite eventually fixing insufficient memory exceptions noticed execution plans still stored issue continued whole days meaning apps using queries complex plans facing sever performance difficulties points plans start get taken dont ever tend stay cache long im wondering anyone could help pinpointing area concern part represents system query plans kept plans retained hour part represents plans cached checking dm exec query stats part dbcc memorystatus results memory manager kb vm reserved vm committed awe allocated reserved memory reserved memory use memory node id kb vm reserved vm committed awe allocated multipage allocator singlepage allocator memoryclerk sqlgeneral total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlbufferpool total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlqueryexec total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqloptimizer total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlutilities total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlstoreng total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlconnectionpool total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlclr total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlservicebroker total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlhttp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sni total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk fulltext total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlxp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk bhf total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlqereservations total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk host total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sosnode total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore objcp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore phdr total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xproc total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore temptables total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore notif total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore viewdefinitions total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xmldbtype total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xmldbelement total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xmldbattribute total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore stackframes total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokertblacs total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerkek total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerdsh total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerusercertlookup total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerrsb total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerreadonly total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerto total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore events total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore systemrowset total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore schemamgr total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore dbmetadata total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore tokenperm total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore objperm total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore sxc total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore lbss total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore sni packet total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore service broker total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore lock manager total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator buffer distribution buffers stolen free cached database clean database dirty latched buffer counts buffers committed target hashed stolen potential external reservation min free visible available paging file procedure cache value totalprocs totalpages inusepages global memory objects buffers resource locks xdes setls se dataset allocators subpdesc allocators se schemamanager sqlcache replication serverglobal xp global sorttables query memory objects value grants waiting available buffers maximum buffers limit next request waiting cost timeout wait time last target small query memory objects value grants waiting available buffers maximum buffers limit optimization queue value overall memory target memory last notification timeout early termination factor small gateway value configured units available units acquires waiters threshold factor threshold medium gateway value configured units available units acquires waiters threshold factor big gateway value configured units available units acquires waiters threshold factor memorybroker cache value allocations rate target allocations future allocations last notification memorybroker steal value allocations rate target allocations future allocations last notification memorybroker reserve value allocations rate target allocations future allocations last notification available memory largest free contiguous block total avail mem kb max free size kb part dbcc memorystatus memory manager kb vm reserved vm committed awe allocated reserved memory reserved memory use memory node id kb vm reserved vm committed awe allocated multipage allocator singlepage allocator memoryclerk sqlgeneral total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlbufferpool total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlqueryexec total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqloptimizer total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlutilities total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlstoreng total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlconnectionpool total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlclr total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlservicebroker total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlhttp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sni total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk fulltext total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlxp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk qsrangeprefetch total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk bhf total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sqlqereservations total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk host total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator memoryclerk sosnode total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore objcp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore sqlcp total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore phdr total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xproc total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore temptables total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore notif total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore viewdefinitions total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xmldbtype total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xmldbelement total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore xmldbattribute total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore stackframes total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokertblacs total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerkek total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerdsh total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerusercertlookup total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerrsb total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerreadonly total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore brokerto total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore events total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator cachestore systemrowset total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore schemamgr total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore dbmetadata total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore tokenperm total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore objperm total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator userstore sxc total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore lbss total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore sni packet total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore service broker total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator objectstore lock manager total kb vm reserved vm committed awe allocated sm reserved sm commited singlepage allocator multipage allocator buffer distribution buffers stolen free cached database clean database dirty latched buffer counts buffers committed target hashed stolen potential external reservation min free visible available paging file procedure cache value totalprocs totalpages inusepages global memory objects buffers resource locks xdes setls se dataset allocators subpdesc allocators se schemamanager sqlcache replication serverglobal xp global sorttables query memory objects value grants waiting available buffers maximum buffers limit next request waiting cost timeout wait time last target small query memory objects value grants waiting available buffers maximum buffers limit optimization queue value overall memory target memory last notification timeout early termination factor small gateway value configured units available units acquires waiters threshold factor threshold medium gateway value configured units available units acquires waiters threshold factor threshold big gateway value configured units available units acquires waiters threshold factor memorybroker cache value allocations rate target allocations future allocations last notification memorybroker steal value allocations rate target allocations future allocations last notification memorybroker reserve value allocations rate target allocations future allocations last notification memory left total avail mem kb max free size kb part part taken points memory low difference seems query plans retained period time held hour im hoping someone look memory statuses possibly point direction problem resides also sql server server pack update ok looking memorystatus noticed object cache store 297mb part high running bit consume majority vas wanted take look bit detail ive running query get size plan cache cachestore sqlcp non sp cachestore objcp sp select sumsingle pages kb summulti pages kb plan cache sizegb sys dm os memory cache counters type cachestore sqlcp type cachestore objcp seems cycling every two minutes stores flushed every tim stats rise 200mb majority 180mb cachestore objcp would right thinking use following query analyse object cache select top objtype usecounts size bytes kb left sql text text sys dm exec cached plans outer apply sys dm exec sql text plan handle sql order kb desc query taken around highest point cache mb returns around objects less top terms size seem triggers sum size 65mb normal barking wrong tree
46102 ive testing different methods compressing storing sql server backups using sql server r2 enterprise edition im wondering effective compression algorithm long term storage backups outside sqls internal compression algorithms im worried physical storage tape drives anything trying turn 3tb data log files smallest single file example would zip 7z many variables within database able accurately estimate effective ill need tests sql servers internal compression best ill get
46125 im using django every get error integrityerror duplicate key value violates unique constraint myapp mymodel pkey detail key id already exists postgres database fact myapp mymodel object primary key would postgres attempt use primary key likely application djangos orm causing issue occurred times row ive found occur happens one times row given table seems happen every table completely stops days happening least minute per table occur happening intermittently tables right away fact error intermittent happened times weeks load db testing application makes wary low level problem
46127 comments table simplified comments id user id text parent id parent id nullable might key parent comment select descendants specific comment comments might several levels
46273 installed sql server r2 express successfully realised need get full text search downloaded advanced services installation package run option feature selection part full text search please dont tell hav uninstall reinstall
46289 suppose export data one server another linked servers statement efficient executing source server insert destinationlinkedserver destinationdb dbo table select dbo udf getexportdata executing target server insert dbo table select openquery originlinkedserver select origindb dbo udf getexportdata one faster consume fewer resourcers total source target server servers sql server
46373 declare identity like id num id num increment unique numbers create table new employees id num int identity11 fname varchar minit char1 lname varchar30 recommended use identity alternative primary key since identity provided unique number row
46408 im designing database store data different languages using utf think best way display querys results ordering according users language query one correct ways follows select collate de de test1 assuming correct way work international data best collation database postgresql documentation says posix collations specify traditional behavior ascii letters treated letters sorting done strictly character code byte values think best choice case wrong bonus question slow select collation query
46410 using postgresql v9 following tables create table foo id bigserial null unique primary key type varchar60 null unique create table bar id bigserial null unique primary key description varchar40 null unique foo id bigint null references foo delete restrict say first table foo populated like insert foo type values red green blue way insert rows bar easily referencing foo table must two steps first looking foo type want inserting new row bar example pseudo code showing hoping could done insert bar description foo id values testing select id foo type blue another row select id foo type red
46486 created function accepts start end date end date optional wrote case filter use start date end date passed case dateend null datestart else dateend end call function recent month data select thefunction null query hangs specify end date select thefunction result returned normally took code function ran fine inside query window cant duplicate issue fiddle either query like select thefunction also works fine anything query could causing function hang null passed end date sql fiddle execution plan select thefunction estimated plan select thefunction null
46577 consider following query merge parameter rowlock target using select areaid parametertypeid value source areaid parametertypeid value target areaid source areaid target parametertypeid source parametertypeid matched update set target value source value updatedid target id matched insert areaid parametertypeid value values source areaid source parametertypeid source value statistics gives following output table parametertype scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table area scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table parameter scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads worktable appears messages tab makes think tempdb used merge seeing anything execution plan would indicate need tempdb merge always use tempdb anything bol explains behavior would using insert update faster situation left right table structure
46672 currently working database audit project based triggers fired update specific tables triggers write changes table information written table name updated column timestamp user old value new value triggers work fine single updates comes multi row updates working code like updatepriority begin set updatedcolumn priority insert dbo audittable tablename source recordid user timestamp updatedcolumn oldvalue newvalue select nbookingitem tablename nvarcharmax select code tbl leg source inner join inserted ins leg source id ins sourceid ins id recordid bigint select username inserted inner join tbl user modifiedbyid user id user nvarcharmax getdate timestamp datetime updatedcolumn updatedcolumn nvarcharmax del priority oldvalue nvarcharmax ins priority newvalue nvarcharmax inserted ins inner join deleted del ins id del id ins priority del priority ins priority null del priority null ins priority null del priority null end error message msg level state procedure mytrigger line subquery returned value permitted subquery follows subquery used expression suggestions fix trigger order handle multi row operations
46870 two tables school staff school code staff type name last update date time person id abe principal jan abe principal feb persons person id name abc xyz oracle query select maxlast update date time last update school code person id school staff staff type name principal group school code person id order school code gives results last update school code person id jan abe feb abe want select first one school latest date thanks
46942 trc file trace dba one databases dont sql profiler tool installed pc cant view contents analyze trace log read file without sql profiler installed pc
46957 table contains records un expanded form record associated integer weight essentially informs us many times record replicated order get true population say records table sampn ids unique record weight frequency weight un expanded dataset looks like sampn weight attrib1 attrib2 attrib3 expanded dataset like note removed weight field essential sampn attrib1 attrib2 attrib3 tried using cursors taking really long time execute clever way really fast predefined sql stored procedure achieves update thanks answers really great learning experience performed expansion operation dataset pauls auxiliary table numbers best execution time
46980 given variable contains stored procedure name declare stored procedure name varchar512 set stored procedure name stored procedure name execute stored procedure without passing arguments
47025 next year helping effort clean several sql server environments stored procedures estimate used regular basis another used rare occasion meaning lot work since multiple departments teams access databases procedures always ones calling procedures meaning must determine procedures called top want determine months days eliminates possibilities one approach use sql server profiler track procedures called compare list procedures marking whether procedures used could move procedures different schema case department comes screaming using profiler effective approach done something similar found another way better way
47046 ive used purge binary logs well flush logs mysql directory still contains files mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin index reason using commands working files taking lot space would like get rid safely
47051 aware microsoft provided code transfer logins sql servers however account password particular account various roles permissions assigned server level equivalent piece code script permissions also thanks
47058 sql server instance configured send mail everything working correctly cant figure view existing configuration particular smtp server ssms start configuration wizard cant find anything online plenty info set nothing view current settings view existing settings
47098 im currently creating sql read postgres catalogs build table definitions however encountering problem serial bigserial data types example create table cruft temp id bigserial primary key select information schema columns table schema cruft table name temp db cruft temp id nextvalcruft temp id seq regclass bigint db pg catalog int8 never yes gives database name db schema name cruft table name temp column name id default value nextval data type bigint int8 bigserial realize could check see default value sequence dont believe would accurate since could manually create sequence create non serial column default value sequence anyone suggestion might accomplish anything checking default value nextval seq edited sql solution added case tl dr new users unfamiliar pg catalog sequences select oid relname sequencename pg class relkind select sch nspname schemaname tab relname tablename col attname columnname col attnum columnnumber seqs sequencename pg attribute col join pg class tab col attrelid tab oid join pg namespace sch tab relnamespace sch oid left join pg attrdef def tab oid def adrelid col attnum def adnum left join pg depend deps def oid deps objid deps deptype left join sequences seqs deps refobjid seqs oid sch nspname information schema sch nspname like pg wont work user schemas matching pg col attnum seqs sequencename null view serial bigserial columns order sch nspname tab relname col attnum
47127 built following sql server query encountering anti semi join defect sql server results inaccurate cardinality estimates urgh runs forever since longstanding production sql server cant easily suggest upgrade versions force traceflag hint specific query im hard time refactoring select anyone care help ive made sure try use best joins based clustered key pairs select top doc2 id direction cd address type cd external identification hash value publishdate sender address id d2 sender address id address id address id message size subject emi employee id assentor emcsdbuser doc2 dnolock inner join assentor emcsdbuser employee msg index eminolock processdate emi processdate doc2 id emi doc2 id inner loop join assentor emcsdbuser doc2 address anolock emi doc2 id doc2 id emi address type cd address type cd emi address id address id inner join sis dbo sis snolock external identification external identification publishdate doc2 id select doc2 id assentor emcsdbuser doc2 address d2anolock doc2 id d2a doc2 id d2a address type cd frm option fast note employee msg index table 500m rows doc2 5b rows sis 500m rows help would appreciated
47186 given variable contains stored procedure name declare stored procedure name sysname set stored procedure name stored procedure name drop stored procedure
47237 today experienced degradation performance production sql server durring time occurred logged several query processor could start necessary thread resources parallel query execution errors reading ive done suggests many cpus use executing complex query however checked outage cpu utilization something else could referring havent come across yet likely culprit performance degradation chasing red herring sp configure values follows name minimum maximum config value run value cost threshold parallelism
47266 users want refresh qa database production want two tables lets call t1 t2 retain original qa data copied two tables qa db1 temp qa database db2 refreshed db1 production refresh want overwrite t1 t2 data db2 db1 contain pre refresh qa values done following use select d1 dbo t1 d2 dbo t1 refreshed d1 prod truncate t1 following step select count beforetruncatecount t1 go truncate table t1 go select count aftertruncatecount t1 go go back copy data d2 t1 d1 t1 get error already object named t1 database drop table copy better method whole procedure
47267 previous question merge data sets without including redundant rows asked filtering redundant historical data import davidspillett correctly replied couldnt trying instead filtering table import want create view table returns records price changed heres original scenario rephrased suite question table historical prices items table contains rows price recorded multiple dates want create view data shows price changes time price changes want see changes dont want see example price yesterday price today price changes price today inferred price yesterday need record yesterday example http sqlfiddle com c95ff table data effective product kind price 23t00 24t00 redundant implied record 25t00 26t00 27t00 redundant implied record 28t00 redundant price changed back expected view data effective product kind price 23t00 25t00 26t00 28t00 initial attempt used row number select effective product kind price select history row number partition product kind price order effective asc rownumber history rownumber order effective returned effective product kind price 23t00 good 25t00 26t00 good bad tried searching similar question answer hard work phrase search example worth lot words suggestions appreciated thanks
47295 tl dr ive got unfixable corruption indexed view details running dbcc checkdb dbname extended logical checks data purity infomsgs errormsgs one databases produces following error msg level state line spatial index xml index indexed view viewname object id contains rows produced view definition necessarily represent integrity issue data database checkdb found allocation errors consistency errors table viewname repair rebuild minimum repair level understand message indicates materialized data indexed view viewname identical underlying query produces however manually verifying data turn discrepancies select viewname noexpand except select t1 forcescan join t2 select t1 forcescan join t2 except select viewname noexpand noexpand used force use index viewname forcescan used prevent indexed view matching happening execution plan confirms measures working rows returned meaning two tables identical integer guid columns collations come play error fixed recreating index view running dbcc checkdb repair allow data loss repeating fixes also help dbcc checkdb report error get rid even rebuilding fixed question would still stand error reported although data checking queries run successfully update bug fixed releases longer reproduce sql server sp2 cu sp2 kb contains fix without kb article creating non clustered index causes dbcc checkdb extended logical checks raise corruption error two connect bugs closed https connect microsoft com sqlserver feedback details creating non clustered index causes dbcc checkdb extended logical checks raise corruption error https connect microsoft com sqlserver feedback details unfixable dbcc checkdb error also false positive otherwise strange
47304 bak file created today someone else manually created ssms r2 im trying manually restore database unfortunately file isnt appearing go browse script restore process ive seen problem im sure could cause bak appear
47345 migrating part mysql database aws data question write row 1k varchar fields datetime ints estimate need 25k records inserted hour peak times ran iostat current database reported around tps figure type iops ill need
47356 looking way find windows server last started using sql commands trying stay within default security configurations dont want enable xp cmdshell
47357 force users queries always run hint nolock type select customer executed server select customer nolock question various pros cons nolock respectfully know place discuss
47402 sql server standard database connect use sql server management studio since ssms supported windows xp problem sql server gives time exception index outside bounds array possible edit table visual editor open table client work database objects queries question solution windows xp work properly database
47431 sql server consuming server ram recently caused lot performance bottlenecks slowness researched issue one common solution could find internet set maximum limit sql server done much improvement gained want know maximum memory value set sql server keeps consuming resources
47444 im experienced dba work im trying make case requesting additional resources sql server hoping could get smart folks provide rough rough estimate running im suspecting allocation resources given production sql server low hardware software database sql server r2 enterprise database windows windows r2 enterprise bit pretty sure running vmware processor intelr xeonr cpu e7 27ghz ghz processors installed memory 4gb hard drive database files 300gb hard drive backups 150gb hard drive logs 100gb application main databases add 170gb data reporting services database ssrs server houses maybe different reports comprising average 700k records get generated daily user base simultaneous users maybe could considered resource intensive generating data crunching large reports majority users interact database asp net website report server website additionally developers use ssis bids extensively remoting directly onto server remote connections max finally fairly involved data warehousing operation probably brings million records per day way ssis packages also run server current problems chronic sever server timeouts response time website pretty bad suspect amount memory 4gb probably large bottleneck previous requests additional memory denied common response need perform query optimizations arent sql pros im sure tell setup db admin pros want make sure im expending time trying squeeze little potential performance hardware bottleneck thanks tl dr avoidance
47545 aware concept bulk insert wherein load data flat file database want unload data table flat file want export data table flat file anyone tell using sql server r2
47842 tried restore database dump version version got restored tried reconnect getting following error error hy000 connection using old pre authentication protocol ref used client option secure auth enabled tried adding following lines ini restarted servicebut issue persist till skip grant tables following link says bug mysql https github com santisaez powerstack blob master packages mysql mysql powerstack secure auth patch anyone fixes solution
47861 two queries query select eid item item sums qty total sold tbl sales tbl matentry eid item group eid result eid item total sold rupa pan america john player classmate lepakshi lee puma query select eid item item sums qty total stock tbl purchases tbl matentry eid item group eid result eid item total stock rupa pan america john player classmate lepakshi lee puma combine sql statements single statement getting incorrect output far tried select eid item item sump qty total stock sums qty toatl sold sump qty sums qty balance stock tbl matentry left outer join tbl purchases item eid left outer join tbl sales item eid group eid order eid eid item stock sold balance rupa pan america john player classmate lepakshi lee puma get correct result mistake error query please review query help get correct data expected output eid item total stock total sold balance stock rupa pan america john player classmate lepakshi lee puma
48011 existing table data dbo test col1col2col3 primary need change table partitioned like dbo testcol1col2col3 ps datecol2 achieve without dropping recreating table
48055 suppose something like source table variable values leftid int null rightid int null customvalue varchar100 null target table mapping leftid int null rightid int null customvalue varchar100 null want merge values target following rules match source leftid target leftid source rightid target rightid matched target update customvalue matched target insert delete unmatched values target match leftid source delete records related lefids im merging last rule hard describe sorry instance source foo foo target bar foo car merge result result target foo updated foo inserted foo deleted car unchanged heres far takes care update insert merge mapping target using select leftid rightid customvalue values source leftid rightid customvalue target leftid source leftid target rightid source rightid matched insert leftid rightid customvalue values source leftid source rightid source customvalue matched update set customvalue source customvalue delete part rule
48072 run explain mysql explain select last name employees order last name id select type table type possible keys key key len ref rows extra simple employees null null null null using filesort row set sec indexes table mysql show index employees table non unique key name seq index column name collation cardinality sub part packed null index type comment index comment employees primary subsidiary id null null btree employees primary employee id null null btree employees idx last name last name null btree employees date birth date birth null null yes btree employees date birth subsidiary id null null btree rows set sec index last name optimizer use mysql explain select last name employees force indexidx last name order last name id select type table type possible keys key key len ref rows extra simple employees null null null null using filesort row set sec still index used wrong fact index non unique btw last name varchar1000 update requested rolandomysqldba mysql select countdistinct last name distinctcount employees distinctcount row set sec mysql select count1 select count1 count500last name employees group last name count1 count1 row set sec
48108 need add constraint two columns says given value present one columns duplicated column duplicated column either constraint looking make primaryemail secondaryemail would invalid userid primaryemail secondaryemail joe yahoo com null smo gmail com joey yahoo com joe yahoo com present first column therefore present second column regardless row possible define type constraint sql server started defining table emails weve since reverted model favor two hard columns many reasons including query speed query complexity probability user using multiple email accounts actively decreases order magnitude one defines traditional two column constraint per row basis two columns doesnt give us create unique nonclustered index idx uniqueemail notnull userprofile primaryemail secondaryemail primaryemail null secondaryemail null
48166 fresh install xampp import linux live db working windows dev stage started encountering problems insert everything else seems work well errors get mysql error log 16c0 innodb error table mysql innodb table stats found 16c0 innodb recalculation persistent statistics requested table sizaradb pages required persistent statistics storage present corrupted using transient stats instead 16c0 innodb error table mysql innodb table stats found 16c0 innodb recalculation persistent statistics requested table sizaradb translations required persistent statistics storage present corrupted using transient stats instead open table mysql innodb index stats internal data dictionary innodb though frm file table exists tried fix googling errors trying see fixes people still working working days please help solve
48365 im working implementing paul randals method manually spreading dbcc checkdb several days large databases basically consists dividing tables database roughly equally buckets running dbcc checkalloc twice week running dbcc checkcatalog week running dbcc checktable one bucket day week anyone used technique existing scripts im concerned may actually cover everything checkdb books online documentation checkdb says addition checkalloc checkcatalog checktable also validates contents every indexed view database validates link level consistency table metadata file system directories files storing varbinarymax data file system using filestream sql validates service broker data database questions additional checks necessary important indexed views probably bit concerning dont think using service broker filestream yet ways perform additional checks separately checkalloc checkcatalog seem run quickly even large dbs reason run every day note standard routine thousands existing databases across hundreds servers least every database certain size means options like restructuring databases use checkfilegroup arent really practical us
48390 moving sql instance db collation sql latin1 general cp1 ci sql defaults latin1 general ci completed sql r2 installation used default latin1 general ci collation restoration database still sql latin1 general cp1 ci excepted problems occurred temp tables latin1 general ci whilst db sql latin1 general cp1 ci need advice pitfalls please installation sql r2 option installation use sql collation used backwards compatibility option select collation database sql latin1 general cp1 ci allow problems temp tables pitfalls would lose functionality features kind using current collation sql move years sql problems would point forced go latin1 general ci read dbas script complete rows complete databases run insert script database new collation im scared wary would recommend
48405 restore failed server servername microsoft sqlserver smoextended system data sqlclient sqlerror restore could start database ecp microsoft sqlserver smo database created accessible using object explorer database ecp accessible objectexplorer thanks advice make database work edit query select state desc sys databases name ecp returns recovery pending deleted database new try restore verifyonly disk path file returns attempting restore backup may encounter storage space problems subsequent messages provide details path specified ecpdata1 ecpdata1 mdf valid directory directory lookup file ecpdata2 ecpdata2 ndf failed operating system error 3failed retrieve text error reason directory lookup file ecpdata3 ecpdata3 ndf failed operating system error 3failed retrieve text error reason directory lookup file ecpdata4 ecpdata4 ndf failed operating system error 3failed retrieve text error reason directory lookup file ecplog1 ecplog1 ldf failed operating system error 21failed retrieve text error reason backup set file valid since says backup set valid get files specified make work right server dont drive adjust backup file possible im familiar windows server r2 kind symlinks like linux
48408 databases created using entity framework code first apps working general im pretty happy code first lets programmer first dba second necessity reading dataattributes describe want database question penalty eating nvarcharmax strings table see example several columns particular table defined key databasegeneratedattributedatabasegeneratedoption identity public int id get set public string name get set public string message get set public string source get set public datetime generated get set public datetime written get set expect query sort based name source generated written expect name source character length occasionally expect table start pretty small 100k rows grow significantly time 1m rows obviously message could small large probably queried want know performance hit name source columns defined nvarcharmax never expect larger characters
48458 large tables basic strucure one rownumber bigint datadate date column data loaded using sqlbulkimport every night new data ever loaded historical record sql standard enterprise partitioning bit data needs tied back systems rownumber datadate combination unique primary key notice due way defined pk ssms table designer rownumber listed first datadate second also notice fragmentation always high datadate appears would expect indexer add pages day wonder actually indexing based rownumber first hence shift everything else around rownumber identity column int generated external system sadly resets start datadate example data rownumber datadate data loaded rownumber order one datadate per load import process bcp tried loading temp table selecting order order rownumber datadate still comes high fragmentation
48462 im maintaining sql server database hosts approximately 9tb data 45tb raw schema analysis schema basically two copies data ingested recovery model simple ldf 6gb whatever reason mdf 5tb maybe additional columns analysis tables many nvarcharmax columns may mistakenly understood please correct im wrong may causing additional space allocation thats shrinking database 9tb prior thoughts please let know additional questions im new database administration optimization efforts usually dont side job many thanks andrija
48525 recently ran situation log backup shrinkfile ldf file remained size dbcc loginfo clearly showed one active vlf ssms said space ldf free first attempt shrink second attempt third fourth attempt success log reduced requested size meanwhile dbcc loginfo saying every shrinkfile another vlf became active decided run test new database create database logs test use logs test first look vlfs logs test database dbcc loginfo fileid filesize startoffset fseqno status parity createlsn put database full recovery making backup alter database logs test set recovery full first look vlfs logs test database dbcc loginfo fileid filesize startoffset fseqno status parity createlsn backup database logs test disk program files microsoft sql server mssql10 mssqlserver mssql backup logs test bak init go dbcc loginfo fileid filesize startoffset fseqno status parity createlsn create table put stuff create table newtablea int go insert newtable values10 insert newtable values20 insert newtable values30 go run update script log file grown accomodate log records set nocount declare counter int set counter counter begin update newtable set set counter counter end dbcc loginfo fileid filesize startoffset fseqno status parity createlsn far good vlfs added status run backup log backup log logs test disk program files microsoft sql server mssql10 mssqlserver mssql backup logs test trn init go ran dbcc loginfo one active vlf exactly expecting dbcc loginfo fileid filesize startoffset fseqno status parity createlsn run shrinkfile command thinking left ldf 1mb dbcc shrinkfile nlogs test log dbcc loginfo fileid filesize startoffset fseqno status parity createlsn luck ldf still 100mb two active vlfs run shrinkfile amount free space changed dbcc shrinkfile nlogs test log dbcc loginfo fileid filesize startoffset fseqno status parity createlsn still luck ldf still 100mb four active vlfs run shrinkfile one last time get dbcc shrinkfile nlogs test log dbcc loginfo fileid filesize startoffset fseqno status parity createlsn active vlfs ldf file 1mb questions necessary run shrinkfile one time shrink ldf ldf 1mb still many vlfs showing dbcc loginfo possible know stored within vlf lsn would like know operation took place thank update found reading log content thank input
48537 recently started using management studio using mysql workbench handy feature could stay lower case reserved word like select insert would convert upper case automatically replicate behavior ssms
48580 sql server many trace flags need turned saw trace flag need turned want know trace flag need tuned
48630 query table postgres order based date field number field table records data types table fcv id serial fcv fecha comprobante timestamp without time zone fcv numero comprobante varchar60 query select fcv id fcv fecha comprobante factura venta order fcv fecha comprobante fcv numero comprobante query takes seconds take order query takes seconds problem need run query shortest time possible search google create composite index following query create index factura venta orden factura venta using btree fcv fecha comprobante asc nulls last fcv numero comprobante asc nulls last alter table factura venta cluster factura venta orden query taking time even im using postgres explain rows sort cost rows width actual time rows loops sort key fcv fecha comprobante fcv numero comprobante sort method external merge disk 2928kb seq scan factura venta cost rows width actual time rows loops total runtime ms postgres running phenon ii 1055t cores gb ram gb disk optimize query
48643 query checks column type uniqueidentifer exist table null value get results back subquery return null works fine happens using know null check subquery curious work query example select guid tablea guid select guid tableb working test select newid select newid broken test select newid select null
48705 using sql server full recovery mode given full backup series log backups would like able check whether log chain complete last full backup current tail log without actually restoring backups purpose test consistency backups already know existing backups using restore headeronly get firstlsn lastlsn every file compared consecutive files order determine whether compatible however dont know check whether tail log follows last log backup firstlsn tail log could compare lastlsn last log backup obtain firstlsn tail log need solution works sql server upwards ideally using sql far searched google avail btw first posted stackoverflow migrated since flagged topic edit tried two provided solutions small example sql server backup database testdb disk temp backup test full bak fire update queries backup log testdb disk temp backup test log1 bak fire queries provided answers martin smiths answer yields shawn meltons answer yields restore headeronly disk temp backup test log1 bak yields appears first one several orders magnitude test sql sp1 queries yielded correct answer
48731 sql server login domain user database see login mapped user dbo database dont understand domain user nowhere found sql servers security logins current user reports dbo system user reports domain user suser name cant find domain user sys syslogins going database user login circumventing sql server
48760 special steps necessary prevent data corruption restarting server hosting ms sql server instance example recently encountered recommendation stopping sql service manually understanding handled windows shutdown process im sure zillion steps individual people may recommend like mentioned id like avoid repeating obsolete superstitious practices recommendations microsoft widespread industry standards question relates short term procedure rebooting machine theres another question regarding long term procedure ensuring machine unused taking permanently
48872 table millions rows column allows null values however row currently null value column verify fairly quickly query however execute command alter table mytable alter column mycolumn bigint null query takes forever relatively speaking actually takes minutes twice long adding check constraint way instantly update tables metadata column especially since know row null value column
48898 using sql server r2 maintenance plans setup automated backups cleanups notifications one thing cant figure difference success completion way think completion doesnt care job failed succeeded failed obviously didnt complete maybe perhaps left case scripts might way tell actual outcome script completed still feels like success failed couldnt find much documentation either
48899 best practice coding design conventions postgres ddl dml sql could share recommend looking something similar google programming thank advance
48923 first background setup server root access disabled log say john also belongs sudo group therefore able run superuser commands created new password less user santa using command sudo adduser shell bin bash gecos santa claus disabled password santa changed login sessions owner santa using command sudo su santa created new postgresql database createdb myapp db database got created without asking password given condition make sql dump database myapp db whose owner santa using command pg dump supposed work isnt john host pg dump myapp db santa localhost owner myapp db backup sql password run command asks password see password supposed enter didnt enter password database creating database owner santa tried entering password john sudo user got error fatal password authentication failed user santa also tried didnt work either john host su santa santa host pg dump myapp db santa localhost owner myapp db backup sql password time created password user santa entered still get error fatal password authentication failed user santa missing please let know missing necessary details information requested comments john host sudo su postgres postgres host psql list databases name owner encoding collate ctype access privileges app db santa utf8 en us utf en us utf postgres postgres utf8 en us utf en us utf template0 postgres utf8 en us utf en us utf postgres postgres ctc postgres template1 postgres utf8 en us utf en us utf postgres postgres ctc postgres rows output du santa john host sudo postgres psql postgres du santa list roles role name attributes member santa superuser create role create db replication
48991 ive ms10775a course past week one question came trainer couldnt answer reliably index update statistics found discussions online arguing doesnt
49140 slightly loaded question already assumed described scenario wrong dba deploying application written includes ms sql server database asked take database backup development machine restore production server thus deploying greenfield deployment existing data migrated expecting provide ddl script diligently tested ensured contains everything required execute ssms database created one click using backup facility deployment seem right without expert sql server cant think solid reason would thought example would contamination database development machine perhaps computer name directory structure user names stored somewhere case backup restore valid deployment technique
49385 database sql server want drop currently single user mode currently use select sys sysprocesses returns msg level state line database main de already open one user time know identify session kill attempt set offline alter database main de set offline rollback immediate yields msg level state line changes state options database main de made time database single user mode user currently connected msg level state line alter database statement failed
49398 weve nightly backup job sql server appends bak file instead overwriting googling discovered master dbo xp delete file noticed delete several backups prior date parameter im thinking keeping days thus deleting like declare dt datetime select dt getdate execute master dbo xp delete file 0nd program files microsoft sql server mssql11 mssqlserver mssql backup nbak dt1 seems ok backup create filenames like note today concat declare today varchar10 select today convertchar10 getdate126 backup database perfmaster disk concatd program files microsoft sql server mssql11 mssqlserver mssql backup perfmaster today bak noformat noinit name nfull database perfmaster backup skip norewind nounload stats methods employ accomplish backups days history
49744 insert empty string converted null insert test values row containing null query table use select test rows selected use null select test null null appears oracle decided empty strings used insert remain empty strings queries documentation empty string becomes null remains empty string
49757 set compression either page row clustered index table setting compression table sql server provides options suggests different impression clustered index table essentially thing mental model clustered indexes work tells compressing clustered index must also compress table
49803 find list privileges provided mysql bit overwhelming im sure privileges mind three typical users situation root developer application root self explanatory developer user needs able easily access database make adjustments etc starters im setting user privilege set select insert update delete create drop file references index alter show databases create temporary tables lock tables execute create view show view create routine alter routine event trigger application even limited set limited manipulating specific database im sure reasonable set privileges grant reasonable set privileges grant developer application
49947 recently inherited codebase large amount stored procedures system supporting encountering numerous performance problems looking number stored procedures pattern like create temp table build dynamic sql query insert bunch records declare sql varcharmax set sql insert temptable select somecolumn somecolumn2 somecolumn3 etc mytable someparam somevalue set sql sql somecolumn somevalue someotherparam someothervalue set sql sql someothercolum someothervalue execute dynamic sql exec sql select temp table bring bunch additional information return client select temptable inner join immediate thoughts dynamic sql cache plans meaning plans generated every time insert select pattern table locking likely issue written stored procedures way instead select mytable inner join someparam somevalue somecolumn somevalue someotherparam someothervalue someothercolumn someothervalue comparing execution plans client statistics sql management studio sped stored procedures apprehensive suggesting wholesale writes stored procedures trying set profiling live customer scenario yet unable prove thoughts anyone offer confirmation theory behind thoughts better ways proving suspicions problem read dynamic sql always closed case depends used understanding locking also falls fact nowhere get confirmation type insert select lock tables
49984 situation postgresql database quite heavily updated time system hence bound im currently considering making another upgrade need directions start improving picture situation looked past months see update operations accounts disk utilization another picture situation looks detailed hour window see peak write rate around 20mb software server running ubuntu postgresql type updates small updated typically individual rows identified id update cars set price price updated time stamp id id removed optimized indexes much think possible servers configuration linux kernel postgres conf pretty optimized well hardware hardware dedicated server 32gb ecc ram 4x 600gb rpm sas disks raid array controlled lsi raid controller bbu intel xeon e3 quadcore processor questions performance seen graphs reasonable system caliber read writes hence focus hardware upgrade investigate deeper software kernel tweaking confs queries etc hardware upgrade number disks key performance update upgraded database server four intel ssds instead old 15k sas disks im using raid controller things improved quite lot see following peak performance improved around times thats great however expecting something like times improvement according answers capabilities new ssds goes another question new question something current configuration limiting performance system bottleneck configurations etc postgresql main postgresql conf data directory var lib postgresql main hba file etc postgresql main pg hba conf ident file etc postgresql main pg ident conf external pid file var run postgresql main pid listen addresses localhost port unix socket directory var run postgresql wal level hot standby synchronous commit checkpoint timeout 10min archive mode archive command rsync postgres var lib postgresql wals dev null max wal senders wal keep segments hot standby log line prefix datestyle iso mdy lc messages en us utf lc monetary en us utf lc numeric en us utf lc time en us utf default text search config pg catalog english default statistics target maintenance work mem 1920mb checkpoint completion target effective cache size 22gb work mem 160mb wal buffers 16mb checkpoint segments shared buffers 7680mb max connections etc sysctl conf sysctl config net ipv4 ip forward net ipv4 conf rp filter net ipv4 icmp echo ignore broadcasts ipv6 settings autoconfiguration net ipv6 conf default autoconf net ipv6 conf default accept dad net ipv6 conf default accept ra net ipv6 conf default accept ra defrtr net ipv6 conf default accept ra rtr pref net ipv6 conf default accept ra pinfo net ipv6 conf default accept source route net ipv6 conf default accept redirects net ipv6 conf default forwarding net ipv6 conf autoconf net ipv6 conf accept dad net ipv6 conf accept ra net ipv6 conf accept ra defrtr net ipv6 conf accept ra rtr pref net ipv6 conf accept ra pinfo net ipv6 conf accept source route net ipv6 conf accept redirects net ipv6 conf forwarding updated according postgresql tuning vm dirty ratio vm dirty background ratio vm swappiness vm overcommit memory kernel sched autogroup enabled kernel sched migration cost etc sysctl postgresql shm conf shared memory settings postgresql note another program uses shared memory well coordinate size settings two maximum size shared memory segment bytes kernel shmmax maximum total size shared memory pages normally bytes kernel shmall kernel shmmax kernel shmall updated according postgresql tuning output megacli64 ldinfo lall aall adapter virtual drive information virtual drive target id name raid level primary secondary raid level qualifier size gb sector size vd emulated mirror data gb state optimal strip size kb number drives per span span depth default cache policy writeback readahead direct write cache ok bad bbu current cache policy writeback readahead direct write cache ok bad bbu default access policy read write current access policy read write disk cache policy disks default encryption type none vd cached
50016 table many rows deleted get id missing rows next insert example id col1 get value first available id next insert want get id something like select id table clause pointing least available value id select insert table id values
50076 trying make sql server failover cluster two db machines understand machines need nics organization ip scheme assigned something like want know assign ip nic enough like assigning two nics machine private network scheme allow communicate directly
50127 two different options modern sql server page verify torn page detection checksum none also course option believe checksum introduced sql server upgrading restoring db prior version would maintain previous page verify method implicit upgrade problem involved production database went production using sql server since moved sql server r2 server page verify set none expecting torn page detection going back amount time seem think db originally developed sql server migrated sql server may explain observed result wondering torn page detection checksum became feature sql server behaved migrated upgraded newer versions edit summing answers little discrpenacy dates torn page detection came sql server link http support microsoft com kb link http technet microsoft com en us library aa337525v sql aspx first link indicates sql second sql2000 tend put faith sql7 suggestion link two confused default sql7 default sql2000
50231 postgresql cluster command group rows physically disk grouping information neighboring rows lack better term often accessed together performance improves since fewer disk blocks need read given query oracle anything similar would even help performance large table almost never updated option
50355 im helping friend setting encryption data sql server r2 standard edition upon original research thought could use tde realize available enterprise datacenter versions sql servers upon research sql server r2 features saw allow data encryption key management im sure means implement efficient low cost method data encryption something sql server use third party tools encrypt whole volume db backups also someone point way use data encryption comes feature standard edition would really appreciate every time search encryption sql server keep ending use tde current scenario feasible size business purchase enterprise edition reason encryption hipaa compliance access gain file system database backups data encrypted use could include physical access machine access local admin
50391 sql far know logical query processing order conceptual interpretation order starts following way group select order following list easy see cant select aliases clause alias hasnt created yet sql sql server follows strictly cant use select aliases youve passed select mysql possible use select aliases clause even though logically processed select clause possible give example select yearorderdate count amount sales orders group yearorderdate amount statement invalid sql referring select alias amount msg level state line invalid column name amount works fine mysql based upon im wondering mysql taking shortcut sql rules help user maybe using kind pre analysis mysql using different conceptual interpretation order one though rdbms following
50652 acceptable practice use single sequence primary key across tables instead primary key unique given table unique tables objectively better using single primary key sequence across tables im junior software developer dba still learning many basics good database design edit case anyone wondering recently read critique database design one companys dbas mentioned problem design didnt use single primary key across entire database sounded different ive learned far edit2 answer question comments oracle 11g wondering non database specific level question depend upon database would interested know case would looking answer specific oracle
50664 ive recently discovered production web servers run mysql backed regularly im used backing sql server dbs dont ton experience mysql dbs best practices using mysqldump db backup tools ill probably cron job schedule done nightly backup files backup system thanks
50708 im fan surrogate keys risk findings confirmation biased many questions ive seen http stackoverflow com use natural keys instead surrogate keys based identity values background computer systems tells performing comparative operation integer faster comparing strings comment made question beliefs thought would create system investigate thesis integers faster strings use keys sql server since likely little discernible difference small datasets immediately thought two table setup primary table rows secondary table rows row primary table total rows secondary table premise test create two sets tables like one using natural keys one using integer keys run timing tests simple query like select table1 inner join table2 table1 key table2 key following code created test bed use master select countdatabase id sys databases name naturalkeytest begin alter database naturalkeytest set single user rollback immediate drop database naturalkeytest end go create database naturalkeytest name naturalkeytest filename sqlserver data naturalkeytest mdf size 8gb filegrowth 1gb log name naturalkeytestlog filename sqlserver logs naturalkeytest mdf size 256mb filegrowth 128mb go alter database naturalkeytest set recovery simple go use naturalkeytest go create view getrand select rand randomnumber go create function randomstring stringlength int returns nvarcharmax begin declare cnt int declare str nvarcharmax declare randomnum float cnt stringlength begin select randomnum randomnumber getrand set str str castchar randomnum nvarcharmax set cnt cnt end return str end go create table naturaltable1 naturaltable1key nvarchar255 null constraint pk naturaltable1 primary key clustered table1testdata nvarchar255 null create table naturaltable2 naturaltable2key nvarchar255 null constraint pk naturaltable2 primary key clustered naturaltable1key nvarchar255 null constraint fk naturaltable2 naturaltable1key foreign key references dbo naturaltable1 naturaltable1key delete cascade update cascade table2testdata nvarchar255 null go insert rows naturaltable1 insert naturaltable1 naturaltable1key table1testdata values dbo randomstring25 dbo randomstring100 go insert rows naturaltable2 insert naturaltable2 naturaltable2key naturaltable1key table2testdata select dbo randomstring25 t1 naturaltable1key dbo randomstring100 naturaltable1 t1 go create table idtable1 idtable1key int null constraint pk idtable1 primary key clustered identity11 table1testdata nvarchar255 null constraint df idtable1 testdata default dbo randomstring100 create table idtable2 idtable2key int null constraint pk idtable2 primary key clustered identity11 idtable1key int null constraint fk idtable2 idtable1key foreign key references dbo idtable1 idtable1key delete cascade update cascade table2testdata nvarchar255 null constraint df idtable2 testdata default dbo randomstring100 go insert idtable1 default values go insert idtable2 idtable1key select t1 idtable1key idtable1 t1 go code creates database tables fills tables data ready test test code ran use naturalkeytest go declare loops int declare maxloops int declare results table finishedat datetime default getdate keytype nvarchar255 elapsedtime float loops maxloops begin dbcc freeproccache dbcc freesessioncache dbcc freesystemcache dbcc dropcleanbuffers waitfor delay declare start datetime getdate declare end datetime declare count int select count count dbo naturaltable1 t1 inner join dbo naturaltable2 t2 t1 naturaltable1key t2 naturaltable1key set end getdate insert results keytype elapsedtime select natural pk keytype cast end start float elapsedtime dbcc freeproccache dbcc freesessioncache dbcc freesystemcache dbcc dropcleanbuffers waitfor delay set start getdate select count count dbo idtable1 t1 inner join dbo idtable2 t2 t1 idtable1key t2 idtable1key set end getdate insert results keytype elapsedtime select identity pk keytype cast end start float elapsedtime set loops loops end select keytype formatcastavgelapsedtime datetime hh mm ss fff avgtime results group keytype results something wrong int keys times faster character natural keys note ive written follow question
50727 two tables first table contains articles blog posts within cms articles may also appear magazine case foreign key relationship another table contains magazine specific information simplified version create table syntax two tables non essential rows stripped create table base article id int11 null auto increment date published datetime default null title varchar255 null description text content longtext published int11 null default primary key id key base article date published date published key base article published published engine innodb default charset latin1 create table mag article basearticle ptr id int11 null issue slug varchar8 default null rubric varchar75 default null primary key basearticle ptr id key mag article issue slug issue slug constraint basearticle ptr id refs id foreign key basearticle ptr id references base article id engine innodb default charset latin1 cms contains around articles total written simple python script used populate test database sample data want replicate issue locally select one tables mysql problem picking appropriate index retrieving articles quickly however two tables joined together simple query select base article inner join mag article mag article basearticle ptr id base article id published order base article date published desc limit mysql fails pick appropriate query performance plummets relevant explain extended execution time second id select type table type possible keys key key len ref rows filtered extra simple mag article primary null null null using temporary using filesort simple base article eq ref primarybase article published primary test mag article basearticle ptr id using edit sept remove clause query explain still looks query still slow one potential solution force index running query force index base articel date published results query executes around milliseconds id select type table type possible keys key key len ref rows filtered extra simple base article index null base article date published null using simple mag article eq ref primary primary test base article id would prefer force index query avoid several reasons notably basic query filtered modified variety ways filtering issue slug base article date published may longer best index use anyone suggest strategy improving performance query
50741 ive read typically indexing recommendation leave fill factor logic behind seems new data may inserted table existing values thus fill factor shouldnt set hypothetical example usernames new names may added name field fill factor could create problem even though pages full new data wont organized appropriately data question involves table data organized date clustered index id non clustered index order date id thus new orders occur existing orders new ids appear existing ids happen sequentially table like would appropriate performance perspective set fill factor reindex meaning performance advantages pages full since new data appear existing data
50797 started sql server single user mode like sqlservr try connect sqlcmd get following error msg level state server servername line login failed user user name reason server single user mode one administrator connect time user logged onto server domain administrator tried user logged nothing sql server fact trying create new sa dont know current password edit seems even sqlservr sqlcmd still getting error sure sqlcmd calls happening elsewhere
50826 making node sql server failover cluster need install msdtc component yes installed single shared disk
50837 execute two queries select session id transaction id sys dm tran session transactions select session id request id transaction id sys dm tran active transactions join sys dm exec requests transaction id transaction id ive read bol dont see clear explanation difference would occur get different results former query returns results latter returns active transactions session transaction ids request id think means request made session could someone help understand difference two concepts ive queried edit reran queries get result first dmv session id actually contained second result set
50867 attempting install oracle database 11g windows 64x laptop get way step get fail environment variable path exceeds recommended length created odb directory set oracle home odb shortened much possible correct way install oracle database 11g windows
50906 successfully installed postgresql apt repository vms running ubuntu however get install properly host machine running ubuntu install time seems gone ok perhaps error im understanding postgresql clusters exist see man pg createcluster setting postgresql pgdg12 creating new cluster main config etc postgresql main data var lib postgresql main locale en us utf port update alternatives using usr share postgresql man man1 postmaster gz provide usr share man man1 postmaster gz postmaster gz auto mode try add postgresql user get createuser could connect database postgres could connect server file directory server running locally accepting connections unix domain socket var run postgresql pgsql see postgresql running system monitor file var run postgresql folder completely empty edit vms file var run postgresql called main pid nothing host machine log file located var log postgresql whats going isnt going vms like said installations vms including postgis pgadmin came perfect idea host machine isnt going
50951 table composite primary key consisting columns used ensure duplicates entered table need new table need reference keys table foreign keys question approach efficient lookup speeds create new table including columns reference foreign key create new identity column primary key table use foreign key new table database expected hold large amount data built view minimising amount data held table mind option would best approach since save int columns datetime column every row want avoid increasing lookup time unnecessary
51155 want create new database 200gb data file mdf 50gb log file ldf slow minutes still hasnt created time consuming normal yes takes time enhance creating speed using sql server r2 windows server 2008r2 16gb ram limited 12gb ssms core i7 cpu
51215 sql management studio allows create scripts db objects however far couldnt find way correctly script schema user permissions user schema included script created make something wrong msft bit sloppy
51219 im running sql server r2 sp1 windows server box net script running visual studio following reaches database makes change iterates total number times iterate however stopping connections cant figure could adjust script use single thread id prefer know im missing max connection setting useful know future reference heres ive checked far sql connection string visual studio set ssms database instance connection properties set infinity user connections googled information server looks like handle connections stepped code alongside sp who2 gives information logical connections seeing connections starts script errors max pooled connections reached error logical connections changed connection string use data source perfsql02 initial catalog masked integrated security true max pool size im sure else check know lot moving parts im getting feeling im missing max pool setting somewhere
51340 question take excellent one posed cast date sargable good idea case concerned clause joining events table column type date one table datetime2 date effectively join using cast date use traditional range query date date question preferable datetime values almost never match predicate date value expect stay order 2m rows datetime 5k date consideration makes difference expect behavior join might using clause prefer retain performance scaling answer change mssql generalized use case treat events table like calendar table select events columns aggregationstasks column events left outer join tasks appropriately states intent clearer casttasks datetimecolumn date events datecolumn effective scalable tasks datetimecolumn events datecolumn tasks datetimecolumn dateaddday1events datecolumn group events columns
51349 following table create table k1 date k2 int references sid partitionschemek1 table partitioned k1 k1 low selective data appended order k1 following primary keys column order different preferred alter table add primary key clustered k1 k2 alter table add primary key clustered k2 k1 pk non clustered create another clustered index lot queries look like select join id k2
51440 given following components declare date declare time7 best way combining produce datetime27 result value things dont work listed select operand data type date invalid add operator select cast datetime27 operand data type datetime2 invalid add operator select dateaddnanoseconddatediffnanosecondcast00 time datediff function resulted overflow number dateparts separating two date time instances large try use datediff less precise datepart overflow avoided azure sql database sql server using datediff big select cast datetime data types datetime time incompatible add operator select cast datetime cast datetime returns result loses precision
51524 economic way license sql server standard edition test server given following environment live sql server standard edition test sql server developer edition dev sql server developer edition problem scenario developer could code using feature works developer edition available deployed live server client would first discover problem thoughts host test database live server doesnt give live test isolation would like uses live server resource buffers cpu etc could disconnect test database use minimise run second database instance live server still poor live test isolation processes using server ram cpu
51945 performs index scan instead index seek heres current index table create nonclustered index idx dmcasarms courselist cdesc dbo courselist desc asc code asc sql statement select code coursecode courselist desc bachelor science information technology go select code coursecode courselist desc pre school basic education science high school go execution plan anyway optimize
51970 im working oracle 11g database need list index organized tables dbas view query thanks
52005 checked sys databases find databases need log backups surprised quite log reuse wait desc log backup meaning job set run log backups databases isnt actually creating log backup files searching suggested change database modes full simple back full reset things still unable get log backup successfully run using sql server use ola hallengren method backup found http ola hallengren com sql server backup html thank
52129 persisted computed column table simply made concatenated columns create table dbo id int identity1 null constraint pk id primary key varchar20 null varchar20 null varchar20 null date null varchar20 null comp persisted null comp unique valid date combination therefore use following query get end date basically next start date value comp select t1 id t1 comp t1 d2 select top t2 dbo t2 t2 comp t1 comp t2 t1 order t2 dbo t1 t1 null dont care inactive records order t1 comp added index computed column assist query also others create nonclustered index ix comp dbo comp null query plan however surprised would thought since clause stating null sorting comp referencing column outside index index computed column could used scan t1 t2 saw clustered index scan forced use index see yielded better plan select t1 id t1 comp t1 d2 select top t2 dbo t2 t2 comp t1 comp t2 t1 order t2 dbo t1 index ix comp t1 null order t1 comp gave plan shows key lookup used details according sql server documentation create index computed column defined deterministic imprecise expression column marked persisted create table alter table statement means database engine stores computed values table updates columns computed column depends updated database engine uses persisted values creates index column index referenced query option enables create index computed column database engine prove accuracy whether function returns computed column expressions particularly clr function created net framework deterministic precise docs say database engine stores computed values table value also stored index key lookup required get referenced query assume used calculate comp also query use index t2 t1 queries ddl sql fiddle tagged sql server version main problem also get behaviour
52244 assuming table entity eid auto incrementing want able reference autoincrement value assigned later transaction way multiple transactions think optimal start transaction insert entity insert t2 eid values new eid ref commit
52314 programmer dealing big table following scheme updatetime pk datetime notnull name pk char14 notnull thedata float clustered index name updatetime wondering faster select maxupdatetime mytable select max updatetime value select updatetime mytable group updatetime inserts table chunks rows date thought grouping might ease max calculation instead trying find max rows grouping rows calculation max would faster assumption correct group also costly
52317 table sql server express lot unused space need free space database name rows reserved data index size unused mytablename kb kb kb kb get sql release 3165104kb ive already tried alter table mytablename rebuild dbcc cleantable mydbname mytablename alter index mytablename reorganize alter index pk image mytablename rebuild online table create table dbo mytablename imageid int identity11 null datescan datetime null scanimage image null constraint pk image primary key clustered imageid asc pad index statistics norecompute ignore dup key allow row locks allow page locks fillfactor primary primary textimage primary go thing done replaced scanimage every row much smaller image much unused space
52358 benefits dropping temporary table sql server eg drop table temp since temporary tables automatically dropped server statement would seem non functional
52492 simple mysql table use server booking system user log server valid booking server sample data might look like server user start end server01 alicebob server02 carlos server03 danerinfrank check whether user carlos booking server02 use following sql query select id booking user carlos start end server server02 query work multiple comma separated users check alice booking server01
52517 gb table postgres rows adding uuid guid column wondering best way populate column want add null constraint understand postgres correctly update technically delete insert basically rebuilding entire gb table also slave running dont want lag behind way better writing script slowly populates time
52632 confuse sharding replication works according definition replication replica set mongodb group mongod processes maintain data set sharding sharding method storing data across multiple machines per understanding data gb replication servers store 75gb data servers means 75gb server 75gb server 75gb server correct wrong sharding stored 25gb data server 25gb data server 25gb data server right encountered line tutorial shards store data provide high availability data consistency production sharded cluster shard replica set replica set 75gb shard 25gb equivalent makes confuse lot think missing something great please help
52641 use following statement unlock account alter user username account unlock statement use verify account currently locked
52698 group tables want know physical size disk tables plus indexes easier way gui sql server r2
52766 recommended way perform minor upgrade postgresql using enterprise db built windows installer uninstall first install existing installation current installation performed postgresql windows x64 exe want upgrade using postgresql windows x64 exe
52826 developing user defined function takes two arguments create replace function gesio events table regclass events table regclass returns void events table events table exactly schema simply explained loop records events table manipulate records want append insert manipulated records events table following fashion open reccurs execute formatselect order session id event time event table loop fetch reccurs rec found exit end something rec insert rec events table end loop save rec events table
52828 sql account following permissions database db executor role see account member created script create role db executor authorization dbo go grant execute db executor go run select update insert delete table works fine try truncate table gives error message find object tablename exist permissions permission account missing
52845 typical star schema simulated mentioning two queries first query simply joins fact table dimension tables calendar table second query joins aggregates experimented created indexes studying execution plan reading suggested indexes improved performance extent question done case indexes applied query modified gain better performance reduce execution time first query create fill tables create indexes create table facttable id bigint identity primary key fkdim1 bigint null fkdim2 bigint dateref datetime fact1 money fact2 money create table dim1table id bigint identity primary key dim1name nvarchar20 dim1val1 money dim1val2 money create table dim2table id bigint identity primary key dim2name nvarchar20 dim2val1 money dim2val2 money create table calendartable id bigint identity primary key date datetime unique nonclustered weekday nvarchar10 month nvarchar10 alter table facttable add constraint fk dim1 foreign key fkdim1 references dim1tableid alter table facttable add constraint fk dim2 foreign key fkdim2 references dim1tableid alter table facttable add constraint fk calendar foreign key dateref references calendartable date declare counter int set counter counter begin insert dim1tabledim1namedim1val1dim1val2valuesdim1 cast counter nvarcharrand 10000rand insert dim2tabledim2namedim2val1dim2val2valuesdim2 cast counter nvarcharrand 10000rand set counter counter end declare startdate datetime declare enddate datetime set startdate cast1 datetime set enddate dateaddd startdate startdate enddate begin insert calendartable date weekday month select startdate datenamedw startdate datenamemonth startdate set startdate dateadddd startdate end set counter counter begin insert facttable fkdim1fkdim2datereffact1fact2values counter counter dateadddd counter cast1 datetime rand rand set counter counter end code create indexes create nonclustered index dim1tableindex1 dbo dim1table dim1name ascinclude id dim1val1 dim1val2 create nonclustered index dim1tableindex2 dbo dim2table dim2name ascinclude id dim2val1 dim2val2 create nonclustered index facttableindex1 dbo facttablefkdim1 ascincludefkdim2 dateref fact1 fact2 create nonclustered index facttableindex2 dbo facttablefkdim2 ascincludefkdim1 dateref fact1 fact2 create unique nonclustered index calnedarindex1 dbo calendartable date ascinclude id weekday month query simple join fact table calendar dimension tables clause select d1 dim1name d2 dim2name date weekday month d1 dim1val1 d2 dim2val2 fact1 fact2 facttable join dim1table d1 d1 id fkdim1 join dim2table d2 d2 id fkdim2 join calendartable dateref date execution details indexes turned mentioned rows affected table calendartable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table dim2table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table dim1table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table facttable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms execution plan indexes enabled rows affected table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table facttable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table dim1table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table calendartable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table dim2table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms execution plan second query aggregates join select d1 dim1name month sumd1 dim1val1 sumdim1val1 sumd2 dim2val2 sumdim2val2 sumf fact1 sumfact1 avgf fact2 fact2avg facttable join dim1table d1 d1 id fkdim1 join dim2table d2 d2 id fkdim2 join calendartable dateref date group d1 dim1name month performance indexes turned rows affected table dim1table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table calendartable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table dim2table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table facttable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms execution plan indexes enabled rows affected table dim1table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table calendartable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table dim2table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table facttable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms finally execution plan improvements got significant consider large number rows example remove clause query indexes reduce execution time around seconds seconds restate questions indexes redesigned new indexes added enhance performance performance enhanced redesigning queries done indexes redesigning queries presented simple examples tried cover typical scenarios type queries star schema concept behind answers specific questions apply generally well using sql server
52929 connect local development database get error saying password expired ive trying change sqlplus avail sqlplus tpmdbo password localhost global sql plus release production wed nov copyright oracle rights reserved error ora password expired changing password tpmdbo new password retype new password error ora invalid username password logon denied password unchanged get error matter new password type main question reset password however im also curious theres way make password never expire local dev database really dont care security anything none data important
52968 following documentation describes see refcursor returned function like create function reffuncrefcursor returns refcursor begin open select col test return end language plpgsql begin select reffuncfunccursor fetch funccursor commit works however want keep results screen keep transaction open execute commit result set discarded execute fetch commit time first result set discarded way commit transaction keep result set version pgadmin
53085 way generate create script existing table purely sql without using smo since sql access smo lets say stored procedure receives table name returns string contains create script given table let describe situation im facing may different way approach instance several dozen databases database schema tables index created part third party software installation need way work aggregate data ad hoc manner nice people dba se already helped create trigger different database currently need find way make select table across databases recorded database names table called databasees wrote following script execute select statement object idtempdb tmp null drop table tmp select tmp database1 dbo table1 declare statement nvarcharmax ninsert tmp select table1 column1 cloumn2 declare lastdatabaseid int set lastdatabaseid declare databasenametohandle varchar60 declare databaseidtohandle int select top databasenametohandle name databaseidtohandle database ref databasees database ref lastdatabaseid order database ref databaseidtohandle null begin declare sql nvarcharmax quotename databasenametohandle dbo sp executesql exec sql statement set lastdatabaseid databaseidtohandle set databaseidtohandle null select top databasenametohandle name databaseidtohandle database ref databasees database ref lastdatabaseid order database ref end select tmp drop table tmp however script fails following message explicit value identity column table tmp specified column list used identity insert adding set identity insert tmp help since cant specify column list keep generic sql way switch identity given table drop column add column obviously changes column order column order changes need specify column list would different depending table query thinking could get create table scrip sql code could manipulate string manipulation expressions remove identity column also add column database name result set anyone think relatively easy way achieve want
53105 ive faced problem net web application running slow even ive optimized queries turned another developer making reports runs bunch non optimized queries time ive decided create separate server currently created jobs making backup copying another server restoring temporary solution order second server date data least minimal latency im investigating opportunity create read replica im dba ive read bunch articles regarding sql server replication mechanism best option prod web application isnt affected replication mean lots lock syncronizing tables dont need real time sync mirroring also dont need king cluster solution read syncing copy prod database ive choosed transactional replication mechanismnot updatable asynchronous distributing policyon schedule ive question transactional replication suit problem among sql server replication mechanisms opportunit migrate sql server sql server would transactional replication breaking changes ive read article technet might occur errors isnt sql server always mechanism better solve problemim considering option last one im still using r2 yet migration planned soon
53151 trying get reporting done employee time records two tables specifically question employees listed members table day enter time entries work theyve performed stored time entry table example setup sql fiddle http sqlfiddle com e3806 end result im going table shows members column list show sum hours date queried columns problem seems row time entry table particular member row member ive tried several different join types left right inner outer full outer etc none seem give want would based last example sql fiddle desired end result member id counttime entry timeentrydate sumhours actual sumhours bill adavis btronton cjones dsmith egirsch frowden im currently getting query specific date member id counttime entry timeentrydate sumhours actual sumhours bill egirsch correct based one time entry row dated egirsch need see zeros members order get reports eventually web dashboard report information first question searched join queries etc im honestly sure function might called hope isnt duplicate help others trying find solution similar problems
53201 running site moodle users currently find slow think tracked problem mysql creating temporary tables disk watch variable created tmp disk tables mysql workbench server administration number increases roughly tables days usage created tmp disk tablesis 100k also memory seem released usage keeps increasing system becomes pretty much unusable start mysql need start almost every day begins using available memory finishing day blobs database control queries either cant attempt optimise also used percona confirguration wizard generate configuration file ini didnt solve problem either questions change stop mysql creating temporary tables disk settings need change throw memory stop mysql eating memory edit enabled slow queries log discovered query select get lock logged slow quick search revealed allowed persistent connections php configuration mysqli allow persistent turned reduced rate mysql consumes memory still creating temporary tables though also checked key buffer size large enough looked variable key writes zero increase key buffer size zero key reads zero key writes assume key buffer size large enough increased tmp table size max heap table size 1024m increase created tmp disk tables may indicate tables cant fit memory didnt solve ref http www mysqlperformanceblog com much overhead caused disk temporary tables edit see many sort merge passes per second show global status output consider increasing sort buffer size value sort merge passes hour consider sort buffer size large enough ref mysql manual sort buffer size edit modified sort join buffers suggested rolandomysqldba result displayed table think created tmp tables disk still high restarted mysql server changed value checked created tmp tables disk day 8h calculated average suggestions seems something doesnt fit inside kind container cant work tmp table size sort buffer join buffer created max heap table size tmp tables disk 125m 256k 256k 100k 125m 512k 512k 100k 125m 1m 1m 100k 125m 4m 4m 100k configuration database server web server windows server r2 windows server r2 mysql iis core cpu core cpu 4gb ram 8gb ram additional information param value num tables db size database 5g database engine innodb read write ratio innodb data read innodb data written avg table size 15k rows max table size 744k rows setup given limited control web server using little cpu ram excluded machine bottleneck majority mysql settings originates config auto generation tool monitored system using perfmon representative days conclude os swapping disk ini client port mysql default character set utf8 mysqld port basedir program files mysql mysql server datadir dbs data default character set utf8 default storage engine innodb sql mode strict trans tablesno auto create userno engine substitution max connections query cache size 350m table cache tmp table size 125m table definition cache max heap table size 32m thread cache size myisam specific options myisam max sort file size 100g myisam sort buffer size 125m key buffer size 55m read buffer size 1024k read rnd buffer size 256k sort buffer size 1024k join buffer size 1024k innodb specific options innodb data home dir dbs innodb additional mem pool size 32m innodb flush log trx commit innodb log buffer size 16m innodb buffer pool size 2g innodb log file size 407m innodb thread concurrency
53462 google search spewed forth millions hits find tables without clustered indexed pk normally clustered index table however table could easily natural key clustered index non clustered surrogate index like identity column find tables db without primary key defined tables db manual inspection grossly inefficient
53726 want understand would huge difference execution query uat runs sec vs prod run secs uat prod exactly data indexes query set statistics io set statistics time select conf de duplicate email address rtrimemail address maintenance conf target conf target ct conf leftinternet user id iconf registration type select count1 portfolio email address ct email address deactivated yn registration type select count1 capital market email address ct email address deactivated yn uat sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms rows affected table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table portfolio scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table capital market scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table conf target scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms prod sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms rows affected table portfolio scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table capital market scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table conf target scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms note prod query suggests missing index beneficial tested point discussion want understand uat sql server create worker table prod creates table spool uat prod also execution times different uat vs prod note running sql server r2 rtm servers pretty soon going patch latest sp uat max memory 8gb maxdop processor affinity max worker threads logical physical processor map physical processor physical processor physical processor physical processor physical processor physical processor physical processor physical processor logical processor socket map socket socket logical processor numa node map numa node prod max memory 60gb maxdop processor affinity max worker threads logical physical processor map physical processor hyperthreaded physical processor hyperthreaded physical processor hyperthreaded physical processor hyperthreaded physical processor hyperthreaded physical processor hyperthreaded physical processor hyperthreaded physical processor hyperthreaded logical processor socket map socket socket logical processor numa node map numa node numa node update uat execution plan xml http pastebin com z0pwvw8m prod execution plan xml http pastebin com gwty16yy uat execution plan xml plan generated fro prod http pastebin com 74u3ntr0 server configuration prod poweredge r720xd intelr xeonr cpu e5 v2 50ghz uat poweredge intelr xeonr cpu x5460 16ghz posted answers sqlperformance com update thanks swasheck suggestion changing max memory prod 60gb mb able generate plan prod query completes time uat need understand also wont able justify monster server replace old server
53815 assuming need make sure application relies sql server database backend available around clock even one server machine fails developer dba struggling understand use scenario failover high availability two servers windows failover cluster sql server clustered instance two sql server instances kept date transactional replication two sql servers sql server availability group configured synchronous commit mode scenarios works kind workload kind failure outage handled scenarios even comparable exchangable
53995 sysadmin sql server need would like setup security production server prevent accidentally restoring production database restored databases test machine often developers debug test always really careful ten years today wasnt thought put deny restore permission ever need really restore remove deny cant find anything like anyone know maybe better idea
54059 following index created table database create index idx index1 table1 col1 col2 col3 server suggesting following missing index create index idx index2 table1 col1 col2 include col3 col4 col5 col6 seems logical amend existing index definition include suggested columns rather creating new index needs maintained query selects col1 col2 could use index1 effectively index2 correct maybe missing something
54149 table columns selecting data sql plus output wraps making difficult read id rather like either horizontal scroll bar appear somehow send output less run following statements sqlplus set linesize set pagesize set long spool output txt select big table bash run less output txt output still appears wrapped unreadable
54261 ive got query id like get working im trying count instances foreign key certain date isnt null left join distinct original table see variables entries heres query select fulllist fk fc id select distinct fk fc id data item fulllist left outer join select temp fk fc id count number select data item di item value like null di timestamp temp group fk fc id lj lj fc fk id fulllist fk fc id error error column lj fc fk id exist line lj fc fk id fulllist fk fc id
54283 column data holds json document roughly like name foo tags foo bar would like turn nested tags array concatenated string foo bar would easily possible array string function theory however function act json arrays wonder turn json array postgres array
54318 table like id propinsi kota aceh denpasar aceh banda aceh sumatera asahan table many rows problem want replace space text column kota rows like id propinsi kota aceh denpasar aceh banda aceh sumatera asahan searched google function replace mysql affects one row select replacestring column search replace kota someone fix problem
54377 sql servers sys dm os memory cache entries possible view original cost entry cache well current cost cache entry original cost current cost respectively dmv sys dm os buffer descriptors contains record pages currently memory well metadata pages one interesting chunk info available dvm lru values data pages possible get lru values data pages buffer pool sql server
54403 table million records table structure create table metaplay track id int11 null default user id int11 default null completed int11 default null skipped int11 default null created int11 default null updated int11 default null id int11 null auto increment primary key id key created created key updated updated key skipped skipped key track id track id engine myisam default charset latin1 data numeric point inserts updates per minute also pull daily weekly monthly track playing records table question followings better architectural design best performance would appreciate highlight hardware details well mysql ssd cached storage 4gb ram mysql ssd 4gb ram nosql solution anything else also suggest mysql specific tuning tips table like
54608 upgraded mysql logs littered messages startup found possible solution seem official http forums mysql com read php22578559579891 msg 7f87b1d26700 innodb error table mysql innodb table stats found 7f87b1d26700 innodb recalculation persistent statistics requested table drupal sessions required persistent statistics storage present corrupted using transient stats instead 7f903c09c700 innodb error table mysql innodb table stats found official solutions fixes
54893 reporting purposes need able query dependencies views underlying tables column level via sys sql expression dependencies one way get sql server store referenced columns use schemabound views users create views would like enforce far ive seen isnt possible allow views schemabinding created within sql server database though although seems legit requirement ways force sql server keep track columns referenced views hidden way enforce schemabound views sql server
54943 msdn online article snapshot isolation sql server states isolation level connection wide scope set connection set transaction isolation level statement remains effect connection closed another isolation level set connection closed returned pool isolation level last set transaction isolation level statement retained subsequent connections reusing pooled connection use isolation level effect time connection pooled isnt self contradictory paragraph vs retained isolation level last set transaction isolation level statement retained closing connection returning pool understood default isolation level arbitrary value different connections pool different isolation levels value depend connection opened default values connection th pool changed last one quite unknown hand
54954 usually conditions required query statements dont use clause ive seen clause used many places even conditions present done specific benefits execution time enable functionalities using similar
55019 recent versions postgresql dec share query two cores get performance boost get faster cores
55198 ive got zoo million animals track sql server database black swans wanted get details black swans wanting swamp results page select top animal colour like black species like swan yes inadvisedly fields freetext indexed turns animals query returns empty set milliseconds would twice fast id used rather like premonition latter save typing turns head zookeeper thinks may entered swans blackish modify query accordingly select top animal colour like black species like swan turns none either fact black animals except black ones query takes seconds return empty seems combination top like causing trouble though select count animal colour like black species like swan returns quickly even select animal colour like black species like swan returns empty fraction second one idea top conspire cause dramatic loss performance especially empty result set edit clarify im using freetext indexes meant fields freetext point entry normalized database sorry confusion poor wording part
55327 sql server job sql server agent jobs need move transfer another updated sql server r2 instance able script use new query window upgraded dev server seemsas far know changes make script point correct server file path get new schedule uid number sure assign number job built ssis package pointing file path thanks advice script code use msdb go object job elfcopy script date begin transaction declare returncode int select returncode object jobcategory uncategorized local script date exists select name msdb dbo syscategories name uncategorized local category class begin exec returncode msdb dbo sp add category class njob type nlocal name uncategorized local error returncode goto quitwithrollback end declare jobid binary16 exec returncode msdb dbo sp add job job name nelfcopy enabled notify level eventlog notify level email notify level netsend notify level page delete level description nthis job copies elf files folders stage locations active directories category name uncategorized local owner login name nbio wddocmanagement job id jobid output error returncode goto quitwithrollback object step runpackage script date exec returncode msdb dbo sp add jobstep job id jobid step name nrunpackage step id cmdexec success code success action success step id fail action fail step id retry attempts retry interval os run priority subsystem nssis command file ssis packages elfcopy dtsx connection brorporap1 wddocumentmanagement data source brorporap1 initial catalog wddocumentmanagement provider sqlncli integrated security sspi auto translate false connection rcsmtp smtpserver brutmurex3 bio ri redcross net usewindowsauthentication true enablessl false maxconcurrent checkpointing reporting database name nmaster flags error returncode goto quitwithrollback exec returncode msdb dbo sp update job job id jobid start step id error returncode goto quitwithrollback exec returncode msdb dbo sp add jobschedule job id jobid name nweeklyschedule enabled freq type freq interval freq subday type freq subday interval freq relative interval freq recurrence factor active start date active end date active start time active end time schedule uid nc406cae9 49b7 40dd cef44160f562 error returncode goto quitwithrollback exec returncode msdb dbo sp add jobserver job id jobid server name nlocal error returncode goto quitwithrollback commit transaction goto endsave quitwithrollback trancount rollback transaction endsave go
55363 need put random values database dont want end completely randomized text like 7hfg43d3 instead would like randomly pick one values supplied
55368 simple way listing size every table every database mssql server used query sys tables get results single database databases per server way getting results databases would great currently im create temporary list databases master sys databases iterate cursor building query inserting results temp table exec sp executesql sqlstring
55383 ssis package simple select statement loading table anonymized sql statement painfully obvious look table name also simplified package row count purposes demo issue ive query produces rows sql server produces rows ssis query follows declare currentblahdate datetime set currentblahdate select maxblahdate dbo thiscooltable sl nolock inner join dbo thatcooltable slf nolock sl coolid slf coolid slf typecode valuea valueb select dbo calendar castbasedate date cast currentblahdate date please ignore purposes demo actual query issue even though executed sql server returns row calendar table expected however executed environment ssis get rows returned turn query stored procedure execute sproc ssis get row count alter query select dbo calendar castbasedate date cast select maxblahdate dbo thiscooltable sl nolock inner join dbo thatcooltable slf nolock sl coolid slf coolid slf typecode valuea valueb date receive row reason im seeing behavior update receive ton flack choice nolock nonsense
55498 folks currently exploring capabilities mysql simple exercises diverse queries reading following article explains table join works http www codinghorror com blog visual explanation sql joins html however stuck full outer join example comprised tablea tableb tablea field type null key default extra id int11 pri null auto increment name varchar100 yes null mysql select tablea id name pirate monkey ninja spaghetti tableb field type null key default extra id int11 pri null auto increment name varchar100 yes null mysql select tab id name rutabanga pirate darth vader ninja trying proposed website select tablea full outer join tableb tablea name tableb name receive error anyone idea reason could thank advance assistance
55550 want delete oracle instance oracle created aix os know delete dbf ctl files terminal thinks thats best way think must cleaner way thanks advance
55568 two database tables one contains hundreds millions records lets call one history one calculated daily basis want copy records history one run insert history select daily trick started get slower slower number records kept growing around million records need copied daily history single operation takes long complete another efficient way copying data one table another
56023 see current search path show search path set search path current session set search path user public postgis well permanently set search path given database alter database mydb set search path user public postgis permanently set search path given role user alter role johnny set search path user public postgis would like know determine database role settings respect search path prior altering
56045 sql servers instance name sqlexpress sql server service name looks like mssql sqlexpress relation instance name service name im trying check sql server service status name wonder sql server service name different another computers
56096 lets say two postgresql database groups authors editors two users maxwell ernest create role authors create role editors create user maxwell create user ernest grant authors editors editors authors grant editors maxwell maxwell editor grant authors ernest ernest author would like write performant function returns list roles preferably oids maxwell belongs something like create replace function get roles returns oid return oids maxwell authors editors ernest sure inheritance
56130 table 250k rows test database hundred millions production observe issue table nvarchar250 string identifier null unique index pk identifiers made first part different values test database thousand production sign finally number digits long example could thousand rows start abcd bgx1741f xml followed thousand different numbers query single row based identifier cardinality estimated cost low works fine query one row several identifiers expression expression estimations index completely wrong full table scan used force index hint fast full table scan actually executed order magnitude slower lot slower production optimizer problem test duplicated table schema tablespace exact ddl exact content recreated unique index first table good measure created exact index clone table dbms stats gather schema statsschemanameestimate percent 100cascade true even see index names consecutive difference two tables first one loaded random order long time period blocks scattered disk tablespace together several big tables second loaded one batched insert select cant imagine difference original table shrinked since last big deletion hasnt single delete query plans sick clone table strings black brush picture also gray brush example rows start identifier black brushed row query produces cardinality row query produces cardinality etc cant coincidence oracle seems care end identifiers could cause behavior obviously would pretty expensive recreate table production user tables http stack imgur com ndwze jpg user indexes http stack imgur com dg9um jpg changed schema tablespace name see table index names query plan screenshot
56304 materialized view postgres id like update new columns however materialized views also depend upon view error message indicates dropping view isnt possible objects depend error drop materialized view latest charges objects depend also appears documentation replace keyword isnt valid materialized view shortcut aside dropping dependent objects rebuilding one
56374 someone explain difference types vacuum postgresql read doc says full locks tables freeze freezes tuples think thats wrong
56482 factors determine maximum possible number threads mysqld create care consideration mysql limitations may imposed operating system care linux though want include information specific windows feel free far tell threads created replication aspects innodb one per client connection max connections additional handle super connections else threads max max connections super replication slave threads innodb
56494 read page mysql documentation tried make sense current innodb usage currently allocate 6gb ram buffer pool database size heres output show engine innodb status running v5 buffer pool memory total memory allocated additional pool allocated dictionary memory allocated buffer pool size free buffers database pages old database pages modified db pages pending reads pending writes lru flush list single page pages made young young youngs non youngs pages read created written reads creates writes buffer pool hit rate young making rate pages read ahead evicted without access random read ahead lru len unzip lru len sum cur unzip sum cur wanted know well utilizing buffer cache initially glancing output appeared indeed using based pages made young young numbers buffer pool hit rate saw elsewhere web means used pretty heavily true whats throwing loop young making rate young non young accesses would indicate used right anyone help make sense
56527 ive downloaded adventureworks based memory sample followed steps described accompanying doc however try run script sql server management studio get error message alter database statement allowed within multi statement transaction error points line exists select sys data spaces type fx alter database current add filegroup adventureworks2012 mod contains memory optimized data go since less official microsoft documentation im assuming something im wrong cant figure
56616 running sql server sql server management studio option right click database select tasks generate scripts way automate via command line somehow want create script includes schema data entire data base tools like scriptdb sqlpubwiz exe seem target sql server sql server
56804 database lot tables starting elgg want drop tables prefix anyone give solution thanks advance
56844 quick way find columns sql server r2 encrypted encrypted data need nullify data encrypted columns development server according business rules know columns use regularly want thorough also want able prove ive found ive searched web looked information schema checked dmvs thought would useful also sys columns sys objects far luck
56876 came across interesting behaviour sql server observed today hoping someone could explain query comparison using nvarchar field ignored trailing space string auto trimmed value comparison query using like operator ignore space collation used latin1 general ci consider sql fiddle http sqlfiddle com note like operator return result trailing space string operator bonus points unable replicate varchar field would thought space would handled way data types true
56893 dont kind id table still mysql giving result result giving place php code
56897 postgresql table need create view new column column needs auto incremental column starting going possible without effecting original schema legacy data structure
56930 trying find changed password login sql server r2 already checked default trace log event default trace include security related events audit add db user event audit add login server role event audit add member db role event audit add role event audit add login event audit backup restore event audit change database owner audit dbcc event audit database scope gdr event grant deny revoke audit login change property event audit login failed audit login gdr event audit schema object gdr event audit schema object take ownership audit server starts stops also looked transaction log backup find luck way find also aware server side trace help unfortunately server side trace include audit login change password event best article found aaron bertrand tracking login password changes sql server
57058 postgres use ispell compatible dictionaries text search provide required files
57418 im investigating big switch mysql nosql dbaas ive run issue trying forecast expenses essentially cant figure many queries current mysql server handles per day try estimate number requests ill using cloudant charges per puts posts deletes per gets heads ive found lot information using show status show global status get stats mysql collects theres timeframe reference instance show global status returns following queries great except idea timeframe wraps number million queries per month year since beginning time mysql docs dont really elaborate much queries number statements executed server variable includes statements executed within stored programs unlike questions variable count com ping com statistics commands variable added mysql thanks advance help
57445 order use sql queries must group aggregate column names special cases possible use without group sql queries must co exist time
57723 created superuser portal following command create role portal superuser password portal tried login postgres portal user getting following error rails fatal role portal permitted log cant follow going course alter user login command enable portal user login would like understand super user cant login
57785 would like create computed index table sql server newer simple index sql server older check sql server version select castleftcastserverpropertyproductversion varchar decimal5 create unique nonclustered index ix1 table table column1 column2 column1 null column2 null else create nonclustered index ix1 table table column1 column2 problem whole statement evaluated sql server throws error incorrect syntax near keyword possible somehow create different index based sql server version
58214 im trying get table modified checking file modification date described answer result always correct file modification date updates several minute update table correct behaviour postgresql store table modifications cache flush hard drive get correct last modification date table lets assume auto vacuum modifications ok use postgresql linux centos x64
58284 possible drop empty tables huge database mysql im looking sql command automatically remove empty tables currently tables dataset old empty tables used new application clarify tables type myisam
58308 name following database schema design pattern eventual goal find literature subject todays cursory net search full generic words able pin term exists kind thing fruit id farm apple fruit id color fruit id fruit id banana fruit id length fruit id fruit id orange fruit id seedless fruit id fruit id fruitpack id destination fruitpackfruits fruitpack id fruit id fruit type fruit id fruit id fruit type varchar fruit type would varchar column filled values like apple banana orange cherry kind poor mans referential integrity obviously one failures kind design able insert values dont resolve useful join ie cherries speak heres another example pattern single log id table name record id timestamp table acts sort tracker modification times various tables strictly speaking got ref integrity table name record id part supposed refer record another table requiring join actually get full data im going take granted schema sufficient caricature sort collection groups items people question whats kind poor mans referential integrity called im trying learn referential integrity want identify poor designs name look lets design database schema aspects ex pros cons opinions teachings etc commonly seen disaster schema
58312 using database name postgresql connect named database name current database determined entering db current database produces error syntax error near current database line current database
58341 recently heard host mysql database ssd drive big chance disk failure data lost given queries database inserts updates questions questions disadvantages using mysql ssd solutions alternatives available mysql ssd usage
58455 would like insert record data type variable new variable table trigger would sql look like following attempts unsuccessful execute insert table values new execute insert table values new execute insert table select new
58772 guys probably know sql server provide box solution export security related statements declared element database database level also object level im talking ability come information users user defined roles permissions database level grant create function permissions object level grant select object xxx would think sql server must something like neither sql server export wizard various scripts generated result right clicking objects capture information seen online many different possible solutions using non curated scripts people graciously post since sure security information captured cant fully rely scripts option using starting point write something hate invent wheel requirement would think many people may isnt tool provided someone either part sql server product 3rd party tool could reliably provide information least community supported script people would agree job thanks
58888 running following queries ms sql server second query fails first also run without clauses queries fail loss either would fail since empty result sets help insight appreciated create table temp id int primary key create table temp2 id int select temp id select temp2 id
59000 postgresql table prices columns price decimal product id int also created updated columns prices get updated regularly keep old prices table given product last price table current price efficient way get last price specific product index product id query last record add third column active boolean mark latest price create composite index product id active something else
59006 long quite elucidating answer differences timestamp time zone vs timestamp without time zone available post would like know valid use cases actually using timestamp without time zone considered anti pattern
59062 table designed variably named columns depending type record looking applicable name column change possible column names stored another table query easily therefore query im really looking goes something like select col1 select colname names colnum type type col2 select colname names colnum type type tbl1 type type obviously doesnt work get similar result ive tried building query string executeing returns commands completed successfully doesnt seem return rowset turns using incorrect query build dynamic sql built empty string sql server definitely executed empty string correctly note reason need occur rather simply hard coding column names column names user configurable
59128 ran brent ozars sp blitz script one things complaining sql server agent account sysadmin permission removed sysadmin permission agent wouldnt start see image theres nothing note event log restore sysadmin permission agent starts difficulty account managed service account none managed service accounts use one running reporting services one running sql service sysadmin permission sysadmin permission actually necessary minimum permissions account needs
59170 try create report data really slow big table table structure create table posts id serial null project id integer moderation character varying255 keyword id integer author id integer created timestamp without time zone updated timestamp without time zone server id character varying255 social creation time integer social id character varying255 network character varying255 mood character varying255 default null character varying url text source id integer location character varying255 subject id integer conversation id integer constraint posts pkey primary key id create index index posts author id posts author id create index index posts keyword id posts keyword id create index index posts project id network social id posts project id network social id create index index posts project id social creation time posts project id social creation time desc create index index posts server id posts server id create index index posts social id posts social id query select date trunchour timestamp epoch posts social creation time interval second creating network count posts posts posts project id posts moderation junkspam posts social creation time group network creating order creating count explain plan groupaggregate cost rows width actual time rows loops sort cost rows width actual time rows loops sort key date trunchour text timestamp without time zone social creation time double precision interval network sort method external merge disk 92032kb seq scan posts cost rows width actual time rows loops filter moderation text junkspam text social creation time social creation time project id rows removed filter total runtime ms rows time ms seq scan force use indexes help groupaggregate cost rows width actual time rows loops sort cost rows width actual time rows loops sort key date trunchour text timestamp without time zone social creation time double precision interval network sort method external merge disk 92048kb bitmap heap scan posts cost rows width actual time rows loops recheck cond project id filter moderation text junkspam text social creation time social creation time rows removed filter bitmap index scan index posts project id network social id cost rows width actual time rows loops index cond project id total runtime ms example row table id project id moderation keyword id author id created updated server id social creation time social id network mood url source id location subject id conversation id pending vkontakte https vk com wall update real help work mem set new plan hashaggregate cost rows width actual time rows loops seq scan posts cost rows width actual time rows loops filter moderation text junkspam text social creation time social creation time project id rows removed filter total runtime ms update think create integer column save date like yyymmdd stackexchange think performance gains ps sorry bad english
59193 database load files staging table staging table joins resolve foreign keys insert rows final table one partition per month around billion rows three months data fastest way get rows staging final table ssis data flow task uses view source fast load active insert select command tried data flow task get around billion rows around hours cores gb ram server feels slow
59447 trying design grade assignment database facing following dilemma student table following characteristics matriculation number know fact unique first name last name course studiesbsc mechanical engineering msc mechanical engineering bsc computer science etc email remark maybe special notes particular student however also following condition every student time belong two different course studies student bsc msc mechanical engineering time thought decided create separate table called course studies two columns auto increment idpk course study include possible course studies connect student course studies tables using many many relationship time thought another implementation would use surrogate key auto increment id student table instead creating separate course studies table could simply incorporate student table column problem primary key since student belongs two different course studies would two different rows unique id question think best implementation given situationplease explain know natural primary keys vs surrogate primary keys highly debated subject doesnt seem universal answer however given situation think best implementation additional details provided edit two good answers saying less thing chose accept one votes
59472 looking something like could store output sp who2 table without first create table create table test exec sp who2
59509 assuming postgres database table called party less well defined party types person organization would store party type party table party type person normalize party party type party typeid name person
59770 indexed data affect query performance means passed value ordered form clause improve query performance happen case pass value randomly etc example select name emp id ordered values select name emp id randomly ordered values another way select name emp id select empid trans order empty ordered values asking mysql well sql server database one tell database engine get result case execution plan
59776 multiple nvarcharmax columns db named shippernameconsigneename proddescbilloflading need unique index combination columns failed limit triedafter reading following link indexing wide keys alter table dbo productdetail add shippernamehash hashbytessha2 shippername persisted alter table dbo productdetail add consigneenamehash hashbytessha2 consigneename persisted got following error following statement msg level state line string binary data would truncated statement terminated alter table dbo productdetail add productdeschash hashbytessha2 product description persisted also statements created column varbinary8000 course hasnt solved problem way built unique index combination columns
59840 table geometry column one record one point stored spatial index created queries searching nearest location use index resulting bad performance example script create table create table location locationid int null identity11 primary key locationpoint geometry add records declare counter int counter begin set nocount select set counter counter declare randomlocation geometry geometry pointrand rand insert locationlocationpoint values randomlocation end create index create spatial index spatial structurebe dbo locationlocationpoint using geometry grid bounding box xmin ymin xmax ymax grids level medium level medium level medium level medium cells per object statistics norecompute allow row locks allow page locks search query use index doesnt declare currentlocation geometry geometry point2450 select top location order locationpoint stdistance currentlocation asc
59916 streaming replication hot standby setup seems running good login execute selects result seems date master however log standby see lot cp stat mnt wal drive wals 0000000100004ba800000070 file directory cet log record zero length 4ba8 70dd79d0 cet log started streaming wal primary 4ba8 timeline cet fatal could receive data wal stream ssl error sslv3 alert unexpected message mean worry ps master see expect related ssl thing cet log ssl renegotiation failure cet log ssl error unexpected record im running postgresql ubuntu edit regarding wal logs following setup master slave mounted network storage fstab using cifs command directory chowned owned postgres user master following settings postgresql conf archive mode archive command rsync mnt wal drive wals dev null slave hot standby following recovery conf standby mode primary conninfo host localhost port user replicator password pass trigger file tmp pgsql trigger restore command cp mnt wal drive wals dev null archive cleanup command usr lib postgresql bin pg archivecleanup mnt wal drive wals ssh tunnel forwarding port slave port master connecting localhost actually master db
60108 setup ola hallengrens database maintenance plan database mirrored wanting know need run script sql server instances primary
60129 working third party database try view definition view right clicking create new query edit window getting error property may exist object may retrievable due insufficient access rights text encrypted
60179 background query running sql server r2 joins left joins different tables database fairly large many tables million rows different tables large ish company warehouses across country warehouses read write database pretty large pretty busy query im trouble looks something like select t1 something t2 something etc table1 t1 inner join table2 t2 t1 id t2 t1id left outer join select table t3 t3 t1id t1 t1id etc t1 something notice one joins non correlated sub query problem starting morning without changes anybody team knows system query usually takes mins run started taking hour half run ran rest database humming along fine ive taken query sproc usually runs ive run ssms hard coded parameter variables slowness strangeness take non correlated sub query throw temp table use instead sub query query runs fine also strangest add piece code end query query runs great name like ive concluded perhaps incorrectly little experiments reason slow due sqls cached execution plan set query little different create new execution plan question query used run fast suddenly starts running slowly middle night nothing else affected except one query troubleshoot keep happening future know sql internally make slow bad query ran could get execution plan wont run maybe expected execution plan would give something issue execution plan keep sql thinking really crappy execution plans good idea also problem parameter sniffing ive seen since even hard code varaibles ssms still get slow performance
60342 postgres way combining distinct neat way getting result select count select foo union select union select null foo anyarray null count row select count select foo union select union select null foo distinct anyarray null error syntax error near line foo distinct anyarray null
60449 database mydatabase created sql server r2 upgraded sql server trying execute query calculate percentile select distinct key percentile cont0 within grouporder eachprice overpartition key q1percentile cont0 within grouporder eachprice overpartition key q2 percentile cont0 within grouporder eachprice overpartition key q3 percentile cont1 within grouporder eachprice overpartition key q4 mydatabase getting error stating msg level state line percentile cont function allowed current compatibility mode allowed mode higher change compatibility mode implications changing compatibility mode please advice
60465 production serverubuntu running postgresql want use features hence want upgrade could someone help upgrading downtime mins prime concern preventing data loss file redundancy
60480 table postgresql database defined following create table public match item id bigint default item id bigint default owner id bigint default owner id bigint default data varchar100 null default constraint match pk primary key item id item id contain lot rows lot queries like following performed table select match owner id owner id select match owner id owner id thinking creating indexes owner id owner id since columns keys good idea yes create create one index columns create two indexes include columns
60590 another application struck bad design multiple threads execute ensuredatabaseschemaexists method concurrently looks basically like exists select sys objects object id object idnmytable type nu begin create table mytable end however even executed serializable transaction code seem thread safe parallel code tries create table multiple times chance force select statement acquire lock prevents another thread select statement better pattern multi threaded ensureschemaexists methods
60651 stored procedures second stored procedure improvement first one im trying measure exactly much improvement measuring clock time doesnt seem option get different execution times even worse sometimes rarely happens execution time second stored procedure bigger execution time first procedure guess due server workload moment include client statistics also provides different results dbcc dropcleanbuffers dbcc freeproccache good story set statistics io could option could get overall score many tables involved stored procedures include actual execution plan could option also get estimated subtreecost first stored procedure second one say second stored procedure faster using reads field sql server profiler say second stored procedure faster first procedure matter execution conditions workload server server stored procedures executed etc possible prove second stored procedure better execution time first stored procedure
60777 trying determine indexes use sql query condition group currently running slow query select group id counter ts timestamp timestamp group group id table currently rows execution time query increases lot increase time frame table question looks like create table counter id bigserial primary key ts timestamp null group id bigint null currently following indexes performance still slow create index ts index counter using btree ts create index group id index counter using btree group id create index comp index counter using btree ts group id create index comp index counter using btree group id ts running explain query gives following result query plan hashaggregate cost rows width index scan using ts index counter cost rows width index cond ts timestamp without time zone ts timestamp without time zone sql fiddle example data http sqlfiddle com 7492b question performance query improved adding better indexes must increase processing power edit postgresql version used edit tried erwin proposal exists select group id groups exists select counter group id group id ts timestamp timestamp unfortunetly didnt seem increase performance query plan query plan nested loop semi join cost rows width seq scan groups cost rows width bitmap heap scan counter cost rows width recheck cond group id id ts timestamp without time zone ts timestamp without time zone bitmap index scan comp index cost rows width index cond group id id ts timestamp without time zone ts timestamp without time zone edit query plan lateral query ypercube query plan nested loop cost rows width seq scan groups cost rows width result cost rows width one time filter null initplan returns limit cost rows width index scan using comp index counter cost rows width index cond group id ts null ts timestamp without time zone ts timestamp without time zone initplan returns limit cost rows width index scan backward using comp index counter cost rows width index cond group id ts null ts timestamp without time zone ts timestamp without time zone
60789 given sql server table large number rows columns large value data types multiple indexes allocated space available largest possible transaction log size single column primary key clustered index optional consideration question average record size 1k optional consideration question update statement needs run every row sets value non indexed column optional consideration question techniques employed reduce peak disk space consuption including data files log file tempdb applicable required update purposes question following allowed applying changes batches run single user mode change recovery model
60837 calculating difference dates number days using mysql datediff function facing issue sql code given select datediffselect curdate select company createdon dbname company inner join dbname user user company id company company id getting result follows error code subquery returns row understand error cant use ids point follows select datediff select curdate select company createdon dbname company inner join dbname user user company id company company id company company id run query got output follows need select users depends company registered time exist days need display company registered time days mentioned condition code need solve subquery result datediff function compare company createdon value results companies exists days help would grateful
61163 hi trying connect postgres pgadmin3 using ssh tunneling however using standard port ssh tunneling using non standard port
61212 one systems sensitive client data store clients data separate database clients system however developing new system clients maybe thinking might unfeasible one database per client instance store sensitive records audit history however dont know perfectly normal theres another way maintaining security thoughts
61246 icon server blue database symbol mean
61293 want rename column mysql version database something like alter table t1 change integer number rows table o1 operation cant seem find answer manual google table millions records wouldnt feasible directly
61520 would like update selection rows table works update t1 set col1 newvalue col0 plpgsql function following gives syntax error create replace function foointarray int returns void body begin update t1 set col1 newvalue col0 intarray end body language plpgsql volatile error error syntax error near intarray line col0 intarray edit replace intarray intarray function recorded running select fooarray error becomes error operator exist integer integer line col0 intarray
61616 im attempting install sql server express sp1 x64 windows sp1 x64 machine previously sql server express installed instance upgraded sql server standard since uninstalled following options selected install include sql server product updates install related kb install features default directories named instance sqlexpress default instance root directory default services accounts sql server database engine nt service mssql sqlexpress default database engine configuration install fails following error title microsoft sql server service pack setup following error occurred could find database engine startup handle help click http go microsoft com fwlinklinkid prodname microsoft 20sql 20server evtsrc setup rll evtid prodver evttype 0xd15b4eb2 25400x4bdaf9ba buttons ok ive read may related corrupt mssql sqlexpress virtual account ideas fix thanks jon summary txt overall summary final result failed see details exit code decimal start time end time requested action install setup completed required actions features troubleshooting information features next step sqlengine use following information resolve error uninstall feature run setup process next step replication use following information resolve error uninstall feature run setup process machine properties machine name montreal machine processor count os version windows os service pack service pack os region united states os language english united states os architecture x64 process architecture bit os clustered product features discovered product instance instance id feature language edition version clustered package properties description microsoft sql server service pack productname sql server type rtm version installation location 097a5adf24ea31e1a16d x64 setup installation edition express slipstream true sp level patch level product update status success kb kb product updates selected installation title service pack knowledge based article kb version architecture x64 language title sql server sp1 gdr product update knowledge based article kb version architecture x64 language update source mu user input settings action install addcurrentuserassqladmin true agtsvcaccount nt authority network service agtsvcpassword agtsvcstartuptype disabled asbackupdir backup ascollation latin1 general ci asconfigdir config asdatadir data aslogdir log asprovidermsolap asservermode multidimensional assvcaccount assvcpassword assvcstartuptype automatic assysadminaccounts astempdir temp browsersvcstartuptype disabled cltctlrname cltresultdir cltstartuptype cltsvcaccount cltsvcpassword cltworkingdir commfabricencryption commfabricnetworklevel commfabricport configurationfile ctlrstartuptype ctlrsvcaccount ctlrsvcpassword ctlrusers enableranu true enu true errorreporting false features sqlengine replication snac sdk filestreamlevel filestreamsharename ftsvcaccount ftsvcpassword help false iacceptsqlserverlicenseterms true indicateprogress false installshareddir program files microsoft sql server installsharedwowdir program files x86 microsoft sql server installsqldatadir instancedir program files microsoft sql server instanceid sqlexpress instancename sqlexpress issvcaccount nt authority network service issvcpassword issvcstartuptype automatic matrixcmbrickcommport matrixcmservername matrixname npenabled pid quiet false quietsimple false role allfeatures withdefaults rsinstallmode defaultnativemode rsshpinstallmode defaultsharepointmode rssvcaccount rssvcpassword rssvcstartuptype automatic sapwd securitymode sqlbackupdir sqlcollation latin1 general ci sqlsvcaccount nt service mssql sqlexpress sqlsvcpassword sqlsvcstartuptype automatic sqlsysadminaccounts montreal jonathan bailey sqltempdbdir sqltempdblogdir sqluserdbdir sqluserdblogdir sqmreporting false tcpenabled uimode autoadvance updateenabled true updatesource mu x86 false configuration file program files microsoft sql server setup bootstrap log configurationfile ini detailed results feature database engine services status failed see logs details reason failure error occurred setup process feature next step use following information resolve error uninstall feature run setup process component name sql server database engine services instance features component error code 0x851a0019 error description could find database engine startup handle error help link http go microsoft com fwlinklinkid prodname microsoft sql server evtsrc setup rll evtid prodver evttype 0xd15b4eb2 400x4bdaf9ba evttype 0xd15b4eb2 400x4bdaf9ba feature sql server replication status failed see logs details reason failure error occurred dependency feature causing setup process feature fail next step use following information resolve error uninstall feature run setup process component name sql server database engine services instance features component error code 0x851a0019 error description could find database engine startup handle error help link feature sql browser status passed feature sql writer status passed feature sql client connectivity status passed feature sql client connectivity sdk status passed rules failures global rules scenario specific rules rules report file program files microsoft sql server setup bootstrap log systemconfigurationcheck report htm
61633 disclaimer im aware supposed done time consistency tables arent concert im trying whatever pops mind right alternatives punctual demand backups complement robust scheduled ones pretty much want know reading problem copy myisam table files frm myd myi gets transaction tables small could take risk couple worries becuase size dont mind waiting transaction get done worries getting read error failing get response query thats know something please let know
62029 postgresql explain explain analyze show estimate cost executing query explain mysql doesnt provide information get estimate cost without installation tools im using mysql
62051 driving nuts want rename column read read blog table tried alter table blog rename column read read alter table blog change column read read varchar255 null always get error error sql syntax check manual corresponds mysql server version right syntax use near column read read line im using mysql
62129 using mysql wamp server environment want log queries log file queries running php phpmyadmin want log
62144 database tables mssql contain field userid varchar9 others due application redesign need alter tables database check field exists need change varchar50 need add someone point kind batch procedure dont much experience mssql databases detailed explanation would appreciated
62165 setup server runs windows server sql server express installed connect machines sql server express database via machinename sqlexpress however come connecting software script using ip address wont allow connection tried turning firewall allowing remote connections sql database enabling tcp ip within sql configuration attempt connect via software sql server management studio get following message error message error occurred establishing connection server connecting sql server failure may caused fact default settings sql server allow remote connections provider tcp provider error connection could made target machine actively refused microsoft sql server error connection successfully established server error occurred login process provider tcp provider error established connection aborted software host machine microsoft sql server error please let know free take look seem getting know amended details per information uk fast sent said within support remit help look forward hearing
62208 records weighs bytes possible todays technology someone storage needed kind db would hold data make possible retrieve example record 5hphagt65tzzg1ph3csu63k8dbpvd8s5ip4neb3kesreabuatmu 1mshws1bnwmc3tle8g35uxss58fkipzb7a 1q1pe5vpgeemqrcvrmbtbk842y6pzo6nk9 number records
62500 running postgressql column relation rows contains nodes 3d space one referencing user created query user created many nodes following added explain analyze information explain analyze select user id countuser id treenode project id group user id query plan hashaggregate cost rows width actual time rows loops seq scan treenode cost rows width actual time rows loops filter project id total runtime ms see takes seconds isnt bad considering amount data wonder improved tried add btree index user column didnt help way alternative suggestions sake completeness complete table definition indices without foreign key constraints references triggers column type modifiers id bigint null default nextvalconcept id seq regclass user id bigint null creation time timestamp time zone null default edition time timestamp time zone null default project id bigint null location double3d null reviewer id integer null default review time timestamp time zone editor id integer parent id bigint radius double precision null default confidence integer null default skeleton id bigint indexes treenode pkey primary key btree id treenode id key unique constraint btree id skeleton id treenode index btree skeleton id treenode editor index btree editor id treenode location index btree location treenode location index btree location treenode location index btree location treenode parent id btree parent id treenode user index btree user id edit result use query index proposed ypercube query takes seconds without explain analyze explain analyze select id select count treenode project id user id id number nodes auth user query plan seq scan auth user cost rows width actual time rows loops subplan aggregate cost rows width actual time rows loops bitmap heap scan treenode cost rows width actual time rows loops recheck cond project id user id id rows removed index recheck bitmap index scan treenode user index cost rows width actual time rows loops index cond project id user id id total runtime ms rows time ms edit result use index project id user id schema optimization yet erwin brandstetter suggested query runs seconds speed original query explain analyze select user id countuser id ct treenode project id group user id query plan hashaggregate cost rows width actual time rows loops seq scan treenode cost rows width actual time rows loops filter project id total runtime ms rows
62576 knowledge databases sql based university classes anyhow spent monts almost year company working databases read books taken part trainings databases mysql postgresql sqlite oracle also nonsql dbs us mongodb redis elasticsearch etc well said begginer lot lacks knowledge today someone told something totally begginers knowledge let explain lets take sql database create simple table person records inside id name age alex brad chris david eric fred greg hubert irvin john karl part would like focus id index far thought works way table created index empty adding new record table index recalculated based alghortims example grouping one one 2n xn 1n example size elements like id name age alex group0 brad group0 chris group0 david group1 eric group1 fred group1 greg group2 hubert group2 irvin group2 john group3 karl group3 using query select person id simple calculation look object group2 row returned hubert approach works time ok size course alghoritm organise rows groups sure much complicated think simple example shows point view would like present another approach showed today lets take table id name age alex brad chris david eric fred greg hubert irvin john karl creating something similar hashmapin fact literally hash map maps id address row id lets say id addr running query select person id map directly id address memory row returned course complexity o1 got questions adventages disadventages solutions one popular current database implementations maybe different dbs use different approaches exist nonsql dbs thank advance comparison tree hash table one element searching ologn o1 deleting ologn o1 inserting ologn o1 space elements searching ologn o1 deleting ologn o1 inserting ologn o1 space number records right cost rebuilding tree hash table insert delete case tree change pointers case balanced tree needs effort also case hash table operation especially operation generate conflicts
62598 look following example starting top row id work way selecting limit rows secs yet seen select id dont yet sec continue work way like get id skip already sec row id continue manner finally stop id accumulated rows desired limit id sec skip already sec skip already sec skip already sec course sql algorithm different described desired result id rows wanted increase limit rows row id would included results however increased limit rows row id would added sec already seen note though shouldnt matter postgresql case want quickly build table test create table table id serial primary key sec integer default null insert table sec values create index index table sec table sec
62660 application db running sql server ive got job scheduled task periodically executes expensive query writes results table later queried application ideally would like run expensive query something changed since query last executed since source tables big select checksum candidate columns something like ive got following ideas explicitly write last changed timestamp must queries flag something like tracking table whenever change something source table use trigger however id really like know whether lightweight way detect changes table without explicitly tracking writes example get current rowversion table something like
62812 use loops mysql test script begin select select set end end syntax errors im running loop using sqlyog client standard query window syntax errors following form error code error sql syntax check manual corresponds mysql server version right syntax use near ive also tried use loop example provided https dev mysql com doc refman en html still didnt work part script wrong using mysql im trying make month moving average data hoping loop would able append new month average onto old month average iteration loop
62884 turn desktop windows sp1 often find gb memory already occupied mysql processes dont care much memory database requires actually runs queries app even dont start yet matter barely use mysql barring develop web apps local environments possible stop gluttony tried remove mysql startup group viamsconfig couldnt find name extra info mysql ver distrib win64 x86 mysql server mysql workbench
62976 im playing around permissions locked mongo database im pretty sure trying explicitly add access database instead overwrote allowing permission database im effectively locked mongo database everything read tells create super user add user privilege right dont think users privilege way enter database access server root access
63131 ive looking using indexed views increase performance commonly used views however indexed views support non unique clustered indexes goes little precedence set rest database structure example simplified version couple tables groups group id groupname users userkey username fullname groupid indexes groups groupid non clustered users groupid clustered clustered key groupid users table commonly range users specific group would retrieved obviously would multiple users per group clustered index non unique leaves bit uncertain follow precedence indexing views example non unique clustered index consumableid consumablevariantid allowthresholdoverwrite fullpath groupid manufacturerid type modelid actuality value view would always unique consumableid column left little choice place index views permit non unique clustered indexes regular tables
63138 need know sql queries generated application possible see kind sniffer tried look management studio shows expensive queries
63255 received database file instructions loading install sql server attach using sql server management studio installing everything tried attach mdf file tells directory lookup file foldername filename ldf failed operating system error error found ldf file come database presumably generated automatically drive cd drive going find anything going luck trying create anything trying look log file specific path database file attach database realized select database attach three entries appear database details mdf ndf ldf ldfs current file path points drive path removed time hit ok get different error message database upgraded read read files make database files writeable rerun recovery file activation failure physical name folder file ldf may incorrect new log file created microsoft sql server error creates new log file folder database file great seems like security issues additional information instructions require use login name sa appears sysadmin account connected sql server instance using login checked file properties read directory read either acls allowed unable attach database try attach throws error message attach database failed closing ssms reopening administrator made difference select serverpropertyproductversion returns theres another file comes database called dbdata ini says issql2000 presumably meant loaded sql server ill see get working
63506 one table services need merge two select queries different clauses example select regn region countcallid openservices sumcase descrption like dfc else end dfc oscl status group regn order openservices desc gives result region openservices dfc karaci lahore islamabad another query select regn region countcallid closedyesterday oscl datediffday closedate getdate group regn order closedyesterday desc gives result region closedservices karachi lahore islamabad need merge results show closedservices beside dfc column
63553 change db one sps deleted idea way find enabling option able track future
63641 ive dealt ms sql server datetime types long time never thought following happening query table contains smalldatetime column smalldatetime always returned format yyyy mm dd hh mm ss write different query want apply smalldatetime filter clause something like timestamp yyyy mm dd hh mm ss sql server retrieves error tells possible convert nvarchar valid smalldatetime appears works change specified format write using european format like timestamp dd mm yyyy hh mm ss sql server showing dates format covertable valid applied back dont problem changing date format writing queries want play dates application level java jdbc app dont want applying date format changes time could anyone explain happening way solve db level thanks edit please see screenshot error management studio
63661 full question write im looking first aggregate function found something almost works create replace function public first agg anyelement anyelement returns anyelement language sql immutable strict select wrap aggregate around create aggregate public first sfunc public first agg basetype anyelement stype anyelement problem varcharn column passes first function converted simple varchar without size trying return query function returns setof anyelement get following error error structure query match function result type estado de sql detalhe returned type character varying match expected type character varying40 column contexto pl pgsql function vsr table timeanyelementtimestamp without time zone line return query wiki page link version function would replace dont know install wonder version could solve problem meanwhile way change function returns exact type input column
63676 sql server lot databases one dropped need create trigger send email someone try drop another database mail contain user name name database
63681 process phasing old system migrating onto new one last time phased old system ran systems parallel integrated data everything fully migrated field process able build integration legacy system new system leveraged sql servers change data capture track changes integrate incrementally next migration legacy system phasing based mysql v5 instead sql server familiar mysql wondering technologies similar cdc leveraged mysql current version newer version would worth migrating towards
63825 unified way check existance index given column irregardless actual sql database system used mysql one could instance check existance using show create table mytable result would something like column mycolumn index key index mycolumn indicator key unified among sql database systems better ways check index
64013 execute command line statement optimize table optimize table tablename command statement optimize tables one one selected database
64084 way copy maintenance plans one sql server another servers accessible via copy management studio time different networks
64256 ive told theres oracle memory option 12c uses columnar compression get great query speeds id like leverage business intelligence stuff ive searching google thing find announcements news articles anyone code snippets directions look implement learn
64270 table column called json type json within json natural key select json id id limit id 63631ff3809de7a17398602f create unique index id thus create unique index id tjson id create index id like add table constraint using index fails primary key alter table add constraint pkey primary key using index id error index id contains expressions line alter table add constraint pkey detail create primary key unique constraint using index unique alter table add constraint unique id unique using index id error index id contains expressions line alter table add constraint unique id detail create primary key unique constraint using index able add constraint
64727 made sql fiddle question makes things easier anyone fantasy sports database sorts im trying figure come current streak data like w2 team last matchups l1 lost last matchup winning previous matchup t1 tied recent matchup basic schema create table fantasyteams team id bigint null create table fantasymatches match id bigint null home fantasy team id bigint null away fantasy team id bigint null fantasy season id bigint null fantasy league id bigint null fantasy week id bigint null winning team id bigint null value null winning team id column indicates tie match heres sample dml statement sample data teams weeks worth matchups insert fantasyteams select union select union select union select union select union select insert fantasymatches select union select union select union select union select union select union select union select union select null go example desired output based dml im trouble even beginning figure derive team id steak type streak count ive tried various methods using subqueries ctes cant put together id like avoid using cursor could large dataset run future feel like might way involving table variables join data somehow im still working additional info could varying number teams even number total matchups increase team every week ideas
64876 recently installed sql server express workstation trying deploy sql azure ive done previous workstation using sql server express following right click database tasks deploy database sql azure sql server option completely missing instead replaced new option deploy database windows azure vm cant figure option deploying sql azure missing something needs installed separately sql server ive read online options present editions microsoft remove option sql server express
65142 dataset following structure target polltime value null null null null null null null would like build resultset groups null values showing start end time duration null means target unavialble target startdate enddate durationmin startdate would first null value enddate would next non null value duration calcualtion would based two values clues build query would great thinking joining table sure start
65257 assuming database column containing table names safely delete tables lists tables fairly simple may indeces definitely dont contain complex items dont dependencies tables ie foreign keys etc
65262 dollar amount value historical reasons always stored nvarchar field storing many rows past using field total amounts using application automatically refresh frequently im concerned performance im also concerned cost making change like late development cycle soon database used customer generate millions rows rows participate calculation rows divided groups around parent group processed every minutes totals calculated worth change column type money including stored procedures udts data layer etc seems like could performance impact unfortunately cant generate enough volume resources performance tests thta would realistic im hoping someone experience string number conversion give idea conversion rows time problem
65351 two identical mysql databases one internal server web hosting server want update database web host day database internal server way automate process also manually im manually require get sql dump database internal server import database web host someone advice please
65609 feel kind embarrassed ive always used terms column field completely interchangeably recently caused confusion technical discussion told though wasnt correct translating term spreadsheet terminology ignoring data types stuff make databases useful database column like spreadsheet column database record like spreadsheet row database field like spreadsheet cell specific column specific row right could sworn column field used interchangeably certainly dont add fields table add columns table fields relevant talking data within record thoughts column vs field edit clarify current context ms sql server background sql server ms access might influence use terms
65922 table gotten little control dba per se seem recall deleting huge volume rows one shot cause transaction log issues hamper overall system performance delete etc efficient way create job deletes records small batches hampering access performance prevents problems transaction log process quite slow makes difference additional context delete criteria based something like like blah also one clustered index non clustered indexes
66014 trying connect remote sql server vpn different domain enter server name sql server choose additional connection parameters add extra stuff needed school integrated security sspi user id domain username password password get following error login failed login untrusted domain used windows authentication
66118 lets say table deck cards numbered could return top bottom cards held side unions select query left right hands select top deckofcards order cardnumber desc union select top deckofcards order cardnumber asc would even split could sql server intertwine results returned taken portions union one half left hand right shuffled like deck cards ie cardnumber followed following sequence etc homework question one things passes mind trying get shut eye
66249 anyone help find given details long running query processid process name database host user process login time query start time query duration looking query sp gives data
66387 using postgres would like change column type tables column name description varchar255 text anyone knows would glad help
66471 trying estimate space requirements central database server collecting data identical field databases average daily row count table need estimate row size including indexes table animal existence need roll need roll suggest good approach tia
66553 play basketball game allows output statistics database file one calculate statistics implemented game far ive problem caluclating statistics wanted ive run problem counting number double doubles triple doubles player made season game statistics definition double double triple double follows double double double double defined performance player accumulates double digit number total two five statistical categories points rebounds assists steals blocked shots game triple double triple double defined performance player accumulates double digit number total three five statistical categories points rebounds assists steals blocked shots game quadruple double added clarification quadruple double defined performance player accumulates double digit number total four five statistical categories points rebounds assists steals blocked shots game playergamestats table stores statistics game player plays looks follows create table playergamestats select values nuggets cavaliers nuggets clippers nuggets trailblazers nuggets mavericks nuggets knicks nuggets jazz nuggets suns nuggets kings nuggets kings nuggets thunder tidplayer idseasondayteamopponentpointsreboundsassistsstealsblocks output want achieve looks like player id team doubledoubles tripledoubles nuggets solution found far awful makes puke looks like select player id team sumcase whenpoints rebounds points assists points steals else end doubledoubles playergamestats group player id youre probably also puking laughing hard reading didnt even write everything would needed get double double combinations omitted case statement triple doubles even ridiculous better way either table structure new table structure could write script convert table use mysql postgresql link sqlfiddle example data awful solution posted http sqlfiddle com af6101 note im really interested quadruple doubles see since dont occur game play far know would plus query easily expandable without much rewrite account quadruple doubles
66616 select aa update aa set city chennailastname vinoth id firstname lastname city abcrdrr vinoth chennai john vinoth chennai joe vinoth chennai raja vinoth chennai johsdfgn vinoth chennai wrongly updated lastname city columns rows want rollback old table rows using sql server 2008r2
66741 something like work select case nullifcol lengthcustomers somecol null null else somecol end mytest customers checking column exists however sql server complains somecol existing alternative single statement
66840 trying add null constraint table billion rows afford table lock couple seconds way prevent full table scan alter table statement created index column hoping would used doesnt seem work may check constraint options thank
67852 im trying recreate tables structure inside function using dynamic sql execute create table table name bk like table name similar create table table bk like table need discard constraints using excluding constraints like options still copy null constraints documentation confirms behavior create table table bk like table excluding constraints question recreate table structure without null constraints alternative remove null constraints table
67875 non forking game daemon written perl uses acync queries write player stats postgresql database need read something database like player banned player vip status use synchronous queries makes game stop short moment value read database rewrite game daemon use async queries reading values tried required many changes question would make sense combine several unrelated queries need make new player connects procedure could return several values time perl program current queries take player id parameter return value player banned select true pref ban id reputation player select countnullifnice false countnullifnice true rep pref rep id special vip player select vip vip pref users id many games player played end select completed pref match id combine queries probably need procedure like one create replace function get user info id varchar returns xxx body declare banned boolean reputation integer vip boolean completed games integer begin select banned pref ban id id select countnullifnice false countnullifnice true reputation pref rep id id select vip vip pref users id id select completed completed games pref match id id return xxx return values end body language plpgsql please help declare procedure properly
67985 find edition installed without management studio installed server functions license manager another software upon investigation high ram usage alert found sqlservr exe process taking almost gb ram looked program menu found configuration manager installed otherwise pretty bare bones clicked properties exe file found place ive found states whether express dev stn ent etc guess express edition wanted know obvious tell tale sign update bob file tells know edition valo get following error run command verify named pipes enabled hresult 0x35 level state named pipes provider could open connection sql server sqlcmd error microsoft sql server native client network related instance specific error occurred establishing connection sql server server found accessible check instance name correct sql server configured allow remote connections information see sql server books online sqlcmd error microsoft sql server native client login timeout expired thomas noticed stock keeping unit name asked question seemed easy guess initial suspicion correct
68077 pgadmin dialog adding new database connections asks maintenance db order able connect set database want connect also rights connect named maintenance db instead db database
68089 im trying achieve following california los angeles san francisco sacramento florida jacksonville miami unfortunately im getting los angeles san francisco sacramento jacksonville miami achieve desired results using stuff function wondering theres cleaner way using coalesce state city california san francisco california los angeles california sacramento florida miami florida jacksonville declare col nvarcharmax select col coalesce col city tbl city california select col thanks
68150 oracle datafile system files actual data stored collection datafiles make tablespace last database collection tablespaces correct wrong concepts datafile tablespace database would like understand difference schema database details online resources helpful seemed confusing regarding difference
68264 official postresql convention regarding capitalization db table field names examples official site suggest lowercase word separation wonder whether policy official create table films code char5 constraint firstkey primary key title varchar40 null integer null date prod date kind varchar10 len interval hour minute
68266 would right datatype store email addresses postgresql use varchar even text wonder specific data type emails
68639 months programming sql server knowledge good many regards already existing project work came across many tables large composite primary keys clustered index gathered large column composite column clustered index hits performance hard times logical solution identity column time come across many people flaming usage identity columns never came across example identity column bad idea recently standardized every table identity column clustered index whether use pk require export purposes would like examples real life scenarios using identity column clustered index bad idea though times makes life easy never encountered scenario considered bad ps think question bit naive bugging much ask
68700 may sound like dumb question software developer new database design concept makes sense maybe doesnt carry possible field record table simply point field record table example two tables one containing list employees another containing history employees coming going office employees id first name last name history event id event time event type entry exit employeeid establish relationship history employeeid employees id foreign key duplicates data history employeeid employees id would contain id number would stored memory twice went database changed john smiths employee id would need write script something scour database find replace id want employees id contain real id history employeeid simply contain pointer employees id way updated john smiths id change would centralized one field one table possible thanks
68771 using oracle sql developer manage oracle database recently added third party database jdbc drivers able connect new mysql sql server installations need help right settings sql server connection username host name port including formats
68991 hope point right direction im frequent user sql googleing found script corrected script bit want script select databases except system dbs set recovery simple shrink log files every db ldf except system db script use master declare isql varchar2000 dbname varchar64 declare c1 cursor select name master sysdatabases name mastermodelmsdbtempdbreportserverreportservertempdb open c1 fetch next c1 dbname fetch status begin select isql alter database dbname set recovery simple select isql replace isql dbname dbname print isql exec isql select isql use dbname checkpoint select isql replace isql dbname dbname print isql exec isql select isql dbcc shrinkfile dbname ldf select isql replace isql dbname dbname print isql exec isql fetch next c1 dbname end close c1 deallocate c1
69043 accidental dba sql cluster hosts databases suddenly size one database increased drastically 100gb 250gb checked datafile size grown twice last days identified tables truncated data deleted 130gb worth data datafile still showing 250gb reclaim space thanks lot help
69081 query using find locations within 1km known point using spherical law cosines formula latitude longitudes currently query runs roughly records minutes acceptable would like make fast possible main query using select loc base key locations loc left outer join baseline base base key select key baseline dbo circledistanceloc lat base latitude loc long base longitude circle distance scalar value function alter function circledistance add parameters function lat1 varchar250 lat2 varchar250 lng1 varchar250 lng2 varchar250 returns float begin declare distance float declare lat1 float float declare lng1 float float declare lat2 float float declare lng2 float float select lat1 float cast lat1 float select lng1 float cast lng1 float select lat2 float cast lat2 float select lng2 float cast lng2 float select distance acossinradians lat1 float sinradians lat2 float cosradians lat1 float cosradians lat2 float cosradians lng2 float radians lng1 float return distance end go execution plan anonymizing indexed columns named query function caveats converting float function data getting arrives string unable change prior point left outer join required need know locations known point using law cosines rather haversine simplicity dont require large amount accuracy since interested things within km dba merely net developer really knowledgeable improving query performance beyond indexing help appreciated edit rolling rob marks answers allowed get query execution seconds case theres gains query select columns locations loc left outer join baseline base base key select key baseline base location geo stdistanceloc location geo earth radius dont need math query run location geo computed column using formula geography stgeomfromtextpoint longitude latitude spatial id spherical earth model since im looking large distance seems make query quicker return also spatial index location geo column suggested http social technet microsoft com wiki contents articles tuning spatial point data queries sql server aspx
69354 im trying get idea recommended best practices sql server cumulative updates currently run idea nothing unless issue fixed cu one experience works aint broke dont fix approach im wondering thats really good idea since many cus performance enhancements looking perhaps adding cu patches applied periodic maintenance cycles month two cu released others update question affects answers march microsofts sql server team announced updating servicing model microsoft recommending users install cus released january january cu releases caution messages updated recommend ongoing proactive installation cu become available plan install cu level confidence plan install sps service packs released cu certified tested level sp also microsoft css data indicates significant percentage customer issues often previously addressed released cu applied proactively cu contain added value hotfixes also may contain supportability logging reliability updates enhancing overall experience addition messaging guidance updates made updates cu acquisition model acquisition changes cus course traditionally made available hotfix server accompanied cautionary language associated qfe hotfix inconsistency cus really simple quick hotfixes anymore encompassed updates well tested individual well full system integration levels today therefore placing latest cu per mainstream supported baseline sp2 sp3 rtm sp1 today microsoft com downloads done service packs today additionally soon release maintain cus windows update catalog facilitate acquisition distribution interim cu demand fixes placed hotfix server moving forward reduce friction downloading cus microsoft com downloads require providing receiving email url also evaluating offering latest cu optional update microsoft update like service packs today
69361 back days yesteryear considered big select table select count table performance hit still case later versions sql server im using guess question would apply edit since people seem slating slightly im looking benchmark academical point view whether right thing course
69467 old database users membership role setup automatically asp net application years ago sql server version currently running sql server users database log file huge ldf file approx times size mdf file recovery model currently set full understand dont need point time restoration simply changed recovery model simple within sql server management studio clicked ok save changes would risking current database way sql server fine making changes like live databases would log file automatically shrink thanks advice mark
69655 query like select id name json aggb item join item id id group id name select columns dont item id json object read row returns json object like f1 foo f2 bar would need remap json object fetched match proper column keys id like avoid keep original column names
69656 im using steps create table user already existed somehow vanished database db mysql use db mysql drop table user mysql error 42s02 unknown table user mysql create table user id int auto increment null username varchar255 group id varchar255 default null primary keyid default character set utf8 collate utf8 unicode ci engine innodb mysql error hy000 cant create table db user errno tried mysqladmin flush tables repeated steps wasnt helpful also restarted mysql service good ideas google failed far thanks extra info mysql show engine innodb status latest foreign key error error foreign key constraint table db user index table would contain columns first columns data types table match ones referenced table one set null columns declared null constraint constraint fk cfbd431e285fac6d foreign key group id references group id
69953 working harmonized system try catalog mysql database works example like live animals horses asses mules hinnies live bovine animals live swine live purebred breeding animals weighing less lb weighing lb sheep goats live chickens ducks geese turkeys guineas live animals live nesoi nesoi elsewhere specified indicated see clear parent child relationship relationship always traced back numbering used thread learned best use text data field codes etc question somewhere log parent child relationship would necessary select accounts code like get subaccounts fine feel parent child table could make things complicated id like hear people feel make sense
71393 ive struggling little bit around performance troubleshooting including baseline troubleshooting sql performance could anyone help point possibly get helpful information around topic
71596 reason try open tables stored frm ibd files whether mysql phpmyadmin gives syntax error says exist ive read post similar problem dont know check innodb file per table enabled im overall really confused also converted copy mysql bin file txt file see data database completely lost database created last year mysql bin files reason largest right ibd frm files databases im loss restore back mysql least something read im using wampserver mysql windows server also supposed download plugin innodb
71608 scenario youre handed database backup told restore server thats already hosting databases given useful information backup contains whether source trusted question potential implications restoring backup could well malicious question protect server data databases impact restoring potentially malicious backup restore verifyonly would seem good first step ultimate answer probably restore database sandbox vm access outside world lets assume option table else done situation
71852 three tables students table idpk student name nationality teachers table idpk teacher name email classroom table idpk date teacher idfk teachers id student idfk students id given teachers name david example student id example asked insert teacher id classroom table based id teachers table would insert classroom date teacher id student id select id teachers teacher name david given students id directly given name student suppose given teachers name david students name sam get teacher id teachers table also student id students table insert classroom table based respective names
71961 use mysqldump single transaction according docs flush tables read lock get consistent state start transaction writers waiting however caught following situation last night excerpt show full processlist hundreds command query time state waiting table flush info insert db external notification command query time state sending data info select sql cache db external notification rest threads sleep anyone idea inserts waiting dont see flush tables ddl anything mentioned manual cause queries wait full mysqldump command mysqldump quick add drop table single transaction master data uxx pxx dbname guess quick redundant probably leftover earlier times script old shouldnt hurt anyting
72083 basically sql server null means value thus cant compared returns unexpected results example following query doesnt return rows value null want select table value date null last modified understand following workaround seriously add parentheses check null every single field every single time want include seems ugly intuitive crazy select table value value null date null last modified mean know null value thus cant compared cant infer fact definitely something null nothing nothing something null seems logical anyone know cleaner way include nulls results using comparisons without include explicit check every time also turning nulls tables definitely option edit real problem dont want way showed exposed goes writing program lets build queries database tables lets user dynamically create filters essentially end day constructs sql statement gets results display user fields chosen user fields given database literally put isnull check every single field would really inefficient make looking sql super ugly program table definition agnostic meaning dont care whats table dont want know tables definition want pick table choose fields filter equals equals etc click button view results request
72134 large database 16m rows containing perceptual hashes images id like able search rows hamming distance reasonable timeframe currently far properly understand issue think best option would custom sp gist implementation implements bk tree seems like lot work im still fuzzy practical details properly implementing custom index calculating hamming distance tractable enough know though basically appropriate approach need able query matches within certain edit distance hash understand levenshtein distance strings equal length functionally hamming distance least existing support want though clear way create index remember value im querying changes pre compute distance fixed value since would useful one value hashes currently stored char string containing binary ascii encoding hash convert int64 easily enough real issue need able query relatively fast seems like could possible achieve something along lines want pg trgm im bit unclear trigram matching mechamism works particular similarity metric returns actually represent looks kind like edit distance insert performance critical computationally expensive calculate hashes row primarily care searching
72330 fairly well documented scalar udfs force overall serial plan running functions parallel given large number rows coming point pipeline udf must calculated cant engine distribute among processors state within udf order shouldnt matter claims udfs black box must use cursor see user cursor parallelized within sp cases state maintained iterations seems like parallelizable otherwise extra points explaining engine forces whole plan serial instead udf calculation stage support parallel udf reasonable feature request
72358 little web application using sqlite3 db db fairly small right generating content display using following query select dbid dlstate retreivaltime seriesname snip irrelevant columns dataitems group seriesname order retreivaltime desc limit offset limit typically offset drive pagination mechanism anyways right one query completely killing performance takes approximately milliseconds execute table 67k rows indexes seriesname retreivaltime sqlite select name sqlite master type index order name snip irrelevant indexes dataitems seriesname index dataitems time index index retreivaltime yeah poorly named however explain query plan seems indicate theyre used sqlite explain query plan select dbid dlstate retreivaltime seriesname dataitems group seriesname order retreivaltime desc limit offset scan table dataitems use temp tree group use temp tree order index seriesname collate nocase thats relevant drop group behaves expected sqlite explain query plan select dbid dlstate retreivaltime seriesname dataitems order retreivaltime desc limit offset scan table dataitems using index dataitems time index basically naive assumption would best way perform query would walk backwards latest value retreivaltime every time new value seriesname seen append temporary list finally return value would somewhat poor performance cases offset large happens rarely application optimize query provide raw query operations needed insert performance critical need create additional index two thats fine current thoughts commit hook updates separate table used track unique items seems like overkill
72493 consider table values hashes like field type null key default extra id int11 pri null auto increment val char9 null val hashed char50 yes null following query finishes seconds select hashes order desc limit however query takes min seconds select val hashes order desc limit see query running process list shows status sorting result situation completely reproducible note another process performing insert operations table continuously would specific query take longer run query ive always believed queries avoided specifically performance reasons
72641 already asked stack overflow mysql im using postgresql unfortunately surprisingly postgresql seem something like checksum table postgresql solution would fine generic one would better found http www besttechtools com articles article sql query check two tables identical data dont understand logic used background wrote database generating code need check whether old new code produce identical results
72750 im struggling bulk importing quite big innodb table consisting roughly million rows 7gb biggest table ive worked far research improve innos import speed moment setup looks like etc mysql cnf innodb buffer pool size memory innodb read io threads innodb write io threads innodb io capacity innodb thread concurrency innodb doublewrite innodb log file size 1g log bin innodb autoinc lock mode innodb flush method direct innodb flush log trx commit innodb buffer pool instances import done via bash script mysql code set global sync binlog set sql log bin set foreign key checks set unique checks set autocommit set session tx isolation read uncommitted load data local infile filepath table monster commit data provided csv file currently test settings smaller test dumps million million rows use time import script sh compare performance drawback get overall running time ive wait full import finish get result results far rows second rows seconds rows seconds million rows minutes million rows minutes million rows cancelled hours seems cookbook solution one figure optimal mix settings besides suggestions change set also would really appreciate information could better benchmark importing process gain insight happening bottleneck might tried read documentation settings im changing im aware side effects might even decrease performance badly chosen value moment would like try suggestion chat use myisam import change table engine afterwards id like try moment drop table query also takes hours finish seems another indicator setting less optimal additional information machine im currently using 8gb ram solid state hybrid hard drive 5400rpm also aim remove obsolete data table question still need somewhat fast import test automatic data cleanup feature developing case server crashes wed like use 2nd server replacement needs date data last import took hours mysql show create table monster row table monster create table create table monster monster id int11 null auto increment ext monster id int11 null default id int11 null default email varchar250 null name varchar100 null address varchar100 null postcode varchar20 null city varchar100 null country int11 null default address hash varchar250 null lon float106 null lat float106 null ip address varchar40 null cookie int11 null default party id int11 null status int11 null default creation date datetime null someflag tinyint1 null default someflag2 tinyint4 null upload id int11 null default news1 tinyint4 null default news2 tinyint4 null someother id int11 null default note varchar2500 null referer text null subscription int11 default hash varchar32 default null thumbs1 int11 null default thumbs2 int11 null default thumbs3 int11 null default neighbours tinyint4 null default relevance int11 null primary key monster id key party id party id key creation date creation date key email email4 key hash hash8 key address hash address hash8 key thumbs3 thumbs3 key ext monster id ext monster id key status status key note note4 key postcode postcode key id id key cookie cookie key party id party idstatus engine innodb auto increment default charset utf8
72770 default mysql config file etc mysql cnf installed debian package using apt often set log bin variable binlog enabled log bin var log mysql mysql bin log want disable binary logging installation comment line cnf works course wonder way disable binary logging setting explicitely log bin debian style mean included file like etc mysql conf mycustomfile cnf default cnf changed easily updated apt necessary tried log bin log bin log bin none works
72816 creating clustered column store index sql server getting error timeout expired timeout period elapsed prior completion operation server responding microsoft sql server set exec sp configure remote query timeout reconfigure exec sp configure row count data space mb
72858 use domain accounts sql server service accounts sometimes multiple servers logically thematically related ill use set domain accounts service accounts user account permissions server may different theres usually lot overlap gist question user access one instance exploit shared service accounts gain access server heres specific situation im trying address two servers default sql instances call org sql org sql use domain account service id mydomain orgdbservice mydomain orgagentservice etc although im sure thats strictly relevant think id question used single account services reuse domain accounts servers database service org sql org sql runs mydomain orgdbservice example date ive never particularly questioned security implications since servers common purpose user base even specific user permissions may differ add third instance lets call org sql rpt one good thematic fit others theres one key difference going allow external partner employee org access server like credentials belong db owner couple databases wont belong server roles public course may admin access os desktop limited time prior making server live wont know passwords service accounts given worry reusing domain accounts service accounts new instance risk person could use legitimate credentials org sql rpt gain access either org sql org sql risk could mitigated using different service account credentials generally bad idea reasons edit new instance hosting database integration reporting services least analysis services external user elevated database privileges explicit instance permissions wont able create logins jobs reports example
72864 know normal target db restoring state also would like queries sanity check data date take read non restoring state temporarily check data put back restoring without breaking whole restore chain thanks
72974 suggested way rebuild entire sql server database another database sql server sp2 let explain database trying enable partial containment add alwayson cluster getting nothing deadlock errors trying set containment partial database gone sql server 2008r2 sp sp1 sp2 tde microsoft support looking couple days looking promising think leaning towards form corruption application everything else seems able still access fine setting one little flag isnt working strange issue reference found online shows exact issue technet forum post portuguese translated link never resolved point cant wait longer want rebuild data new database suppose could script entire thing db around 20gb already would one nasty script anyone suggestion recreate new database based another without standard backup restore scripting right way go
73226 developer student looking advice best approach follow creating table model entity number optional fields exists need model organization entity key fields id name also join table users organization specifies belongs organization roles question pertains number optional fields belong organization website email social links ideas approaching problem thus far add table optional fields pros easy crud one table faster navigating joins etc cons seems bit dirty might become difficult migrations future create contact information table references organization id references contact type id website email facebook etc lookup table generic value field actual content pros feels cleaner allows arbitrary number contact types future cons probably lot slower tons tables leaning towards similar approach im physical addresses im unsure whether best solution dba forte 3rd even 4th option unaware id really interested hear well
73635 okay setting scene three tables table1 table2 datatable want insert table1 table2 using datatable source every row datatable want row table1 table2 table2 needs inserted id pk table1 insert table1 select mytable insert table2 select identity insert mytable id get id last inserted record table1 cursor loop ways
73680 current database assumes times local user changing database stores everything utc application converts utc time database correct timezone user need update every datetime database utc time better way application timezone library update one individually due daylight savings time bst simple dateadd isnt option roughly million cells update
73711 trying test speed sql server queries however query becomes lot faster database live make changes select query performed way select query without sql server optimizing
73826 install sql server management studio desktop access database sql server instance find installer google searches return express versions whereas looking full sql server management studio
73850 using alwayson availability group feature sql server regular full database backups transaction log backups done every day secondary database read transaction log backup either primary replica secondary replica mark replicas transaction logs reusable anyway transaction log backup size big reduce using shrink file restore database locally perform shrink operation log file size reduces mb question database perform shrink operation transaction log file primary secondary guess past several years back ups log file made become huge executing dbcc sqlperf logspace see file used point keep huge size log file sys database files check max size set growth guess need space get anyway shrink example order prevent future growth trying find confirmation bad idea actually back ups database log files performed secondary databases easier perform shrink file primary log file size reduced well
73921 immediately marking duplicate read mike walshs transaction log keep growing run space dont think gave answer situation looked dozen similar questions relevant ones mostly said duplicate pointed mikes question details bunch 500mb databases sql server r2 simple recovery mode choice nightly full backups 200mb data files 300mb log files log doesnt grow 300mb immediately rather slowly course couple months open transactions least according sp who2 activity monitor right click database select properties tells 50mb free particularly right backup shouldnt whole log free simple mode shouldnt log free long isnt open transaction log reuse wait desc sys databases says says nothing based question answer referenced says shouldnt wait anything reuse space dbcc shrinkfile log file shrinks 1mb willing reclaim space set something shrinks logs weekly keep things getting control im confused sql server would make understand crazy transaction needed 300mb log anything extreme basic oltp mikes question answer simple recovery model introduction easiest talk simple recovery model first model telling sql server fine using transaction log file crash restart recovery really choice look acid properties make sense quickly longer need crash restart recovery purpose go ahead reuse log file sql server listens request simple recovery keeps information needs crash restart recovery sql server sure recover data hardened data file less data hardened longer necessary log marked truncation means gets used keeps saying log space reused slow growth course months doesnt seem missing something keeping sql server recognizing data hardened freeing log edit action report aka little knowledge dangerous finding popular question felt like owed explanation happened months ago learned hopefully save people grief first space available see ssms view properties database space available data file view running following database youll find space available reported ssms difference filesizemb usedspacemb select db name mf physical name mf type desc filetype mf size filesizemb filepropertymf name spaceused usedspacemb mf name logicalname sys master files mf join sys databases db db database id mf database id db name yourdatabasename confirm normal circumstances using little log space 20mb less leads second item second perception logs growing slowly time however reality logs growing rapidly nights guy responsible applying patches 3rd party application applying patches patch done single transaction depending patch 200mb data needed 300mb log key tracking query aaron bertrand https sqlblog org reviewing autogrow events default trace declare path nvarchar260 select path reversesubstringreverse path charindex reverse path nlog trc sys traces default select databasename filename spid duration starttime endtime filetype case eventclass data log end sys fn trace gettable path default eventclass order starttime desc showed log growing certain evenings customer wasnt using database led conversation guy applying patches answer mystery thanks people provided help get answer
74283 given softwarereleases table id version produce output id version
74306 using following command add constraints one raster image postgis postgresql alter table schema1 table1 add constraint enforce scalex rast unique rast getting following errors error data type raster default operator class access method btree hint must specify operator class index define default operator class data type kindly someone help fix error basic idea operator classes thx zia
74343 dropped sql server windows login ran code check orphaned database users however database user corresponding dropped windows login appear orphaned user would exec sp change users login action report
74457 tl dr prove practice execution alter table table name drop foreign key constraint name statement corrupt existing data important consideration execution statement consider data changes fact irrelevant analogy opening stable door harmful action horse bolting boss difference opinion whether use foreign keys mysql innodb database im using enforcing ri taking advantage delete cascade update restrict set null hes confident enforce ri application level argument chiefly drupal doesnt use gets along fine without theyre inflexible need change data structure hes removed existing tables change things caused data corruption noticeable weeks months later high traffic high activity sites hed rather use arguments chiefly databases db engines supported drupal myisam sqlite enforce fks default drupal leaves documented whereas might different d8 yes pain deal perhaps fault lies poor planning designing part developer fks surely enforcing ri fks dbms level likely cause data corruption otherwise case point d6s user reference module restricting changing user status existing content references user must certain status waste time resources make code attempt dbms already guarantee code work well better dbms essentially hell come way thinking prove act removing foreign key regardless subsequent data inserts updates wont corrupt existing data cant see way clear prove usefulness advantage im sure would satisfactorily observe document effect drop foreign key would immediately execution comparing data execution data execution persuade boss use foreign keys proving act later removal alteration wont corrupt existing data whereas using cause issues would best set practical usage tests note dont much want prove right egotistical point view use fks benefits data application code use dbms level application code level
74461 want use parameter within clause value provided strongly typed dataset trying moment get right results provide parameter3 results dont provide value desire provide value parameter3 use query value null want see results query paramerter3 null ones alter procedure dbo getdata parameter1 varchar256 parameter2 varchar256 parameter3 int null select table1 table1 url like parameter1 table1 id parameter2 parameter3 null table1 id2 parameter3 order table1 title edit tried thomas answer executed like exec return value dbo getdata parameter1 nasda parameter2 nasda parameter3 null select return value return value go also updated stored procedure thomas said
74517 im trying create postgres trigger ensure columns value set updated basically make readonly far ive come following draft trigger first correct track value returning new must preface original id new create function check id change returns trigger begin old original id new original id raise exception change original id end return new end language plpgsql create trigger client update trigger update client row execute procedure check id change
74627 two tables mysql database parent child im trying add foreign key references child table based parent table significant difference update cascade delete cascade parent table create table parent id int null primary key id engine innodb question difference following sql queries delete cascade create table child id int parent id int index par ind parent id foreign key parent id references parentid delete cascade engine innodb update cascade create table child id int parent id int index par ind parent id foreign key parent id references parentid update cascade engine innodb update cascade delete cascade create table child id int parent id int index par ind parent id foreign key parent id references parentid update cascade delete cascade engine innodb errors queries queries mean
74679 understanding use execute owner clause part procedure create make body procedure run different user goal execute command requires sysadmin role dbcc traceon1224 procedure supposed called unprivileged user ran following script sa user select user name user id issysadmin srvrolemembersysadmin dbo existsselect sys procedures name myproc drop procedure myproc go create procedure myproc execute owner select user name user id issysadmin srvrolemembersysadmin dbo dbcc traceon1224 msg level state procedure myproc line user dbo permission run dbcc traceon return go exec myproc output inline comments turns outside procedure seem sysadmin membership inside procedure procedure owned dbo user understand possible grant sysadmin role database user least gui doesnt offer possibility dont see could ever make database user server role also tried execute sa results execute user sa exist permission documentation states specify user name login name understand didnt work run procedure sysadmin role membership
74752 table employee id name salary city ram c1 sham c2 jadu c1 madhu c4 hari c2 gopal c3 komal c3 bappa c4 query city earning highest tried select city sumsalary maxsalary employee group city order salary desc limit works fine one max earning cities doesnt output max cities first one tried query select city maxtotalsalary maxsalary select city sumsalary totalsalary employee group city temptable giving city max c1 correct city max c4 means outputting first city name table c1 correct max earning city name c4 right query
74773 group one column sorting another im trying following select dbidretreivaltime fileitems sourcesite something group seriesname order retreivaltime desc limit offset want select last items fileitems descending order rows filtered distinct values seriesname query errors error column fileitems dbid must appear group clause used aggregate function need dbid value order take output query join source table get rest columns note basically gestalt question lot extraneous details removed clarity original question system im migrating sqlite3 postgresql ive largely outgrown sqlite select dbid dlstate sourcesite snip bunch rows note fileitems join select dbid fileitems sourcesite something group seriesname order maxretreivaltime desc limit offset di di dbid dbid order retreivaltime desc basically want select last distinct items database distinct constraint one column sorting order different column unfortunately query works fine sqlite errors postgresql error psycopg2 programmingerror column fileitems dbid must appear group clause used aggregate function unfortunately adding dbid group clause fixes issue group seriesnamedbid means distinct filtering query results longer work since dbid database primary key values distinct reading postgres documentation select distinct nnn requires returned results sorted nnn therefore id want via select distinct id query distinct nnn maxretreivaltime sort retreivaltime rather nnn take largest query using table get rest rows id like avoid database 175k rows 14k distinct values seriesname column want latest query somewhat performance critical need query times second naive assumption basically db needs iterate row descending order retreivaltime simply stop seen limit items full table query non ideal dont pretend really understand database system optimizes internally may approaching completely wrong fwiw occasionally use different offset values long query times cases offset completely acceptable basically offset crappy paging mechanism lets get away without needing dedicate scrolling cursors connection ill probably revisit point ref question asked month ago lead query ok notes select dbid dlstate sourcesite snip bunch rows note fileitems join select seriesname maxretreivaltime max retreivaltime fileitems sourcesite something group seriesname order max retreivaltime desc limit offset di di seriesname seriesname di max retreivaltime retreivaltime order retreivaltime desc works correctly query described remove group clause fails optional application psycopg2 programmingerror column fileitems seriesname must appear group clause used aggregate function think im fundamentally understanding subqueries work postgresql going wrong impression subquery basically inline function results fed main query
74879 postgresql debian lot huge indexes legacy database im trying optimize thinking dropping useless ones tell often used used usage statistics somewhere trick query
75091 quite annoying problem want use innodb main database engine give myisam need former using galera cluster redundancy copied description follows newbb post table new table called newbb innopost changed innodb tables currently hold entries running selects freshly started database caching involved point database yields following results omitting complete output please note even ask database sort results select post postid post attach newbb post post post threadid rows set sec select post postid post attach newbb innopost post post threadid rows set min sec seconds seconds wondering happening read answers stackexchange involving innodb suggesting increasing innodb buffer pool size installed ram wont solve problem initial query particular id take least 50x longer stalling whole websever queueing connections queries database afterwards cache buffer might kick threads database likely cache never hold relevant queries served queries simple joins keys used explain select post postid post attach newbb innopost post post threadid id select type table type possible keys key key len ref rows extra simple post ref threadidthreadid 2threadid visible dateline threadid const myisam table create table newbb post postid int10 unsigned null auto increment threadid int10 unsigned null default parentid int10 unsigned null default username varchar100 null default userid int10 unsigned null default title varchar250 null default dateline int10 unsigned null default pagetext mediumtext allowsmilie smallint6 null default showsignature smallint6 null default ipaddress varchar15 null default iconid smallint5 unsigned null default visible smallint6 null default attach smallint5 unsigned null default infraction smallint5 unsigned null default reportthreadid int10 unsigned null default importthreadid bigint20 null default importpostid bigint20 null default converted utf8 int11 null htmlstate enumoffonon nl2br null default nl2br primary key postid key threadid threadiduserid key importpost index importpostid key dateline dateline key threadid threadidvisibledateline key converted utf8 converted utf8 key threadid visible dateline threadidvisibledatelineuseridpostid key ipaddress ipaddress key userid useridparentid key user date useriddateline engine myisam auto increment default charset latin1 innodb table exactly create table newbb innopost postid int10 unsigned null auto increment threadid int10 unsigned null default parentid int10 unsigned null default username varchar100 null default userid int10 unsigned null default title varchar250 null default dateline int10 unsigned null default pagetext mediumtext allowsmilie smallint6 null default showsignature smallint6 null default ipaddress varchar15 null default iconid smallint5 unsigned null default visible smallint6 null default attach smallint5 unsigned null default infraction smallint5 unsigned null default reportthreadid int10 unsigned null default importthreadid bigint20 null default importpostid bigint20 null default converted utf8 int11 null htmlstate enumoffonon nl2br null default nl2br primary key postid key threadid threadiduserid key importpost index importpostid key dateline dateline key threadid threadidvisibledateline key converted utf8 converted utf8 key threadid visible dateline threadidvisibledatelineuseridpostid key ipaddress ipaddress key userid useridparentid key user date useriddateline engine innodb auto increment default charset latin1 server 32gb ram server version mariadb trusty wsrep log mariadb org binary distribution wsrep r4002 need innodb variables setting attach post update dropped indexes apart primary index afterwards result looked like rows set sec explain select post postid post attach newbb innopost post post threadid id select type table type possible keys key key len ref rows extra simple post null null null null using row set sec added one index back mix threadid results following rows set sec explain select post postid post attach newbb innopost post post threadid id select type table type possible keys key key len ref rows extra simple post ref threadid threadid const row set sec strange without relevant indexes full scan took seconds compared seconds using indexes one perfectly tailored index still taking seconds complete still far slow real world usage update setup mysql 0ubuntu0 ubuntu another server exact hardware configuration exactly database tables results nearly first myisam table rows set sec result innodb table rows set min sec update contents cnf mariadb database server configuration file copy file one etc mysql cnf set global options cnf set user specific options one use long options program supports run program help get list available options print defaults see would actually understand use explanations see http dev mysql com doc mysql en server system variables html passed mysql clients reported passwords enclosed ticks quotes escpecially contain chars remember edit etc mysql debian cnf changing socket location client port socket var run mysqld mysqld sock entries specific programs following values assume least 32m ram formally known safe mysqld versions currently parsed mysqld safe socket var run mysqld mysqld sock nice mysqld basic settings user mysql pid file var run mysqld mysqld pid socket var run mysqld mysqld sock port basedir usr datadir var lib mysql tmpdir tmp lc messages dir usr share mysql lc messages en us skip external locking instead skip networking default listen localhost compatible less secure bind address fine tuning max connections connect timeout wait timeout max allowed packet 16m thread cache size sort buffer size 4m bulk insert buffer size 16m tmp table size 32m max heap table size 32m myisam replaces startup script checks myisam tables needed first time touched error make copy try repair myisam recover backup key buffer size 128m open files limit table open cache myisam sort buffer size 512m concurrent insert read buffer size 2m read rnd buffer size 1m query cache configuration cache tiny result sets fit query cache query cache limit 128k query cache size 64m write intensive setups set demand query cache type demand logging replication location gets rotated cronjob aware log type performance killer enable log runtime general log file var log mysql mysql log general log error logging goes syslog due etc mysql conf mysqld safe syslog cnf want know network errors log warnings enable slow query log see queries especially long duration slow query log slow query log file var log mysql mariadb slow log long query time log slow rate limit log slow verbosity query plan log queries using indexes log slow admin statements following used easy replay backup logs replication note setting replication slave see readme debian settings may need change server id report host master1 auto increment increment auto increment offset log bin var log mysql mariadb bin log bin index var log mysql mariadb bin index fab performance safer sync binlog expire logs days max binlog size 100m slaves relay log var log mysql relay bin relay log index var log mysql relay bin index relay log info file var log mysql relay bin info log slave updates read applications support stricter sql mode prevents mistakes like inserting invalid dates etc sql mode engine substitutiontraditional innodb innodb enabled default 10mb datafile var lib mysql read manual innodb related options many default storage engine innodb cant change log file size requires special procedure innodb log file size 50m innodb buffer pool size 20g innodb log buffer size 8m innodb file per table innodb open files innodb io capacity innodb flush method direct security features read manual want chroot chroot var lib mysql generating ssl certificates recommend openssl gui tinyca ssl ca etc mysql cacert pem ssl cert etc mysql server cert pem ssl key etc mysql server key pem mysqldump quick quote names max allowed packet 16m mysql auto rehash faster start mysql tab completition isamchk key buffer 16m important additional settings override file files must end cnf otherwise theyll ignored includedir etc mysql conf contents inno variables mariadb none show variables like inno variable name value innodb adaptive flushing innodb adaptive flushing lwm innodb adaptive hash index innodb adaptive hash index partitions innodb adaptive max sleep delay innodb additional mem pool size innodb api bk commit interval innodb api disable rowlock innodb api enable binlog innodb api enable mdl innodb api trx level innodb autoextend increment innodb autoinc lock mode innodb buffer pool dump shutdown innodb buffer pool dump innodb buffer pool filename ib buffer pool innodb buffer pool instances innodb buffer pool load abort innodb buffer pool load startup innodb buffer pool load innodb buffer pool populate innodb buffer pool size innodb change buffer max size innodb change buffering innodb checksum algorithm innodb innodb checksums innodb cleaner lsn age factor high checkpoint innodb cmp per index enabled innodb commit concurrency innodb compression failure threshold pct innodb compression level innodb compression pad pct max innodb concurrency tickets innodb corrupt table action assert innodb data file path ibdata1 12m autoextend innodb data home dir innodb disable sort file cache innodb doublewrite innodb empty free list algorithm backoff innodb fake changes innodb fast shutdown innodb file format antelope innodb file format check innodb file format max antelope innodb file per table innodb flush log timeout innodb flush log trx commit innodb flush method direct innodb flush neighbors innodb flushing avg loops innodb force load corrupted innodb force recovery innodb foreground preflush exponential backoff innodb ft aux table innodb ft cache size innodb ft enable diag print innodb ft enable stopword innodb ft max token size innodb ft min token size innodb ft num word optimize innodb ft result cache limit innodb ft server stopword table innodb ft sort pll degree innodb ft total cache size innodb ft user stopword table innodb io capacity innodb io capacity max innodb kill idle transaction innodb large prefix innodb lock wait timeout innodb locking fake changes innodb locks unsafe binlog innodb log arch dir innodb log arch expire sec innodb log archive innodb log block size innodb log buffer size innodb log checksum algorithm innodb innodb log compressed pages innodb log file size innodb log files group innodb log group home dir innodb lru scan depth innodb max bitmap file size innodb max changed pages innodb max dirty pages pct innodb max dirty pages pct lwm innodb max purge lag innodb max purge lag delay innodb mirrored log groups innodb monitor disable innodb monitor enable innodb monitor reset innodb monitor reset innodb old blocks pct innodb old blocks time innodb online alter log max size innodb open files innodb optimize fulltext innodb page size innodb print deadlocks innodb purge batch size innodb purge threads innodb random read ahead innodb read ahead threshold innodb read io threads innodb read innodb replication delay innodb rollback timeout innodb rollback segments innodb sched priority cleaner innodb show locks held innodb show verbose locks innodb sort buffer size innodb spin wait delay innodb stats auto recalc innodb stats method nulls equal innodb stats metadata innodb stats persistent innodb stats persistent sample pages innodb stats sample pages innodb stats transient sample pages innodb status output innodb status output locks innodb strict mode innodb support xa innodb sync array size innodb sync spin loops innodb table locks innodb thread concurrency innodb thread sleep delay innodb track changed pages innodb undo directory innodb undo logs innodb undo tablespaces innodb use atomic writes innodb use fallocate innodb use global flush log trx commit innodb use native aio innodb use stacktrace innodb use sys malloc innodb version innodb write io threads rows set sec number cores machine intelr xeonr cpu e3 v3 50ghz proc cpuinfo one last note ran queries indexes suggested rolandomysqldba queries took 20s want point crucial main table bulletin board first query threadid returns less second threads google bots constantly crawl threads
75142 straightforward way adapt types mysql queries postgresql setting variables mysql like set aintconst set arealconst seems assigning variables select queries using variables subsequently sql like select pfid id platform bios like intel select clientid id client platformid pfid id grateful pointers especially
75214 error entirety reads psql could connect server file directory server running locally accepting connections unix domain socket tmp pgsql second time setting postgresql via homebrew mac clue going previously working point mustve entered command messed things im sure whenever enter sql command command line receive message ive run command check whether server running apparently attempt start server using postgres usr local pgsql data receive following error postgres access server configuration file usr local pgsql data postgresql conf file directory ive uninstalled reinstalled postgresql via homebrew problem persists im completely loss get working help would appreciated
75335 know numeric decimal data types sql server work syntax creating ranges values store etc however msdn documentation describes relationship two numeric functionally equivalent decimal normally see qualifier functionally equivalent means two things arent exactly two different types indistinguishable outside implication true differences numeric decimal happen behave outside observer actually equivalent numeric legacy synonym decimal
75408 im investigating benefits upgrading ms sql one big selling points sql memory optimized tables apparently make queries super fast ive found limitations memory optimized tables max sized fields maximum 1kb per row timestamp fields computed columns unique constraints qualify nuisances really want work around order gain performance benefits make plan real kicker fact cant run alter table statement go rigmarole every time much add field include list index moreover appears shut users system order make schema changes mo tables live db find totally outrageous extent actually believe microsoft could invested much development capital feature left impractical maintain leads conclusion must gotten wrong end stick must misunderstood something memory optimized tables led believe far difficult maintain actually misunderstood used mo tables kind secret switch process makes practical use maintain
75439 problem instance mysql running mostly database innodb tables exhibiting occasional stalls update operations duration minutes insert update delete queries remaining query end state obviously unfortunate mysql slow query log logging even trivial queries insane query times hundreds timestamp corresponding point time stall resolved query time lock time rows sent rows examined set timestamp insert sessions redirect login2 data hostname fk users primary fk users id sessions timestamp values null null null anonymous 64ef367018099de4d4183ffa3bc0848a device statistics showing increased although excessive load time frame case updates stalling according timestamps statement sar pm dev tps rd sec wr sec avgrq sz avgqu sz await svctm util pm dev8 pm dev8 pm dev8 pm dev8 pm dev8 sar pm cpu user nice system iowait steal idle pm pm pm pm pm often notice mysql slow log oldest query stalling insert large ish rows table varchar primary key full text search index create table files id files varchar32 null default filename varchar100 null default content text primary key id files key filename filename fulltext key content content engine innodb default charset latin1 investigation show engine innodb status shown indeed always update table using full text indexes causing stall respective transactions section show engine innodb status entries like two oldest running transactions transaction active sec sync index lock structs heap size row locks undo log entries table lock table vw fts 000000000000224a 00000000000036b9 index trx id lock mode ix table lock table vw fts 000000000000224a 00000000000036b9 index trx id lock mode ix table lock table vw fts 000000000000224a 00000000000036b9 index trx id lock mode ix table lock table vw fts 000000000000224a 00000000000036b9 index trx id lock mode ix table lock table vw fts 000000000000224a 00000000000036b9 index trx id lock mode ix table lock table vw fts 000000000000224a 00000000000036b9 index trx id lock mode ix transaction active prepared sec committing mysql tables use locked lock structs heap size row locks undo log entries mysql thread id os thread handle 0x7fe0e239c700 query id root query end insert files id files filename content values f19e63340fad44841580c0371bc51434 file 70380a686effd6b66592bb5eeb3d9b06 doc table lock table vw files trx id lock mode ix heavy full text index action going sync index stopping subsequent updates table logs seems bit like undo log entries number sync index advancing reaches point operation done fts size specific table quite impressive du fts 000000000000224a 00000000000036b9 fts 000000000000224a 00000000000036b9 index ibd fts 000000000000224a 00000000000036b9 index ibd fts 000000000000224a 00000000000036b9 index ibd fts 000000000000224a 00000000000036b9 index ibd fts 000000000000224a 00000000000036b9 index ibd fts 000000000000224a 00000000000036b9 index ibd total although issue also triggered tables significantly less massive fts data size like one du fts 0000000000003a21 index fts 0000000000003a21 index ibd fts 0000000000003a21 index ibd fts 0000000000003a21 index ibd fts 0000000000003a21 index ibd fts 0000000000003a21 index ibd fts 0000000000003a21 index ibd total time stall cases roughly opened bug bugs mysql com devs could look nature stalls first made suspect log flushing activity culprit percona article log flushing performance issues mysql describing similar symptoms occurrences shown insert operations single myisam table database affected stall well seem like innodb issue nonetheless decided track values log sequence number pages flushed log section outputs show engine innodb status every seconds indeed look like flushing activity ongoing stall spread two values decreasing mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference mon sep cest lsn pages flushed difference spread reached minimum flushing activity seems ceased coinciding end stall points made dismiss innodb log flushing cause flushing operation block updates database needs synchronous means log space occupied would preceded asynchronous flushing phase starting innodb max dirty pages pct fill level seeing lsns keep increasing even stall log activity ceasing completely myisam table inserts affected well page cleaner thread adaptive flushing seems work flush logs without causing dml queries stop numbers log sequence number pages flushed show engine innodb status issue seems somewhat alleviated setting innodb adaptive flushing lwm forcing page cleaner work error log entries coinciding stalls show innodb status excerpts approximately hours operation look like semaphores os wait array info reservation count os wait array info signal count mutex spin waits rounds os waits rw shared spins rounds os waits rw excl spins rounds os waits spin rounds per wait mutex rw shared rw excl latest detected deadlock 7fe0e2e44700 file os file reads os file writes os fsyncs reads avg bytes read writes fsyncs row operations queries inside innodb queries queue read views open inside innodb main thread process id state sleeping number rows inserted updated deleted read inserts updates deletes reads yes database deadlocks infrequent latest handled around hours stats read tried tracking semaphores section values period time especially situation normal operation stall wrote small script checking mysql servers processlist running couple diagnostic commands log output case obvious stall numbers taken different time frames normalized results events second normal stall 1h avg 1m avg os wait array info reservation count signal count mutex spin waits rounds os waits rw shared spins rounds os waits rw excl spins rounds os waits quite sure seeing numbers dropped order magnitude probably due ceased update operations mutex spin waits mutex spin rounds however increased factor investigating list mutexes show engine innodb mutex mutex entries listed normal operation well stall enabled innodb status output locks see going give detail configuration variables ive tinkered without definite success mysql show global variables variable name like innodb adaptive flush variable name value innodb adaptive flushing innodb adaptive flushing lwm mysql show global variables variable name like innodb max dirty pages pct variable name value innodb max dirty pages pct innodb max dirty pages pct lwm mysql show global variables variable name like innodb log variable name value innodb log buffer size innodb log compressed pages innodb log file size innodb log files group innodb log group home dir mysql show global variables variable name like innodb double variable name value innodb doublewrite mysql show global variables variable name like innodb buffer pool variable name value innodb buffer pool dump shutdown innodb buffer pool dump innodb buffer pool filename ib buffer pool innodb buffer pool instances innodb buffer pool load abort innodb buffer pool load startup innodb buffer pool load innodb buffer pool size mysql show global variables variable name like innodb io capacity variable name value innodb io capacity innodb io capacity max mysql show global variables variable name like innodb lru scan depth variable name value innodb lru scan depth things already tried disabling query cache set global query cache size increasing innodb log buffer size 128m playing around innodb adaptive flushing innodb max dirty pages pct respective lwm values set defaults prior changes increasing innodb io capacity innodb io capacity max setting innodb flush log trx commit running innodb flush method direct yes use san persistent write cache setting sys block sda queue scheduler noop deadline
75451 list tables current database together number rows table words think query come something like mysql tables database number rows database database different approaches welcome
75550 fairly new db design development requirement simple drilldown slicing based time language words language particular day however db mysql far luck running kind queries manually calculating data storing tables specific application need show charts graphs iphone users usage words per language per day week month dont need realtime rows one month usage user approx want understand possible mysql warehouse scehemas execute queries without performance issues could options postgres mysql enterprise cubes really cant pay enterprise solutions ready write code kind processing application want migrate correct way guess ideal case would without using tools create fact dimensions current db shift api run olap queries gathered possible mysql postgres showing promise still reading
75821 lets say sqlserver2008r2 higher full recovery mode databases always thought transaction commited commit transaction written transaction log ram checkpoint occurs time transactions criterias transactions last checkpoint current written disk backup log happens datas written mdf file correct collegues says im wrong hard find correct answer even bol thanks
75876 testing purposes need get data set database tables arbitrary reproducible order idea later compare two runs using textual diff tool idiom obviously select table columns order column column asking idiomatic way achieve effect purposes without bothering list every column order clause ordering long reproducible subsequent runs query
75894 per pgsql docs always needed many choices available index declaration foreign key constraint automatically create index referencing columns yet create constraint run table see index fact get created indexes table primary key primary key btree id fki table product foreign key btree product could explain gets created still need create another index product column improve performance queries
75990 sql server multiple databases server used training purposes periodically need cleared fresh start quantities databases small would use adam andersons code remove objects manually change use statement databases id rather looking automate process im trying use sp msforeachdb without luck far suggestions thanks advance declare command nvarcharmax select command exists select sys databases name name like learndb learndb1 learndb2 etc begin declare stmt nvarcharmax declare char1 set char10 select stmt isnull stmt drop procedure schema nameschema id name sys procedures select stmt isnull stmt alter table schema nameschema id object name parent object id drop constraint name sys check constraints select stmt isnull stmt drop function schema nameschema id name sys objects type fn tf select stmt isnull stmt drop view schema nameschema id name sys views select stmt isnull stmt alter table schema nameschema id object name parent object id drop constraint name sys foreign keys select stmt isnull stmt drop table schema nameschema id name sys tables select stmt isnull stmt drop type schema nameschema id name sys types user defined select stmt isnull stmt drop trigger schema nameschema id name sys objects type tf exec sp executesql stmt end exec sp msforeachdb command
76021 inserting less rows table takes minutes however number inserted rows bigger time needed insert data grows hours problem connected query indexes everything working fine long time nothing changed structure query tables indexes problem appeared first time weeks ago appears repeatedly days number inserted rows bigger example one day number inserted rows process takes minutes day number rows takes hours insert data tried rebuild indexes helped
76038 little background recently inherited responsibility support development database application original developers left looking application database appears several issues weekly shrink index plan database account used web application access db owner role foreign keys tables use guid column primary key queries built parameterized bring issues management normally trouble problem less six months sql experience whereas managers former developers working project several years
76091 want change mysql database name db instance amazon rds possible
76130 recommended way back large data sets mongodb lets say data size order 10tb would back considering hidden possibly delayed replica set node delay would protect us accidental drops whole database viable solution options would recommend investigating thanks
76207 im using following code pull top queries ordered cpu select top qs sql handle qs execution count qs total worker time total cpu qs total worker time total cpu seconds qs total worker time qs execution count average cpu seconds qs total elapsed time qs total elapsed time total elapsed time seconds st text qp query plan sys dm exec query stats qs cross apply sys dm exec sql textqs sql handle st cross apply sys dm exec query planqs plan handle qp order qs total worker time desc however im seeing anyone shed light query plan sql text showing null sort system process external application running sql r2 thanks always everyone
76273 database currently running ec2 move bigger machine question using rds came pricing get ec2 c3 large instance two ssds 16gb two vcpus 4gb memory demand per hour closest considering price rds machine would db m3 medium per hour single az machine amount memory one vcpu additionally would pay storage io prices would similar two advantages ec2 mentioned already one vcpu put write ahead log second disc using ec2 great performance improvement writing lot db run pgbouncer ec2 instance performance keep connections open edit configuration file eventually improve performance advantages rds automatically daily backups rds cover advantages ec2 especially advantages
76302 setup mirroring database sql server standard edition tried see data synchronized able check data taking database snapshot since database snapshots available sql server standard edition alternative solutions available verify whether data synchronized
76375 check progress status submit alter index reorganize rebuild
76628 im trying improve performance following query update temptable set received number temptable inner join select agentid ruleid countdistinct groupid number temptable passed group agentid ruleid ruleid temptable ruleid agentid temptable agentid currently test data takes minute limited amount input changes stored procedure query resides probably get modify one query add index tried adding following index create clustered index ix test temptableagentid ruleid groupid passed actually doubled amount time query takes get effect non clustered index tried writing follows effect select agentid ruleid countdistinct groupid number temptable passed group agentid ruleid update temptable set received number temptable inner join ruleid temptable ruleid agentid temptable agentid next tried use windowing function like update temptable set received countdistinct case passed groupid else null end partition agentid ruleid temptable point started get error msg level state line incorrect syntax near distinct two questions first count distinct clause write incorrectly second anyone suggest improvement havent already tried fyi sql server r2 enterprise instance edit link original execution plan also note big problem query run times https onedrive live com redirresid 4c359af42063bd98 edit2 full loop statement requested comments im checking person works regular basis purpose loop declare counting int select counting begin cascading rule check counting begin update w1 set passed temptable w1 temptable w3 w3 agentid w1 agentid w3 ruleid w1 cascaderuleid w3 rulepassed w1 passed w1 notflag update w1 set passed temptable w1 temptable w3 w3 agentid w1 agentid w3 ruleid w1 cascaderuleid w3 rulepassed w1 passed w1 notflag update temptable set received number temptable inner join select agentid ruleid countdistinct groupid number temptable passed group agentid ruleid ruleid temptable ruleid agentid temptable agentid update temptable set rulepassed totalneeded received select counting counting end
76788 im new mysql would like know create database charset utf like navicat create mydatabase seems using kind default charset
76802 want run job every seconds however sql server define interval less seconds job used insert update visitor information segmentation information database tracked google search rows inserted seconds job inserts update table database way schedule using sp job scheduling configuration
76834 isnumeric function unexpected behavior msdn documentation says isnumeric returns input expression evaluates valid numeric data type otherwise returns valid numeric data types include following int bigint smallint tinyint decimal numeric money smallmoney float real also footnote isnumeric returns characters numbers plus minus valid currency symbols dollar sign complete list currency symbols see money smallmoney transact sql okay listed currency symbols expected considered numeric far good odd part first currency symbols linked article numeric including euro currency sign hex 20a0 naira sign hex 20a6 rial sign hex fdfc weird cant seem find version environment dependent however things get weirder others cant explain numeric huh replicaten9 numeric replicaten9 first basic question explains cases importantly though logic behind isnumeric could explain predict cases heres good way reproduce things declare tbl tabletxt nvarchar1000 insert tbl txt values nchar8356 nchar8352 nchar8358 nchar65020 ne n1e ne1 n1e1 n1 n1 replicaten9 replicaten9 replicaten9 replicaten9 select unicodelefttxt firstcharasint lentxt txtlength txt txt isnumerictxt isnumeric tbl run local sql server box get following results firstcharasint txtlength txt isnumeric null 1e e1 1e1
77247 getting error trying create catalog sql server integration services idea missed installation anywhere else catalog backup file program files microsoft sql server dts binn ssisdbbackup bak could accessed make sure database file exist sql server service account able access itmicrosoft sqlserver integrationservices common objectmodel
77298 im running sqlcmd batch file wondering make return errorlevel something goes wrong backup
77376 production sql server server hosting databases want host databases new server new server sql server installed ready want know best convenient way migrate whole data includes security permission users memberships databases one word want exactly copy current sql server new instance new server thankful guide case best regards
77402 another dba company tasked reviewing database design vendor developed us vendor said use kimball basis design note looking arguments kimball vs inmon etc designed mart multiple facts dimensions fairness company never designed single mart always consultants never sent classes anything knowledge warehousing marts dimensional modelling etc based little experience find internet self reading inmons kimballs books trying make way stage set level knowledge come design challenge fact table called claim loss statistics insurance trying capture payments claims rolled monthly level money reserves kind like bank account claims wish see monthly amounts payments biggie wish see account current balance reserves ill give pictorial example say set usd reserves claim gets set aside respects functions kind like bank account october dont pay anything yet business wants see payments reserve balance end october month year payments reserve balance november comes along make payments dollars wish see amounts aggregated reserve balance follows month year payments reserve balance say zero payments december january next year month year payments reserve balance struggle understanding payments part correct rolled monthly level within record rollup want year quarter etc reserves amount different balance business wants see much balance month cant aggregate field would get wonky results somehow strikes wrong cant truthfully say ive modelled enough know enough say know know values fact granularity numbers granularity month standpoint stand one aggregate dollars within month balance correct pushing back design wrong ok fact sense code smell bad design accurate help would appreciated note please dont say way please explain way learn edit well learned initial understanding fact wrong granularity monthly granularity transaction level means within month year ie really financial reporting period multiple payment recovery transactions posted date transaction date prior report business sees also data stored legacy system comes wanted put transactional data one row per reserve monthly balance one row per month learned realize problem much additive vs non additive even semi additive grain suspecting start dba team discussed project team reported attempting put two different grains fact correct either role transactions monthly level allowing payments recoveries monthly reserve balance ie semi additive fact everything would monthly grain need find way break reserve balance transactions preserve transaction level grain need break fact two facts one monthly level reserve balance transaction level payments recoveries reason also couldnt put payments recoveries monthly level monthly level fact depends business needs given learned marking thomas answer correct one however feel discussion started original question still good one others learn leave original portion question intact also intend award bounty nikadams answer taught lot additive non additive semi additive facts corrected lot misunderstandings dimensional modelling
77489 2gb left need remove history table table empty database disk space released database file 320gb
77560 run manual vacuum analyze verbose larger tables major delete insert changes seems work without issue although sometimes tables vacuum job run hours see post similar issues reasoning research found large tables large number dead tuples even running vacuum example stats produced query response record relname example last vacuum last autovacuum tup dead tup av threshold expect av record relname example last vacuum last autovacuum tup dead tup av threshold expect av record relname example last vacuum last autovacuum tup dead tup av threshold expect av last field states tables would meet threshold autovacuum however run vacuum analyze vebose tables shouldnt dead tuple count close 125m 300m documentation states vacuum reclaims storage occupied dead tuples mean vacuum working update per request repsonse logs verbose jobs info vacuuming public example info scanned index idx example gp id dd id remove row versions detail cpu 83s 42u sec elapsed sec info scanned index index example id remove row versions detail cpu 10s 91u sec elapsed sec info example removed row versions pages detail cpu 09s 05u sec elapsed sec info index idx example gp id dd id contains row versions pages detail index row versions removed index pages deleted currently reusable cpu 00s 00u sec elapsed sec info index index example id contains row versions pages detail index row versions removed index pages deleted currently reusable cpu 00s 00u sec elapsed sec info example found removable nonremovable row versions pages detail dead row versions removed yet unused item pointers pages entirely empty cpu 26s 51u sec elapsed sec info vacuuming pg toast pg toast info index pg toast index contains row versions pages detail index row versions removed index pages deleted currently reusable cpu 00s 00u sec elapsed sec info pg toast found removable nonremovable row versions pages detail dead row versions removed yet unused item pointers pages entirely empty cpu 00s 00u sec elapsed sec info analyzing public example info example scanned pages containing live rows dead rows rows sample estimated total rows table shows dead tuples stats tables much lower dead tuples morning either vacuum autovacuum working handful tables output nothing yet still show dead tuples record relname example last vacuum last autovacuum tup dead tup av threshold expect av couple times seen logs indexes get checked seems correspond long running vacuum jobs idea working around record locking dont think writes happening jobs run info vacuuming public example info scanned index index example gsg id dd id remove row versions detail cpu 88s 54u sec elapsed sec info scanned index index example id remove row versions detail cpu 74s 13u sec elapsed sec info example removed row versions pages detail cpu 71s 32u sec elapsed sec info scanned index index example gsg id dd id remove row versions detail cpu 84s 11u sec elapsed sec info scanned index index example id remove row versions detail cpu 46s 70u sec elapsed sec info example removed row versions pages detail cpu 67s 38u sec elapsed sec info index index example gsg id dd id contains row versions pages detail index row versions removed index pages deleted currently reusable cpu 00s 00u sec elapsed sec info index index example id contains row versions pages detail index row versions removed index pages deleted currently reusable cpu 00s 00u sec elapsed sec info example found removable nonremovable row versions pages detail dead row versions removed yet unused item pointers pages entirely empty cpu 49s 13u sec elapsed sec info vacuuming pg toast pg toast info index pg toast index contains row versions pages detail index row versions removed index pages deleted currently reusable cpu 00s 00u sec elapsed sec info pg toast found removable nonremovable row versions pages detail dead row versions removed yet unused item pointers pages entirely empty cpu 00s 00u sec elapsed sec info analyzing public example info example scanned pages containing live rows dead rows rows sample estimated total rows
77639 according official microsoft bol dense rank nondeterministic rank according ranking functions itzik ben gan rank dense rank functions always deterministic right found far microsofts definition deterministic functions always return result time called specific set input values given state database set theory tables employees employee salary sue right robin page phil factor employees2 employee salary phil factor sue right robin page ranking functions return different values create table dbo employees id int identity11 null employee varchar null salary smallmoney null primary go create table dbo employees2 id int identity11 null employee varchar null salary smallmoney null primary insert dbo employees employee salary values sue right robin page phil factor go insert dbo employees2 employee salary values phil factor sue right robin page go select rank order salary rank dense rank order salary dense rank employee dbo employees select rank order salary rank dense rank order salary dense rank employee dbo employees2 select ntile3 order salary employee dbo employees select ntile3 order salary employee dbo employees2
77664 im running sql server select results one even mor confusing declare int declare decimal3826 declare decimal3826 select power1 power1 select power1 power1 first select gives correct result second one truncates result
77894 way force users take full backup copy dont interfere differential backups developers need take backups every dont always remember use copy option move backup away causes issues
77935 rebuild clustered index table 15gb data datasize shrunk 5gb kind data removed data size mean data column dbcc sp spaceused rebuild clustered index name rows reserved data index size unused ledgerjournaltrans kb kb kb kb rebuild clustered index name rows reserved data index size unused ledgerjournaltrans kb kb kb kb tsql rebuild use dax5test go alter index 212recid dbo ledgerjournaltrans rebuild partition pad index statistics norecompute allow row locks allow page locks online sort tempdb data compression page fillfactor go
78061 im making single call sql server database high latency network table locks occur due latency say query table records sql server return data slow network read lock table server sends response network sql server release lock sending response also would answer vary based size response return kb vs several hundred mb would make difference creating explicit transaction running queries closing transaction would obviously cause tables lock since duration transaction correlated latency
78196 following set sql server linked sql server linked sql server question query sql server sql server via sql server unfortunately several restrictions use openquery use views server would many theyd maintained create link server server due firewalling issues servers ms sql servers
78242 huge postgresql database many tables 100m entries per table database basically read fill necessary tables build indexes write operations db single user access run benchmark multiple queries localhost since db used research purposes queries always use join integer db fields probably buy ssd 512gb purpose used ssd db anything afraid put entire db ssd indexes particular advice tutorial required tuning postgresql ssds note good workstation i7 32gb ram perhaps offer advice
78265 command generate random integers select generate series 116384random int id want generate sets integers set must integer identifier something like end first set random numbers end second set random numbers possible sql command write function
78323 trying compress tables nvarcharmax fields unfortunately row page compression desire impact mb saved gb table also able apply column store column store archival compressions support compression nvarcharmax fields anyone tell alternatives also guess row page compression effect content nvarcharmax columns unique
78341 currently using ssis way user view execution reports ssis catalog without ssis admin sysadmin production environment dont want people manipulate ssis catalog projects thanks
78564 trying copy database sql server sql server using copy wizard local machine sql server installed wizard detecting destination server source db network destination local machine select destination server local machine getting error title copy database wizard destination server sql server later express instance copy database wizard support source earlier sql server error message says destination destination sql server source sql server
78569 database sql azure want create database diagram dont want install sql server copy database etc way anyone knows
79980 table t0 postgres db data looks something like t1 id t2 id null null null query return desired results t1 id t2 id null null query looks something like select distinct t2 id t1 id t2 id t0 t2 id null union select distinct t1 id t1 id t2 id t0 t2 id null faster way operation like bad im several places joins repeated queries seems slow stuff bit seems like must better way heres query fiddle form http sqlfiddle com d41d8
80140 table several columns want select select name name name foo bu instead want combine results single column example union select name name foo union select name name foo union select name name foo elegant way operation
80264 ive tasked discovering instances sql server running within domain several cases multiple instances per server ive seen two different powershell methods finding instances neither seem find instances use wmi srvr new object typename microsoft sqlserver management smo wmi managedcomputer computername instances srvr foreach object serverinstances select name fullname expression computername name return instances use remote registry get sqlinstance1 biggest problem im running servers know running sql server wmi provider allowing remote registry third method use remote desktop access servers im looking approximately machines would like avoid manual steps possible needs work sql server higher would nice know sql server services ssis ssas ssrs main focus sql server
80374 simple script gets four random numbers joins back get matching database id number run script left join get four rows back every time expected result however run inner join get varying number rows sometimes two sometimes eight logically shouldnt difference know rows database ids exist sys databases selecting random number table four rows opposed joining never four rows returned happens sql server causing inner join return varying numbers rows works expected always four rows select rando randomnumber database id select abschecksumnewid randomnumber sys databases database id rando left join sys databases rando randomnumber database id returns varying number rows select rando randomnumber database id select abschecksumnewid randomnumber sys databases database id rando inner join sys databases rando randomnumber database id also returns varying number rows rando select abschecksumnewid randomnumber sys databases database id select randomnumber database id rando inner join sys databases randomnumber database id
80514 technically null null false logic null equal null nulls distinct shouldnt imply nulls unique unique index allow number nulls
80618 started working existing sql server database system fields stored text except ids fields varchar phone numbers zip codes dates addresses monetary values etc learned build database asked collegues said easier way bad practice keep fields varchar could argue changed
80695 need delete rows given table table contains millions records master database replicated several slaves wish without creating replication lag impacting performance research tried dropping table took quite long seconds time master db locked know gradually delete smaller batches wondering theres quicker way thanks
80710 optiona tablea tablea id pkint tableb tableb id pkint tablec tablec id pkint tabled tablea id fk int tableb id fk int tablec id fk int nullable composite key tablea idtableb idtablec id thinking design tabled following optionb tabled tablea id fk int tableb id fk int tablec id varcharmax nullable remove composite key tablec id column something like application need use tabled search value tableb id tablec id column giving key value tablea id wondering option better performance
80817 migrate database one column type image would like export binary files file system one file record sql server
80951 introduction relevant information following example illustrates problem face animal race cat dog cat either siamese persian dog german shepherd labrador retriver animal strong entity race attribute one two offered values cat dog values complex added type dog cat illustrate problem also cats dogs name bunch stuff problem dont know create relational tables example efforts solve problem tried draw er diagram using chens notation represents problem beginner dont know right got apologize drew something wrong please correct case dont wish simply get free solution also learn deal problem solve future thing comes mind create two separate tables one cats one dogs also race attribute animal table would store cat dog value something like animal animal id race attributes cat cat id animal id breed dog dog id animal id breed really bad feeling solution fear wrong hence question questions transform example er diagram transform er diagram relational tables info required leave comment update post soon possible also feel free add appropriate tags since fairly new thank
81011 behaviour would postgresql display example script called begin select foo insert fooname values bar begin point interest end would postgresql discard second begin would commit implicitly decided run begin end block end separate transaction
81035 java use joda time get seconds day int value despite date date second day date second day date second day way postgressql
81065 wondering would possible use partition clause order avoid using sub select example declare table id int code char2 descriptor int insert select a1 union select a1 union select a1 union select b1 union select b1 union select b1 union select b2 union select b2 union select b2 union select c4 union select c4 union select c4 union select c7 union select c7 union select c7 select code select mincode id id want see records code equal a1 b1 c4 partition assign b2 c7 codes etc end could say row number instead using sub query
81094 im trying find information postgresql user defined functions procedural languages performance real time tasks compare builtin functions difference overhead postgres call manage plpython vs plpgsql vs pllua functions im interested postgres integration context data transfer side vm context big overhead use realtime data mapping lets say queries benefit writing user defined functions plpgsql pg language documentation enumerate advantages think apply postgresql procedural languages related findings speed pl languages atypical usage postgresql function language performance vs pl pgsql
81245 built function stored procedure query helpful retrieve information size mytable sql server database
81277 trying deploy sql clr function using httputility urldecode method system web cant get deploy error received net sqlclient data provider msg level state line assembly system web version culture neutral publickeytoken b03f5f7f11d50a3a found sql catalog function part ssdt project using system using system web using system data using system data sqlclient using system data sqltypes using microsoft sqlserver server public partial class userdefinedfunctions microsoft sqlserver server sqlfunctionisdeterministic true public static sqlstring udf urldecodesqlstring encodedxml string decodedxml decodedxml httputility urldecodeencodedxml tostring return new sqlstringdecodedxml relation thread sql server vs2012 ssdt database project tried target frameworks eg also tried create assembly system web add assemblies eg microsoft build system xaml also fail see system web list supported libraries ideas
81310 one please explain simple terms overlapping candidate key overlapping name suggests consider relation rlmnop mn functional dependency bringing overlapping candidate key relation lets restrict discussion dependencies im interested bcnf moment
81311 looking database came across table used primary key foreign key ive seen table foreign key build hierarchy structure would use another column reference primary key since primary key unique situation wouldnt row able point back seems tautological link since already row already row reason would done certain constraint written way looking diagram table column used halves definition
81369 could select grams ie substrings length string using sql example grams string example exa xam amp mpl ple im using postgresql precise
81388 know cycle current error log easily running sp cycle errorlog im wondering sql server ever delete old archived error log files cant seem find answer anywhere
81460 testing table create table public test patient table entity id integer null site held integer null constraint entityid pk primary key entity id create table public test messageq table entity id varchar null master id integer null message body varchar null constraint mq entity id pk primary key entity id create index test patient table siteid idx public test patient table site held alter table public test messageq table add constraint test patient table test messageq table fk foreign key master id references public test patient table entity id delete action update action deferrable test patient data insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values insert test patient table values testing message insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values aaa insert test messageq table values bbb tried find messages message table site interested wrote cte works fine lets say interested site patient msg branches select distinct test messageq table master id patient id test patient table site held site id test messageq table inner join test patient table test messageq table master id test patient table entity id site held order patient id messages patients select test messageq table master id select patient msg branches patient id patient msg branches select messages patients result expected aaa aaa aaa aaa aaa aaa aaa aaa wrap whole thing function returning wrong rows help see drop function getmessagefromsitestext create replace function getmessagefromsitesin ids text returns setof test messageq table declare sites int result test messageq table rowtype begin sites string arrayids raise info entire array sites patient msg branches select distinct test messageq table master id patient id test patient table site held site id test messageq table inner join test patient table test messageq table master id test patient table entity id site held anysites order patient id messages patients select test messageq table master id select patient msg branches patient id patient msg branches select result messages patients return query select result end language plpgsql using function select getmessagefromsites1111122222 select getmessagefromsites1 select getmessagefromsites33333 always returns result multiple rows obviously wrong rows help aaa aaa aaa aaa aaa aaa aaa bbb solution thanks horse name two working solutions one sql one pl pgsql solution pl pgsql create replace function getmessagefromsitesin ids text returns setof test messageq table declare sites int result test messageq table rowtype begin sites string arrayids raise info entire array sites return query patient msg branches select distinct test messageq table master id patient id test patient table site held site id test messageq table inner join test patient table test messageq table master id test patient table entity id site held anysites order patient id messages patients select test messageq table master id select patient msg branches patient id patient msg branches select messages patients end language plpgsql solution sql create replace function getmessagefromsites2ids text returns setof test messageq table patient msg branches select distinct test messageq table master id patient id test patient table site held site id test messageq table join test patient table test messageq table master id test patient table entity id site held string array int messages patients select test messageq table master id select patient msg branches patient id patient msg branches select messages patients language sql testing code select getmessagefromsites1111144444 select getmessagefromsites22222 select getmessagefromsites1 select getmessagefromsites33333 select getmessagefromsites211111 select getmessagefromsites222222 select getmessagefromsites233333 select getmessagefromsites4444411111 select getmessagefromsites1 pg stored procedure working expected solution better simplified solution see erwins answer case closed
81552 sql server r2 full installation adding another instance database engine machine thought quick installation sql server copying registering files new instance please clarify
81595 looking properties particular login possible see list users mapped login profiled sql server management studio ssms see ssms connects every database one time retrieves information sys database permissions possible write single query retrieves user mapping information shown forced use cursor sp msforeachdb something like
81607 hi working script update statistics tables dbs idea parametrise later quick fix wanting implement olas scripts today follow script tested servers schedule run live server sunday morning would like get ideas share set nocount declare dbs table int null identity11 primary key clustered dbname sysname null declare int int sql varchar1008 int int mydb sysname insert dbs select name sys databases inner join sys master files database id database id data space id state online database id exclude master tempdb model left msdb read read write user access multi user name tablebackups troubleshooting order size desc select rowcount select begin begin try drop table end try begin catch end catch create table int null identity11 primary key clustered mysql varchar1008 null select mydb quotename dbname sql use quotename dbname char13 char13 insert tmysql select update statistics quotenamename sys tables type char13 dbs print cast sql ntext begin try exec sql select rowcount end try begin catch select end catch select begin select sql use mydb char13 mysql begin try exec sql end try begin catch end catch print cast sql ntext select end select end
81631 large 6db trace table clustered key datetime created getdate connection pool connections database table rises high average across cluster computers average concurrent connections attempting insert database fits memory hardly io seen trying figure whether sustained insert load clustered index gets point rebalances tree whether cause slowdown number inserts system sustain question mind whether rebalancing index something sql server clustered index even non clustered index questions reasons periodic cyclic slow insert performance rebalance operations automatically trigger clustered indexes rebalance operations automatically trigger non clustered indexes info sql server really big server 256gb cores 40mbit lan
82000 lock pages memory right granted service account used sql server allows sql server prevent memory paged disk ive noticed several sql server machines local policy configured allow right service account used sql server since large number servers tedious best manually check one using local system policy management console sql query extended stored procedure method use determine server question right would like use exec xp readerrorlog lock memory privilege granted since relies checking current sql server error log error log may contain relevant entry assuming log rolled since server last restarted realize could check older logs modify first parameter etc however retain error logs may enough want fail safe way confirming setting
82094 know replace function bug char0 column nvarchar128 nchar0x0000 characters bad import im using sql server r2 collation column sql latin1 general cp1 ci tried stuff online possibly find nothing get stinking char0 characters column heres latest attempt baffling bug sql server results function loops char replaces 0x0000 specific char alter function dbo replacecharzero teststring nvarcharmax chartoreplacewith nchar1 returns nvarcharmax begin declare int fixedstring nvarcharmax len teststring begin substring teststring char0x00 begin print found cast varchar set fixedstring fixedstring chartoreplacewith end else begin print found cast varchar set fixedstring fixedstring substring teststring end set end return fixedstring end heres test begin tran declare shortdescription nvarchar128 supplierid int language char2 select top shortdescription shortdescription supplierid supplierid language language supplier multilingual shortdescription like char0x00 set shortdescription replacedbo replacecharzero shortdescription update dbo supplier multilingual set shortdescription null supplierid supplierid language language update dbo supplier multilingual set shortdescription dbo replacecharzero shortdescription supplierid supplierid language language select supplier multilingual supplierid supplierid language language shortdescription like char0x00 rollback tran test grab column variable run function strip 0x0000 update original column null update fixed variable run query see 0x0000 chars still exist
82161 trying run following command sshpass pass ssh pg dump fc foo db pg restore create dbname new db get failed fatal database new db exist
82304 users database member db datareader also need execute permissions stored procedures wondering would happen one stored procedures issue ddl would able make schema changes tables drop etc stored procedure thank
82414 run nodetool repair every node cluster need run one node cassandra take care rest
82573 database admin sql foo good yet tasks get done mssql one rather time intensive procedure fetch cursor fetch status multiple selects update giant tables procedure works ive checked colleague script program id simple print current cursor print counter every feedback could something like mssql working microsoft sql server enterprise edition v9 sql server service pack could print current cursor would go case edit ive tested raiseerror following statements declare cur id int set cur id declare cur cursor select id tablea id order id desc open cur fetch next cur cur id fetch status begin raiserror cur id nowait fetch next cur cur id end leads time waiting without output endless wall assume one every raiserror msg level state line error severity state raised message error number found sys messages error larger make sure user defined message added using sp addmessage
82604 found table looks like create table dbo table1 id int primary key identity iduser int null amount int null attempts int null date datetime null sum amount int null primary table created populated aggregated data particular period job particularities table hold million rows iduser unique sum amount running total previous rows amount table last update delete insert operation type queries select top table1 order sum amount desc attempts desc select top table1 sum amount order sum amount asc think improve preformance change clustered index like create table dbo table2 id int identity iduser int null amount int null attempts int null date datetime null sum amount int null constraint pk nueva primary key clustered sum amount desc attempts desc id asc primary read using unique clustered index add bytes hidden column http msdn microsoft com en us library ms190639v sql aspx decide add identity cluster index sure right approach want ask risk sound ridiculous need sure could improved impact disk size rebuild index data inserted edit id think bad habit ill kept sure previous job calculate running total ive access lot tables like like hundreds daydont ask dba team ask create new index size issues thinking rearrange table structure via clustered index also changing data types exceeds normal ranges
82824 looking sql server logs come across following informational message instance sql server using process id since utc information message user action required message generated last three days see process id using activity monitor something may cause highlight problem need look
82921 one insert script written following insert tablename column1 column2 values value1 value2 value1 value2 following error facing parsing insert statement msg level state line number row value expressions insert statement exceeds maximum allowed number row values simple question change values limit
83125 huge gb sql dump need import mysql havent import huge sql dump usual mysql uroot dbname dbname sql taking long table around million rows gotten million around hours seems whole thing would take hours thats days impractical question faster way info findings tables innodb foreign keys defined however many indexes access original server db make new back hot copy etc setting innodb flush log trx commit suggested seems make clearly visible exponential improvement server stats import mysql workbench https imgflip com gif ed0c8 mysql version community innodb buffer pool size 16m innodb log buffer size 8m need increase
83164 understand upon installation postgresql password db root user postgres postgres select usename passwd null pg shadow usename column postgres row one advised set alter role postgres password secret update pg hba conf file accordingly question sql use revert back previous situation password needed user postgres general remove password requirement role asking change password rather remove password requirement null passwd column table pg shadow
83421 kind trivial task homeworld dont yet make sql would prefer solve set based without cursors resultset come query like select someid mydate dbo udflasthitrecursiveparam1 param2 mydate qualifying work send three params udf udf internally use params fetch related days older rows view udf traverse mydate return included total calculation return named qualifying udf list rows date order calculate days rows first row resultset defaults hit difference pass next row sum gaps days 90th day must pass reached set hit reset gap would also work instead omit row result column udf work yet date calc date maxdiff qualifying table maxdiff column gap date previous line problem attempts far cant ignore second last row sample edit per comment add tag also paste udf compiled though placeholder wont give useful result cte someid otherkey mydate cost select someid otherkey mydate cost dbo vgetvisits someid someid visitcode otherkey otherkey convertdatemydate visitdate union select top someid otherkey mydate cost dbo vgetvisits convertdate mydate dateadddd 90convertdate visitdate convertdate visitdate someid someid visitcode otherkey otherkey convertdatee mydate visitdate order mydate another query define separately close need blocked fact cant calculate windowed columns also tried one similiar give less output lag mydate surrounded datediff select mydate visitcode cost someid otherkey maxdiff datediff select maxdiff last valuediff diff order diff mydate asc rows unbounded preceding current row select diff isnulldatediffday last valuer mydate order mydate asc rows preceding preceding mydate0 datediff isnulllast valuer mydate order mydate asc rows preceding preceding mydate dbo vgetvisits visitcode someid someid otherkey otherkey diff visitcode someid someid otherkey otherkey diff order mydate asc
83984 hello trying run website sent error appeared connect postgresql server fatal pg hba conf entry host 4x xxx xx xxx user userxxx database dbxxx ssl xampp htdocs xmastool index php line googling says need add entry pg hba conf file particular user pg hba conf file type database user address method ipv4 local connections local dbxxx userxxx md5 host dbxxx userxxx xx xxx xxx xxx md5 host md5 ipv6 local connections host md5 allow replication connections localhost user replication privilege host replication postgres md5 host replication postgres md5 error still persist restarted xampp server several times changes appears thanks advance
84090 im writing upcoming blog post mine ranking aggregate window functions specifically segment sequence project iterators way understand segment identifies rows stream constitute end beginning group following query select row number partition somegroup order someorder use segment tell row belongs different group previous row sequence project iterator actual row number calculation based output segment iterators output following query using logic shouldnt include segment theres partition expression select row number order somegroup someorder however try hypothesis queries use segment operator difference second query need groupby segment doesnt eliminate need segment first place example create table dbo sometable somegroup int null someorder int null somevalue numeric8 null primary key clustered somegroup someorder query select row number partition somegroup order someorder dbo sometable query select row number order somegroup someorder dbo sometable
84204 one stupid app rely hardcoded connection string inside increase security sql server id love make sql users one hardcoded inside app want allow user able use sql server certain host ip address
84297 want get rows value null value null particular username column rows null particular username values null appear output two rows username null value appear example sample output done using sql query username col2 abc ef null null der null output username col2 der null
84333 known fact dmvs dont hold accurate information regarding number pages count rows however stats updated cant see wouldnt working monitoring tool want know disk size index data etc eventually would like find right fill factor things etc space used function old sp spaceused differs little bit space usage record count see anything missing select sp spaceused convert numbers mb sp spaceused tblborderrelationship go select reserved data index size unused run select code picture get slightly different figures set transaction isolation level read uncommitted select schema namet schema id schemaname name tablename type desc ms shipped published lob data space id filestream data space id replicated replication filter merge published sync tran subscribed filetable name indexname type desc unique primary key unique constraint fill factor padded sump rows partition object idi index id rowcounts suma total pages partition object idi index id totalpages suma used pages partition object idi index id usedpages suma data pages partition object idi index id datapages suma total pages partition object idi index id totalspacemb suma used pages partition object idi index id usedspacemb suma data pages partition object idi index id dataspacemb sys tables inner join sys indexes object id object id inner join sys partitions object id object id index id index id inner join sys allocation units partition id container id name like dt object id name tblborderrelationship figures bigger picture including index names calculations check results figures sp spaceused select reserved data index size unused figures select select reserved data index size far really apart fact calculate unused space make accurate changes replaced results much accurate noticed records inserted table question obviously stats date still results match mb difference right new result sets figures sp spaceused select reserved data index size unused go figures select select reserved data index size
84434 possible update primary key column value cascading update among foreign keys referencing edit run followinq query select sys foreign keys referenced object id object idmytable see update referential action set thus action taken updating primary keys columns update foreign keys make cascade update edit order script creation dropping foreign keys schema run following script taken declare schema name sysname declare table name sysname declare constraint name sysname declare constraint object id int declare referenced object name sysname declare disabled bit declare replication bit declare trusted bit declare delete referential action tinyint declare update referential action tinyint declare tsql nvarchar4000 declare tsql2 nvarchar4000 declare fkcol sysname declare pkcol sysname declare col1 bit declare action char6 declare referenced schema name sysname declare fkcursor cursor select object schema nameparent object id object nameparent object id name object namereferenced object id object id disabled replication trusted delete referential action update referential action object schema namereferenced object id sys foreign keys order open fkcursor fetch next fkcursor schema name table name constraint name referenced object name constraint object id disabled replication trusted delete referential action update referential action referenced schema name fetch status begin action create set tsql alter table quotename schema name quotename table name drop constraint quotename constraint name else begin set tsql alter table quotename schema name quotename table name case trusted check else nocheck end add constraint quotename constraint name foreign key set tsql2 declare columncursor cursor select col namefk parent object id fkc parent column id col namefk referenced object id fkc referenced column id sys foreign keys fk inner join sys foreign key columns fkc fk object id fkc constraint object id fkc constraint object id constraint object id order fkc constraint column id open columncursor set col1 fetch next columncursor fkcol pkcol fetch status begin col1 set col1 else begin set tsql tsql set tsql2 tsql2 end set tsql tsql quotename fkcol set tsql2 tsql2 quotename pkcol fetch next columncursor fkcol pkcol end close columncursor deallocate columncursor set tsql tsql references quotename referenced schema name quotename referenced object name tsql2 set tsql tsql update case update referential action action cascade set null else set default end delete case delete referential action action cascade set null else set default end case replication replication else end end print tsql action create begin set tsql alter table quotename schema name quotename table name case disabled check else nocheck end constraint quotename constraint name print tsql end fetch next fkcursor schema name table name constraint name referenced object name constraint object id disabled replication trusted delete referential action update referential action referenced schema name end close fkcursor deallocate fkcursor generate drop foreign keys script modify action value equal drop declaration clause declare action char6 drop
84607 particular table add key mysql alter table tasks add key fruitful user count user id fruitful error hy000 incorrect key file table tasks try repair googling issue seems problem often either configuration issue disk space issue fact database running amazon rds instance means basically managed server dedicated mysql standard configuration also disk allocated us full considering perhaps disk vm powered xen believe full allocated disk space likely even room network storage rebooted rds instance hope would get new instance another vm however help next troubleshooting step table mysql show create table tasks table create table tasks create table tasks user id char32 null module id int11 null default successful tinyint1 default null fruitful tinyint1 default null last run timestamp null default current timestamp update current timestamp last pulled timestamp null default primary key user idmodule id key phone scrapes user user id key phone scrapes module module id key urgency last pulledlast run key successful user count user idis successful key successful successful key fruitness fruitfulis successful constraint tasks ibfk foreign key user id references users id constraint tasks ibfk foreign key module id references modules id engine innodb default charset utf8 row set sec
84801 got bitten feature recently hstore column uninitialized start adding entries silently swallowed without error expected create table test hstoreid int map hstore insert test hstoreidmap values0 insert select test hstore id map update test hstore set map map hstorekey1 value1 id update select test hstore id map key1 value1 update test hstore set map null id update select test hstore id map null update test hstore set map map hstorekey1 value1 id update select test hstore id map null null constraint column safeguard something like thatthis doesnt actually work update test hstore set map map null hstorekey1 value1 else map hstorekey1 value1 id
84833 query yesterday intended page results first page results query returned records instead expect changing query way resulted records meant execution plan issue im familiar way view execution plan production running query sql studio didnt result problem probably due minor differences read suggestions thing could caused corrupted index ran checkdb database found errors end cleared execution plans well wasnt corruption issue kind problem specific execution plan mean simply error execution plan hitting bug sql server sql server rtm updates looked documentation fixes cumulative updates service packs none issues appeared related ideas thoughts could cause p1 varchar8000 p2 bit p3 varchar8000 p4 bit p5 varchar8000 select select top row number order addeddate desc row id prefix firstname lastname company address city state zip country workphone homephone mobilephone email mailinglists addeddate awaitingoptin optindate processed processeddate deleted source grrecid databaseid select count tablea left outer join tableb tablea grrecid tableb grrecid tablea accountid p1 tablea email tablec email tablea deleted p2 matches tablec accountid p3 processed p4 deleted source p5 row row order row
86263 writing large multi step cte performance reasons one query data must moved one table another quantity rows moved uncertain could zero subsequent table origin previous query deleted must previous query completed finally rows must written place deleted rows second query completed first two queries using returning enforce execution order second query im determining first query completed subquery select count first query third query im determining second query completed subquery select exists select second query subquery determine first query completed correct subquery determine second query must return rows completed optimal accuracy precision performance using subqueries enforce execution order giving duplicate key value violations query subsection copy table insert table column column select column column main table column bigint returning main table deleted delete main table column bigint select count copy table returning insert main table column column select column column another table column bigint exists select main table deleted final query violating unique constraint
86274 ive got big table 9m rows want group rows field containing year far thats pretty easy greatly simplified select count year dataset group year order defined irregular time periods spanning multiple years ive got clue group results group clause could make subquerys every time period select select count dataset year pre1945 period2 dataset feels right im wondering possible let postgresql especially query strong simplification real query multiple conditions amongst st within clause spanning four tables choosing subquery approach results bloated query better way create result
86312 playing around db projects visual studio generated change script following lines go set ansi nulls ansi padding etc set numeric roundabort go setvar databasename foo setvar defaultfileprefix foo setvar defaultdatapath setvar defaultlogpath go error exit go setvar issqlcmdenabled true go issqlcmdenabled like ntrue begin print nsqlcmd mode must enabled successfully execute script set noexec end go use databasename go create nonclustered index someindex dbo sometable somecolumn asc go significance colons beginning lines stackoverflow question says colon bind variables colon error exit
86313 trying run simple query get rows created november select count dbo profile created smss returns conversion varchar data type datetime data type resulted range value understand data converted varchar datetime created set datetime need tell server created datetime getting varchar message edit value database yyyy mm dd reply sqlzim says need use convert tell sql format date db replace space character letter select count dbo profile created convertdatetime2014 01t00 convertdatetime2014 30t23
86383 simple query granted much memory demo table create table dbo test tid integer identity null filterme integer null sortme integer null unused nvarcharmax null constraint pk dbo test tid primary key clustered tid go example rows insert dbo test tablockx filterme sortme select top checksumnewid checksumnewid sys columns ac1 cross join sys columns ac2 go query select tid filterme sortme unused dbo test filterme order sortme estimated rows optimizer reserves almost mb sort
86415 often need select number rows group result set example might want list highest lowest recent order values per customer complex cases number rows list might vary per group defined attribute grouping parent record part definitely optional extra credit intended dissuade people answering main options solving types problems sql server later main advantages disadvantages method adventureworks examples clarity optional list five recent recent transaction dates ids transactionhistory table product starts letter inclusive history lines per product five times daystomanufacture product attribute special case exactly one history line per product required single recent entry transactiondate tie break transactionid
86432 using sql server emaintenance plan backup purposes backup database task creates unique filename understand format way final set numbers example full database backup initiated via backup database task would create filename like adventureworks backup bak referencing lsn something else
86526 working stored procedure retrieves objectguid active directory storing result temp table returning value output parameter use processes sp called different stored procedures well web applications php asp classic asp net read regarding temp tables created inside stored procedure destroyed upon completion stored procedure furthermore scope particular temporary table session created meaning visible current user multiple users could create temp table named tablex queries run simultaneously would affect one another would remain autonomous transactions tables would remain autonomous objects may notice sample temporary table name started sign sounds like good go wanted get advice make sure arent gotchas unaware sp thanks advance create procedure stp adlookup user varchar100 objectguid varbinary256 output set nocount declare qry char1000 create table tmp objectguid nvarchar256 set qry select openqueryadsi select objectguid ldap mydomaincontroller com samaccountname user insert tmp exec qry select objectguid castobjectguid varbinary256 tmp drop table tmp set nocount go
86596 update overwhelming response main question interesting responses focused part solve performance puzzle explicit order although ive marked answer already wouldnt surprised even better performing solution original question arose extremely fast solution could find particular problem works without order clause full sql needed produce problem along proposed solution using sql server r2 matters create orders table object idtempdb orders null drop table orders create table orders orderid int null identity11 custid int null storeid int null amount float null create clustered index ix orders storeid amount desc custid add million rows 100k customers orders cte0 select union select rows cte1 select cte0 cte0 rows cte2 select cte1 cte1 rows cte3 select cte2 cte2 rows cte4 select cte3 cte3 rows cte5 select cte4 cte2 rows finalcte select row number order number cte5 insert orders custid storeid amount select custid number storeid number amount randnumber finalcte number set statistics io set statistics time storeid find top customers ordered expensive purchase amount solution without order declare top int select distinct top top custid orders withforceseek storeid optionoptimize top fast logical reads cpu time ms elapsed time ms go solution order declare top int select top top custid orders storeid group custid order maxamount desc optionmaxdop logical reads cpu time ms elapsed time ms uses sort operator go execution plans solution respectively solution gives performance need couldnt get work performance adding kind order clause see solution certainly seems like solution would deliver results order since table one index seek forced thus eliminating possibility using allocation order scan based iam pages questions right guarantee order case without order clause another method force plan fast solution preferably one avoids sorts note would solve exact problem storeid find top customers ordered expensive purchase amount would also still use orders table different indexing schemes would ok
86636 mysql innodb allows us disable doublewrite buffering setting innodb doublewrite databases doesnt seem allow setting tweaked could innodb still able maintain data integrity acid disable doublewrite buffering situations safe turn innodb doublewrite buffer
86724 learning postgresql trying figure create temporary table declaration used place regular table debugging purposes looked documentation create table says values used query gives example documentation values clause linked therein example either wrote simple test follows drop table exists lookup create temp table lookup key integer val numeric values postgresql complaining syntax error near questions fix statement adapt used block thanks advance
86779 possible refresh materialized view incrementally postgresql data new changed consider table materialized view create table graph xaxis integer null value integer null create materialized view graph avg select xaxis avgvalue graph group xaxis periodically new values added graph existing value updated want refresh view graph avg every couple hours values updated however postgresql whole table refreshed quite time consuming next version allows concurrent update still refreshes entire view 100s millions rows takes minutes whats good way keep track updated new values refresh view partially
86802 mysql user want view views want table database ive granted user permissions certain views following grant show view mydatabase awesome view thisuser show grants statement see permissions expected however id like user query views tables related views cant find way seems want user select view select must also granted table wrong deny selectstatement rest tables command line try select got following select mydatabase fordibenforyoutable error select command denied user thisuser localhost table fordibenforyoutable thats want indeed also got denied select view data way make available user views tables
86855 ive recently discussion colleague pushing remove order clauses production query order column primary key lengthy discussion tried explain cant guarantee ordering based primary key final conclusion wasnt going push mssql queries changed still going change db2 queries couldnt immediately find article disproving db2 orders queries primary key currently wondering whether question db2 order query order clause use primary key guarantee data coming ordered correctly without order clause parallel system
87122 newbie databases read around found probably great idea use email address primary key string comparisons slower effects performance complex joins email changes id change foreign keys requires lot effort users table requires every user email address email address unique adding unique index email column suffice afaik unique fields allow null values whereas require every user email address allowing null values something im missing im suppose make email column unique make sure data validation server user enter email address every user one
87145 typical case parameter sniffing causes bad execution plan land plan cache causing subsequent executions stored procedure slow solve problem local variables optimize unknown optionrecompile however also dive query try optimize im trying determine whether given limited time fix problems would like know cost see stick optionrecompile net effect query plan recreated every time query run think need know find cost creating query plan answer question ive googled query ive gone documentation columns dm exec query stats dmv ive also inspected output window ssms actual query plan find info finally ive searched dba se none led answer anyone tell possible ot find measure time needed plan creation
87300 came across following sentence blog post know data helps make right decisions terms data types nullability churn helps long term maintenance goals initial maintenance plans cant figure meant churn find plenty articles talking churn without saying
87317 data warehouse fairly large record count million rows often run queries count records certain dates count records certain flags select isfoo count widgetcount widgets join flags flagid flagid date startdate group isfoo performance isnt awful relatively sluggish perhaps seconds cold cache recently discovered use group indexed views tried something similar following create view testview schemabinding select date flagid count big widgetcount widgets group date flagid go create unique clustered index pk testview testview date flagid result performance first query 100ms resulting view index 100k although row count large range dates flag ids means view contains rows thought perhaps would criple performance writes widget table performance inserts updates table pretty much unaffected far could tell plus data warehouse table updated infrequently anyway seems way good true need careful using indexed views way
87330 im trying better understand conceptually relationship statistics execution plans stored procedure execution correct saying statistics used creating execution plan stored procedure used actual execution context words true plan created assuming properly reused important date statistics particularly motivated article read statistics row estimations ascending date column describes scenario similar one face daily several clients databases ascending date time column one largest tables query regularly using specific stored procedure prevent execution plans growing stale hundred thousand rows added day updating statistics frequently combat issue would make sense use option recompile hint stored procedures query advice recommendations would appreciated update im using sql server sp1
87355 following oracle sql works quite ugly ors concise way select foobar subject stat term subject stat term subject english term subject comm term subject comm term subject stat term
87435 know varcharmax nvarcharmax columns used data stored row data row pointer another location large value stored following questions field stored row max ones using clustered index table read whole record fields stored row read varcharmax nvarcharmax considered large value type large value types usually stored row means
87467 site large simple int int date tables stats table rows gets bigger every day hosting provider suggested split partition tables seen recommendation elsewhere numerous occasions however struggling reconcile advice stated max capacity sql server database size terabytes table rows limited available storage based upon figures table described could easily centillions rows power ah ha might say difference capability performance virtually every question sql server performance answer depends table design query design asking question table design couldnt much simpler could queries simple count operations based indexed id field
87692 way flush ib logfile0 ib logfile1 without dumping tables sql file deleting inserting somebody entered couple plain text credit card numbers customer notes table came pci scan removed table still exist log files
88794 trying examine sql extended events like used sql profiler following event session exists select name sys dm xe sessions name pysoup tracing begin drop event session pysoup tracing server end create event session pysoup tracing server add event sqlserver rpc completed actionsqlserver client app name sqlserver sql text add event sqlserver sp statement completed actionsqlserver client app name sqlserver sql text add event sqlserver sql batch completed actionsqlserver client app name sqlserver sql text add event sqlserver sql statement completed actionsqlserver client app name sqlserver sql text add target package0 event fileset filename nc program files microsoft sql server mssql11 mssqlserver mssql log pysoup tracing xel add target package0 ring bufferset max events limit go alter event session pysoup tracing server state start thought action clause supposed list columns returned event however dont see sqlserver client app name column view event data gui wrong
88942 dont think theres way id like able query value running session currently commit write session parameter havent seen anything performance views anyone know sys view value could retrieved clarification need pull parameter setting another session running independent current session
89031 im trying migrate query oracle sql server query works great oracle select countdistinct partition count mytable error got tried run query sql server use distinct allowed clause anyone know problem kind query possible sql server please advise
89670 someone point ms article blog post explains details alwayson availability group secondary replica catches primary secondary server long downtime tests aag async manual failover read configuration killed secondary instance continuos insert primary started secondary instance minutes aag dashboard turned green almost immediately secondary restart started catch primary number rows became instances transaction log backup done transaction logs done primary test questions size log cache messaging framework etc used keep tran log blocks sent secondary replica structure log cache send queue etc whatever used transport aag replication sizes configured increased similar encrease tran log backup retention period log shipping example backed truncated tran log test secondary replica syncronised primary automatically used find row difference primary secondary apparently tran log truncated bring sync automatic catch process work limitations
89676 datawarehouse context update record fact tables inside etl one thing create nonclustered indexes heaviest queries drop afterwards lead us much less time spent scanning tables queries time spent building indexes low impact minutes bad practice note partition tables right
89760 one tables auto incrementing id field also another field richter code unique constraint seasons field change thats im using primary key programs code load function first thing check richter code field search parameter doesnt return anything goes search id field parameter problem seems truncate value soon encounters alpha character im getting complete garbage query see screenshot example prevent mysql changing query
89815 trying find way figure couple sql databases taken offline checked logs could find info moreover default trace enabled info earlier dba took offline emails written communication find info please suggest thanks
90033 want drop default constraints check constraints unique constraints primary keys foreign keys tables sql server database know get constraint names sys objects populate alter table part
90137 im looking specific best practice pattern concerning entities shared different entities relation one many example one may generic entity address could used store common address fields customers suppliers employees etc would seasoned dba take route would rather add fields corresponding entities im also thinking maintainability constraints may future differ depending entity things like would love get references authoritative established works subject
90258 using pg dump pg restore backup restore postgresql database getting error messages non zero exit status pg restore tried super simple base case outlined still got errors pg restore archiver db error processing toc pg restore archiver db error toc entry schema public postgres pg restore archiver db could execute query error schema public already exists command create schema public steps reproduce install fresh vanilla ubuntu distro im using vagrant vagrant box install postgresql configure allow local connections postgresql user postgres linux user create test database im vagrant vagrant ubuntu trusty psql username postgres postgres psql type help help postgres create database mydb create database postgres vagrant vagrant ubuntu trusty psql username postgres mydb psql type help help mydb create table dataentry bigint create table mydb insert data values1 insert mydb insert data values2 insert mydb insert data values3 insert mydb create backup database like pgpassword postgres pg dump dbname mydb username postgres format custom pg backup dump delete rows data table mydb able tell restored data successfully restore database pgpassword postgres pg restore clean create dbname postgres username postgres pg backup dump data restored pg restore command step exits status shows following output pg restore archiver db error processing toc pg restore archiver db error toc entry schema public postgres pg restore archiver db could execute query error schema public already exists command create schema public warning errors ignored restore ignore running command programmatically need use exit status determine restore failed initially wondered problem put database public default schema reasoned public would created result create option pg restore data restored could conceivably try create schema well since table tried steps table different schema results error messages identical something wrong seeing error
90354 problem definition database server needs transferred datacenter runs microsoft sql server enterprise bit contains two databases 2tb 1tb little downtime would ideal workload databases used net website constantly getting updated available weekend would acceptable though currently use db would remain one use switch new one switch would ideally made changing dns entries point new db server making sure db updated also time taken operation really matter long switch one server downtime kept low approaches considered backup restore done past involved high downtime even though done internal network efficiently internet log shipping far understand approach would minimize downtime configuring master slave transferring exact copy master db slave read mentioned access slave would necessary need way replica master db without data corruption also seems quite efficient terms resources utilization wouldnt impact much master performance might wrong approach feel free correct database mirroring im aware approach seems like valid option need real time sync performance master quite important asynchronous would way go approach chosen options server runs directly bare metal hardware lower level solutions unfortunately option maybe better way get done constraints described databases quite big point hard maintain thats problem versions sql server microsoft sql server enterprise bit transferred network two datacenters probably internet disks sent one site initial sync unfortunately option sort security transfer would ideal best situation give quite good overview needs task hopefully face situation
90482 way export postgres table data json file need output line line like id 1name david id 2name james edit postgres version
90858 running postgresql table fields id name addr n1 ad1 n2 ad2 need move data new table fields like id data name n1 addr ad1 name n2 addr ad2 row json solution select id row jsont data select id name addr myt adds id result well way choose fields need name addr data field
91223 daily task overwrite number development databases using backups associated production databases backups produced maintenance plans production server transferred dev server ftp day run sql statement similar overwrite database restore database database1 disk nd path database1 backup bak file nounload replace stats go time run replace file name correct recent file would like automate somehow minimise chance operator error problem cant control name bak file although format consistent database name date time whatever seven digit number folder usually contain several days worth backups
91247 query gets list posts created people follow follow unlimited number people people follow others style query obvious optimization would cache post ids unfortunately time right explain analyze select post id post actionid post commentcount posts post inner join users user post userid user id left outer join activitylogs activitylog post activitylogid activitylog id left outer join weightlogs weightlog post weightlogid weightlog id left outer join workouts workout post workoutid workout id left outer join workoutlogs workoutlog post workoutlogid workoutlog id left outer join workouts workoutlog workout workoutlog workoutid workoutlog workout id post userid many post private null order post createdat desc limit yields limit cost rows width actual time rows loops nested loop left join cost rows width actual time rows loops nested loop left join cost rows width actual time rows loops nested loop left join cost rows width actual time rows loops nested loop left join cost rows width actual time rows loops nested loop left join cost rows width actual time rows loops nested loop cost rows width actual time rows loops index scan using posts createdat public index posts post cost rows width actual time rows loops filter userid many integer rows removed filter index scan using users pkey users user cost rows width actual time rows loops index cond id post userid index scan using activitylogs pkey activitylogs activitylog cost rows width actual time rows loops index cond post activitylogid id index scan using weightlogs pkey weightlogs weightlog cost rows width actual time rows loops index cond post weightlogid id index scan using workouts pkey workouts workout cost rows width actual time rows loops index cond post workoutid id index scan using workoutlogs pkey workoutlogs workoutlog cost rows width actual time rows loops index cond post workoutlogid id index scan using workouts pkey workouts workoutlog workout cost rows width actual time rows loops index cond workoutlog workoutid id total runtime ms optimized time following relevant indexes gets used create index posts createdat public index public posts using btree createdat desc private null dont get used create index posts userid fk index public posts using btree userid create index posts following index public posts using btree userid createdat desc private null perhaps requires large partial composite index createdat userid private null
91338 started alter table query hours ago recently realized via pg stat activity waiting lock discovered query holding lock table want alter letting go query simple query changing column data type running massive table rather killing process holding onto lock weve decided wed rather kill alter table wrap alter table transaction far understand fact query waiting lock means always waiting lock never changed anything true safe us outright cancel alter table query possible query already modified something cancelling would leave database halfway state kind ps plan cancel using select pg cancel backendpid bad idea please let know
91388 inherited database looking clean speed table contains rows many junk data inserted due error behalf programmer add new optimized indexes converted table myisam innodb looking delete lot rows contain junk data database mysql root access server first running commands adminer phpmyadmin results command running delete tablename columnname like essentially delete anything column begins dash runs minutes view process list gone run select tablename columnname like returns millions rows delete statement completing ps aware date mysql working moving db mysql innodb maybe mariadb xtradb happens looking answer db edit removed see answer
91509 msdn page says reorganize rebuild based amount fragmentation alter index reorganize alter index rebuild online however noticed even really high fragmentation large small tables reorganize works fine fragmentation goes less msdn page say supposed work like drawback missing hidden problem dont rebuild
92117 would like ask question best practice described document http info mongodb com rs mongodb images mongodb performance best practices pdf use multiple query routers use multiple mongos processes spread across multiple servers common deployment co locate mongos process application servers allows local communication application mongos process appropriate number mongos processes depend nature application deployment little bit background deployment lot application server nodes runs one jvm based process stateless restful ws best practice suggests every single application server node runs mongos process means number jvm processes always equals number mongos processes mongos processes connect config servers several mongo shards replica sets within shard even though using sharded deployment really sharding collections fact large number databases spread across shards creation time main use case sharding moment since best practice also suggest appropriate number mongos processes depend nature application deployment started wonder whether usage mongos actually appropriate would better us several dedicated mongos nodes let app servers connect without mongos running locally opinion best approach decide many mongos instances appropriate relation application server instance count size mongodb cluster recently started look cluster management stateless web services mean tools like docker apache mesos kubernetes using docker generally discouraged practice run one process within container considering fact becomes really hard make sure application server container mongos container always co located physical node equal amount processes makes wonder whether best practice still applies cluster architecture described please suggest would better way locate deploy mongos processes architecture
93510 postgres database table foo among things column score ranges want query return total number scores number scores number scores number scores something like following select count total count select foo score low count select foo score mid count select foo score high foo tried got error select count statements ideas im sure theres super simple way postgres cant figure correct terms google
93588 question xtp checkpoint im using sql server database simple recovery model mode also replicated open transactions ive run dbcc opentran returns active open transactions keep getting message whenever try create drop table delete data ive replaced actual database name word database name transaction log database database name full due xtp checkpoint anyone know might happening importantly make stop yes database really simple recovery model mode transaction log truncate automatically incidentally another database full recovery mode thing started returning error transaction log database database name full due xtp checkpoint tried change log growth settings unlimited growth wouldnt let returning error reproduce problem without xtp stuff except filegroup heres http pastebin com jwsieu9u
93823 mysql manual replication scale solutions spreading load among multiple slaves improve performance environment writes updates must take place master server reads however may take place one slaves see setup replication looks relatively simple havent seen application communicate slaves assume application would determine slave read application also know server writes possible application send queries master reads proxied slaves
94545 hi everyone thanks help following situation table called statements contains fields idint stmnt datedate debitdouble creditdouble balancedouble want calculate balance following rules first row balance chronologically debit credit rest rows current row balance chronologically previous row balance current row debit current row credit see picture rows arranged date thats used word chronologically twice emphasize importance stmnt date value thank much help
94552 doesnt restore operation work created dumpfile database using mysqldump root databasename home databasename bkup sql opened dumfile confirmed contains create table statements tables database dropped database created empty database name running following restore command mysqldump root databasename home databasename bkup sql restore command resulted following printing terminal mysql dump distrib linux x86 host localhost database databasename server version set old character set client character set client set old character set results character set results set old collation connection collation connection set names utf8 set old time zone time zone set time zone set old unique checks unique checks unique checks set old foreign key checks foreign key checks foreign key checks set old sql mode sql mode sql mode auto value zero set old sql notes sql notes sql notes set time zone old time zone set sql mode old sql mode set foreign key checks old foreign key checks set unique checks old unique checks set character set client old character set client set character set results old character set results set collation connection old collation connection set sql notes old sql notes dump completed log mysql check contents database found database empty follows mysql use databasename database changed mysql show tables empty set sec database restored specific syntax use ensure database get restored properly
94717 database stores bunch custom fields using hstore order merge another database doesnt support hstore id like split keys extra columns users add new custom fields cant rely knowledge keys ahead time makes answer attributes hstore column separate columns view applicable problem record doesnt key present records get column null value
94887 ive debian servers postgresql historically servers postgresql localized latin charset back fine handle things like polish greek chinese changing become growing issue tried create utf8 database got message error encoding utf8 match locale fr fr detail chosen lc ctype setting requires encoding latin9 times made research subject old pal google could find complicated procedures like updating debian lang recompile postgresql correct charset editing lc system variables obscure solutions time let issue aside recently came back greeks want stuff latin dont want looking issue one colleague come said nah easy look edited nothing didnt magic tricks make sql query create database utf8 db encoding utf8 owner admin template template0 lc collate lc ctype connection limit tablespace pg default worked fine actually didnt know lc ctype surprised using wasnt first solutions google even stack overflow looked around found mention postgresql documentation lc ctype posix character set allowed settings lc ctype one character set work correctly since lc ctype setting frozen initdb apparent flexibility use different encodings different databases cluster theoretical real except select posix locale thus disabling real locale awareness made wonder easy perfect downside ive hard time finding answer yet come posting tl dr downside using lc ctype specific localization bad expect break
95425 dont add manual locking transaction anything manual running queries php script execute two update queries time update table set status processing id status pending update table set status processing id status pending rely updated rows count possible return requirement web server two processes time try process row avoid processing solution first run select query check status given id pending processing chance processing im sure happen one update query rely rows updated count
95595 probably asked cant figure phone clicks table sql fiddle http sqlfiddle com 855e0 create table phone clicks id integer null date date null industry id integer null clicks integer default null insert phone clicksid date industry id clicks values table holds phone click event counts multiple industry ids dates possible count clicks available industry ids multiple date ranges conditions would like output industry id today yesterday last days ive tried using counting partition date got nowhere possible select data one query additional benefit would able specify previous months date ranges today yesterday march february january etc update ive updated fiddle define current month previous months pre previous month date ranges sql fiddle http sqlfiddle com 855e0 im using postgresql solutions welcome well migrating soon
95600 application working displays tasks based status date order however particular status sort condition inverted example table looks like id status planned date inactive active inactive inactive active active active returned id status planned date active active active active inactive inactive inactive note example simple two statuses used enumeration different values field new pending active inactive cancelled completed also fields need sorted planned date priority numeric value normal mentioning fyi dont believe much relevant general idea understood simple example sort status field enum simply perform select id status planned date tbl tasks order status asc sort planned date field asc active status desc inactive status
95646 using sql server r2 version running windows server r2 standard database size around 207mb contained 100s thousands records table decided keep first records delete remaining minimise size database deleted records database also rebuilt indexes delete toptrends handleid select top handleid toptrends order lastmodifieddatetime desc go alter index toptrends rebuild fillfactor sort tempdb statistics norecompute go checked size database database log files database log file size increased size database file remained thought decrease file size deletion around file size deletion around 207892same size database log file 625mb 300mb cant reduce size database purging unwanted old records table rebuilding indexes database log file increased dramatically purging table dont want going large
95740 innodb tables production database hit int auto increment limit need alter bigint otherwise writes start failing tables production mysql 19a database running amazon rds alter like without disrupting production reads inserts happening time alter table mytable change id id bigint null auto increment ddl table create table mytable id int11 null auto increment siteid int11 null filter varchar10 null default date varchar10 null cards varchar250 null apples varchar45 null carrots varchar45 null corn varchar45 null peas varchar45 null primary key id unique key unique siteidfilterdatecards key date date key cards cards key apples apples key siteid siteid engine innodb auto increment default charset utf8
96000 always cluster consists servers one primary others isare secondary idea dedicate secondary readonly replica would somewhat search server know set connectionstring use secondary replica add applicationintent readonly dont understand address secondary stored procedure im using distributed query way set parameters query like statements something query would use replica primary node thing obviously start server1 primary server2 secondary server1 fails server2 primary server1 secondary get fixed use static server2s name far ive managed get current replicas server name variable use exec find first available replica declare replicaserver nvarchar50 select top replicaserver rcs replica server name sys availability groups cluster agc inner join sys dm hadr availability replica cluster states rcs rcs group id agc group id inner join sys dm hadr availability replica states ars ars replica id rcs replica id inner join sys availability group listeners agl agl group id ars group id ars role desc secondary connected state query declare cmd nvarcharmax select replicaserver somebase someschema sometable exec cmd thats shame guess
96039 code declare mytable table month int salary int insert mytable values select month salary mytable output want concat salary grouping month nvarchar like would efficiently
96245 cron task needs extract customers birthdays given month mysql innodb table birthday field indexed type date filtering april query customers table either select customers birthday like select customers monthbirthday one would recommend
96331 recently upgraded sql server validation however bug discovered certain trigger coded follows create trigger dbo trigger dbo foo update update update foobar set datetime getdate bar foobar id bar id go safely execute oddly sql server however sql server throws would expect syntax error syntax error duplicate specification action update trigger declaration throw syntax error sql server google fu failed seemingly work sql server
96346 running query article http sqlity net en cxpacket waits performance problem see threads waiting regards suspended query wait type cxpacket however spid question threads running showing wait types null every thread suspended state wait type cxpacket expecting one threads kind wait type cxpacket anyone explain happening situation thanks
96556 im converting old ms access based system postgresql access fields made selects could used parts equations later fields like select samples id samples wet weight samples dry weight percent water percent water percent water samples postgresql postgres throws error error column percent water exist heres work around selecting sub selection select s1 id s1 percent water s1 percent water percent water select samples id samples wet weight samples dry weight percent water samples s1 kind shortcut like first code block get around complicated nesting could also say samples wet weight samples dry weight percent water small example much larger system math going code dozens complex bits math stacked top id prefer cleanly possible without repeating
96743 postgres get stack trace exceptions using code exception others get stacked diagnostics error stack pg exception context works fine natural exceptions raise exception using raise exception error stack trace according mailing list entry might intentional although cant life figure makes want figure another way throw exception using raise missing something obvious anyone trick exception get postgres throw would contain string choosing would get string error message full stack trace well heres full example create replace function error test returns json declare error stack text begin comment see normal exception give stack trace raise exception exception get stack trace give divide zero error complete stack trace select case exception wrap error object send back json exception others exception catching one postgres threw like divide zero error get full stack trace place exception thrown however since catching exception raised manually using raise exception context stack trace get stacked diagnostics error stack pg exception context raise warning stack trace error error stack return jsonv error stack end language plpgsql
96917 im upgrading ran issues upgrade specifically got error trying start mongod via ssh tried use default dbpath instead one specified new yaml config file went ahead rebooted machine mongod running im bit paranoid point would like know theres way make sure storage engine wiredtiger shell
97171 procedure like simplified create procedure test username varchar64 select member inner join order memberid memberid username username non clustered index username column member table plan cache shows implicit conversion seek keys prefix mydatabase dbo member username scalar operatorconvert implicitvarchar64 username wondering might causing implicit conversion parameter field data type username varchar64 sp called framework like exec test username nwebsite com thank
97470 mysql states use group select output rows sorted according group columns order columns however mysql states relying implicit group sorting mysql deprecated achieve specific sort order grouped results preferable use explicit order clause info also stated exactly deprecated mean mysql behavior implicit group still guaranteed work mysql current latest version like every single version order null still required stop mysql needless sorting edit rick james covers database issues ordering group without order meaning usefulness order null wisdom using deprecated feature meaning deprecated mysql manual case
97738 table 3b rows wed like change column null null column contained one index clustered pk index data type isnt changing int nullability statement follows alter table dbo workflow alter column lineid int null operation takes excess stop havent even let run completion yet blocking operation taking long well probably copy table dev server test long actually takes im curious anyone knows sql server hood converting null null also affected indexes need get rebuilt query plan generated doesnt indicate whats happening table question clustered heap
97773 query mysql serves well getting records within current month select date fieldval table date field curdate interval month query works well month two records days bring two records date field val want number records returned exactly number days current month current month days two records bring date field val modify query achieve result
97781 two update queries similar structure yet sql server query plan one shows indexes used shows regular table scan following queries per query plan use indexes update payment metadata set payment metadata commoditycode raw materials payment metadata c1 raw materials payment metadata c2 ingredients payment metadata c3 payment metadata ruletext payment metadata lastupdatedindex payment metadata lastupdatedindex payment metadata isexcluded payment metadata logtext commodity raw materials ingredients payment metadata payment metadata isprocessed payment metadata enrichedvendor nfl payment metadata vendor nfl second query uses index update payment metadata set payment metadata commoditycode raw materials payment metadata c1 raw materials payment metadata c2 ingredients payment metadata c3 payment metadata ruletext payment metadata lastupdatedindex payment metadata lastupdatedindex payment metadata isexcluded payment metadata logtext commodity raw materials ingredients payment metadata payment metadata isprocessed payment metadata enrichedvendor payment metadata vendor following table definition create table dbo payment metadata id int identity11 null company code varchar null comp code desc varchar null vendor acct group varchar null vendor varchar null vendor name varchar null vendor abn varchar null vendor pterm varchar null vendor pterm desc varchar null purchasing group varchar null purchasing group des varchar null po doctype varchar null po doctype desc varchar null purchasing document varchar null po date varchar null po createdby varchar null plant int null item number varchar null material number varchar null material group varchar null material group desc varchar null account assignment varchar null acct assignment desc varchar null gl account varchar null gl account desc varchar null po desc varchar null po quantity decimal null order uom varchar null order price unit varchar null invoice receipt varchar null invoice reference varchar null invoice date datetime null invoice scan date datetime null invoice item int null invoice amount decimal null gst decimal null invoice gross amount decimal null currency varchar null document type varchar null document number varchar null document date datetime null posting date datetime null payment term varchar null baseline date datetime null due date datetime null payment document varchar null clearing date datetime null commoditycode varchar null ruletext nvarchar max null isprocessed bit null datasource varchar null iscontracted bit null ispreferred bit null vendorriskscore varchar null enrichedvendor varchar null lastupdatedindex int null logtext nvarchar max null isexcluded bit null c1 varchar null c2 varchar null c3 varchar null originalvendor varchar null adjustedamount decimal null primary see change clause usage numeric vs non numeric characters suspect impact query plan one non clustered index columns enrichedvendor vendor help would appreciated update including query plans noticed query suggests index green may solution answer
97898 ive recently come environment lot databases logins enforce password policy flag enabled upcoming audit necessitating verification logins passwords used following query obtain list logins whether flags select servername servername name srvrolemembersysadmin name sysadmin type desc create date policy checked disabled password hash pwdcomparename password hash usernameaspassword sys sql logins however doesnt tell passwords actually adhere password policy flag relevant creating user known way test existing users password policy compliance access old passwords would prefer method doesnt require
98529 reading upon mysql internals going mysql user table mysql shell get mysql select mysql user limit row host localhost user root password 81f5e21e35407d884a6cd4a731aebfb6af209e1b password obviously hashed begin star asterisk
98553 given following mysql database structure booking system retrieve available days two user supplied dates id code date arrival date departure apt01 apt01 apt02 apt02 example user enters start date end date available days period 16th 21st using apt01 26th 27th using apt02 means available days requested user query data get result
98575 heres scenario im working localization project mine typically would go code however want sql bit since trying buff sql bit environment sql server standard net note programming language irrelevant im including completeness sort accomplished wanted extent wanted least year since done sql joins except basic ones quite complex join diagramme relevant tables database plenty necessary portion relationships described image complete database pk fk constraints setup operating none columns described nullable tables schema dbo query almost want given id supportcategories id languages return either right proper translation language string stringkeyid stringkeys id exists languagestringtranslations stringkeyid languageid stringtranslationid combination exists loads stringtranslations text stringtranslationid languagestringtranslations stringkeyid languageid stringtranslationid combination exist loads stringkeys name value languages id given integer query mess follows select case null else select case dbo stringtranslations text null dbo stringkeys name else dbo stringtranslations text end result dbo supportcategories inner join dbo stringkeys dbo supportcategories stringkeyid dbo stringkeys id inner join dbo languagestringtranslations dbo stringkeys id dbo languagestringtranslations stringkeyid inner join dbo stringtranslations dbo stringtranslations id dbo languagestringtranslations stringtranslationid dbo languagestringtranslations languageid dbo supportcategories id end result select select case dbo stringtranslations text null dbo stringkeys name else dbo stringtranslations text end result dbo supportcategories inner join dbo stringkeys dbo supportcategories stringkeyid dbo stringkeys id inner join dbo languagestringtranslations dbo stringkeys id dbo languagestringtranslations stringkeyid inner join dbo stringtranslations dbo stringtranslations id dbo languagestringtranslations stringtranslationid dbo languagestringtranslations languageid dbo supportcategories id problem capable providing supportcategories respective stringtranslations text exists stringkeys name didnt exist perfect providing one basically enforce language translation specific key default use stringkeys name stringkeys defaultlanguageid translation ideally would even instead load translation stringkeys defaultlanguageid pointed right direction rest query ive spent lot time know write like usually would done want sql im trouble getting output like caveat want limit number actual queries applied columns indexed like without real stress testing index edit another note im trying keep database normalized possible dont want duplicate things avoid example data source dbo supportcategories entirety id stringkeyid dbo languages records showing two examples id abbreviation family name native en indo european english english fr indo european french fran ais langue fran aise dbo languagesstringtranslations entirety stringkeyid languageid stringtranslationid added example dbo stringkeys entirety id name defaultlanguageid billing api sales open waiting customer waiting support work progress completed dbo stringtranslations entirety id text billing api sales open waiting customer waiting support work progress completed les apis added example current output given exact query outputs result billing desired output ideally would like able omit specific supportcategories id get regardless language english used french language moment id result billing api sales additional example given add localization french add languagestringtranslations output would change note example obviously would add localized string stringtranslations updated french example result les apis additional desired output given example following output would desired updated french example id result billing les apis sales yes know technically thats wrong consistency standpoint would desired situation edit small updated change structure dbo languages table drop id int column replace abbreviation renamed id relative foreign keys relationships updated technical standpoint appropriate setup opinion due fact table limited iso codes unique begin tl dr question could modify query return everything supportcategories return either stringtranslations text stringkeys id languages id combination stringkeys name exist initial thought could somehow cast current query another temporary type another subquery wrap query yet another select statement select two fields want supportcategories id result dont find anything ill standard method typically use load supportcategories project run query manually supportcategories id thanks suggestions comments critique also apologize absurdly long dont want ambiguity im often stackoverflow see questions lack substance didnt wish make mistake
98745 need know databases sql server user connect sys databases get databases sys server principals sys syslogins get server logons cant find table contains connection tables anyone idea solve thanks
98949 user called test user created mysql ms windows 2008r2 want grant user select privileges databases except mysql database note around database inside instance edit edit2
98954 postgresql supports retrieving current running transaction id using query like select txid current mysql equivalent
99317 query execution plan show locking details default possible view locks along type acquired execution query
99326 ive tasked sending small monthly report one customers report previously run manually instance output copied spreadsheet send customer attachment im looking permanent solution intend using sp send dbmail stored procedure run query send attachment everything works formatting message initially tried attach output csv file query result seperator results everywhere run report normally output looks fine sql sending csv message body doesnt think might work better export output html send attachment xml dont know anyone suggestions thanks advance
99334 come across three old databases sitting sql server need move believe standard approach restore instance update export finally restore fine except instances available workarounds methods might worth trying information databases contain tables views appear simple backups 200mb size
100643 dont get see sql query select nchar65217 select nchar65218 select nchar65219 select nchar65220 nchar65217 nchar65218 print equal nchar65217 nchar65219 print equal nchar65217 nchar65220 print equal based transitive relation means sql server considers character however environments say example theyre im confused string comparison works sql server comparison doesnt behave one machine one platform different environments characters represent one human understandable character abundant unicode character map course results tremendous problems im working text processing application data comes almost everywhere need normalize text processing know reason difference might find solution handle thank
100665 following query works select unnestarray ta integer integer however wasnt able use different column type varchar255 select unnestarray 1hello 3world ta integer varchar255 error function return row query specified return row match detail returned type unkown ordinal position query expects text seems second case column type inferred unknown cast varchar255 automatically make second example work return columns right type possible without warnings without modifying array definition background trying improve performance large bulk insert operations using psycopg2 python module support using multiple rows values arguments stumbled onto example trying methods
100749 suppose table id column maintaining unique values manually inserting updating records instead creating unique key column using date time id column value using index key table affect query performance execute select query clause even cardinality id column select mytable id mean unique constraint help improve query performance force user maintain record uniquely sql get higher selectivity unique constraint column dont know much unique constraint unique index answer given question helps understanding difference uniqueindex uniquekey want know unique key improve query performance
100899 table structure create table dbo audit schema version schema ver major int null schema ver minor int null schema ver sub int null schema ver date datetime null schema ver remark varchar null sample data seems problem sqlfiddle putting sample data insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values1613cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values1613cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values1713cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11013cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11213cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11213cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11613cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11613cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11613cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11613cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values250cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values260cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values270cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values280cast20141209 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values290cast20141209 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values2100cast20141209 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values2130cast20150323 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11013cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11614cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11615cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values220cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values230cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values240cast20140417 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11313cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values11613cast20130405 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values2110cast20141209 datetimestored procedure build insert audit schema version schema ver major schema ver minor schema ver sub schema ver date schema ver remark values2120cast20141209 datetimestored procedure build sqlfiddle sample data someone sql expertise guide achieve final result know pivot dynamic columns right approach cant figure expected results far select row number partition convertvarchar10 schema ver date order schema ver date rownum convertvarchar10 schema ver date upg date convertvarchar1 schema ver major convertvarchar2 schema ver minor convertvarchar2 schema ver sub schema ver audit schema version schema ver remark like stored procedure build order upgrade date
100965 im trying combine multiple date ranges load max cases may may overlap largest possible contiguous date ranges example data create table test id serial primary key null range daterange insert test range values daterange2015 daterange2015 daterange2015 daterange2015 daterange2015 daterange2015 null daterange2015 daterange2015 table looks like id range rows desired results combined visual representation
101211 poorly managed database table grown enormous gigs orphan records trying clean put dangerously full hard drive back normal state deleting approx million records table running type notice seeing drop hard drive space seeing memory drop system table queries running get table size database using simple recovery model many questions similar responses saying need shrink database go explain bad scary fragmented data etc since database size still bad shrink production database shrink cause downtime lock database sql server management studio two options shrink database files given situation would best option rule percentage free space db even reading tag description shrink makes want another way
101917 first command use master go second command alter database mydb set single user rollback immediate go third command restore database mydb disk nd restore backup restore acctdb bak file move acctdb nd program files microsoft sql server mssql10 mssqlserver mssql data wfstageacct mdf move acctdb log nd program files microsoft sql server mssql10 mssqlserver mssql data wfstageacct log ldf nounload replace stats go forth command alter database mydb set multi user go run commands one one restore database different server sometime restore database changed single user mode accessed connection run whole script except last part together would block connection user
102066 provisioned server ansible playbook ive used root bedrock ansible playbook one tasks set mysql server together mysql root user password urgently need change password steps took updated variables ansible roles executed command ansible playbook hosts staging server yml order reprovision server tasks executed expected changes script failed mariadb set root user password message msg unable connect database check login user login password correct cnf credentials guess mysql root password set reprovisioning server change password possible change mysql root password reprovisioning server ansible options
102208 ive heard pretty sure developer edition free charge downloading registration required started looking today could find get understanding wrong right sorry didnt find similar question ideas
102292 may fall category opinion im curious people using trace flag startup parameter sql server used circumstances experience query regression certainly seems like potential performance benefit across board im considering enabling globally non production environment letting sit couple months ferret issues fixes rolled optimizer default although understand case introducing unexpected plan changes seems odd keep fixes hidden versions using 2008r2 mostly
102370 im creating accounting software need enforce double entry bookkeeping classical problem one row per transaction versus two rows lets take example see would implemented scenarios consider account cash account rent pay monthly rent transfer cash account rent account one row per transaction one row system transaction would stored transactions tx id posting date transaction records id tx id credit account debit account amount cash rent two rows per transaction two row system id mirror transaction record create opposite record sum id get zero balance transactions tx id posting date transaction records id tx id type account amount credit cash debit rent problem first id like note reason transactions transaction records tables instead one table able handle split transactions case transfer cash account two different accounts first tried implement one row per transaction pain calculate account balance actually retrieve data im leaning towards second scenario however also issues update single record assuming ive made mistake instead recording rent ive recorded transaction records one credit one debit amount reconciliation want fix typo would fix database dont know connection records case split one transaction records solution came add ref id records pair uniquely identify records opposite sides inside context specific tx id approach better simpler simplify question want represent movement funds account account two scenarios gave valid designs store transaction also pointed cons pros first one easier save harder retrieve second one opposite might pros cons spot right hence ask opinion experienced people
102463 understand trigger table defined statement run execute update defined foreign key references update cascade update rows cause trigger called times put differently changes table cascaded fk constraint like single update like series updates
102492 way calculate today yesterday last month last year sql assuming today may find today last year may today last month april yesterday last year may yesterday last month april
102605 wanted try contained database users feature azure sql database v12 im problem authenticating seems odd created database called classifier added ip firewall rules could connect azure db server ssms workstation able get connected via ssms administration tried adding user password database like create user classifier password thepassword also added user data writer reader roles exec sp addrolemember db datawriter classifier exec sp addrolemember db datareader classifier im able connect database credentials ssms things go awry ive tried several different connection string incantations cant seem get connected web app im working didnt work azure environment im running localhost connection string azure database wont connect heres connection string im using moment add name classifier connectionstring data source xxxxxxx database secure windows net initial catalog classifier user id classifier password xxxxxxxxxxxxx encrypt true trustservercertificate false connection timeout providername system data sqlclient ive tried resetting password via ssms user updating connection string also double checked password copying right connection string connect dialog ssms make sure didnt typo kind enabled auditing azure db server hoping get details failing get im stuck ive able find way documentation blogs indicate thing look sql server logs see real error state would indicate narrowly nature failure since im dealing azure theres way far know could cause application fail ssms linqpad visual studio server explorer incidentally succeeds
102620 im wondering query definition materialized view postgres reference hoped similar regular view select information schema views table name view gives following columns table catalog table schema table name view definition check option updatable insertable trigger updatable trigger deletable trigger insertable possible materialized views research far appears materialized views deliberately excluded information schema information schema show objects exist sql standard http www postgresql org message id sss pgh pa us since appear entirely excluded information schema im sure go id like twofold query whether particular materialized view exists far way ive found try creating mat view name see blows query definition materialized view similar view definition column information schema views
102677 supposing table four columns abcd data type possible select distinct values within data columns return single column create function achieve
102745 want take backup particular tables available database bak file done using sql script
102903 acceptable circular reference two tables foreign key field situations avoided data inserted example opinion circular reference would acceptable create table account id int primary key identity name varchar50 create table contact id int primary key identity name varchar50 accountid int foreign key references accountid alter table account add primarycontactid int foreign key references contactid
103273 two example queries shown drop create database partitioned table table several partitions data including last unbounded one partitioned data goes script adds new partition new partition starts first script transaction log shows every record last partition partition deleted inserted second script shows activity rows took place deletes inserts difference two scripts range left vs range right partition function range right causes deletes inserts range left causes rows last partition deleted reinserted thought range left range right controlled border value went left right partition clearly something else range left range right dont understand also like idea adding partitions without impacting system willing use range right gets however worried may bug kind rely may fixed later version feature relied scripts range left deletes inserts use master go comment next line first run drop database partitiontest go create database partitiontest go use partitiontest go add filegroups alter database partitiontest add filegroup datepartitiontest go alter database partitiontest set recovery simple go add files alter database partitiontest add file name npartitiontest filename nd partitiontest ndf filegroup datepartitiontest go part different two scripts left vs right create partition function orders id function bigint range left values go create partition scheme create partition scheme orders scheme partition orders id function datepartitiontest datepartitiontest datepartitiontest datepartitiontest create table create table dbo orders orddate datetime null id bigint identity11 null addr varchar100 null partition table create unique clustered index ix orders orders orddate ascid asc orders scheme id go insert rows partitions partition case use partitiontest set nocount go declare int set declare date datetime begin set date dateaddmi i2012 01t10 insert testtable values date insert orders values date denzil insert orders values dateaddmonth3 date denzil insert orders values dateaddmonth6 date denzil insert orders values dateaddmonth9 date denzil set end check rowcount partition select partition orders id function id partionnumcount countrows orders group partition orders id function id alter partition scheme orders scheme next used datepartitiontest go set check point log file checkpoint go add new partition alter partition function orders id function split range select operationcount numlogrecords fn dblognullnull allocunitname dbo orders ix orders group operation order count desc select name tablenamei name indexname partition id partitionid partition numberrows fg name sys tables inner join sys indexes object id object id inner join sys partitions object id object id index id index id inner join sys destination data spaces dds partition number dds destination id inner join sys filegroups fg dds data space id fg data space id name orders index id range right inserts deletes use master go comment next line first run drop database partitiontest go create database partitiontest go use partitiontest go add filegroups alter database partitiontest add filegroup datepartitiontest go alter database partitiontest set recovery simple go add files alter database partitiontest add file name npartitiontest filename nd partitiontest ndf filegroup datepartitiontest go part different two scripts left vs right create partition function orders id function bigint range right values go create partition scheme create partition scheme orders scheme partition orders id function datepartitiontest datepartitiontest datepartitiontest datepartitiontest create table create table dbo orders orddate datetime null id bigint identity11 null addr varchar100 null partition table create unique clustered index ix orders orders orddate ascid asc orders scheme id go insert rows partitions partition case use partitiontest set nocount go declare int set declare date datetime begin set date dateaddmi i2012 01t10 insert testtable values date insert orders values date denzil insert orders values dateaddmonth3 date denzil insert orders values dateaddmonth6 date denzil insert orders values dateaddmonth9 date denzil set end check rowcount partition select partition orders id function id partionnumcount countrows orders group partition orders id function id alter partition scheme orders scheme next used datepartitiontest go set check point log file checkpoint go add new partition alter partition function orders id function split range select operationcount numlogrecords fn dblognullnull allocunitname dbo orders ix orders group operation order count desc select name tablenamei name indexname partition id partitionid partition numberrows fg name sys tables inner join sys indexes object id object id inner join sys partitions object id object id index id index id inner join sys destination data spaces dds partition number dds destination id inner join sys filegroups fg dds data space id fg data space id name orders index id
103402 triggers one table one works inserts create trigger get user name insert field data row execute procedure add info updates values table one updates fill history table create trigger set history update field data row execute procedure gener history problem insert new row table procedure add info makes update therefore fires second trigger ends error error record new field field1 avoid
103625 due mishap deleted entire var lib mysql directory since database contain anything important want go hassle restoring old backup instead create directory structure scratch without reinstalling mysql
103688 asked identify permissions issue stored procedure stored procedure behaves two possible ways depending values used parameters exec ps stored procedure handled differently exec ps stored procedure could say ps stored procedure divided logically two completely separate processes using dm exec procedure stats dm exec query stats find execution plan shows sql stored procedure used able however recover parameters defined values possible using dm exec procedure stats dm exec query stats management views reconstruct execution stored procedure shows values used parameters id really like find cache actual execution stored procedure execute using execute login someone resolve permissions issues
103815 related question joining multiple tables results duplicate rows two tables joining share key person table one name per primary key email table multiple emails per personid want show first email per person presently get multiple rows per person multiple emails running sql server edit sql first email literally first email row per person edit first email see would first email row shows join sql works query matter email shows one email shows hope makes clearer table1 person table2 email select person personname email email person left join person id email personid
104172 tables named public test easily grant access user test tables tried grant table public test test working
104192 problem understanding sql server decides call user defined function every value table even though one row fetched actual sql lot complex able reduce problem select groupcode ordercategory orderline join orderhdr orderid orderid join product product product cross apply dbo getgroupcode factory ordernumber xxx yyy rmphase orderline query sql server decides call getgroupcode function every single value exists product table even though estimate actual number rows returned orderline primary key plan plan explorer showing row counts tables orderline 5m rows primary key ordernumber orderline rmphase clustered orderhdr 900k rows primary key orderid clustered product rows primary key product clustered index used scan create unique nonclustered index product factory product product factory function actually slightly complex thing happens dummy multi statement function like create function getgroupcode factory varchar4 returns table type varchar8 groupcode varchar30 begin insert type groupcode values xx yy return end able fix performance forcing sql server fetch top product although max ever found select groupcode ordercat orderline join orderhdr orderid orderid cross apply select top factory product product product cross apply dbo getgroupcode factory ordernumber xxx yyy rmphase orderline plan shape also changes something expected originally also though index product factory smaller clustered index product pk would affect even forcing query use product pk plan still original calls function leave orderhdr completely plan starts nested loop orderline product first function called would like understand could reason since operations done using primary keys fix happens complex query cant solved easily edit create table statements create table dbo orderhdr orderid varchar8 null ordercategory varchar2 null constraint orderhdr pk primary key clustered orderid create table dbo orderline ordernumber varchar16 null rmphase char1 null orderline char2 null orderid varchar8 null product varchar8 null constraint orderline pk primary key clustered ordernumberorderlinermphase create table dbo product product varchar8 null factory varchar4 null constraint product pk primary key clustered product
104378 im getting extremely long delays seconds sql server management studio attempting connect sql server instance tcp using windows authentication happens connecting object explorer new blank query window connected running queries fast problem happen connect using sql server authentication environment windows logged domain user tcp connection via ip address hostname server remote location connected via vpn encryption logged co workers windows computer domain account connected sql server vpn delay co worker logged pc domain account experienced delay tests show problem unique pc also problem appears connecting specific sql server vpn connect sql servers local network via windows authentication without delay things ive tried success disabled anti virus firewall renamed folder userprofile appdata roaming microsoft sql server management studio force ssms recreate user settings force network protocol tcp rather default also tried named pipes server isnt setup installed ssms tried instead disabled ipv6 blackholed crl microsoft com etc hosts file disabled customer experience improvement program ssms visual studio windows uninstalled sql server related apps pc reinstalled tcpview clues using tcpview noticed make new connection state becomes established right away one two connections sql server continually attempted closed time wait co workers computer connections established solid im pretty sure source timeouts connections fail dont addons ssms ideas update intellisense autocomplete clue noticed finally connect intellisense autocomplete doesnt work require separate connections ssms tried disabling didnt seem resolve long connection delay
104421 lately ive refactoring sql server indexes products developed employer one products online dashboard containing multiple user levels user admin level create projects link users user level project name field also field administratoruserid keep track project admin created combined non clustered unique index two fields meaning project names unique per administrator heres catch noticing often select administratoruserid name according indexing guidelines please correct im wrong create non clustered index field order optimize queries question existing index name administratoruserid already improve queries advisable create separate index besides would downside administratoruserid present two separate indexes
104460 mysql know database backed table table sql statements results locking update columns backing might end integrity problems understanding apply microsoft sql server sql server handles internal freeze keep db consistent also heard backing single threaded meaning uses one core assuming backup single file also assuming multicore machine example cores least significant larger number one personal experience never issues taking backups neither locking overhead issues experience limited thats always recommend turning backup compression server properties happens backup job running also significant differences different versions example licenses
104565 didnt happen yet thinking messing around training environment mistake clicked database name touched letter lets assume hit enter database called dont remember original name ctrl doesnt work case like production environment know could happen database isnt set single user happens arguments sake lets say database nobody using right
104573 years worth inventory data want extract first last day months data best way
104596 consider following table id group id order val reset val val null null null null null null null null null null row need compute cumulative sum val previous rows ordered order val grouped group id time non null reset val encountered need use value sum rows follow also need build top reset val instead using actual sum note group multiple reset values result expect table id group id order val reset val val cumsum null null null null null null null null null null reset values could use window query select temp coalescesumval partition group id order order val rows unbounded preceding preceding cumsum temp sqlfiddle originally mistakenly thinking could put reset val beginning coalesce wont work since wont reset value following rows also tried solution resets back zero value column adapting proving non trivial value must propagate following rows recursive query seems like natural fit havent able figure yet probably mention table actually deal much larger hundreds thousands couple million rows example please mention performance pitfalls answer
104898 building config table want one row default value example list table databases table called msg return values msg table one row alldbs want value returned isnt another row joined database output list table dbname createdate master model msdb tempdb dummy msg table dbname msgval alldbs message dummy message desired output dbname msgval dummy message master message model message msdb message tempdb message get result query clunky seems like better way select dbname msgval list join msg dbname dbname union select dbname msgval list msg dbname select dbname msg dbname alldbs efficient way write query sqlfiddle link using sql
104987 possible create atomic transaction postgresql consider table category rows id name tablets phones column name unique constraint try begin update category set name phones id update category set name tablets id commit im getting error duplicate key value violates unique constraint category name key detail key name tablets already exists
105023 point become familiar language database system need test new feature configuration query etc contained simulated testing implementing system especially concerning feature modifies data always essential test new query simulation test environment specify clear always safest test however way determine risk minimal testing worth effort another way phrasing ever professional practice take measured risk implement feature also lets assume everything backed worst case scenario data could effort restored someone cite specific expert experience address please include references appropriate possible
105195 im creating conceptual diagram yes know ive included attributes keys consolidate im whilst learning please treat conceptual focus relationships tables diagram mind hurdle im trying ascertain best way model profile location organization relationships first rules one profiles member friend one organizations vice versa one profiles member friend profiles one organizations member friend organizations friend member differ friends like read members depending level full access amend things complicate things locations set refinable rules organization owns two locations depending location rules member profile organization may full access one location restricted access sorry youll likely open image another window better viewing size see concept profiles organizations much well yet modelled concept friends members imagine handled much like current intermediary tables setting owner admin member friend etc record hence thinking following concept see option image would remove current organization organization locations tables relationships replacing option organization table somewhat recursive relationship profile suppose crux matter whether im programmatically minded polymorphism detriment simplicity flexibility confusing entirely process thanks thoughts advance much appreciated revised diagram response mdccls questions yes profile made one person meaning though rationale headed believe youre correct organization person could subtypes profile therefore profile either made one person one organization one email address per profile yes organizations least email address correct one fixed address possibility rarity though im learning one therefore model future longevity etc confirm location could therefore owned one person location definitely integral entity others perhaps clarify done succinctly let read though answers hopefully pertain beneficial additions question first see answer end role owner organization owner zero locations person owner zero locations therefore previously surmised simply put profile owner zero location yes profile owner location assumes role permissions super user profile admin amend certain details location mainly helps edits details data supplied via profile primarily supplied basic member said location leaves basic member read related location details supply data must scrutineered admin owner beyond profile organization person much like basic member read lets term guest location set public private though cant supply input like basic member correct intuition amazing yes foreseen single location could contain one many locationtypes complicate things anticipated individual locationtypes could varying permissions profiles associated parent location permissions would filter location locationtype much like os folder security permissions note via diagram might referring type description yes see correct ability profile1 person organization act upon profile2 person organization owned locations theyre friend member correct permissions paramount reasonable agree agree yes hmm perhaps much profile person profile person friends whatever description would revolve around location organization act upon organization location though semantically doubt organization would want appear subservient member locations organization able matter good cause still tad grey goes possibly detriment similarity member friend relations close thought combine hindsight diagram interpreting appears may right keep separate going differentiate single relationship via enum property owner admin member friend concept location owned organization zero many profile person organization act upon though clear difference profiles act upon location via relation member friend denoted roles perhaps default relation profile friend much like guest answer enabling view read location data msg email location owner admin allow receive location updates news etc member would
105386 im trying perform insert update selecting data another db far insert pdone reps veeva rep iddisplay nameusernamefirstlastemail select id concatucaseleftfirstname 1ucaseleftlastname 1username firstname lastname email veeva user id 00580000003ub5vaaw first problem got error err error sql syntax check manual corresponds mariadb server version right syntax use near veeva user id 00580000003ub5vaaw line im sure wrong query advice firstname could john john john want normalize john ucaseleftfirstname fine apply lastname firstname john lastname doe username john doe space concatenate right insert statics fields like one url veeva values present query shown add two columns insert avatar url rep type planning add duplicate key update possible add restriction based column lets said update lastsyncdate
105431 would like use oracles automatic memory management limit around 4gb past experience shown plenty dev pc easier get idea performance issues less believe instructions follow oracle automatic memory management says short enable automatic memory management set memory target optionally memory max target former parameter dynamic value latter harder limit changed stopping starting database set follows sysdba sql alter system set memory target 4g scope spfile system altered sql alter system set memory max target 8g scope spfile system altered check values sql show parameter target scope memory current uptime spfile pick spfile restarting sql shutdown immediate database closed database dismounted oracle instance shut sql startup however simplistic ora specified value memory target small needs least 13104m hard revert opinion also immediately obvious get memory adjustment post senior posters correct shred either case think nice one place
105443 im running sql server laptop along ton installed applications visual studio video games obviously production server development debugging ive scripted fairly small simple database dozen tables views ive inserted less rows dummy data testing one point accidentally created 100gb index using badly formed cross joins query creating index consuming ram laptop 16gb slowed everything crawl aborted query rather waiting finish promptly dropped created entire database index removed creation scripts however sql server kept consuming 16gb ram point forward even query aborted database dropped rebooted laptop next ram usage sql server dropped 7gb remained ever since regardless whether drop 5mb existing databases etc id like get sql server back reasonable memory consumption level dont know begin looking possible causes know pretty open ended question im willing legwork little guidance dont know begin troubleshooting since im dba apparently google doesnt know either
105461 table people piece work every entry table user id name date report enter need make weekly report people done per day starting sunday group week starting sunday make column count per day t0001 tod t0001 tod t0001 tod t0001 tod t0001 tod t0001 tod t0001 tod b0002 ben b0002 ben b0002 ben im looking name total tod ben
105525 two tables t1 table id int date datetime t2 table id int date datetime tables non clustered index id date join tables select t1 t1 inner join t2 t2 t1 id t2 id t1 date getdate t2 date getdate also written select t1 t1 inner join t2 t2 t1 id t2 id t1 date getdate t2 date getdate question two queries gives better performance equal
105537 table million rows index date field try extract unique values indexed field postgres runs sequential scan even though result set items optimiser picking plan avoid answers suspect much related query index explain select labeldate pages group labeldate query plan hashaggregate cost rows width group key labeldate seq scan pages cost rows width rows table structure http pages table public pages column type modifiers pageid integer null default nextval createdate integer null archive character varying16 null label character varying32 null wptid character varying64 null wptrun integer null url text urlshort character varying255 starteddatetime integer renderstart integer oncontentloaded integer onload integer pagespeed integer rank integer reqtotal integer null reqhtml integer null reqjs integer null reqcss integer null reqimg integer null reqflash integer null reqjson integer null reqother integer null bytestotal integer null byteshtml integer null bytesjs integer null bytescss integer null byteshtml integer null bytesjs integer null bytescss integer null bytesimg integer null bytesflash integer null bytesjson integer null bytesother integer null numdomains integer null labeldate date ttfb integer reqgif smallint null reqjpg smallint null reqpng smallint null reqfont smallint null bytesgif integer null bytesjpg integer null bytespng integer null bytesfont integer null maxagemore smallint null maxage365 smallint null maxage30 smallint null maxage1 smallint null maxage0 smallint null maxagenull smallint null numdomelements integer null numcompressed smallint null numhttps smallint null numglibs smallint null numerrors smallint null numredirects smallint null maxdomainreqs smallint null byteshtmldoc integer null maxage365 smallint null maxage30 smallint null maxage1 smallint null maxage0 smallint null maxagenull smallint null numdomelements integer null numcompressed smallint null numhttps smallint null numglibs smallint null numerrors smallint null numredirects smallint null maxdomainreqs smallint null byteshtmldoc integer null fullyloaded integer cdn character varying64 speedindex integer visualcomplete integer gziptotal integer null gzipsavings integer null siteid numeric indexes pages pkey primary key btree pageid pages date url unique constraint btree urlshort labeldate idx pages cdn btree cdn idx pages labeldate btree labeldate cluster idx pages urlshort btree urlshort triggers pages label date insert update pages row execute procedure fix label date
105965 two sql server databases one client windows application second server want sync two databases every often every minutes read different ways syncing like replication time stamp log tables using triggers microsoft sync framework actually dont like use syncing method might black box like replication dont want sql server specific tables blocked im updating syncing server method think use circumstance remember every several minutes must send several table changes client server fetch also two table changes server found method strange new possible log executed specific preferred stored procedures client send parameters sql file server execute happen server sent client think simple yet useful method please suggest useful approach thank much edit remember real time synchronization makes special means client user using table synchronization process server must happen every several minutes none tables must locked
105999 new sql administration tasked creating nightly jobs send email certain details contained within spreadsheet far following exec msdb dbo sp send dbmail profile name support recipients test mail co uk subject post code analysis query nset ansi warnings set count select substringpostofficebox14 postcode countcase new accounttype new accounttype else null end new connections countcase new accounttype new accounttype else null end domestic metered countcase new accounttype new accounttype else null end commercial metered low countcase new accounttype new accounttype else null end commerical metered high countcase new accounttype new accounttype else null end domestic keypad countcase new accounttype new accounttype else null end generator countcase new accounttype new accounttype else null end commercial keypad crm4 mscrm dbo accountextensionbase inner join crm4 mscrm dbo customeraddressbase accountid parentid new accountstage addresstypecode substringpostofficebox12 bt group substringpostofficebox12substringpostofficebox14 order substringpostofficebox12substringpostofficebox14 attach query result file query attachment filename pca test csv query result header query result separator query attachment filename would like append date tried using select convertvarchar10 getdate dd mm yyyy appending file name follows query attachment filename pca test select convertvarchar10 getdate dd mm yyyy csv advice would greatly appreciated
106001 say large table holds users info another table holds several locations use another table holds user id location id order retrieve data use left join query doesnt make whole process longer retrieve rather one table eg could location text table edit example create table user id int11 null name varchar45 default null gender enummf default null create table user location user id int11 null location id int11 null create table location id int11 null location varchar45 parent id varchar45 note please assume related fields properly indexed edit currently large database users retrieve location via junction table described asked optimize database search results slow ive added memcache improved significantly wondering left joins example current query something like select users left join user location user location user id user id left join location location id user location location id get location several fields retrieved junctions needed view users profile phone numbers addresses passwords many others different tables order create page user profile send server large query first time gets cached fine wondering would someone build database like
106014 would like partition table 1m rows date range commonly done without requiring much downtime risking losing data strategies considering open suggestions existing table master children inherit time move data master child period time data master table children create new master children tables create copy data existing table child tables data reside two places child tables recent data change inserts going forward point new master table delete existing table
106037 select values less given id greater given id tried query better way fiddle sql begin declare rootvalue int declare repid int set repid set rootvalue select id tbllookups id repid declare rootminustwo int declare rootplustwo int set rootminustwo select count tbllookups id rootvalue set rootplustwo select count tbllookups id rootvalue rootminustwo rootplustwo begin select tbllookups id rootvalue rootvalue end else rootminustwo rootplustwo select tbllookups id repid union select tbllookups id rootvalue union select top rootminustwo tbllookups id rootvalue else rootminustwo rootplustwo select tbllookups id repid union select tbllookups id rootvalue union select top4 rootplustwo tbllookups id rootvalue else rootminustwo rootplustwo select tbllookups id repid union select tbllookups id rootvalue union select tbllookups id rootvalue end forgot add something point records many records satisfying condition example ids supply also return
106126 running postgres centos select query worked years stopped working hangs upgraded took notice dont know immediately upgraded select id group number uniq id table one id group number select id group number table two id select id table three timestamp interval days client id tables id integer stored character varying legacy system group number stored smallint sub query table two returns million records sub query table three returns records return second run separately adding either query sub queries causes query hang indefinitely days let run ive seen others online problem query returning using seems like straight forward sub query plenty hardware gb ram xeon cores disk 15k rpm raid happening ie major ongoing bug postgres fix debug meantime results explain query plan index scan using table one id pk table one cost rows width filter hashed subplan subplan subplan bitmap heap scan table three cost rows width recheck cond timestamp days interval client id bitmapand cost rows width bitmap index scan table one timestamp idx cost rows width index cond timestamp days interval bitmap index scan fki table three client id cost rows width index cond client id subplan materialize cost rows width seq scan table two cost rows width settings postgresql conf max connections shared buffers 24gb temp buffers 8mb work mem 96mb maintenance work mem 1gb cpu tuple cost cpu index tuple cost cpu operator cost effective cache size 128gb collapse limit join collapse limit update used following method adjust work mem query begin set work mem 256mb query set work mem default commit using returned seconds vs never work mem 96mb using left join returned seconds vs seconds work mem 96mb looks like problem work mem using left join workaround however real problem postgres going days work mem 96mb 15k sas drives raid fast even going disc query returned bit slower update results explain analyze left join approach query plan nested loop anti join cost rows width actual time rows loops hash anti join cost rows width actual time rows loops hash cond t1 id text t3 id text seq scan table one t1 cost rows width actual time rows loops hash cost rows width actual time rows loops buckets batches memory usage 51kb bitmap heap scan table three t3 cost rows width actual time rows loops recheck cond client id filter timestamp days interval rows removed filter heap blocks exact bitmap index scan fki table three client id cost rows width actual time rows loops index cond client id index scan using table two id2 idx table two t2 cost rows width actual time rows loops index cond id t1 id text group number t1 group number heap fetches planning time ms execution time ms rows time ms exists approach query plan nested loop anti join cost rows width actual time rows loops hash anti join cost rows width actual time rows loops hash cond t1 id text t3 id text seq scan table one t1 cost rows width actual time rows loops hash cost rows width actual time rows loops buckets batches memory usage 51kb bitmap heap scan table three t3 cost rows width actual time rows loops recheck cond client id filter timestamp days interval rows removed filter heap blocks exact bitmap index scan fki table one client id cost rows width actual time rows loops index cond client id index scan using table two id2 idx table two t2 cost rows width actual time rows loops index cond id t1 id text group number t1 group number heap fetches planning time ms execution time ms rows time ms
106264 spin comments previous question postgres query takes forever using postgresql always seems recheck cond line bitmap index scans query plans output explain like explain output referenced question bitmap heap scan table three cost rows width recheck cond timestamp days interval client id bitmapand cost rows width bitmap index scan table one timestamp idx cost rows width index cond timestamp days interval bitmap index scan fki table three client id cost rows width index cond client id output explain analyze simple huge table little work mem explain analyze select aa bitmap heap scan aa cost rows width actual time rows loops recheck cond rows removed index recheck heap blocks exact lossy bitmap index scan aai cost rows width actual time rows loops index cond mean index conditions checked second time bitmap index scan else learn explain output
106539 new subject databases may sound ignorant curious key made explicit within table primarily tell user given column value hopefully guaranteed unique within row uniqueness still even isnt mentioned
106632 working table character types set nvarchar nvarcharmax converting varchar specifying character width based upon actual usage production production data uses range characters characters actual used width given column going add padding applicable insert statements procedure update listings rowlock set subtype idsettings idsettings idretsclass idretsclass idretsclass idretssetting idretssetting idretssetting isnew subtype like single family home subtype like modular subtype like mobile home subtype like story subtype subtype residential subtype house lot subtype houses lot subtype detached subtype like single family subtype ranch subtype semi detached subtype single subtype one family subtype residential subtype ranch type subtype stories subtype cape cod subtype split level subtype bi level subtype detached single subtype single family homes subtype house subtype detached housing subtype det large overhaul table consists literally nvarchar columns max dropping indexes recreating afterwards question situations varcharmax preferred expect 4k characters learn prepare improve performance clustered index update affects clustered key update non clustered indexes update procedures timing using query execution plan displayed plan clustered index update link actual execution plan
106762 deadlock report tells conflict involving waitresource key 543066506c7c see keylock hobtid dbid objectname mydatabase myschema mytable indexname myprimarykeyindex id locka8c6f4100 mode associatedobjectid within resource list want able find actual value key id example sql statement would need use obtain information
106795 using postgres tables agent create table agent agent id bigserial null agent total users integer null agent dim time id integer null unnecessary columns dim time create table dim time dim time id bigserial null dim time date date null dim time month start date date null dim time week start date date null dim time quarter start date date null dim time year start date date null dim time guid uuid null default uuid generate v4 agent dim time id field agent fk referencing dim time id dim time dim time table date related week start date month start date etc example dim time date dim time week start date monday start week start month always first find agent total users agent given date range dimension week month quarter ive tried select dim time week start date agent total users agent join dim time agent dim time id dim time id dim time week start date select generate series2015 day interval output dim time week start date agent total users need first value case week start dates output expecting dim time week start date agent total users
106898 convert dateb set dateb dateaddmonth datediffmonth getdate returns date integer thanks
107078 database sql server r2 tables varchar500 columns want switch datetime2 bigint guarantee data columns switched valid proper type column changes affect indexes keys discussing colleagues come two ways approach problem would done sql scripts create temp table via select drop old table recreate table proper datatypes recreate indexes alter current table data types via alter table alter column datetime2 rebuild recreate indexes confident data convert cleanly leaning towards colleague dba friend prefer colleague cant remember trained way dba friend vacation didnt ask someone provide insight option think better ultimately decision wondering would preferred
107096 team uses oracle sql developer ive relying heavily explain plans lately try determine efficient way solve various problems recently coworker pointed explain plan always accurate actually happens database autotrace better indication since query actually run data testing query ive gotten following results method cost query explain query autotrace query explain query autotrace using autotrace query cost increase query nearly obviously using query cases dont understand causes differ
107238 big query necessary post im getting error msg level state line xml could serialize data node noname contains character 0x0000 allowed xml retrieve data using xml convert binary varbinary image data type use binary base64 directive part use xml codfuncionario results codfuncionario xml path type value text varcharmax experiencia node noname look value 0x0000 one subqueries part xml select codfuncionario stuff select cast descfuncao desctempoexperiencia varcharmax linked server db dbo tblfuncionarioexperiencia t0 inner join linked server db dbo tblfuncao t1 t0 codfuncao t1 codfuncao inner join linked server db dbo tbltempoexperiencia t2 t0 codtempoexperiencia t2 codtempoexperiencia codfuncionario results codfuncionario xml path type value text varcharmax experiencia linked server db dbo tblfuncionarioexperiencia results group codfuncionario t2 t0 codfuncionario t2 codfuncionario left join
107475 im working postgresql db design wondering best store timestamps assumptions users different timezones use database crud functions looked options timestamp null default time zone utc bigint null default timestamp would send string would represent exact utc timestamp insert moment bigint would store exact thing number format time zone issues handled millis handed server always millis utc one main advantage storing bigint could would easier store retrieve passing correctly formatted timestamp complex simple number millis since unix epoc question one would allow flexible design could pitfalls approach
107549 production backup mongodb recommends mongodump instead mongoexport accuracy data however would need scrub data mongodb database backing aware server side data scrubbing options mongoexport two questions mongoexport access mongodb cache ram would alter working set ram like mongodump mongodump command query option provides json document query optionally limits documents included output mongodump take query exclude certain fields document
107556 imported existing sql server 2008r2 production database vs database project get number errors along lines error sql71501 user mydbuser unresolved reference login mydbuser dont really need vs db project manage users im concerned would try remove upon deploy werent files generated create user mydbuser login mydbuser create user mydomainuser login mydomain mydomainuser error marker shows specifically login thats system level object understand outside scope db project preferred change create user mydbuser without login add create login clause beginning file removing login reference seems simpler removing users altogether would simplest want make sure im using tool way intended issues publishing back production proper procedure adding user login via project
107597 using nagios servers monitoring web environment cluster backend cassanra cluster nodes question want write plugin nagios cassandras nodes monitoring unfortunately im good familiar cassandra dont sure parameters need exactly checked im planing use nodetool utility grab data nodes lot commands provides lot information cfstats info status etc monitoring need get data memory nodes usage used disk space may something else
107669 last week something strange happened database sudden application blocked users able save new entities etc looking activity monitor sql server compatibility mode saw following three entries time users got connection timeout killed process could save normally problem entities tried save block inserted db times even though code prevent happening number column unique without constraint check happens code use entity framework anyone know async network io wait types occur avoid exactly mean
107744 trigger stored procedure sp runs trigger runs need function finds next saturday put sp lets say wednesday today trigger runs today sp must find next saturday plus even saturday time earlier pm must find current day also pm must return next saturday would like put whole trigger sp dont want get crowded need ideas thanks edit thanks onaye coded create definer root localhost procedure newguess muserid int numm1 int numm2 int numm3 int numm4 int numm5 int numm6 int begin set today select weekdaycurdate monday first day today today saturday set nextsaturday select date addnowinterval ifweekdaynow weekdaynow5 weekdaynow day end today saturday set current time select curtime set nextsaturday select date addnowinterval ifweekdaynow weekdaynow5 weekdaynow day current time cast21 time set nextsaturday curdate end current time cast21 time set nextsaturday curdate interval week end end insert guessestbl useridnum1num2num3num4num5num6current datetimedraw date values museridnumm1numm2numm3numm4numm5numm6now nextsaturday end worked solved
107820 major browsers moving beyond ssl3 tls1 pci security council declared end life date protocols considered sufficiently strong encryption need move away protocols use newer stronger ones windows servers easily disable old protocols instead offer tls1 greater however noted elsewhere microsoft sql server r2 sql server standard least start lower protocols disabled however growing number versions ms sql server sql server standard business intelligence enterprise express web compact editions course sql server pre release editions support support use tls1 greater protocols
107947 broad question regarding sql server given quiz sure answer access sql server home question utilise sql server tools identify query optimisations missing indexes etc somebody give brief answer thank
108129 using postgresql query like select count ab primary keys tables indexes default postgresql use seq scan ab use hash join force index scan index scan result showed seq scan much faster two takes time full scan ab index scan index scan explain analyze select count journalpaper journal paper id paper paper id someone explain thank much
108210 table representing movies fields id pk title genre runtime released tags origin downloads database polluted duplicated rows want enforce uniqueness problem different movies could title even fields except tags downloads enforce uniqueness thought two ways make fields except downloads primary key im keeping downloads since json probably impact performance keep id primary key add unique constraint columns except downloads read question similar didnt quite understand currently table related tables future could moment slightly less records expect number grow dont know somewhat relevant issue edit modified schema would create table create table movies id serial primary key title text null runtime smallint null check runtime released smallint null check released genres text null default array text tags text null default array text origin text null default array text downloads json null inserted timestamp null default current timestamp constraint must unique uniquetitleruntimereleased ingenrestagsorigin also added timestamp column problem wont touch always automatic unique
108266 installed instances sql server plus ssis following server note amount ram nearly gb max min memory settings applied instances assume instances use equal amount resources would really case mb gb good starting number set memory much memory would allocate ssis
108287 select posted date posted date result contains record posted date today database server country problem
108290 function new customer called several times per second per session web application first thing lock customer table insert exists simple variant upsert understanding docs calls new customer simply queue previous calls finished lock table obtains table level lock waiting necessary conflicting locks released sometimes deadlocking instead definition create function new customersecret bytea returns integer language sql security definer set search path postgrespg temp lock customer exclusive mode insert customercustomer secretcustomer read secret select secretdecodemd5encodesecret hexhex existsselect customer customer secret secret returning customer id insert collectioncustomer id select customer id select customer id customer customer secret secret error log bst detail process waits exclusivelock relation database blocked process process waits exclusivelock relation database blocked process process select new customerdecode text hex process select new customerdecode text hex bst hint see server log query details bst context sql function new customer statement bst statement select new customerdecode text hex relation postgres select relname pg class oid relname customer edit ive managed get simple ish reproducible test case looks like bug due sort race condition schema create table test id serial primary key val text create function testv text returns integer language sql security definer set search path postgrespg temp lock test exclusive mode insert testval select existsselect test val select id test val bash script run simultaneously two bash sessions psql postgres postgres select testblah done error log usually handful deadlocks calls bst error deadlock detected bst detail process waits exclusivelock relation database blocked process process waits exclusivelock relation database blocked process process select testblah process select testblah bst hint see server log query details bst context sql function test statement bst statement select testblah edit ypercube suggested variant lock table outside function psql postgres postgres begin lock test exclusive mode select testblah end done interestingly eliminates deadlocks
108710 suppose postgresql server running ssl enabled using standard linux postgresql tools examine ssl certificate im hoping output similar would get running openssl x509 text im hoping one two liner command line answer dont resort running packet sniffer access postgresql server look configuration files directly superuser login cant get value ssl cert file setting pg read file using openssl client connect doesnt work postgresql doesnt seem want ssl handshake right away quick look psql documentation could find command line parameter makes show information startup though show certain cipher information
108952 part table definition create table dbo jobitems itemid uniqueidentifier null lots columns constraint primarykey guid primary key nonclustered itemid asc create unique clustered index jobitemsindex dbo jobitems itemid asc legacy design please dont ask anyway look list indexes see therere two indexes one jobitemsindex pk guid jobitems table question need separate index maintan pk already jobitemsindex unique includes column suitable maintaining pk constraint
108975 looking information schema role table grants saw public grantee column ive checked information schema enabled roles role name exist public role
109078 trying get info mysql using index create inner join trying order end sql query select product inner join productstore ps productuuid ps productuuid order ps storetitle limit im using order select take sec remove order taking like 16ms run sql explain sql follow order id select type table type possible keys key key len ref rows extra simple ps primary null null null using filesort simple eq ref primary primary foeniks core ps productuuid null without order id select type table type possible keys key key len ref rows extra simple ps primary null null null null simple eq ref primary primary foeniks core ps productuuid null field indexing right varchar length table design create table productstore productuuid binary16 null storeuuid binary16 null distributorlastused binary16 default null storetitle varchar282 default null storeurl varchar282 default null storedescription text storedescriptiondemo text storeprice int11 null default storepricenext int11 null default storepricecost int11 null default overwrites int11 null default updated datetime null default added datetime null default allowdisplay tinyint1 null default activated tinyint1 null default primary key productuuidstoreuuid key productstorelanguagetostore idx storeuuid key productstoretodistributor idx distributorlastused key storeurl storeurl180 using btree key teststoretitle storetitle182 constraint productstoretodistributor foreign key distributorlastused references distributor distributoruuid delete set null update cascade constraint productstoretoproduct foreign key productuuid references product productuuid delete cascade update cascade constraint productstoretostore foreign key storeuuid references store storeuuid delete cascade update cascade engine innodb default charset utf8 product table create table product productuuid binary16 null productmanufactureruuid binary16 null productmanufacturersku varchar40 default null productean varchar40 default null cnetid varchar10 default null edbid int10 default null overwrites int10 null default updated datetime null default added datetime null default activated tinyint1 null default primary key productuuid key manufacturersku productmanufacturersku16 key producttomanufacturer idx productmanufactureruuid key cnetid cnetid key productean productean constraint producttomanufacturer foreign key productmanufactureruuid references manufacturer manufactureruuid delete action update cascade engine innodb default charset utf8
109210 table columns type columns set varchar38 create row empty value one columns take storage space value empty words mysql reserve storage space column depending type row created
109377 microsoft buying revolution results amongst things integration sql server looking features supported sql server find support anyone know feature integration belongs versions integrate feature
109392 say running query begin tran update users set name jimmy name john dont rollback transaction changes still made throw error act rollback anyway
110460 postgres im following query quite often select distinct onrecipient messages left join identities messages recipient identities name timestamp timea timeb order recipient timestamp desc decided create view create view myview select distinct onrecipient messages left join identities messages recipient identities name order recipient timestamp desc realized query view like select myview timestamp timea timeb get significantly worse performance explain analyze queries found reason database second case brings records left join applies clause words clause pushed views query also tried remove order view still database performs left join full data rather filtered set reason behavior way get comparable performance using view
110774 thinking buying sql standard server implementing etl via ssis since expensive us would like test developing ssis packages free version since express version integrate ssis want try evaluation expires version sql server find anything possible limitations could anyone help
110781 table called example create table exists example id int11 null auto increment int11 null int11 null int11 null primary key id engine innodb default charset latin1 want insert values exists value exists update using following statement insert example values duplicate key update valuesa valuesb valuesc queries executed table look like execute statement result looks like wrong statement
110880 application uses postgresql table table big billions rows column integer integer digits negatives thought changing numeric60 would good idea would numeric60 take fewer bytes performance table queried lot
110911 set database collation latin1 general bin make string comparisons case sensitive impact performance impact dml ddl operations database database already exists tables
110916 table following structure create table rings id ringtype char2 number mediumint unsigned id user int11 data insert rings values aa11 aa21 aa31 aa111 aa121 aa131 aa141 aa151 ab161 ab171 ab181 ab191 ab202 ab212 ab222 wish group data based id user id ringtype contiguous range numbers list min max results look like id user id ringtype min max aa aa ab ab went several posts topic able tweak fit data help would appreciated
110949 tadd address table concattadd street number tadd street name tadd apt number tadd city tadd postal code tadd country address way exclude apt number doesnt exist thinking tadd apt number null return rows apt number even something works deal extra comma duplicate please post link comments
111013 best way think ask question starting example imagine two queries select car serialnumber tire serialnumber dbo tcar car inner join dbo ttire tire tire carid car id car brand jaguar select car serialnumber tire serialnumber dbo tcar car cross apply select tire serialnumber dbo ttire tire tire carid car id tire car brand jaguar note ttire carid indexed tcar brand indexed two would return output know second query foolish stand serve example question guess even dont know details sql server perform clever limited lock data read first query join im wondering perform lock data read second query apply mainly obviously imo ttire data read case apply sql server perfom lock edit example simple seems sql server manage create execution plan apply question though terms rbar effect occurs
111095 wondering scalar valued function grant user execute rather select meanwhile table valued functions works fine select permission db datareader membership clear example need user read permission database created user called testuser give db datareader membership created table valued function called fn inlinetable great testuser runs sql day long select dbo fn inlinetable need scalar function created scalar function called fn scalartest testuser run sql select dbo fn scalartest1 well understandably given testuser permission execute fn scalartest question based link https stackoverflow com questions insert update delete function sql server says function used perform actions modify database state let scalar function used select permission rather execute permission hope question makes sense thank
111187 ive imported data new database 600m rows timestamp integer double created indexes tried alter columns got space issues database vacuumed pgadmin iii tells size temporary files 50g temporary files like sql server transaction log get rid seems database much bigger total size database gb using posgres windows server screenshot database statistics tab
111223 table sql server looks like id version name date fielda fieldb fieldz foo foo null null bar null bee null working stored procedure diff takes input data version number input data columns name uptil fieldz field columns expected null row usually data first fields rest null name date version form unique constraint table need diff data input respect table given version row needs diffed row identified name date version change values field columns need show diff update fields need type decimal may nvarchars would prefer diff happen without converting type although diff output could convert everything nvarchar since used display purposed suppose input following requested version name date fielda fieldb fieldz foo null null foo null bar null baz null null diff needs following format name date field oldvalue newvalue foo fielda foo fielda null foo fieldb null bar fieldb baz fielda null solution far first generate diff using except union convert diff desired output format using join cross apply although seems working wondering cleaner efficient way number fields close place code actually large number lines input table existing table expected quite large time new sql still trying learn performance tuning sql create table diff change nvarchar null name nvarchar null date int null fielda decimal null fieldb decimal null fieldz decimal null generate diff temporary table insert diff select select old change name date fielda fieldb fieldz mytable mt version version mt name castmt date varchar select name castdate varchar diffinput except select old change diffinput union select new change diffinput except select new change name date fielda fieldb fieldz mytable mt version version mt name castmt date varchar select name castdate varchar diffinput mydiff select d3 name d3 date crossapplied field crossapplied oldvalue crossapplied newvalue select d2 name d2 date d1 fielda oldfielda d2 fielda newfielda d1 fieldb oldfieldb d2 fieldb newfieldb d1 fieldz oldfieldz d2 fieldz newfieldz diff d1 right outer join diff d2 d1 name d2 name d1 date d2 date d1 change old d2 change new d3 cross apply values fielda oldfielda newfielda fieldb oldfieldb newfieldb fieldz oldfieldz newfieldz crossapplied field oldvalue newvalue crossapplied oldvalue crossapplied newvalue crossapplied oldvalue null crossapplied newvalue null crossapplied oldvalue null crossapplied newvalue null thank
111258 order get overview compareable data current task create performance baseline get figures different productive sql server instances thoughts want use several dmvs want include profiler trace incl exec plans want include perfmon data try achieve general performance monitoring startable stoppable also scheduable returns information required identify success ongoing performance optimization tasks couple aggregated simple figures help visualize long term progress esp management executable execution plans within profiler trace compare individual queue changes improvements index optimization tasks found couple information describing creation performance baselines either complicated focus one desired performance indicators mostly perfmon data matching sample description following creating performance baseline sql server question anyone experience creating kind performance monitor quickly doable manner
111334 consider following product table highly trimmed id int auto increment category id int subcategory id int vendor id int price decimal62 inserted timestamp given category id attempting retrieve list containing vendor lowest latest price subcategory latest mean vendors may multiple prices given category id subcategory id combination recently inserted price category id subcategory id vendor id used theres tie vendors prices lowest id used tie breaker example data id category id subcategory id vendor id price inserted first find recent prices every subcategory vendor combination row price would removed recent vendor subcategory subcategory lowest price would vendor id subcategory lowest price two vendors tie ids choose one lowest vendor id would expect following results category id subcategory id vendor id price heres far feel like already starting get hand doesnt even account ties vendors prices select subcategory id vendor id price products join select mina price min price subcategory id products join select maxinserted latest price time vendor id subcategory id products category id group vendor id subcategory id inserted latest price time vendor id vendor id subcategory id subcategory id category id group subcategory id price min price subcategory id subcategory id category id go wanted see easier way comes grouping aggregating results additional groupings aggregations method give best performance important easier read less important
111335 junior dba years experience job fine tune queries advise developers particular code written indexes needed one simple question dev team asks frequently yesterday ran fine changed suddenly asked check infrastructure side first reaction problem always appears put maximum blame infrastructure always first thing validated answer changed questions development team guys ever faced situation please share experience
111347 one servers win r2 sql server constantly attack sa account hit like times per second different passwords dont sa account still would like stop probing probably consuming resources keep checking logs blocking offending ips firewall level manually still would like better solution sql server runs locally iis serve websites need connect sql server remotely database development ssms first thought setting vpn sure going play well ssms services like ftp interim solution stop sql server visible outside world firewall disabling port elsewhere enable disable developing perhaps ip thanks
111419 sql server ran dbcc sqlperflogspace took two log backups ran dbcc sqlperflogspace change used even though dbcc opentran foo says active open transactions mean inactive open transactions preventing log free space changing backups thanks
111462 scenario lets assume sql server sockets numa node socket physical cores gb memory total numa node gb ram key table loaded first numa node question lets assume lot traffic reading table physical cores socket owns numa node percent cpu utilization negatively influence cost non local numa access coming sockets hand cost non local numa access irrespective busy socket hope question makes sense please let know doesnt try clarify background database issue production server last week business processed appeared impacted others queries logical reads taking minute looked overall cpu utilization around percent look socket specific cpu metrics metrics average
111477 want download jsonbx rds instance rds postgresql features supported shows built features mean way install extension rds feature matrix work around
111487 learning formulate query like expressions relational algebra traditional part many perhaps introduction databases courses usually justified assertion relational algebra mathematical foundation relational databases general sql particular implication important know however seems formulating expressions relational algebra basically formulating queries sql much thought processes underly tasks particular cant really see knowing relational algebra makes easier write sql queries vice versa makes wonder teaching relational algebra sort historical hangover actually specific benefits knowing question specific practical benefits knowing relational algebra sufficient importance make worthwhile teaching database administrators feel relational algebra important career trajectory sort sub question whether time spent learning relational algebra could effectively used learning sql
111897 using mysql ver distrib debian linux gnu show tables page wise terminal
112090 need install sql server msde sp4 windows machines run windows sql server msde works fine merge replication configured testing scenario windows setup closing unexpectedly installation know version old workaround install windows
112094 need add column table contains columns groupkey shows number item status number status group according insert date status number changed back forward several times insert date time date status changed columns never change like log table rows added deleted changend fourth column calculated column need flag column show status last time status changed based insert date last status show else show hope explained well enough example
112167 sql server r2 database used several deployed programs question easy way display much space table consumes tables database distinguish logical space disk space use ssms management studio storage properties shown database reads mb mb available right size im concerned mb available limit concerned assuming know enough disk space drill table takes forever know write queries test around id like know theres already easy built way
112179 setting cron job collect results mongodb database profiler id like collect results within hrs period plan run mongo command javascript question mongo shell write query find date range hrs ago db system profile find timestamp lte current date time gt date time hrs ago
112408 table coursemaster like courseid coursename abc def ghi jkl mno pqr stu another table studentmaster student details like rollno name address course ram ram address hari hari address jeff jeff address daisy daisy address want fetch student details coursenamenot courseid values course comma separated would simple query fetch details join knowledge run two queries result want one query fetching details student studentmaster front end one fetching coursename coursemaster corresponding courseid loop fact want result one query rather write two queries small task guess possible expected result look like rollno name address course ram ram address abcdefpqr hari hari address defpqr jeff jeff address ghimnopqrstu daisy daisy address ghi thank valuable suggestion highly appreciate
112424 way sql server data written one table routed another sql server another host clarify using hibernate envars write audit logs hibernate envars allow data sent another server instead server audit log created hibernate id like audit logs sent another server way configure sql server write specific tables another server
112576 tables related like example company id name cnpj department id name code id company classification id name code id company workers id name code id classification id department suppose classification id id company department id company represents another company allow creation worker two companies classification department linked company separately dont want happen think problem relationships dont know solve
112810 im getting extremely slow query indexed column given query select orders shop id order updated desc limit explain analyze returned query plan limit cost rows width actual time rows loops index scan backward using index orders updated orders cost rows width actual time rows loops filter shop id rows removed filter planning time ms execution time ms rows table description table public orders column type modifiers id integer null default nextvalorders id seq regclass sent boolean default false created timestamp without time zone updated timestamp without time zone name character varying255 shop id integer recovered timestamp without time zone total price double precision indexes orders pkey primary key btree id index orders recovered btree recovered index orders shop id btree shop id index orders updated btree updated postgres server running aws rds t2 micro instance table around million rows
112876 given table primary key create table customers customerid int null primary key firstname nvarchar50 lastname nvarchar50 address nvarchar200 email nvarchar260 unique primary key customerid traditionally might need additional covering indexes example quickly find user either customerid email create index ix customers customeridemail customers customerid email kinds indexes ive created decades required unique actually index exists avoid table scan covering index order aid performance index constraint enforce uniqueness today remembered tid bit information sql server use fact column foreign key constraint column unique index constraint trusted order help optimize query execution fact sql server index design guide data unique want uniqueness enforced creating unique index instead nonunique index combination columns provides additional information query optimizer produce efficient execution plans creating unique index preferably creating unique constraint recommended case given multi column index contains primary key composite index de facto unique constraint particularly need sql server enforce every insert update fact non clustered index unique advantage marking de facto unique index actually unique create unique index ix customers customeridemail customers customerid email seems sql server could smart enough realize index already unique virtue fact contains primary key perhaps doesnt know theres advantage optimizer declare index unique anyway except perhaps might lead slowdowns inserts updates must perform uniqueness checks never unless knows index guaranteed already unique contains primary key find guidance microsoft composite index contains primary key benefits unique indexes include following data integrity defined columns ensured additional information helpful query optimizer provided mark composite index unique already contains primary key sql server figure
112992 several identical databases schema table structure within instance need find size one table example databases instance databases personal information table need find way query size personal information table instead going individually database way similar sp spaceused size data column
113122 currently foreign key two entities would like make relation conditional entitytype one tables heres hierachy tables done via fk refrences child parent store employees transactionalstores kiosks brickmortars onlines currently fk relation employee store alter table employees add constraint employee store foreign key transstoreid references transactionalstoresstoreid would like add conditional transactionalstores storetype online type possible must subclass transactionalstores two new subtypes physicalstores virtualstores
114260 table create table dbo realty id int identity11 null rankingbonus int null ranking id rankingbonus persisted null view create view dbo filteredrealty select realty id realtyid coalescerealty wgs84x ruian cobce wgs84x ruian obec wgs84x wgs84x coalescerealty wgs84y ruian cobce wgs84y ruian obec wgs84y wgs84y realty ranking realty join category realty categoryid category id left join ruian cobce realty cobceid ruian cobce cobce kod left join ruian obec realty obecid ruian obec obec kod left join okres realty okresid okres okres kod left join externfile realty id externfile foreignid externfile ismain externfile foreigntable inner join person realty ownerid person id person confirmstatus dbml model linqtosql filteredrealty view ranking field recognized nullable int fix type generated code every time change anything database frustrating lot manual work aggregates used filteredrealty regarding related question ranking column view considered nullable realty ranking non nullable
114332 worked couple times post deployment scripts always intuitively used build action postdeploy first time try follow built instruction scripts template use somescript sql syntax immediately line getting marked wrong sql80001 wrong syntax next found suggestions set pds build action none help error stays missing
114337 relatively simple query table 5m rows select mtid publication mtid last modifier limit explain analyze output limit cost rows width actual time rows loops bitmap heap scan publication cost rows width actual time rows loops recheck cond mtid last modifier bitmapor cost rows width actual time rows loops bitmap index scan publication pkey cost rows width actual time rows loops index cond mtid bitmap index scan publication last modifier btree cost rows width actual time rows loops index cond last modifier total runtime ms far good fast uses available indexes modify query bit result select mtid publication mtid select last modifier limit explain analyze output limit cost rows width actual time rows loops seq scan publication cost rows width actual time rows loops filter hashed subplan last modifier subplan result cost rows width actual time rows loops total runtime ms fast using seq scan course original query run application bit complex even slower course hibernate generated original select slowness even select query generated hibernate quite challenge change features available union available would fast questions index used second case could used improve query performance way additional thoughts seems could use first case manually select putting resulting list query even numbers list four times faster second solution however seems wrong also could times faster completely incomprehensible query planner uses completely different method two queries would like find nicer solution problem
114360 update statement actually change data data already updated state performance benefit putting check clause prevent update example would difference execution speed update update following create table mytable id int primary key value int insert mytable id value values update update mytable set value id value select rowcount update update mytable set value id select rowcount drop table mytable reason ask need row count include unchanged row know whether insert id exist used update form performance benefit using update form possible get row count need somehow
114376 server restarted verified trace flag active using dbcc tracestatus trace flag function removes messages errorlog traces started stopped see trace flag flag start parameters follows question find startup parameters sql server services sql
114403 need calculate rolling sum date range illustrate using adventureworks sample database following hypothetical syntax would exactly need select th productid th transactiondate th actualcost rollingsum45 sumth actualcost partition th productid order th transactiondate range interval day preceding current row production transactionhistory th order th productid th transactiondate th referenceorderid sadly range window frame extent currently allow interval sql server know write solution using subquery regular non window aggregate select th productid th transactiondate th actualcost rollingsum45 select sumth2 actualcost production transactionhistory th2 th2 productid th productid th2 transactiondate th transactiondate th2 transactiondate dateaddday th transactiondate production transactionhistory th order th productid th transactiondate th referenceorderid given following index create unique index production transactionhistory productid transactiondate referenceorderid include actualcost execution plan horribly inefficient seems like possible express query using window aggregate analytic functions supported sql server far clarity looking solution performs single pass data sql likely mean clause work execution plan feature window spools window aggregates language elements use clause fair game sqlclr solution acceptable provided guaranteed produce correct results sql solutions fewer hashes sorts window spools aggregates execution plan better feel free add indexes separate structures allowed pre computed tables kept sync triggers example reference tables allowed tables numbers dates etc ideally solutions produce exactly results order subquery version anything arguably correct also acceptable performance always consideration solutions least reasonably efficient dedicated chat room created public chat room discussions related question answers user least reputation points take part directly please ping comment less rep would like take part discussion date range rolling sum using window functions
114503 understanding one big benefits using vm share resources virtual machines host host cpus put vms cpus extra cpus shared vms host assigning cpus dynamically based need memory also understood big vms house sql servers vm admins disagree anyone evidence documentation one way dont know matters using vmware
114555 write query includes compound clause select mytable bitfield varcharfield asdf inclusion bit comparison simply excludes fields varchar comparison exclude presence bit field comparison render performance improvement
114580 need setup history feature project keep track prior changes lets say two tables right notes table id userid submissionid message submissions table id name userid filepath example row notes user wants change message want keep track state change change would best approach setting column tables say item old active deleted invisible also want create history audit trail table holds id prior state id new state table ids relate
114665 ive written query select bd utilizadores utilizador bd utilizadores palavra passe bd reas rea bd utilizadores inner join bd permiss es bd utilizadores id bd permiss es user id join bd reas bd permiss es area id bd reas id want join data table bd utilizadores bd reas since direct link use man middle bd permiss es diagram main question way get result
114774 simple table create table content id serial null text text fullfilename text constraint pk id primary key id oids false alter table content owner postgres create index content idx content using gin tsvectordanish regconfig text text rather long aggregated text perform full text searching run following query resorts seq scan explain analyze select id content tsvectordanish text tsquerydanishfelter seq scan content cost rows width actual time rows loops filter tsvectordanish regconfig text felt tsquery rows removed filter planning time ms execution time ms absolutely okay disabling seq scans set enable seqscan get following result bitmap heap scan content cost rows width actual time rows loops recheck cond tsvectordanish regconfig text felt tsquery heap blocks exact bitmap index scan content idx cost rows width actual time rows loops index cond tsvectordanish regconfig text felt tsquery planning time ms execution time ms exactly going parameters needs tuning run better dont like idea removing tool query planners toolbox stands setup running stock postgresql
114850 interest store time fsp ive read achieved timestamp datetime data types double field store output microtime function anyway set even write code create default value field want use something like now6 get example
114856 table million rows following definition indexes create table digiroad liikenne elementti ogc fid serial null wkb geometry geometrygeometry4258 tiee tila numeric90 vaylatyypp numeric90 toiminnall numeric90 eurooppati character varying254 kansalline numeric90 tyyppi numeric90 liikennevi numeric90 ens talo numeric90 talonumero numeric90 ens talo numeric90 oik puol character varying254 tieosan ta numeric90 viim talo numeric90 viim tal numeric90 vas puol character varying254 laut tyypp numeric90 lautta lii numeric90 inv paalu numeric1911 inv paal numeric1911 liitalue numeric90 ketju oid numeric90 tietojoukk numeric90 ajoratanum numeric40 viite guid character varying254 timestamp date tiee kunta numeric90 toissij ti character varying254 viite oid numeric90 elem id numeric90 region character varying40 default region character varying constraint digiroad liikenne elementti pkey primary key ogc fid create index digiroad liikenne elementti wkb geometry geom idx digiroad liikenne elementti using gist wkb geometry create index dle elem id idx digiroad liikenne elementti using btree elem id create index dle ogc fid idx digiroad liikenne elementti using btree ogc fid create index dle region idx digiroad liikenne elementti using btree region collate pg catalog default another table million rows contains attributes rows first table tables joined elem id region create table digiroad segmentti ogc fid serial null wkb geometry geometrygeometry4258 segm tila numeric90 tyyppi numeric90 loppupiste numeric1911 alkupiste numeric1911 vaikutuska numeric90 vaikutussu numeric90 vaikutusai character varying254 tieosanume numeric1911 tienumero numeric90 dyn arvo numeric90 dyn tyyppi numeric90 omistaja numeric90 pysakki va numeric90 pysakki ty numeric90 pysakki su numeric90 pysakki ka numeric90 pysakki yl character varying254 palvelu pa numeric90 toissijain numeric90 siltataitu numeric90 rdtc tyypp numeric90 rdtc alaty numeric90 rdtc paikk numeric1911 rdtc luokk numeric90 rdtc liitt character varying254 palvelu ob numeric90 ketju oid numeric90 tietojoukk numeric90 ajoratanum numeric40 viite guid character varying254 timestamp date sivusiirty numeric1911 toissij ti character varying254 viite oid numeric90 elem id numeric90 region character varying40 default region character varying constraint digiroad segmentti pkey primary key ogc fid create index digiroad segmentti wkb geometry geom idx digiroad segmentti using gist wkb geometry create index ds dyn arvo idx digiroad segmentti using btree dyn arvo create index ds dyn tyyppi idx digiroad segmentti using btree dyn tyyppi create index ds elem id idx digiroad segmentti using btree elem id create index ds ogc fid idx digiroad segmentti using btree ogc fid create index ds region idx digiroad segmentti using btree region collate pg catalog default create index ds tyyppi idx digiroad segmentti using btree tyyppi trying insert rows first table modification new table create table edge table id serial null geom geometry source integer target integer km double precision kmh double precision default kmh winter double precision default cost double precision cost winter double precision reverse cost double precision reverse cost winter double precision x1 double precision y1 double precision x2 double precision y2 double precision elem id integer region character varying40 constraint edge table pkey primary key id since running single insert statement would take long time would able see statement stuck something decided smaller chunks inside loop function function looks like drop function exists insert function create replace function insert function returns void declare const type constant int const type constant int int row count int begin create table exists edge table id serial primary key geom geometry source integer target integer km double precision kmh double precision default kmh winter double precision default cost double precision cost winter double precision reverse cost double precision reverse cost winter double precision x1 double precision y1 double precision x2 double precision y2 double precision elem id integer region varchar40 batch size select count digiroad liikenne elementti row count batch size row count loop raise notice insert batch size row count insert edge table kmh kmh winter elem id region select case ds dyn arvo null else ds dyn arvo end case ds dyn arvo null else ds dyn arvo end dr elem id dr region select dle elem id dle region digiroad liikenne elementti dle dle ogc fid batch size dle ogc fid batch size batch size dr left join digiroad segmentti ds ds elem id dr elem id ds region dr region ds tyyppi const type ds dyn tyyppi const type end loop end language plpgsql volatile strict problem starts going loops quite fast point slows crawl slows time disk usage windows task manager rises suspect related problem somehow running insert statement random value executes quickly problem seems arise running loop inside function explain analyzebuffers one single execution insert edge table cost rows width actual time rows loops buffers shared hit read dirtied nested loop left join cost rows width actual time rows loops buffers shared hit read index scan using dle ogc fid idx digiroad liikenne elementti dle cost rows width actual time rows loops index cond ogc fid ogc fid buffers shared hit read index scan using ds elem id idx digiroad segmentti ds cost rows width actual time rows loops index cond elem id dle elem id filter tyyppi numeric dyn tyyppi numeric vaikutussu numeric region text dle region text rows removed filter buffers shared hit read total runtime ms system running postgresql windows 8gb ram experimented different batch sizes query different ways increasing memory variables postgres configuration nothing seems really solved issue configuration variables changed default values shared buffers 2048mb work mem 64mb effective cache size 6000mb id like find causing happen could done
114902 given table employees employee id salary department id using sql find variants employee transfers one department another average salary departure arrival department grew ps asked question interview never gave answer google little help
115136 production database experiencing wildly fluctuating page life expectancy ple issues crashes zero random times researching ple issue found something seems point vmware issue sure using data right seems like losing buffer cache pages using query select count cached pages count case database id resourcedb else db namedatabase id end database name sys dm os buffer descriptors group db namedatabase id database id order cached pages count desc found totaling results count ple crashes example seem lose pages guess hardware virtual machines stress randomly swap memory server guess happens pages lost ple plummets using sys dm os buffer descriptors view correctly read always shows used buffer cached pages empty significantly reduced either dont memory anymore empty would love way confirm conclusion another explanation count drops much information line added ops comments system admins manage vms hoping understand query go data timing ple crashes seems random database point view indexing high performance stuff happening ple crashes done ton work see work load related one poorly performing query enough use cache rebuilding non routine user activity server buffer counts go even would see used query meaning sql server action wouldnt counts stay different stuff dont access vmware settings hoping understand findings better involving point question ensure using view correctly first end comment chain trying say ple issue lead loss buffer pages issue query using get ple would show low ple pages lost gone false reading amount memory reduced version microsoft sql server sp1 x64 dec copyright microsoft corporation enterprise edition bit windows nt x64 build hypervisor
115175 large 100million row table need update couple fields log shipping etc also obviously want keep bite size transactions trick get print output see progress tried adding print statement nothing output loop code declare chunk size int set chunk size update top chunk size huge table set deleted deleteddate deleted null deleteddate null rowcount begin update top chunk size huge table set deleted deleteddate deleted null deleteddate null end
115201 seems like basic question cant find answers need able get server name instance etc linked server ive tried couple things select linked server servername select linked server serverpropertyservername joy ideas sql r2 2008r2 linked server edit errors msg level state line incorrect syntax near servername
115270 dev box sql server configured high maximum amount memory 8gb 16gb required many development tasks sometimes want memory back though dont want leave 8gb consumed permanently whats good way get sql server suddenly release memory operating system dbcc dropcleanbuffers merely marks clean buffers available restarting sql server problem causes minute database recovery run due bug feature stopping sql server service causes databases shut cleanly please vote connect item seems like egregious bug
115338 recently restored database instance backed sql server r2 enterprise found couldnt access database properties done following checked database owner set correctly using sp helpdb changed database owner sa fix changed database owner back sysadmin user fix issued dbcc updateusage affected database fix run dbcc checkdb restored copy another instance corruption found restored copy backup file throw errors accessing database properties window anyone help error message get trying view properties show requested dialog sqlmgmt property size available database dbname property may exist object may retrievable due insufficient access rights microsoft sqlserver smo sysadmin instance update suggested created new user made sysadmin changed database owner fix unfortunately see profiler trace yields anything useful update aaron original database renamed taken offline still instance backup database restored using original name filenames new database files different original live folder original mdf ldf restored db currently driving critical apps normal
115339 instance sql server installed customer server customers department charge various backups machine sql server log shows full backup every day pm cant find evidence plan scheduled sql server technicians contacted couldnt tell us sort automatic backup told entire machine backup using script found forum thread found physical device name guid means external backup process use msdb go select bs database name bs backup start date bs backup finish date bs server name bs user name backupcreator bmf physical device name msdb backupset bs inner join msdb backupmediafamily bmf bs media set id bmf media set id order bs backup start date desc row query db name 000server name nt authority system 424f084a f35d 4a66 8fc7 072268a89a77 moreover backup start finish date spans seconds guess clear job sql server line log backup database backed database db name creation datetime pages dumped first lsn last lsn number dump devices device information file type virtual device 95380b0a d50b 408f b95f 1ab8975ba7f8 informational message user action required since cant help us track process responsible backups need want coordinate backup ordered manner transaction log backups order keep log reasonable size shrink log every week good way go
115391 simple timeseries table movement history data id serial item id character varying event time timestamp without timezone location id character varying area id character varying frontend developer telling cost high wants know item given timestamp sort table wants add another timestamp field next event doesnt sort yet going double cost code insert new movement need query previous entry item update insert new data inserts course far outnumber queries frequency never seen timeseries table included entry time next event hes telling table broken infrequent query requires sort suggestions dont know query using would select movement history event time timestamp item id h665ayg3 order event time desc limit currently 15k items entered database day however soon 50k items sensor data updated every minutes see query performed often another query get current status pallets select distinct item id movement history order item id event time desc server currently running could running needs
115461 im working database stores address information related question posted tables create table dbo country code char null code3 char null codenumeric char null name varchar null continentcode char null currencycode char null primary key clustered code asc constraint countrycontinentfk foreign key continentcode references dbo continent code constraint countrycurrencyfk foreign key currencycode references dbo currency code create table dbo city id int identity null code varchar null name nvarchar null countrycode char null primary key clustered id asc constraint citycountryfk foreign key countrycode references dbo country code want add capital country table using fk city table know impossible constraints city capitals id also country countrys code city makes sense approach im using database together thinking write method would first add country capital nullable add city table update countries capital city added approach another approach consider adding capital country table instead creating new table countrycapital link country city capital together one better approach think approach good solution database maintained would hard keep data added manually approach hand looks easier maintain manual edits made add city add country add record countrycapital table citys id countrys code
115621 ive created filtered index however run queries index gets used seek first example end dttm join rather clause thats difference queries anybody explain happens index creation create nonclustered index ix patient list bespoke list id includes dbo patient list bespoke list id asc end dttm asc end dttm null queries declare list id int one seeks index select patient lists list id dbo patient lists left join dbo patient list bespoke patient lists list id patient list bespoke list id patient list bespoke end dttm null patient lists list id list id one scans index select patient lists list id dbo patient lists left join dbo patient list bespoke patient lists list id patient list bespoke list id patient lists list id list id patient list bespoke end dttm null
115765 processes require different steps taken start example disable check constraint foreign key select alter table fk table schema fk table name nocheck constraint fk constraint name saproduct information schema table constraints fk join saproduct information schema tables table schema fk table schema table name fk table name constraint type foreign key produce big list statements copying use saproduct go alter table dbo tblprodclassificationcode nocheck constraint fk tblprodclassificationcode tblprodclassification alter table dbo tblprodclassificationcodedescr nocheck constraint fk prodclassificationcodedescr prodclassificationcode alter table dbo tblprodclassificationcodegenerate nocheck constraint fk prodclassificationcodegenerate prodclassification run one go would find table dealing one next delete select delete table schema table name saproduct information schema tables table name like tbl script would produce set statements use saproduct go delete dbo tblblanguage delete dbo tblblgcategoryxref delete dbo tblblgsegmentxref delete dbo tblprodclassification delete dbo tblprodclassificationcode delete dbo tblprodclassificationcodedescr delete dbo tblprodclassificationcodegenerate delete dbo tblprodclassificationdescr delete dbo tblprodclassificationmarket delete dbo tblprodclassificationtier delete dbo tblprodclassificationvalue delete dbo tblproddata delete dbo tblproddatadescr delete dbo tblproddatamarket delete dbo tblproddatatemptier1descr delete dbo tblproddatatemptier1tier2descr delete dbo tblproddatatier delete dbo tblproddatavalue delete dbo tblproddatavaluedate delete dbo tblproddatavaluenumber delete dbo tblproddatavaluestring delete dbo tblprodname delete dbo tblprodnamesizealias delete dbo tblprodnamesizerulealias delete dbo tblprodnamestructure delete dbo tblprodnamestructuredescr delete dbo tblproduct table next one delete trying access tables certain order minimise deadlocks specially put type exclusive locks try avoid lock escalation get complex like see exactly going using sql server microsoft sql server x64 feb copyright microsoft corporation developer edition bit windows nt x64 build hypervisor
115913 update table2 another table1 located another database table1 located another database updated daily transactions last day want update table2 new values added table1 databases located server rows going deleted table1 historical record transactions want replay table2 table2 database server used ssas bi think requires procedure tried use bdid bi go set ansi nulls go set quoted identifier go create procedure transactionupdate insert bdid bi dbo transaction select bdid dbo hl transaction select bdid bi dbo transaction date date go daily procedure dont insert values previously inserted update new values added table1
115943 im dba im responsible database currently hundreds tables 5tb data recently ran following query hopes determining index fragmentation declare databaseid int db idods select object namet object id tablename t2 name indexname index id indexid index type desc indextype index level indexlevel avg fragmentation percent averagefragmentationpercent avg page space used percent averagepagespaceusedpercent page count pagecount sys dm db index physical stats databaseid null null null detailed inner join sys indexes t2 index id t2 index id object id t2 object id order avg fragmentation percent desc first rows result set looks follows importing excel startling reading correctly indexes actually lot fragmented query correct
116054 want prevent explicit inserts serial columns come following trigger drop table test table create table test table id bigserial primary key foobar text create replace function serial id check returns trigger begin new id currvaltg table name id seq raise exception explicit insert serial id currval tried insert currvaltg table name id seq new id end return new end language plpgsql create trigger test table serial id check insert test table row execute procedure serial id check maybe better approach maybe approach broken achieved also think granting rights insert update pgplsql procedure inserting updating approach possible right
116142 im working postgresql table contains following entries id postcode date created al2 2qp al2 2qp sp2 8ag se4 e2 fk20 8ru fk20 8ru se2 fk20 8ru fk20 8ru se1 fk20 8ru se1 8ga se1 hp27 9rz hp27 9rz se1 tn21 8qb tn21 8qb tn21 8qb n4 1ny want achieve query returns recent unique postcode records id id postcode n4 1ny tn21 8qb se4 sp2 8ag al2 2qp se1 hp27 9rz se1 8ga fk20 8ru se2 would best way achieving ive playing around subqueries keep hitting walls comes ordering whilst distinct group
116240 creating temporary table mytable using cursor create problem concurrent users accessing cursor application allow create separate temp tables name following sample code open cursor fetch next cursor variable temp table name create table mytablepk int fetch status begin fetch next cursor variable temp table name end
116280 possible multiple fields range key say table row uniquely identified abc primary hash key want primary range keys fields primary key dynamodb
116330 using sql plus use backspace button erase content line command hit backspace instead erasing writes way configure backspace works intended
116347 previous question mine good idea disable lock escalation adding new calculated columns table creating computed column alter table dbo tblbgiftvoucheritem add isusgift cast isnull case sintmarketid strtype card strtier1 like gg else end bit persisted calculated column persisted according computed column definition transact sql persisted specifies database engine physically store computed values table update values columns computed column depends updated marking computed column persisted allows index created computed column deterministic precise information see indexes computed columns computed columns used partitioning columns partitioned table must explicitly marked persisted computed column expression must deterministic persisted specified try create index column get following error create index fix tblbgiftvoucheritem incl dbo tblbgiftvoucheritem stritemno include strtier3 isusgift filtered index fix tblbgiftvoucheritem incl created table dbo tblbgiftvoucheritem column isusgift filter expression computed column rewrite filter expression include column create filtered index computed column alternative solution
116361 want migrate database instance aws rds mysql aurora doubt replication aurora management write read operations application want separate write operations reads want create master instance write operations instance read replica read operations problem read aws documentation need separation application think hope find way transparent application draw simple schema get aurora aws aws says application writes reads master read replica replication need need master always keep write operations redirects read read replica instance application write read reads master read replica replication replication always running want separate write read process summary master instance detecte different writes reads operations read operation manage read replica need solution aurora offer good features improve rds problem need create balance write read operations write operation processed master send read operation read replica dont want define process make selection application code amazon propose
116365 database design course learning relational algebra relational calculus see relational algebra could useful since closely tied sql professor said relational calculus used alternative sql rdmbs around still practical use relational calculus much theoretical
116368 second insert statement 5x slower first amount log data generated think second qualifying minimal logging however documentation data loading performance guide indicates inserts able minimally logged minimal logging key performance difference second query qualify minimal logging done improve situation query inserting 5mm rows using insert tablock consider following query inserts 5mm rows heap query executes second generates 64mb transaction log data reported sys dm tran database transactions create table dbo minimalloggingtest int null go insert dbo minimalloggingtest tablock select table view sub query correctly estimates generate 5mm rows dbo fivemillionnumbers provides greater consistency laptop processes running option maxdop go query inserting data sql underestimates rows consider similar query operates exactly data happens draw table complex select statement many joins actual production case cardinality estimate low query executes seconds generates 461mb transaction log data create table dbo minimalloggingtest int null go insert dbo minimalloggingtest tablock select table view sub query produces 5mm rows sql estimates rows dbo fivemillionnumbersbadestimate provides greater consistency laptop processes running option maxdop go full script see pastebin full set scripts generate test data execute either scenarios note must use database simple recovery model business context semi frequently moving around millions rows data important operations efficient possible terms execution time disk load initially impression creating heap table using insert tablock good way become less confident given observed situation demonstrated actual production scenario albeit complex queries simplified version
116494 slow query select products counts cid products counts products counts left outer join products products products counts product id products id left outer join trademarks trademark products trademark id trademark id left outer join suppliers supplier products counts supplier id supplier id products counts product id order products counts inflow asc supplier delivery period asc trademark sort desc trademark name asc limit average query time 5s dataset unacceptable solutions see add columns order clause products counts table order types application create lot columns indexes plus products counts intensively updates inserts deletes need perform immediately update order related columns using triggers solution explain id select type table type possible keys key key len ref rows extra simple products counts range product id supplier idproduct idpid count product id supplier id null using using temporary using filesort simple products eq ref primary primary uaot products counts product id simple trademark eq ref primary primary uaot products trademark id simple supplier eq ref primary primary uaot products counts supplier id tables structure create table products counts id int11 null auto increment product id int11 unsigned null supplier id int11 unsigned null count int11 unsigned null cid varchar64 null inflow varchar10 null delete tinyint1 unsigned null default primary key id unique key cid cid unique key product id supplier id product idsupplier id key product id product id key count count key pid count product idcount engine innodb default charset utf8 create table products id int11 null auto increment external id varchar36 null name varchar255 null category id int11 unsigned null trademark id int11 unsigned null photo varchar255 null sort int11 unsigned null otech tinyint1 unsigned null liquid tinyint1 unsigned null default applicable varchar255 null code main varchar64 null code searchable varchar128 null total int11 unsigned null slider int11 unsigned null slider title varchar255 null primary key id unique key external id external id key category id category id key trademark id trademark id engine innodb default charset utf8 create table trademarks id int11 null auto increment external id varchar36 null name varchar255 null country id int11 null sort int11 unsigned null default sort list int10 unsigned null default featured tinyint1 unsigned null direct tinyint1 unsigned null default primary key id unique key external id external id engine innodb default charset utf8 create table suppliers id int11 null auto increment external id varchar36 null code varchar64 null name varchar255 null delivery period tinyint1 unsigned null default tinyint1 unsigned null primary key id key external id external id engine innodb default charset utf8 mysql server information mysqld ver deb sury org trusty debian linux gnu i686 ubuntu
116521 planning stages upgrade sql server r2 sql server system executes stored procedures different databases different servers upgrade one server sql server leave remaining servers sql server r2 would lose ability
116552 first words safely ignore sections including joins starting want take crack code background results serve context please look edit history want see code looked like initially objective ultimately want calculate interpolated gps coordinates transmitter xmit based datetime stamps available gps data table secondtable directly flank observation table firsttable immediate objective accomplish ultimate objective figure best join firsttable secondtable get flanking time points later use information calculate intermediate gps coordinates assuming linear fitting along equirectangular coordinate system fancy words say dont care earth sphere scale questions efficient way generate closest time stamps fixed grabbing getting related intuitive way doesnt involve structure byrdzeye provided basic alternatives however real world experience didnt line join strategies performing full credit addressing alternative join styles thoughts tricks advice may thusfar byrdzeye phrancis quite helpful regard found phrancis advice excellently laid provided help critical stage ill give edge still would appreciate additional help receive regard question bulletpoints reflect believe helped individual question table definitions semi visual representation firsttable fields rectstamp datetime contain milliseconds via vba code see ref receivid long xmitid text25 keys indices pk dt primary unique null compound xmitid asc rectstamp asc receivid asc uk drx unique null compound rectstamp asc receivid asc xmitid asc secondtable fields id long autonumber seeded main table created already sorted primary key xtstamp datetime contain partial seconds latitude double decimal degrees degrees minutes seconds longitude double way straight decimal math performed keys indices pk primary unique null simple xtstamp asc uidx id unique null simple id asc receiverdetails table fields receivid long receiver location description text null ok beginning datetime partial seconds ending datetime partial seconds lat double lon double keys indicies pk rid primary unique null simple receivid asc validxmitters table field primary key xmitid text25 primary unique null simple sql fiddle play table definitions code question msaccess phrancis pointed sql fiddle style access able go see table definitions code based phrancis answer http sqlfiddle com e9942 external link joins starting current inner guts join strategy first create firsttable rekeyed column order compound primary key rectstamp receivid xmitid indexed sorted asc also created indexes column individually fill like insert firsttable rekeyed rectstamp receivid xmitid select distinct row rectstamp receivid xmitid firsttable xmitid select xmitid validxmitters order rectstamp receivid xmitid query fills new table records returns within matter seconds following completes within second two whole method wrapped select count top subquery method used select receiverrecord rectstamp receiverrecord receivid receiverrecord xmitid select top xmitgps id secondtable xmitgps receiverrecord rectstamp xmitgps xtstamp order xmitgps id afterxmit id firsttable rekeyed receiverrecord inner join secondtable xmitgps receiverrecord rectstamp xmitgps xtstamp group rectstamp receivid xmitid separate join needed top method would required methods additionally restriction returned set needed create rekeyed table may need group either could try order three afterxmit id alternatives take longer minutes complete ever complete firstxmitgps id minxmitgps id minswitchxmitgps xtstamp receiverrecord rectstamp xmitgps id null previous inner guts join query first fastish good enough select rectstamp receivid xmitid maxiifb xtstamp rectstampb xtstampnull beforextstamp miniifb xtstamp rectstampb xtstampnull afterxtstamp firsttable inner join secondtable rectstamp xtstamp rectstamp xtstamp group rectstamp receivid xmitid alternative beforextstamp max xtstamp rectstamp xtstamp alternatives afterxtstamp see aside note max1 xtstamp rectstamp xtstamp min1 xtstamp rectstamp xtstamp second slower select rectstamp abyb1 xtstamp beforextstamp abyb2 xtstamp afterxtstamp firsttable inner join select top b1 xtstamp a1 rectstamp secondtable b1 firsttable a1 b1 xtstamp a1 rectstamp order b1 xtstamp desc abyb1 max time points rectstamp abyb1 rectstamp inner join select top b2 xtstamp a2 rectstamp secondtable b2 firsttable a2 b2 xtstamp a2 rectstamp order b2 xtstamp asc abyb2 min time points rectstamp abyb2 rectstamp background telemetry table aliased million entries compound primary key based datetime stamp transmitter id recording device id due circumstances beyond control sql language standard jet db microsoft access users use later versions entries relevant query transmitter id second telemetry table alias involves approximately entries single datetime primary key first step focused finding closest timestamps stamps first table second table join results quirks ive discovered along way debugging feels really odd writing join logic firsttable inner join secondtable rectstamp xtstamp rectstamp xtstamp byrdzeye pointed comment since disappeared form cross join note substituting left outer join inner join code appears make impact quantity identity lines returned also cant seem leave clause say using comma join rather inner left outer join results countselect countselect rows returned query rather one line per table explicit join returns clearly suitable first doesnt seem available use given compound primary key type second join style although arguably legible suffers slower may additional two inner joins required larger table well two cross joins found options aside replacing iif clause min max appears return number entries max xtstamp rectstamp xtstamp works max timestamp doesnt work directly min follows min xtstamp rectstamp xtstamp minimum always false condition less post epoch double datetime field subset access calculation transforms field iif min max methods alternates proposed afterxtstamp value work division zero false generates null values aggregate functions min max skip next steps taking wish find timestamps second table directly flank timestamps first table perform linear interpolation data values second table based time distance points timestamp first table way would like calculated value come 2nd table value data associated point using revised join type part inner guts suggested answers produce select avggps xmitid strdateiso8601msecavggps rectstamp rectstamp ms strdateiso8601msec vba function returning text string yyyy mm dd hh nn ss lll format avggps receivid rd receiver location description rd lat receiver lat rd lon receiver lon avggps lat avggps afterweight avggps lat avggps afterweight xmit lat avggps lon avggps afterweight avggps lon avggps afterweight xmit lon avggps rectstamp rectstamp basic select aftertimestampid rectstamp aftertimestampid xmitid aftertimestampid receivid gpsbefore beforextstamp gpsbefore latitude lat gpsbefore longitude lon gpsafter afterxtstamp gpsafter latitude lat gpsafter longitude lon aftertimestampid rectstamp gpsbefore xtstamp gpsafter xtstamp gpsbefore xtstamp afterweight select receiverrecord rectstamp receiverrecord receivid receiverrecord xmitid select top xmitgps id secondtable xmitgps receiverrecord rectstamp xmitgps xtstamp order xmitgps id afterxmit id firsttable receiverrecord receiverrecord xmitid select xmitid validxmitters group rectstamp receivid xmitid aftertimestampid inner join secondtable gpsafter aftertimestampid afterxmit id gpsafter id inner join secondtable gpsbefore aftertimestampid afterxmit id gpsbefore id avggps inner join receiverdetails rd avggps receivid rd receivid avggps rectstamp rd beginning rd ending order avggps rectstamp avggps receivid returns records conforming least approximately final number expected records run time probably minutes i7 16gb ram ssd win pro system reference ms access handle millisecond time values really accompanying source file txt
116615 want merge one table another need apply conditional logic matched clause would ideally done like merge atable using btable id id matched insert matched needsadjustment update set col1 col1 adjustment col2 col2 adjustment col3 col3 adjustment matched default case needsadjustment update set col1 col1 col2 col2 col3 col3 valid sql according msdn documenation two matched clauses one must specify update action one must specify delete action leads following query merge atable using btable id id matched insert happens matched update set col1 case needsadjustment col1 else col1 adjustment end col2 case needsadjustment col2 else col2 adjustment end col3 case needsadjustment col3 else col3 adjustment end conditional logic moved inside update get around fact merges one matched update clause instead one check per row one check per row per column many columns three example avoid repeating condition every column needs updated better way conditional updates perhaps dont involve merges
116731 piece code msdn page clause use adventureworks2012 go select businessentityid territoryid datepartyymodifieddate salesyear convertvarchar20salesytd1 salesytd convertvarchar20avgsalesytd partition territoryid order datepartyymodifieddate movingavg convertvarchar20sumsalesytd partition territoryid order datepartyymodifieddate cumulativetotal sales salesperson territoryid null territoryid order territoryidsalesyear issues understanding convert function used assume return types one fields expression part convert function cast used instead second question exactly part work sumsalesytd partition territoryid order datepartyymodifieddate exactly saying calculating sum every year
116747 add trigger update column using following format strings current date per day incremental id ids must incremental gaps allowed approach rather naive make table current date current sequence value maintain single record create table dailysequence date date sequence int insert dailysequence values getdate create trigger makehumanreadableid dbo auditmeasures insert declare ret int declare tempdate date declare nowdate date set nowdate getdate select ret sequence tempdate date dailysequence nowdate tempdate begin set ret ret update dailysequence set sequence ret end else begin set ret update dailysequence set sequence ret date nowdate end update auditmeasures set humanreadableid cast nowdate varchar10 cast ret varchar10 inserted inner join auditmeasures inserted id auditmeasures id go questions pitfalls solution code inside trigger wont run inside transaction thus giving incorrect values missing better solution
116965 sql server equivalent using index clause oracle specifically construct create table cc1 int c2 int create index ci c1 c2 alter table add constraint cpk primary key c1 using index ci sql server documentation unique indexes states emphasis added unique indexes implemented following ways primary key unique constraint create primary key constraint unique clustered index column columns automatically created clustered index table already exist specify unique nonclustered index primary key column allow null values seems imply way specifying index used primary key
117036 interest keeping database secure possible id like lock sys system accounts one login assuming os scripts cron jobs logging sys system arent applications outside utilities using either accounts always login sysdba proper os account locking two accounts adverse effects anyone done comment whether good idea
117146 currently running performance problems since database getting big data stored last years dont see reason data older years stored tables new data since dont profound experience administrating databases im looking best ways archive old data info records database total database needs gb hard disk server version sql server compatibility level sql server planning upgrading sql server soon ive thought two possibilities new database create database similar one production server insert old data new database disadvantage since linked servers allowed environment would difficult join old data needed history schema create new schema hist tables production database insert old data new tables new schema advantage easy joining old data would needed future prefere one solutions better possibilities existing tools task easily possible thoughts thanks advance edit additional question would newly created archive table also need primary foreign keys columns without keys constraints
117193 table 170m rows looks follows create table dbo panel subid varchar null lineageid int null buck varchar null lot varchar null glasstype varchar null eta varchar null constraint pk panel primary key clustered subid asc queries table reference subid either clause join one dbas told could make queries joins perform better creating following index create unique nonclustered index ix panel subid lineageid dbo panel subid asc include lineageid told thought nuts checked index usage since index created found following pk panel seeks scans ix panel subid lineageid seeks scans bit shocked see circumstances would new index every get used would sql server ever select maybe better question would would sql server select new index seek instead clustered index approximately 25k times thought seeking new index better choice case helps lineageid essentially indicates panel created distinct values could contain
117306 query runs milliseconds sql server takes seconds sql server think ive narrowed poor cardinality estimate row count spool operator ive read bit spool operators still trouble understanding things query need row count spool operator dont think necessary correctness specific optimization trying provide sql server estimate join row count spool operator removes rows bug sql server ill file connect id like deeper understanding first note write query left join add indexes tables order achieve acceptable performance sql server sql server question understanding specific query plan depth less phrase query differently slow query see pastebin full test script specific test query im looking prune existing customers set potential new customers query much slower expected sql server select potentialnewcustomers 10k rows cust nbr select cust nbr existingcustomers 1mm rows sql server estimated query plan sql server believes left anti semi join row count spool filter rows row reason selects loop join subsequent join existingcustomers sql server actual query plan expected everyone sql server row count spool remove rows looping times sql server expected loop sql server estimated query plan using sql server option querytraceon sql server row count spool reduce estimated rows hash join chosen resulting far better plan left join write reference way may write query order achieve good performance sql server however im still interested specific behavior query whether bug new sql server cardinality estimator writing left join yields much better performance select potentialnewcustomers left join select test cust nbr existingcustomers cust nbr cust nbr test null
117391 running sql r2 db working fine fast last years untill months ago added ntext field active used table starting get server space huge expanding size table read shrinking want loose indexing db working fast years want get fragmentation expending decided delete field values way delete ntext field values release space without removing indexing without shrinking without loosing db performance attaching db size query output show size expanding last months
117469 need create test data involves hierarchy could make easy couple cross joins would give structure completely uniform without variation seems dull lack variation test data sometimes masks problems would otherwise found wanting generate non uniform hierarchy follows rules levels deep level randomly nodes level nodes random per node level level nodes random per node level branches levels deep uniformity depth ok point overlap names child nodes given level names child nodes need unique across nodes level term random defined pseudo random uniquely random needs mentioned since term random often used mean random ordering given set produce duplicates accept random random number children per node level even across nodes level potential spread children per nodes fine random even though done quite easily nested loops preference find set based approach generally speaking generating test data requirements efficiency production code would shooting set based approach likely educational help future finding set based approaches problems loops ruled used set based approach possible set based ideally single query regardless ctes applys etc using existing inline numbers table fine using cursor procedural approach work suppose staging portions data temp tables table variables fine long operations set based loops however said single query approach probably favored multiple queries unless shown multi query approach actually better please also keep mind constitutes better typically subjective please also keep mind usage typically prior sentence also subjective version edition sql server newer suppose pure sql none silly sqlclr stuff least terms generating data creating directories files done using sqlclr focusing generating values create sql multi statement tvf considered procedural set based even though outside mask procedural approach set times absolutely appropriate one time along lines sql scalar functions also allowed also procedural query optimizer sometimes caches value repeats output expected sql inline tvfs itvfs okey dokey set based effectively using cross outer apply stated ok repeated executions queryies produce mostly different result prior run clarification update final result set expressed one row distinct node level3 full path starting level1 means level1 level2 values necessarily repeat across one rows except cases single level2 node containing single level3 node clarification update strong preference node name label number allow resulting test data meaningful realistic sure additional info matters case helps context test data relates answer question import xml files sql server relevant point end goal generating hierarchy create directory structure test recursive file system methods levels directories level end file name searched around via googles found one reference generating random hierarchy linux create random directory file hierarchy question stackoverflow actually quite close terms desired result since also seeks create directory structure testing question answers focused linux unix shell scripting much set based world live know generate random data already create contents files also show variations tricky part number elements within set random particular field number elements within node needs random nodes levels example hierarchy level level iii vi vii ix aaa ddd asdf qwerty beft roygbp poi moi soy joy roy example result set describing hierarchy level level level iii vi vii ix aaa ddd asdf asdf asdf qwerty beft roygbp poi roygbp moi roygbp soy roygbp joy roygbp roy
117484 sql server sample query bottom post im trying create simple report given database last backed executing sample query output text ssms db name column formatted max possible size data issue exists db2 btw ive got column contains data never say characters stored varchar128 get characters data matter rtrim effect output elegant way know make formatted column length max size actual data rather max potential size data guess exists xp sprintf function im familiar doesnt look terribly robust ive tried casting like declare servername length int select servername length len cast serverpropertyservername varcharmax select convertchar servername length serverpropertyservername server sql server wont let use variable database name length varchar definition casting sql server apparently demands literal number declaring char varchar variable im building statement string using something like sp executesql building temp table actual column lengths need really bit trouble hoping go get spaces output character column searched interwebs found bupkus maybe im searching wrong thing google cross seems ssms format column maximum size allowed even actual data much smaller hoping elegant way fix without jumping hoops im using ssms go results grid excel something similar trailing space eliminated hoping basically create report email though sample query query select convertchar32 serverpropertyservername server msdb dbo backupset database name maxmsdb dbo backupset backup finish date last db backup date msdb dbo backupmediafamily inner join msdb dbo backupset msdb dbo backupmediafamily media set id msdb dbo backupset media set id msdb backupset type group msdb dbo backupset database name order msdb dbo backupset database name
117567 part process add articles publication use stored procedure sp addarticle use returns exec sp addarticle publication nusreturns article ntblreturnscontainertypedescr source owner ndbo source object ntblreturnscontainertypedescr type nlogbased description creation script pre creation cmd ndrop schema option 0x000000000803509f identityrangemanagementoption nnone destination table ntblreturnscontainertypedescr destination owner ndbo status vertical partition nfalse ins cmd ncall sp msins dbotblreturnscontainertypedescr del cmd ncall sp msdel dbotblreturnscontainertypedescr upd cmd nscall sp msupd dbotblreturnscontainertypedescr go publications hundreds articles save scripts would like properly formatted format scripts ssms wanted see scripts way use returns exec sp addarticle publication nusreturns article ntblreturnscontainertypedescr source owner ndbo source object ntblreturnscontainertypedescr type nlogbased description creation script pre creation cmd ndrop schema option 0x000000000803509f identityrangemanagementoption nnone destination table ntblreturnscontainertypedescr destination owner ndbo status vertical partition nfalse ins cmd ncall sp msins dbotblreturnscontainertypedescr del cmd ncall sp msdel dbotblreturnscontainertypedescr upd cmd nscall sp msupd dbotblreturnscontainertypedescr go working moment copying pasting script word following link special characters use find replace word put new line similar tricks way level formatting using ssms
117734 need backup sql server r2 databases sizes gb online used simultaneously single enterprise app also need restore state largely synchronized across databases afford seconds desync databases purpose capture production data qa dev environments would strongly like demand databases run full recovery come backup method dedicated capturing data qa environments remains independent main backup process control customers take hours capture full backups gb makes taking full backups sequentially unacceptable databases would desynchronized running simple recovery im looking idea better idea san level snapshot vm disks xcopy mdfs ldfs snapshot copied files attached different server instance recovery process produce consistent databases snapshot pretty much simultaneously googling around convinced bad idea least may get desync vs master msdb etc idea orchestrate complex backup sync restore across databases requires demanding databases run full recovery dont want start parallel backups databases well deadline t0 t0 reached backup logs take minutes take resulting myriad backups try restore roll logs forward back obtain somewhat consistent state across databases relative t0 requires lot planning scripting used reliably would go great lengths avoid missing solution wouldve loved able use db snapshots idea initiate snapshot db seconds fully backup one sequentially following minutes hours restore different server revert one snapshot afaik scenario possible snapshots cant backed along database rolled back place server created addition require enterprise edition dont customers know 3rd party solution capable producing cross db synchronized backups please mention
117740 way postgres like query array field currently want something like select list lowerarray field like currently lower needed much however find one matching field inside array even possible currently use materialized view generate list table join array agg since join table values could right table would duplicate fields left table want edit create view really sluggish ugly create materialized view article list new select id oa nr date deleted lock sds nr kd art nr kd art index kd art extend surface execution surface area cu thickness endintensity drilling array aggo id text offer list article list left join task offer article oa nr group also need return ids task offer table
118057 sql table varchar columns contain greek formatted numbers thousand separator comma decimal separator classic conversion convertnumeric102replace value work thousand separator kills conversion try convertnumeric102replace7 want convert values numeric102 suggestions handle
118158 im attempting run unpivot various columns contained sys databases across various versions sql server ranging unpivot failing following error message msg level state line type column compatibilitylevel conflicts type columns specified unpivot list sql declare dbname sysname set dbname db name select database unpvt databasename configuration item unpvt optionname configuration value unpvt optionvalue select databasename name recoverymodel convertvarchar50 recovery model desc compatibilitylevel convertvarchar50 case compatibility level sql server sql server sql server sql server sql server sql server else unknown end autoclose convertvarchar50 case auto close false else true end autocreatestatistics convertvarchar50 case auto create stats false else true end autoshrink convertvarchar50 case auto shrink false else true end autoupdatestatistics convertvarchar50 case auto update stats false else true end autoupdatestatisticsasynch convertvarchar50 case auto update stats async false else true end closecursoroncommit convertvarchar50 case cursor close commit false else true end defaultcursor convertvarchar50 case local cursor default local else global end ansinull default convertvarchar50 case ansi null default false else true end ansinulls enabled convertvarchar50 case ansi nulls false else true end ansipadding enabled convertvarchar50 case ansi padding false else true end ansiwarnings enabled convertvarchar50 case ansi warnings false else true end arithmeticabort enabled convertvarchar50 case arithabort false else true end concatnullyieldsnull convertvarchar50 case concat null yields null false else true end crossdbownerchain convertvarchar50 case db chaining false else true end datecorrelationoptimized convertvarchar50 case date correlation false else true end numericroundabort convertvarchar50 case numeric roundabort false else true end parameterization convertvarchar50 case parameterization forced simple else forced end quotedidentifiers enabled convertvarchar50 case quoted identifier false else true end recursivetriggers enabled convertvarchar50 case recursive triggers false else true end trustworthy convertvarchar50 case trustworthy false else true end vardecimal storage convertvarchar50 true pageverify convertvarchar50 page verify option desc brokerenabled convertvarchar50 case broker enabled false else true end databasereadonly convertvarchar50 case read false else true end encryptionenabled convertvarchar50 case encrypted false else true end restrictedaccess convertvarchar50 user access desc collation convertvarchar50 collation name sys databases name dbname dbname null src unpivot optionvalue optionname recoverymodel compatibilitylevel autoclose autocreatestatistics autoshrink autoupdatestatistics autoupdatestatisticsasynch closecursoroncommit defaultcursor ansinull default ansinulls enabled ansipadding enabled ansiwarnings enabled arithmeticabort enabled concatnullyieldsnull crossdbownerchain datecorrelationoptimized numericroundabort parameterization quotedidentifiers enabled recursivetriggers enabled trustworthy vardecimal storage pageverify brokerenabled databasereadonly encryptionenabled restrictedaccess collation unpvt designed provide nicely formatted list database options given database similar database configuration item value use master recoverymodel simple master compatibilitylevel sql server master autoclose false master autocreatestatistics true master autoshrink false master autoupdatestatistics true master autoupdatestatisticsasynch false master closecursoroncommit false master defaultcursor global master ansinull default false master ansinulls enabled false master ansipadding enabled false master ansiwarnings enabled false master arithmeticabort enabled false master concatnullyieldsnull false master crossdbownerchain true master datecorrelationoptimized false master numericroundabort false master parameterization simple master quotedidentifiers enabled false master recursivetriggers enabled false master trustworthy true master vardecimal storage true master pageverify checksum master brokerenabled false master databasereadonly false master encryptionenabled false master restrictedaccess multi user master collation latin1 general ci ks ws run server latin1 general ci ks ws collation statement succeeds modify sql certain fields collate clause run servers collations code works servers collations latin1 general ci ks ws declare dbname sysname set dbname db name select database unpvt databasename configuration item unpvt optionname configuration value unpvt optionvalue select databasename name recoverymodel convertvarchar50 recovery model desc collate sql latin1 general cp1 ci compatibilitylevel convertvarchar50 case compatibility level sql server sql server sql server sql server sql server sql server else unknown end autoclose convertvarchar50 case auto close false else true end autocreatestatistics convertvarchar50 case auto create stats false else true end autoshrink convertvarchar50 case auto shrink false else true end autoupdatestatistics convertvarchar50 case auto update stats false else true end autoupdatestatisticsasynch convertvarchar50 case auto update stats async false else true end closecursoroncommit convertvarchar50 case cursor close commit false else true end defaultcursor convertvarchar50 case local cursor default local else global end ansinull default convertvarchar50 case ansi null default false else true end ansinulls enabled convertvarchar50 case ansi nulls false else true end ansipadding enabled convertvarchar50 case ansi padding false else true end ansiwarnings enabled convertvarchar50 case ansi warnings false else true end arithmeticabort enabled convertvarchar50 case arithabort false else true end concatnullyieldsnull convertvarchar50 case concat null yields null false else true end crossdbownerchain convertvarchar50 case db chaining false else true end datecorrelationoptimized convertvarchar50 case date correlation false else true end numericroundabort convertvarchar50 case numeric roundabort false else true end parameterization convertvarchar50 case parameterization forced simple else forced end quotedidentifiers enabled convertvarchar50 case quoted identifier false else true end recursivetriggers enabled convertvarchar50 case recursive triggers false else true end trustworthy convertvarchar50 case trustworthy false else true end vardecimal storage convertvarchar50 true pageverify convertvarchar50 page verify option desc collate sql latin1 general cp1 ci brokerenabled convertvarchar50 case broker enabled false else true end databasereadonly convertvarchar50 case read false else true end encryptionenabled convertvarchar50 case encrypted false else true end restrictedaccess convertvarchar50 user access desc collate sql latin1 general cp1 ci collation convertvarchar50 collation name sys databases name dbname dbname null src unpivot optionvalue optionname recoverymodel compatibilitylevel autoclose autocreatestatistics autoshrink autoupdatestatistics autoupdatestatisticsasynch closecursoroncommit defaultcursor ansinull default ansinulls enabled ansipadding enabled ansiwarnings enabled arithmeticabort enabled concatnullyieldsnull crossdbownerchain datecorrelationoptimized numericroundabort parameterization quotedidentifiers enabled recursivetriggers enabled trustworthy vardecimal storage pageverify brokerenabled databasereadonly encryptionenabled restrictedaccess collation unpvt observed behavior following fields observe either server collation database collation always presented latin1 general ci ks ws collation sql server use sys sp describe first result set easily obtain metadata columns returned particular query used following determine collation mismatch declare cmd nvarcharmax set cmd select databasename convertvarchar50 name recoverymodel convertvarchar50 recovery model desc collation convertvarchar50 collation name sys databases name db name exec sp describe first result set command cmd results collation columns statically set
118178 performance related question lets say user first name michael take following query update users set first name michael users id query actually execute update even though updated value prevent happening
118331 understand single indexed column works sql server implemented using balanced trees plenty interesting videos youtube topic however dont understand works index based multiple columns example create nonclustered index idxitemscatstate items categoryofferstate include id ranking speedup query like select id ranking items category offerstate still implemented tree evaluate combination values restrictions feature
118452 right clicking table selecting select top rows get error workaround obvious upgrade sql server
118458 trying use appears rather badly written application connects sql server database specify seem connect sql server instance wish use without specifying port comma dbserver dbinstance port number problem causes think application badly written reason application thinks port number name database server instance name dbserver dbinstance believe expecting deal port number like used sql server instances require port number specified know must setting tcp ip settings sql server configuration manager tried setting port default well turning dynamic ports neither worked still fairly new sql server anybody could point right direction would greatly appreciated edit solved problem per ste bovs answer also know application could handle port specified internally application storing data temporary csv file didnt bother check input commas enclose quotes came port csv thought next field supposed database name yes badly written application indeed
118492 im attempting look estimated execution plan following sql statement exec msdb dbo sp delete job job id 3a015189 f4eb 439b 9ca0 27afb74719d8 originating server local delete history delete unused schedule sql server throws following error msg level state procedure sp delete msx jobs line column name number supplied values match table definition definition sp delete msx jobs contains following pertinent lines starting line wrapped readability insert temp jobs delete select sjv job id case sjs server id else end sjv owner sid msdb dbo sysjobs view sjv left outer join msdb dbo sysjobservers sjs sjv job id sjs job id isnullsjs server id sjv originating server msx server line stored proc shows definition temp jobs delete create table temp jobs delete job id uniqueidentifier null job cached int null owner sid varbinary85 null looks valid display estimated execution plan returning error run sql server 2008r2 return error im using ssms
118649 way ignore cached query plans data pages memory single query batch something like table hint option turned current connection want force query hit disk im trying tune execution times place trying reduce variables play
118729 process involves executing various commands multiple databases however use dynamic sql change db use var doesnt actually change database executing test db declare currentdb varcharmax declare sql varcharmax set currentdb db name set sql use currentdb use master exec sql select db name returns master current database name put use test db command rather dynamically returns correct name way correctly switch databases
118737 seen question ssis query currently running packages sql gives following script select execution id folder name project name package name reference id reference type environment folder name environment name project lsn executed sid executed name use32bitruntime operation type created time object type object id status start time end time caller sid caller name process id stopped sid stopped name dump id server name machine name total physical memory kb available physical memory kb total page file kb available page file kb cpu count folder id name description created sid created name created time project id folder id name description project format version deployed sid deployed name last deployed time created time object version lsn validation status last validation time pkg package id pkg name pkg package guid pkg description pkg package format version pkg version major pkg version minor pkg version build pkg version comments pkg version guid pkg project id pkg entry point pkg validation status pkg last validation time ssisdb catalog executions inner join ssisdb catalog folders name folder name inner join ssisdb catalog projects folder id folder id name project name inner join ssisdb catalog packages pkg pkg project id project id pkg name package name answer quest investigating reasons packages fail need get hold error messages find would like use sql query error message also script takes near quite select select em ssisdb catalog event messages em em operation id select maxexecution id ssisdb catalog executions event name like validate put whatever predicates might like event name onerror package name infogroup feed dtsx execution path like executable order message time desc email would like tackle get error message information troubleshoot ssis errors welcome
118823 currently ive got one backup file imtdb bak hdd database want increase redundancy db backup essentially copying another disk get error backup failed server media formatted support media families think means created backup meant put backup one drive cant retroactively add want migrate backup drive really copy dont want delete current backup safe copying imtdb bak folder drive
118880 problem using query without problem update t1 set ordinal datediffday t2 opening date t1 date facttransactions t1 inner join dimstore t2 t1 cod store t2 cod storekey gave error conversion failed converting date time character string idea whats going columns ordinalnumericnull opening datevarchar null datevarchar null cod storeintnot null cod storekeypkint null
119621 using mysql innodb storage engine tables innodb buffer pool size gb innodb db indexes around gb server 32gb ram running cent os x64 one big table contains around millions records get updated dump file remote server every hours file csv format dont control format file mb tried inserting data myisam table row row took minutes need take values per line file update database whats best way achieve something like need daily currently flow like mysqli begin transaction read dump file line line update record line line mysqli commit operations takes around minutes complete updates going gives lock wait timeout exceeded try restarting transaction update data loading new table using load data local infile myisam took sec innodb took min sec update table1 t1 table2 t2 set t1 field1 t2 field1 t1 field2 t2 field2 t1 field3 t2 field3 t1 field10 t2 field10 query ok rows affected hours min sec update update join query update table1 join table2 field1 field1 set field2 field2 field3 field3 field4 field4 hours min sec clarifications questions comments rows table updated file sometimes much indexes fields updated indexes table indexes include update fields necessary update one transaction take time hours looking get done hour without locking whole table later update sphinx index dependent table matter steps take longer duration long database available tasks could modify csv format preprocess step thing matters quick update without locking table myisam newly created table csv file using load data infile myi file size mb table indexed field1 column myd myisam table 663mb update details table create table content hash char40 character set ascii null default title varchar255 collate utf8 unicode ci null default og name varchar255 collate utf8 unicode ci null default keywords varchar255 collate utf8 unicode ci null default files count smallint5 unsigned null default files smallint5 unsigned null default files varchar255 collate utf8 unicode ci null default category smallint3 unsigned null default size bigint19 unsigned null default downloaders int11 null default completed int11 null default uploaders int11 null default creation date datetime null default upload date datetime null default last updated datetime null default vote int11 unsigned null default vote int11 unsigned null default comments count int11 null default imdb int8 unsigned null default video sample tinyint1 null default video quality tinyint2 null default audio lang varchar127 character set ascii null default subtitle lang varchar127 character set ascii null default verified tinyint1 unsigned null default uploader int11 unsigned null default anonymous tinyint1 null default enabled tinyint1 unsigned null default tfile size int11 unsigned null default scrape source tinyint1 unsigned null default record num int11 unsigned null auto increment primary key record num unique key hash hash key uploaders uploaders key tfile size tfile size key enabled category upload date verified enabledcategoryupload dateverified key enabled upload date verified enabledupload dateverified key enabled category verified enabledcategoryverified key enabled verified enabledverified key enabled uploader enableduploader key anonymous uploader anonymousuploader key enabled uploaders upload date enableduploadersupload date key enabled verified category enabledverifiedcategory key verified enabled category verifiedenabledcategory engine innodb auto increment default charset utf8 collate utf8 unicode ci row format fixed create table content csv dump temp hash char40 character set ascii null default title varchar255 collate utf8 unicode ci null category id int11 unsigned null default uploaders int11 unsigned null default downloaders int11 unsigned null default verified tinyint1 unsigned null default primary key hash engine myisam default charset utf8 collate utf8 unicode ci update query updates content table using data content csv dump temp update content join content csv dump temp hash hash set uploaders uploaders downloaders downloaders verified verified update testing done test machine tests production machine queries fast mysql update content test join content csv dump temp hash hash set uploaders uploaders downloaders downloaders verified verified query ok rows affected min sec rows matched changed warnings apologize mistake better use join instead record update trying improve mpre using index suggested rick james update bench marking done
119865 transaction opened sql server ways rolled back currently working 3rd party application frequently showing open transactions query sleeping status sometimes days showing via sp whoisactive leads believe error somewhere application allowing transactions commit ways transactions could possibly rollback client side timeout specified client closes restarts application manual kill spid anything else anything transactions open hours days going rollback timeout point anyway harm killing process
120060 xml column contains data similar structure root elements element code value aaa element element code value bbb element element code value ccc element elements root modify data using sql server change value attribute element root elements element code value aaa value element element code value bbb value element element code value ccc value element elements root update xml looks like root attr1 val1 attr2 val2 elements element code value aaa extradata extra element code value bbb extradata extra element code value ccc extradata extra element code value extradata extra element code extradata extra elements extradata xml extradata root would like move value attribute preserve attributes elements
120064 table string column predicate checks rows certain length sql server seeing estimate row regardless length checking yielding poor plans actually thousands even millions rows sql server choosing put table outer side nested loop explanation cardinality estimate sql server sql server estimates rows good workaround short reproduction issue create table 1mm rows dummy data create table customers cust nbr varchar10 null go insert customers tablock cust nbr select top convertvarchar10 row number order select null cust nbr master spt values v1 cross join master spt values v2 go looking string certain length ces yield fairly poor estimates ce much conservative higher estimate therefore much likely yield okay plan rather drastically understimated loop join rows estimated 900k rows actual row estimated 900k rows actual select count customers lencust nbr option querytraceon optionally use ce go complete script showing additional tests also read whitepaper sql server cardinality estimator didnt find anything clarified situation
120488 need determine dates 3rd friday month date range sql server expect use combination dense rank partition set rank however new sql unable find correct code
120635 postgresql im using version possible mass update single query column value value another column column value null use value third column third one absent use current datetime column type timestamp need change columna columnb columnc null foo bar null null baz null null null columna columnb columnc foo foo bar baz null baz quz null null quz current datetime
120756 according blog parameters function stored procedure essentially pass value arent output parameters essentially treated safer version pass reference output parameters first thought goal forcing tvp declared readonly clearly signal developers tvp cant used output parameter must going cant declare non tvp readonly example following fails create procedure dbo test int readonly select msg level state procedure test parameter declared readonly since table valued parameter since statistics arent stored tvp rationale behind preventing dml operations related wanting tvp output parameters reason
120945 run following command get error however one scripts requires set time zone utc error hy000 unknown incorrect time zone utc
121034 best practice using left join exists format benefit using one none preferred select tablea left join tableb idx idx idx null select tablea exists select idx tableb idx idx using queries within access sql server database
121160 mongodb3 appeared new storage engine wiredtiger yet mmapv1 still default choice mongo one might better often matter use case choosing right tool job engine right job fact mmapv1 default engine wiredtiger seems better almost every field features mmapv1 plus better write performance document level concurrency compression snapshots checkpoints system found comparing table mongodbs blog except solaris reason choose wiredtiger edit two videos explain details internals wiredtiger mmapv1
121208 im taking project involves removing limiting permissions database users across server farm fun times one permissions currently limited db owner permissions permission reviewed case case basis common change replace db owner permissions following db datareader db datawriter db ddladmin db executor would like define exact difference two inform clients however far tell difference two db accessadmin permissions db backupoperator permissions db securityadmin permissions effect would lose alter user create schema backup database backup log checkpoint alter application role alter role drop database anything else user would loose db owner replaced four roles actually serve much purpose security wise
121236 seeing note mysqld log note innodb page cleaner 1000ms intended loop took 15888ms settings might optimal flushed evicted time seems mention something like mysql instance stalling sync index question action taken note seen logs mysql os versions mysql community server el7 x86 centos release el7 centos x86 running show variables like innodb suggested shows innodb page cleaners
121370 order datetimecolumn orders datetime column like datetimecolumn order data values last still order values ascending time like datetimecolumn dumb business rule know know basically user spec time time matter goes bottom list
121804 im trying write munin plugin graph db sizes alongside using pg database size want graph components thereof well far ive come following select sumpg relation sizeoid main main size sumpg relation sizeoid vm vm size sumpg relation sizeoid fsm fsm size sum case reltoastrelid else pg total relation sizereltoastrelid end toast size sumpg indexes sizeoid indexes size pg class reltype indices covered pg indexes size however summing values returns something result pg database size difference seems less significant larger dbs example larger db main vm fsm toast indexes sum values pg database size diff mb mb kb row example smaller db main vm fsm toast indexes sum values pg database size diff kb kb kb row missing maybe related maybe im shocked see index size huge something query wrong script used inspect different values select sumpg relation sizeoid main main sumpg relation sizeoid vm vm sumpg relation sizeoid fsm fsm sum case reltoastrelid else pg total relation sizereltoastrelid end toast sumpg indexes sizeoid indexes pg size pretty sumpg relation sizeoid main bigint sumpg relation sizeoid vm bigint sumpg relation sizeoid fsm bigint sumpg indexes sizeoid bigint sum case reltoastrelid else pg total relation sizereltoastrelid end bigint sum values pg size prettypg database sizecurrent database pg database size pg size pretty sumpg relation sizeoid main bigint sumpg relation sizeoid vm bigint sumpg relation sizeoid fsm bigint sumpg indexes sizeoid bigint sum case reltoastrelid else pg total relation sizereltoastrelid end bigint pg database sizecurrent database bigint diff pg class reltype
121877 currently transitioning server company another want keep sql server installed server wiping clean databases maintenance plans jobs im trying delete bunch sql server agent jobs even though disabled still idle mode raises following error trying delete drop failed job job name subplan microsoft sqlserver smo exception occurred executing transact sql statement batch microsoft sqlserver connectioninfo delete statement conflicted reference constraint fk subplan job id conflict occurred database msdb table dbo sysmaintplan subplans column job id statement terminated microsoft sql server error remove idle status job delete gets
121982 please place post questions like let know delete inside glenn berrys diagnostic queries query show much cpu database using query get cpu utilization database query cpu usage database db cpu stats select databaseid db namedatabaseid database name sumtotal worker time cpu time ms sys dm exec query stats qs cross apply select convertint value databaseid sys dm exec plan attributesqs plan handle attribute ndbid db group databaseid select row number overorder cpu time ms desc cpu rank database name cpu time ms cpu time ms cast cpu time ms sum cpu time ms decimal5 cpu percent db cpu stats databaseid resourcedb order cpu rank option recompile would like know query see databases using cpu based past information im trying know causing server high cpu use well picture server pretty good almost always cpu usage using sp whoisactive cant find nothing obviously got lot queries none seems hammering server read write pretty low everytime thats im problems understand low read write server using much cpu nothing common cpu im trying know database heaviest one migrate
122262 trying run sp askbrent powershell using invoke sqlcmd capture output variable query exec saidba monitoring sp askbrent seconds check invoke sqlcmd serverinstance serverinstance query query erroraction stop connectiontimeout running expertmode problem running expertmode notice three things outputs every data shell check null ends following error invoke sqlcmd duplicate column names permitted sql powershell repeat column use column alias duplicate column format column name new name line char check invoke sqlcmd serverinstance serverinstance query query er categoryinfo syntaxerror invoke sqlcmd sqlpowershellsqlexecutionexception fullyqualifiederrorid duplicatecolumnnameerrormessage microsoft sqlserver management powershell getscriptcommand think workaround providing parameters sp askbrent store expertmode data tables select tables afterwards want make sure way get everything back powershell
122582 several hundred currently ever growing tables copy one server another never im sure approach tables format cart eight character customer number part larger project merging cart number tables one carts table thats whole different question altogether anyone best practice method use copy tables database names servers helps said earlier sa account whatever necessary get data servers server farm well
122623 postgres column type uuid specify uuid generated automatically default value row insert
122666 using transactional replication sql server one master publisher distributor dedicated server slaves subscribers writes made master reading done one subscribers issue make insert update delete page refreshing update isnt yet sec delay subscribers updated confuse user row inserted deleted updated isnt reflected subscribers yet considering going peer peer replication seems overhead identity goes back write one also take much time replicate could
122707 im trying understand differences different installers sql server express able tell whatever find documentation id appreciate https www microsoft com en us download confirmation aspxid express 32bit wow64 sqlexpr32 x86 enu exe express 32bit sqlexpr x86 enu exe express 64bit sqlexpr x64 enu exe expressadv 32bit sqlexpradv x86 enu exe expressadv 64bit sqlexpradv x64 enu exe expressandtools 32bit sqlexprwt x86 enu exe expressandtools 64bit sqlexprwt x64 enu exe localdb 32bit sqllocaldb msi localdb 64bit sqllocaldb msi mgmtstudio 32bit sqlmanagementstudio x86 enu exe mgmtstudio 64bit sqlmanagementstudio x64 enu exe
122756 table million record join another table records however potential keys lets assume account number email address membership number alternative email id number table columns table must used joining keys code would something like select tbl1 t1 join tbl2 t2 t1 col1 t2 col1 t1 col1 t2 col2 t1 col1 t2 col3 t1 col5 t2 col1 forth combination huge kills server also sound logical thinking putting columns row increase number records reducing number column however yet sure best solution solution kill server highly appreciated note kindly note column tb1 matched columns tbl2 instance column col1 contains account number joined col1 hold potential account number col1 way joined email address columns
122823 reasons control must find solution issue simply reinstalling instance option server name appears server id sys servers still showing old servername im getting error running command sp dropserver old instance go sp addserver new instance local go error message msg level state procedure sp dropserver line still remote logins linked logins server old instance msg level state procedure sp addserver line server new instance already exists strangest thing remote login null login exec sp dropremotelogin remoteserver old instance go error message msg level state procedure sp dropremotelogin line remote user null mapped local user null remote server old instance logins exist old instance sp helpremotelogin old instance msg level state procedure sp helpremotelogin line remote logins remote server old instance rename instance cant drop non existing login way flush logins
122926 would like add check constraint large table something like alter table accounts add constraint positive balance check balance unfortunately postgresql blocks reads writes constraint check completed verified starting transaction running alter table opening second transaction checking couldnt read write table first transaction completed way add check constraint without locking table
123327 table value column want calculate last row minus first row shown id value want obtain ive tried use command sql server however last first dont work select lastvalue firstvalue counter syntax command sql server
123664 whats difference countcase column end countcase column else end ive using former havent seen difference thus far reason adding else situations sql server incorrectly count
123863 want fast lookup based two columns equal tried use computed column index sql server doesnt seem use use statically populated bit column index get expected index seek seems questions like none focused index wouldnt used test table create table dbo diffs id int null identity dataa int null datab int null diffpersisted isnullconvertbit case dataa null datab null dataa datab else end persisted diffcomp isnullconvertbit case dataa null datab null dataa datab else end diffstatic bit null primary key id create index ix diffpersisted diffs diffpersisted create index ix diffcomp diffs diffcomp create index ix diffstatic diffs diffstatic query select id diffs diffpersisted select id diffs diffcomp select id diffs diffstatic resulting execution plans
123969 monitor backups following query select command percent complete elapsed total elapsed time remaining estimated completion time sys dm exec requests command like backup command like restore notice backup sql server perform restore headeronly backup wondering use execution time could reduced somehow appears take longer actual backup
123978 looking application uses highly dynamic sql queries sql server looking queries constructed weird complicated ways thats different story tell give good reason able stupid find things cant see code queries wrapped sp executesql trace see lot queries coming wrapped sp executesql whole application solution even contain command sp executesql wondered kind configuration know yet forces software wrap queries sp executesql default could cause behaviour
124082 title sums ive got sql server database tables stored procedures must reverse engineered im pretty sure tables never used procs used well biggest problem windows services created used db software database documentation lost person designed whole system nowhere found ive already managed create er diagram help understand relationships experienced database administration idea start also im sorry kind question meant asked
124204 sql database stores application usage logs pcs pcs send usage data sql server around times per day used store recent days application usage customer asked us longer purge data years worth data rows sql database suffering performance issues significant mind far database significant number records added hour application open records within hours record updated associated application close updates see via sql activity monitor taking considerable time complete update query simple select top id tb applicationusage application xxxxxxx computername xxxxxxxxx endtime null order starttime desc effectively finds recent matching application start specific machine doesnt yet associated application close cant think efficient way run query im considering following alternative move two databases working database recent hours worth records final database records im sql guru im probably missing drawbacks method goal would sql agent job move completed records final database every night customer wants run monthly reports report query final database working database maybe records query working database instead would seem logical would work faster seems simple im probably missing something obvious version microsoft sql server r2
124785 table custpassmaster columns one custnum varchar8 created index ix dbo custpassmaster custnum run select statement select dbo custpassmaster custnum ignores index completely confuses another table custdatamaster way columns one custnum varchar8 created index column ix dbo custdatamaster custnum table use practically query select dbo custdatamaster custnum uses index created specific reasoning behind would use index custdatamaster one custpassmaster due low column count first query returns rows second row returned also additional note custpassmaster records custdatamaster records could reasoning behind ignoring index custpassmaster also duplicate records custnum values well another factor basing claim actual execution plan results queries ddl custpassmaster one unused index create table dbo custpassmaster custnum varchar null username char null password char null columns vbterminator varchar null primary create nonclustered index ix dbo custpassmaster custnum dbo custpassmaster custnum asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary ddl custdatamaster ive omitted lot irrelevant fields create table dbo custdatamaster custnum varchar null columns vbterminator varchar null primary create nonclustered index ix dbo custdatamaster custnum dbo custdatamaster custnum asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary dont clustered index either tables one nonclustered index ignore fact datatypes dont entirely match type data stored fields backup ibm db2 database compatible datatypes able query backup database exact queries get exact results data used select statements dont insert update delete statements except backup application copying data
124847 one best option get identity value generated via insert impact statements terms performance scope identity aggregate function max select top identitycolumn tablename order identitycolumn desc
124896 query uses clause happen use exact clause many queries table et al query select datenamedw atdatetime day week count number searches castcastcount decimal10 countdistinct convertdate atdatetime decimal10 average searches per day sumcase numfound else end number searches results castcastsumcase numfound else end decimal10 count decimal10 percent searches results db dbo searchhistory customernumber customernumber group datenamedw atdatetime datepartdw atdatetime order datepartdw atdatetime part wish change clause instead allow use table add customer number ignored dont update queries quite queries clause
124947 im looking alwayson availability groups look appears availability listener group single point failure exactly listener actually run separate server primary sql server say whole application stack second data center configure listeners running sites applications point local copies im sure im missing something dont know
124949 im trying update target table one row size 5k row size 5k also since one row easy know row actual size select sys dm db index physical statsdb idrods hsd es object idntbl bm hsd subject repro null null detailed reproduce table wasnt altered since creation dont see reason fail ideas
125069 table data two columns startdate enddate startdate date employee joined working company enddate date left need find working days employee per month startdate enddate working days june 10days july 31days august 21days query total days work select datediffddstartdateenddate tablename need take days per month update actually three columns startdate enddate salary full query needs divide salary calendar months salary dates sample result june days july august
125171 find error system incorrectly naming men women vice versa database columns allows one character without using temp tables write one update query resolve question asked recent interview im going interviews may similar questions wanted get idea handle
125190 provide reports file system usage im collecting statistics file server usage individual file level see using files folders much storage theyre using many files created last used powershell scripts first reads file system captures attributes want saves file dir rec select lastwritetime directory name extension length name owner expression get acl fullname select owner export csv fileinfo csv 2nd script reads csv file inserts data table data sql parse text split various columns produce variety reports analyse data different ways approach works cumbersome better way collect ntfs information save sql server alternatives ssis edit could combined operate together single process
125198 today discussing following brazil states one abbreviation like usa weve got rj rio de janeiro sp paulo mg minas gerais one programmers proposed use abbreviations rj sp mg etc pk states table planning add new project extrapolating use database countered argument saying someday expand services countries would problem repeated abbreviations example usa sc south carolina brazil weve got sc santa catarina happens mt pa counting weve agreed id column pk identity supposing expand services countries stay brazil started considering idea using varchar2 column pk scenario doesnt sound like totally bad idea cases could applied memory considered order choose one another
125251 query calculation give column alias next column would like use result calculation statement mysql recognise alias used condition instead required rewrite whole query put brackets around carry condition checking sql query select studentid subjectid countstudentid select countsubjectid lectureattendancein subjectid mis4 percentage ifcountstudentid select countsubjectid lectureattendancein subjectid mis4 allowed allowed examadmit attendancein group studentid subjectid subjectid mis4 order studentid asc would like use column alias called percentage statement
125272 recently deployed new environment newer version oracle 12c instead 11r2 recently noticed data returned sorted differently instead small letters capital letters numbers oracle 11r2 get data sorted opposite way numbers capital letters small letters oracle 12c realy confusing end user various applications querying database settings need check compare fix problem oracle 12c queries refer order clause edit settings parameters evironments nls sort type string value nls language type string value dutch value nls sort default phil select nls instance parameters parameter oracle11r2 oracle12c nls language dutch dutch nls territory netherlands netherlands nls sort nls date language nls date format nls currency nls numeric characters nls iso currency nls calendar nls time format nls timestamp format nls time tz format nls timestamp tz format nls dual currency nls comp binary binary nls length semantics byte char nls nchar conv excp false false select nls session parameters nls settings oracle sql developer relevant guess select nls database parameters nls rdbms version differs nls length semantics differs way check values sessions
125279 sql server standard edition know max number user connections dba heading towards number currently user connections number expected increase
125300 constantly see people say indexes slow update delete insert used blanket statement absolute tuning database improve performance keep coming across situation seems contradict rule logically nowhere find anyone say explain way otherwise sql server believe presume dbms indexes created based specific columns specify inserts deletes always affect entire row way affect index updates seem bit unique specifically affect certain columns columns included index update slowed index columns table example say user table one two indexes primary key identity auto increment column possibly another foreign key column update column without index directly like say phone number address update slowed indexes table columns either situation columns updating indexes logically indexes updated shouldnt anything would think sped use indexes clause
125308 im testing different architectures large tables one suggestion ive seen use partitioned view whereby large table broken series smaller partitioned tables testing approach ive discovered something doesnt make whole lot sense filter partitioning column fact view optimizer seeks relevant tables additionally filter column dimension table optimizer eliminates unnecessary tables however filter aspect dimension optimizer seeks pk ci base table queries question select od year avgvalue avgobservationvalue dbo observation join dbo observationdates od observationdatekey od datekey observationdatekey observationdatekey group od year select od year avgvalue avgobservationvalue dbo observation join dbo observationdates od observationdatekey od datekey od datekey od datekey group od year select od year avgvalue avgobservationvalue dbo observation join dbo observationdates od observationdatekey od datekey od year od year group od year heres link sql sentry plan explorer session im working actually partitioning larger table see get partition elimination respond similar fashion get partition elimination simple query filters aspect dimension meantime heres stats copy database https gist github com swasheck 9a22bf8a580995d3b2aa old cardinality estimator gets less expensive plan thats lower cardinality estimates unnecessary index seeks id like know theres way get optimizer use key column filtering another aspect dimension eliminate seeks irrelevant tables sql server version microsoft sql server x64 feb copyright microsoft corporation developer edition bit windows nt x64 build hypervisor
125399 im green comes world database permissions management sql sever lets keep example simple say account admin owner schemas another account minion want full rights update delete insert select alter object table view created schemas possible execute grant statement every time add table view schemas seems bit silly
125422 normal join syntax well known also possible position clause separately join corresponds something rarely seen practice found tutorials found web resource even mentions possible script play around select widgets1 values xwidgetid select widgets2 values somevalue1 somevalue2 somevalue3 xwidgetid somevalue select widgetproperties values xwidgetid propertyname q1 select w1 widgetid w2 somevalue wp propertyname widgets1 w1 left join widgets2 w2 w2 widgetid w1 widgetid left join widgetproperties wp w2 widgetid wp widgetid wp propertyname order w1 widgetid q2 select w1 widgetid w2 somevalue wp propertyname widgets1 w1 left join widgets2 w2 clause join widgetproperties wp w2 widgetid wp widgetid wp propertyname w2 widgetid w1 widgetid order w1 widgetid q3 select w1 widgetid w2 somevalue wp propertyname widgets1 w1 left join widgets2 w2 select join widgetproperties wp w2 widgetid wp widgetid wp propertyname w2 widgetid w1 widgetid order w1 widgetid q1 looks normal q2 q3 unusual positionings clause script necessarily make much sense hard contrive meaningful scenario unusual syntax patterns mean defined noticed positions orderings two clauses allowed rules governing also ever good idea write queries like
125494 get selection given string comma separated values passed cursor multiple values could passed via single variable code somewhat like cursor cursor vsstr1 select field table txtfield1 vsstr1 field varchar2 type vsstr1 varchar2100 pass variable correclty help would appreciated
125504 sure chosen right title question really given individual windows ad user would like find list windows ad groups logins access specific database server run following query select name principal id type type desc default schema name create date modify date owning principal id sid fixed role sys database principals server microsoft sql server r2 sp1 x64 jun copyright microsoft corporation standard edition bit windows nt build service pack get following results partial list need know permissions particular login login access server databases ad groups ad groups list login belong would really like find list ad groups access server according picture user belongs first execute user question execute login mycompany hthorne declare user varchar20 select user substringsuser sname charindex suser sname lensuser sname make sure right credentials select user suser sname system user user name current user original login user session user go specific database use fn permissions run user question use webdataimportstage go select fn permissions null database go revert giving result
125617 database triggers way delete triggers single command single database called system db audits
125771 concatenate multiple columns single row example id name car sam dodge ram maserati john benz null mazda kirk lexus jim rolls gmc expected result set id name car samramjohn dodgemaseratibenzmazdagmc kirkjim lexusrolls using solution found stack overflow select select idstuff query name value varcharmax11 somefield combined1 stuff query car value varcharmax11 somefield combined2 dbo test outer applyselect select id name name car car test test id id xml path type group idsomefield combined1somefield combined2 better solutions inner select comes expensive multi table join single table test shown query line tvf use temporary table also blank column results yield extra commas like id name car samramjohn dodgemaseratibenzmazdagmc kirkjim lexusrolls way prevent
125850 insert id identity column sql server ill make special item table quickly detect item id ids bigger equal one give special item id zero problem ive created table ive place identity column id true insert special item code ive got next error insert mytableid name description values special title special item error insert explicit value identity column table mytable identity insert set change table column property create record id zero
125885 long story short database manages employee data email first name last name etc company bought sap based expense report system needs export employee based data strange format without getting many details export data needs total columns many columns empty value simple put together query basically pulled information database set constants needed relevant query question simply select statement pulls data needed export daily basis specific file name pipe delimited format something effect employee export declare filename varchar500 set filename select somefileserver public somefolder employee p06010603ace replacereplacereplaceconvertvarchar19 convertdatetime getdate txt declare sql varchar8000 declare header varchar8000 set sql bcp exec mydbserver mydbname dbo concuremployeeexport queryout filename exec master xp cmdshell sql perfect get rows like jon doe steve smith columns didnt want display since irrelevant thought done implementation coordinator said yes looks good except first row needs start strange row values meaning resultant query one additional row values simple thought would union wanted except union put additional empty values match number columns query issue run export end bunch empty columns pipe delimited end sso update en imagine going columns submitted said well everything looks good except first row need first values want sso update en union union requires number columns queries thought could somehow generating file replace first line last possible without write another app interface want keep modify first row result get fixed currently sample three rows sso update en jon doe jon doe company com en us usa tk symbolic usd usa cc usa0000202105 eol steve smith steve smith company com en us usa tk symbolic usd usa cc usa0000202105 eol need get sso update en jon doe jon doe company com en us usa tk symbolic usd usa cc usa0000202105 eol steve smith steve smith company com en us usa tk symbolic usd usa cc usa0000202105 eol notice first row removed ideally would like maybe query exports file something effect removing first row export first row static generated using select transaction type error threshold sso password generation update existing record handling en language code validate expense group validate payment group unfortunately brain keeps telling good idea possible know easily net id hate yet another program sitting sorts things
125886 im working sql server want check user exists adding database tested use mydatabase go exists select name sys server principals name niis apppool mywebapi apppool begin create user iis apppool mywebapi apppool login iis apppool mywebapi apppool default schema dbo end alter role db owner add member iis apppool mywebapi apppool go code select name sys server principals doesnt return user exists mydatabase check user exists mydatabase
125915 reviewing company dr procedures looked online solutions always cluster losing quorum compare three pages google results finding first se post subject clustering vs transactional replication vs availability groups lightly touches subject lost quorum everyone agrees losing quorum bad suggestions decreasing potential still happen looking good peer reviewed answer best path recovery always cluster loss quorum
125985 pretty large query view lets call sql really fast unless use order outer select small limit select customs id custom id customs custom name custom name customs slug slug customs use case custom use case sumcase designers id orders user id orders bulk order rows quantity else end sale bulk sumcase designers id orders user id orders bulk order rows quantity else end sale bulk sumcase designers id orders user id order rows quantity else end sale total sumcase designers id orders user id orders bulk order rows quantity else end buy bulk sumcase designers id orders user id orders bulk order rows quantity else end buy bulk sumcase designers id orders user id order rows quantity else end buy total sumcase orders bulk order rows quantity else end total bulk sumcase orders bulk order rows quantity else end total bulk coalescesumorder rows quantity total minshoes id shoe id minshoe models id shoe model id minshoe models name shoe model name minshoe models title shoe model title minmodel categories id model category id minmodel categories name model category name minbusiness orders id business order id minbusiness orders state business order state minbusiness orders published business order published mindesigners id designer id mindesigners email designer email mindesigner details first name designer first name mindesigner details last name designer last name business orders rows left join users designers designers id business orders user id rows business orders users users business orders left join user details designer details designers id designer details user id rows users user details user details users inner join customs business orders id customs business order id rows business orders customs customs business order left join shoes shoes product id customs id shoes product type custom rows customs shoes shoes customs left join shoe models shoe models id shoes shoe model id rows shoes shoe models shoe models shoes left join model categories shoe models model category id model categories id rows shoe models model categories model categories models inner join sizes shoes id sizes shoe id rows sizes shoes shoes sizes left join order rows order rows article id sizes id order rows article type text size text rows sizes order rows order rows size left join orders orders id order rows order id rows order rows orders orders order rows orders state funded confirmed paid delivered production produced ready ship shipped orders id null group business orders id returns around rows query following type executed ms select sql limit related explain output limit cost rows width actual time rows loops buffers shared hit subquery scan cost rows width actual time rows loops buffers shared hit groupaggregate cost rows width actual time rows loops group key business orders id buffers shared hit nested loop left join cost rows width actual time rows loops filter orders state text fundedconfirmedpaiddeliveredproductionproducedready shipshipped text orders id null rows removed filter buffers shared hit nested loop left join cost rows width actual time rows loops buffers shared hit nested loop cost rows width actual time rows loops buffers shared hit nested loop left join cost rows width actual time rows loops buffers shared hit nested loop left join cost rows width actual time rows loops join filter shoe models model category id model categories id rows removed join filter buffers shared hit nested loop left join cost rows width actual time rows loops buffers shared hit nested loop cost rows width actual time rows loops buffers shared hit nested loop left join cost rows width actual time rows loops buffers shared hit merge join cost rows width actual time rows loops merge cond business orders id customs business order id buffers shared hit index scan using business orders pkey business orders cost rows width actual time rows loops buffers shared hit index scan using index customs business order id customs cost rows width actual time rows loops buffers shared hit index scan using users pkey users designers cost rows width actual time rows loops index cond id business orders user id buffers shared hit index scan using index shoes product id product type shoes cost rows width actual time rows loops index cond product id customs id product type text custom text buffers shared hit index scan using shoe models pkey shoe models cost rows width actual time rows loops index cond id shoes shoe model id buffers shared hit materialize cost rows width actual time rows loops buffers shared hit seq scan model categories cost rows width actual time rows loops buffers shared hit index scan using index user details user id user details designer details cost rows width actual time rows loops index cond designers id user id buffers shared hit index scan using index sizes shoe id sizes cost rows width actual time rows loops index cond shoe id shoes id buffers shared hit index scan using index order rows article id order rows cost rows width actual time rows loops index cond article id sizes id filter article type text size text rows removed filter buffers shared hit index scan using orders pkey orders cost rows width actual time rows loops index cond id order rows order id buffers shared hit planning time ms execution time ms query following type instead executed 141ms select sql order custom id limit related explain output limit cost rows width actual time rows loops buffers shared hit read temp read written sort cost rows width actual time rows loops sort key business order id sort method top heapsort memory 27kb buffers shared hit read temp read written subquery scan cost rows width actual time rows loops buffers shared hit read temp read written groupaggregate cost rows width actual time rows loops group key business orders id buffers shared hit read temp read written sort cost rows width actual time rows loops sort key business orders id sort method external merge disk 56936kb buffers shared hit read temp read written hash right join cost rows width actual time rows loops hash cond order rows article id sizes id filter orders state text fundedconfirmedpaiddeliveredproductionproducedready shipshipped text orders id null rows removed filter buffers shared hit read temp read written hash left join cost rows width actual time rows loops hash cond order rows order id orders id buffers shared hit seq scan order rows cost rows width actual time rows loops filter article type text size text rows removed filter buffers shared hit hash cost rows width actual time rows loops buckets batches memory usage 470kb buffers shared hit seq scan orders cost rows width actual time rows loops buffers shared hit hash cost rows width actual time rows loops buckets batches memory usage 567kb buffers shared hit read temp read written hash left join cost rows width actual time rows loops hash cond shoes shoe model id shoe models id buffers shared hit read temp read written hash join cost rows width actual time rows loops hash cond sizes shoe id shoes id buffers shared hit read temp read written seq scan sizes cost rows width actual time rows loops buffers shared hit read hash cost rows width actual time rows loops buckets batches memory usage 2679kb buffers shared hit read temp written hash left join cost rows width actual time rows loops hash cond designers id designer details user id buffers shared hit read hash join cost rows width actual time rows loops hash cond customs id shoes product id buffers shared hit read hash left join cost rows width actual time rows loops hash cond business orders user id designers id buffers shared hit read hash join cost rows width actual time rows loops hash cond customs business order id business orders id buffers shared hit read seq scan customs cost rows width actual time rows loops buffers shared hit read hash cost rows width actual time rows loops buckets batches memory usage 2513kb buffers shared hit seq scan business orders cost rows width actual time rows loops buffers shared hit hash cost rows width actual time rows loops buckets batches memory usage 3679kb buffers shared hit read seq scan users designers cost rows width actual time rows loops buffers shared hit read hash cost rows width actual time rows loops buckets batches memory usage 2154kb buffers shared hit seq scan shoes cost rows width actual time rows loops filter product type text custom text buffers shared hit hash cost rows width actual time rows loops buckets batches memory usage 2748kb buffers shared hit seq scan user details designer details cost rows width actual time rows loops buffers shared hit hash cost rows width actual time rows loops buckets batches memory usage 4kb buffers shared hit hash left join cost rows width actual time rows loops hash cond shoe models model category id model categories id buffers shared hit seq scan shoe models cost rows width actual time rows loops buffers shared hit hash cost rows width actual time rows loops buckets batches memory usage 1kb buffers shared hit seq scan model categories cost rows width actual time rows loops buffers shared hit planning time ms execution time ms table definitions following integrity constraints defined database using orm create table business orders id integer null user id integer published timestamp without time zone constraint business orders pkey primary key id create index index business orders user id business orders using btree user id create table users id serial null email character varying255 null default character varying constraint users pkey primary key id create unique index index users email users using btree email collate pg catalog default create table user details id serial null user id integer first name character varying255 last name character varying255 constraint user details pkey primary key id create index index user details user id user details using btree user id create table customs id serial null shoes assortment id integer business order id integer constraint customs pkey primary key id create index index customs business order id customs using btree business order id create table shoes id serial null product id integer product type character varying255 constraint shoes pkey primary key id create index index shoes product id product type shoes using btree product id product type collate pg catalog default create index index shoes shoe model id shoes using btree shoe model id create table shoe models id serial null name character varying255 null title character varying255 model category id integer constraint shoe models pkey primary key id create index index shoe models model category id shoe models using btree model category id create unique index index shoe models name shoe models using btree name collate pg catalog default create table model categories id serial null name character varying255 null sort order integer created timestamp without time zone null updated timestamp without time zone null access level integer constraint model categories pkey primary key id create unique index index model categories name model categories using btree name collate pg catalog default create table sizes id serial null shoe id integer constraint sizes pkey primary key id create index index sizes shoe id sizes using btree shoe id create table order rows id serial null order id integer quantity integer article id integer article type character varying255 article name character varying255 unit taxed cents integer constraint order rows pkey primary key id create index index order rows article id order rows using btree article id create index index order rows article type order rows using btree article type collate pg catalog default create index index order rows order id order rows using btree order id create index index order rows quantity order rows using btree quantity create index index order rows unit taxed cents order rows using btree unit taxed cents create table orders id serial null user id integer state character varying255 bulk boolean default false constraint orders pkey primary key id create index index orders user id orders using btree user id sql view cant insert order clause inside view need call black box use cases query limit ordered custom id limit ordered total filter rows business order user id orders id business orders id usually rows result graphical explain pg admin even dont understand much seems telling run query ordering query using indexes nested loop joins ordering doesnt uses hash joins ways increase performance
126003 answer https stackoverflow com questions strings primary keys sql database single remark caught eye also keep mind theres often big difference char varchar index comparisons apply still apply postgres found pages oracle claiming char less alias varchar index performance found nothing definitive postgres
126030 last weekly meeting person background experience database administration brought question would scenario justifies storing data line string instead several lines let us assume table called countrystates want store states country ill use usa example list states sake laziness would two columns one called country called states discussed proposed srutzkys answer pk code defined iso alpha table would look like country states statename usa al ca floh ny wy alabama california florida ohio new york wyoming asking question friend developer said data traffic size point view might useful need manipulate data case would intelligence application code could transform string list lets say software access table needs create combo box concluded model useful got suspicious might way make useful id like ask already saw heard done something like way really works
126095 problem experiencing high levels user disruption due sql timeouts accross systems since beginning year sql server instance question high cpu usage higher cores time business hours also noticed high wait times combination cxpacket latch ex accounts waits split cxpacket latch ex non buffered latch wait accounting vast majority latch ex access methods dataset parent suggests problem parallelism example scale wait times cxpacket ms latch ex ms pageiolatch sh ms period jan 11th options consideration change maxdop something modify cost threshold parallelism higher number suggestions welcome ease high cpu load seeing reduce timeouts particular whether proposed course action wise numbers change maxdop cost threshold parallellism background information sql server r2 running amd opteron se cores given instance sql server type workload something order connections time business hours majority oltp type workload olap mixed microsoft sql server r2 sp1 x64 enterprise edition bit windows nt x64 build service pack memory appx gigs cores cores available instance
126127 im trying write query replaces special characters space code helps identify rows alpha numeric characters comma space valid select columna tablea columna like z0 integrate replace function select statement characters alphanumeric comma space result set replaced space one wont work select replacecolumna z0 tablea columna like z0
126154 sysadmins keep pushing us use data domain dd boost taking sql backups anyone successfully used solution know brent ozar says data domain sql backups apparently dd boost makes better solution anyone used dd boost also used sql backup redgate wanted get thoughts would say sysadmins managers apart article brent ozar
126235 run following code takes minutes 106million reads however run inner select statement takes seconds 264k reads side note select query returns records idea exists would make run much longer many reads also changed select statement select top dlc id killed minutes temporary fix changed count assign value variable cnt cnt statement thought exists would better records returned select statement would stop performing scan seeks found least one record whereas count complete full query missing exists select dlc id tabledlc dlc join tabled id dlc id join tablec id id2 name dlc name begin something end
126246 example query select table id adjust query order returned entries follows input ids ie first second third edit clear ids dynamically generated list right order
126446 ive recently inherited sql server database uses binary16 instead uniqueidentifier store guids everything including primary keys concerned
126495 piece sql creates table form select statement postgresql want add constraints table example column null find valid sql postgres documentation seems possible would best approach achieve kind functionality would like creation table fail constraint violated create table constraint beforehand might variation columns result dynamic process
126604 database table currently looks like pagefield id int pk fieldtype string text decimal integer bit value stores value regardless fieldtype strongly typed remove value column replace separate columns textvalue decimalvalue integervalue bitvalue data type would set relevant would mean every row columns would null
126632 table name columns create table test testid int identity primary key clustered name eng nvarchar50 name nat nvarchar50 need query get name column separated like declare namecolumns nvarchar1024 set namecolumns stuff select test name text select name sys columns inner join sys tables object id object id name test name like name xml path type value varcharmax select namecolumns query warning execution plan way remove warning
126846 following code used write number text file instead writing echo text file set cmd echo ver vercheck print cmd exec xp cmdshell cmd output print cmd gives echo pharmsuite vercheck txt instead query writing echo
126852 could somebody tell wrong obvious query db2 select next value schema name sequence name result im getting sql0104n unexpected token end statement found following schema name sequence name expected tokens may include table expr sqlstate
126871 theres something cant learn pivot people trying teach im reading blogs cant understand logic turn query pivot query select case datenameweekdayvit dataaberturareal monday segunda feira tuesday ter feira wednesday quarta feira thursday quinta feira friday sexta feira saturday bado sunday domingo end dia da semana case dateparthourvit dataaberturareal end hora countvit dataaberturareal count reps abertas tb vitima vit dataaberturareal group datenameweekdayvit dataaberturarealdateparthourvit dataaberturareal order result want
126969 ran following query select session idcase transaction isolation level unspecified readuncommitted readcommitted repeatable serializable snapshot end transaction isolation level sys dm exec sessions transaction isolation level dbcc inputbuffer157 one prior session ids see statement one results query showed following id uniqueidentifier select ps nolock id id statement using nolock run isolation level serializable anything overriding nolock
126996 restored northwind databasehttps northwinddatabase codeplex com backup file using sql server trying execute following query results error invalid column name products product alias select orderid countproductid products northwnd dbo orderdetails group orderid products problem
127083 still new query optimisation stored procedure uses cursor go row within table performs following operations calculate time difference row calculate distance row distance timedifference minutes add temp table tried converting cursor loop performance decreased need help converting set based approach instead procedural based approach cursor performs logic read current row cursor variables fetch next crassetignitiononoff current ivehiclemonitoringid current iassetid current dtutcdatetime current sptgeolocationpoint current flatitude current flongitude current fangle current fspeedkph current signitionstatus current eeventcode current seventcode current iassetid prev iassetid begin calculate time difference previous point declare diffinseconds int set diffinseconds datediffsecond prev dtutcdatetime current dtutcdatetime declare diffinminutes int set diffinminutes diffinseconds calcualte distance previous position declare tempdistance float select tempdistance current sptgeolocaitonpoint stdistance prev sptgeolocaitonpoint check distance travelled less time difference points greater user selected idle minutes iidleminutes prev ignition status diffinseconds iidleminutes tempdistance prev signitionstatus begin declare stime varchar30 select stime dbo xpt converttimetoddhhmmss diffinsecondss insert tblexcessiveidletime assetid previousdate currentdate timestring timeinseconds values current iassetid prev dtutcdatetime current dtutcdatetime stime diffinseconds end end set previous values end loop set prev ivehiclemonitoringid current ivehiclemonitoringid set prev iassetid current iassetid set prev dtutcdatetime current dtutcdatetime set prev sptgeolocationpoint current sptgeolocationpoint set prev flatitude current flatitude set prev flongitude current flongitude set prev fangle current fangle set prev fspeedkph current fspeedkph set prev signitionstatus current signitionstatus set prev eeventcode current eeventcode set prev seventcode current seventcode end takes minutes execute cases tried converting loop http www sqlbook com sql avoiding using sql cursors aspx good idea performance number logical reads times cursor took longer process rowcount numberrecords begin check first row rowcount begin set first row previous select previous iassetid iassetid previous sptgeolocaitonpoint sptgeolocaitonpoint previous dtutcdatetime dtutcdatetime previous signitionstatus signitionstatus tblvehiclemonitoringlog rowid rowcount end else begin select current row select current iassetid iassetid current sptgeolocaitonpoint sptgeolocaitonpoint current dtutcdatetime dtutcdatetime current signitionstatus signitionstatus tblvehiclemonitoringlog rowid rowcount implement report logic current iassetid previous iassetid begin calculate time difference previous point declare diffinseconds int set diffinseconds datediffsecond previous dtutcdatetime current dtutcdatetime declare diffinminutes int set diffinminutes diffinseconds calcualte distance previous position declare tempdistance float select tempdistance current sptgeolocaitonpoint stdistance previous sptgeolocaitonpoint check distance travelled less time difference points greater user selected idle minutes iidleminutes prev ignition status diffinseconds iidleminutes tempdistance previous signitionstatus begin declare stime varchar30 select stime dbo xpt converttimetoddhhmmss diffinsecondss insert tblexcessiveidletime iassetid dtignitionon dtnextperiodic stime itimedurationinseconds values current iassetid dateaddhour fgmtoffset previous dtutcdatetime dateaddhour fgmtoffset current dtutcdatetime stime diffinseconds end end set previous values end loop set previous iassetid current iassetid set previous sptgeolocaitonpoint current sptgeolocaitonpoint set previous dtutcdatetime current dtutcdatetime set previous signitionstatus current signitionstatus end increment row number set rowcount rowcount end end loop looking online found calculate time difference two rows https stackoverflow com questions calculate time difference two rows raw data looks like need calculate time difference distance row current iassetid previous iassetid previous sdigitalinputvalue query came rows select row number order dtutcdatetime rn vehiclemonitoringlog dtutcdatetime getdate order iassetid dtutcdatetime select mc ivehiclemonitoringid currentid mp ivehiclemonitoringid previousid mc iassetid currentasset mp iassetid previousasset mc dtutcdatetime currenttime mp dtutcdatetime previoustime datediffsecond mc dtutcdatetime mp dtutcdatetime datediffseconds rows mc join rows mp mc rn mp rn edit query working please let know see performance issues select dt currentasset dt distance dt datediffseconds dt currentignition dt previousignition ta sreference ta scategoryname ta ssitename dbo xpt converttimetoddhhmmssdatediffsecondss select ivehiclemonitoringid currentid leadivehiclemonitoringid partition iassetid order dtutcdatetime previousid iassetid currentasset leadiassetid partition iassetid order dtutcdatetime previousasset sdigitalinputvalue currentignition leadsdigitalinputvalue partition iassetid order dtutcdatetime previousignition dtutcdatetime currenttime leaddtutcdatetime partition iassetid order dtutcdatetime previoustime datediffsecond dtutcdatetime leaddtutcdatetime partition iassetid order dtutcdatetime datediffseconds sptgeolocaitonpoint stdistanceleadsptgeolocaitonpoint partition iassetid order dtutcdatetime distance vehiclemonitoringlog dtutcdatetime utcstartdate dtutcdatetime utcenddate dt inner join tblassets ta ta iassetid dt currentasset currentignition distance datediffseconds iidleminutes
127158 much newbie db work appreciate patience basic question im running sql server local machine small table basic client application test different approaches im getting appears table lock insert update statements client asp net application following code oledbconnection cn new oledbconnection provider sqlncli11 server localhost sqlexpress database db user id uid password pwd cn open oledbtransaction tn cn begintransaction oledbcommand cmd new oledbcommand insert layoutsv2 layouts name layouts enabled layouts data values name data cn tn cmd executenonquery cmd commandtext select scope identity int newkey decimal toint32decimalcmd executescalar console writeline created index newkey thread sleep15000 tn commit tn cn begintransaction cmd commandtext udpate layoutsv2 set layouts enabled layouts key newkey cmd transaction tn cmd executenonquery console writeline updated row thread sleep15000 tn rollback cn close run code management studio run select layoutsv2 cases client thread paused prior commit rollback select query hangs commit rollback occurs table field layouts key assigned primary key properties window shows unique clustered page locks row locks allowed lock escalation setting table disable ive tried available settings table auto changes ive tried select nolock returns result immediately well cautioned places ive tried putting rowlock hint insert update statements nothing changed behavior im looking prior commit insert queries threads read rows except one thats inserted prior commit update queries threads read starting version row updateed way need provide information clarify use case please let know thanks
127221 two queries basically thing different grouping first query query used populate chart second populate table query select key id sumsalary sumbonus created table emp id group key id created query select key id sumsalary sumbonus count full count table emp id group key id created function returns two queries json format chart table problem need query table twice grouping way dealing situations
127303 im calculating median declare temp table id int select select top id select top percent id temp id null order id order id desc select top id select top percent id temp id null order id desc order id asc query want use case many columns want calculate median think would bad repeat block code column im trying define separate function would accept column values process return median define table value funtion another optimized way question related following questions write function sql accept table input return result back table getting error must declare scalar variable sql function even though declared unable execute table valued function https dba stackexchange com questions use udf function insert select clause calculating multiple medians
127316 working project classified ads site main categories items like vehicles cars scooters bikes etc mobiles phones mobiles tablets accessories use tables use json create separate tables item tables currently decided tables save relations joins heavy coding way correct suggest another one pros cons search lot didnt got anything answers question
127405 impression sum datalength fields records table would get total size table mistaken select sumdatalengthfield1 sumdatalengthfield2 sumdatalengthfield3 totalsizeinbytes sometable true used query got online get table sizes clustered indexes doesnt include nc indexes get size particular table database billing purposes charge departments amount space use need figure much space department used table query identifies group within table need figure much space group taking space per row may swing wildly due varcharmax fields table cant take average size ratio rows department use datalength approach described get total space used query thoughts select name schemaname name tablename rows rowcounts suma total pages totalspacemb suma used pages usedspacemb suma total pages suma used pages unusedspacemb sys tables nolock inner join sys schemas nolock schema id schema id inner join sys indexes nolock object id object id inner join sys partitions nolock object id object id index id index id inner join sys allocation units nolock partition id container id ms shipped object id type desc clustered group name name rows order totalspacemb desc suggested create filtered index department partition table directly query space used per index filtered indexes could created programmatically dropped maintenance window need perform periodic billing instead using space time partitions would better respect like suggestion would typically honest use dept example explain need honest really due confidentiality reasons cant explain exact reason need data analogous different departments regarding nonclustered indexes table get sizes nc indexes would great however nc indexes account size clustered index ok including however would include nc indexes anyway cant even get accurate size clustered index
127537 trying install mysql serving centos linux release take look process installation sudo yum install mysql server output dependencies resolved package arch version repository size removing mysql community client x86 el7 mysql57 community mysql community server x86 el7 mysql57 community transaction summary ran mysql damon sudo service mysqld start checking service ps ef grep mysql mysql usr sbin mysqld daemonize pid file var run mysqld mysqld pid comes problem driving crazy want set root password first time sudo mysql secure installation password required type enter key output securing mysql server deployment enter password user root error access denied user root localhost using password googling error cases solution call mysqld safe skip grant tables command service mysqld stop mysqld safe skip grant tables mysql user root mysql update user set password passwordnew password user root flush privileges exit mysqld safe prompts command found error also tested sudo mysqld skip grant tables anything appreciate guide right direction order set root password thank advance
127613 servers one linked server configured points ill call server server user databases various purposes server running sql trying eliminate server copies databases server migrating applications server bs database copies server cs im server see connections server certain database dont know tell procedure task job server using linked server connection server order retire database server need point server connections database server order need know procedures tasks jobs server using connection updated way see dependencies linked server without disabling linked server see starts failing
127617 want sum values using case statements problem compiler complains add group end query negates distinct hah example sample returns entries red12 even though entry fit criteria group messes run query return applicable results case statements show create table bobsled event varchar100 time decimal184 employeeid varchar25 name varchar500 insert bobsled values walk 32red12 red arrow eat red12 red arrow run 13pink01 pink pig walk bl81 blue fire sleep gr99 green pony select distinct employeeid case event walk sum time else end walktime case event run sum time else end runtime case event sleep sum time else end sleeptime bobsled executes sucesfully group employeeid event
127639 fairly simple query select top dc document id dc copies dc requestor dc id cj file number document queue dc join correspondence journal cj dc document id cj document id dc queue date getdate dc print location order cj file number giving horrible performance like never bothered wait finish query plan looks like however remove top get plan looks like runs seconds correct pk indexing fact top changed query plan doesnt surprise im bit surprised makes much worse note ive read results post understand concept row goal etc im curious go changing query uses better plan currently im dumping data temp table pulling first row im wondering better method edit people reading fact extra pieces information document queue pk ci id 5k rows correspondence journal pk ci file number correspondence id mil rows started indexes ended one correspondence journal document id file number
127737 quite number sql servers need upgraded version r2 work planned middle year microsoft ending support sql servers sp3 sp4 running windows server whose support already ended exception extension one year required might go server os upgrade well servers include replication transactional log shipping reporting services integration server running ssis packages question rather would like know risks involved pre checks done planning upgrade also place upgrade better plan side side migration upgrade
128314 made query list tables columns data type etc select name table name column ty name data type max length max lenght nullable null identity identity sys tables join sys columns object id object id join sys types ty system type id ty system type id order questions ques add column primary key could find table help took look sys indexes sys foreign keys information schema table constraints ques sys columns int values max lenght fields 4kb per data datetime decimal thanks
128348 stored procedure finding successfully inserts record returns fails primary key violation caught ignored returns coming stored procedure alter procedure dbo psetuseritemlike userid int itemid int begin set nocount exception handling declare errormessage nvarcharmax declare errorseverity int declare errorstate int begin try insert dbo useritemlikes userid itemid values userid itemid end try begin catch error number ignore primary key violation select errormessage error message line casterror line nvarchar5 errorseverity error severity errorstate error state raiserror errormessage errorseverity errorstate end catch end note actually using return value noticed ssms execute procedure automatically captures return value puts variable couldnt figure happening
128424 happen using sql server standard edition also happen use ola hallengrens scripts provide easy flexible framework backups maintenance question isnt much olas scripts best practice realize ultimate answer depends companys requirements trying seek communitys advice best fulfill understand companys requirements wish set transaction log backups every minutes way hopefully lose minutes data set one job uses databases better set one job database kick parallel ask feeling based see olas script functioning backups kicked serial downside serial would successive backup waits completes could potentially increase amount time backups ie greater minutes plus concern would failure one backup stops others happening wouldnt want case would want others continue backing true olas scripts execute serial also failure stops successive backups better job database single job inclination toward separate jobs wish understand sql server dbas general tend
128433 created table db already exists another db initially populated old db data tables pk receive values already exist records couldnt autoincrement need new table pk autoincrement pk already exists data
128474 user mrdenny wrote set sql server maximum memory isnt going limit aspects sql server amount memory controls buffer pool execution plan cache things like clr full text actual memory used sql server exe files sql agent extended stored procedures etc arent controlled setting problem server going set gb memory things like clr full text server exe files taking additional memory configure sql server go set max limit told way find solution searching google
128535 ive reading msdn try catch xact state following example uses xact state catch block try catch construct determine whether commit roll back transaction use adventureworks2012 go set xact abort render transaction uncommittable constraint violation occurs set xact abort begin try begin transaction foreign key constraint exists table statement generate constraint violation error delete production product productid delete operation succeeds commit transaction catch block execute commit transaction end try begin catch test xact state transaction committable transaction uncommittable rolled back xact state means transaction commit rollback operation would generate error test whether transaction uncommittable xact state begin print transaction uncommittable state rolling back transaction rollback transaction end test whether transaction active valid xact state begin print transaction committable committing transaction commit transaction end end catch go dont understand care check xact state returns please note flag xact abort set example severe enough error inside try block control pass catch im inside catch know transaction problem really sensible thing case roll back isnt example msdn implies cases control passed catch still makes sense commit transaction could somebody provide practical example happen makes sense dont see cases control passed inside catch transaction committed xact abort set msdn article set xact abort example statements inside transaction execute successfully fail xact abort set understand set xact abort happen xact state returns inside catch block initially would written code like use adventureworks2012 go set xact abort render transaction uncommittable constraint violation occurs set xact abort begin try begin transaction foreign key constraint exists table statement generate constraint violation error delete production product productid delete operation succeeds commit transaction catch block execute commit transaction end try begin catch severe problem transaction print rolling back transaction rollback transaction end catch go taking account answer max vernon would write code like showed makes sense check whether active transaction attempting rollback still set xact abort catch block either doomed transaction transaction case nothing commit wrong use adventureworks2012 go set xact abort render transaction uncommittable constraint violation occurs set xact abort begin try begin transaction foreign key constraint exists table statement generate constraint violation error delete production product productid delete operation succeeds commit transaction catch block execute commit transaction end try begin catch severe problem transaction xact state begin still active transaction rolled back print rolling back transaction rollback transaction end end catch go
128914 trying write spec data warehouse server planned data warehouse upgrade run virtual servers vmware hosts ability add remove resources necessary past weve incrementally added ram cpu required demands increased weve lobbied resources primarily disk ram ask give us little possible however recently whenever talk resources criticized specing machine right first place told dev hosts maxed ram available small local government organisation regular users dw normal daily use runs fine get good mdx query performance reports dashboards fast users happy however etl processes run throughout night starting see evidence memory pressure processing datamarts simultaneously last night ssis failed warnings memory error existing dw server win r2 cpus 16gb ram running sql std max server memory set 12gb leaving 4gb os services etc existing dw datamarts olap cubes developing datamart files gb fact rows fact mb etl process olap cube time hours pbi fbi rbi abi ebi planned estimated new server planned win running sql enterprise run sql ssis ssrs ssas storage isnt issue im sure ram cpu according fast track data warehouse reference guide sql server minimum 128gb socket machine seems bit excessive hardware software requirements installing sql server recommends minimum 4gb ram sql thats quite difference good starting point 32gb 64gb justify starting position spec good guides calculate server resources good rules thumb key ingredient metrics ram sizing dw context volume data number cubes time takes etl process cube peak processing load overnight performance viewed end users day
129090 etl flow long running select statement thats creating table fly populating several hundred million records statement looks something like select desttable srctable monitoring purposes would like get rough idea progress statement executing approx rowcount written number bytes similar tried following avail blocked select statement select count desttable nolock returns select rows rowmodctr sysindexes nolock id object iddesttable returns select rows sys partitions object id object iddesttable furthermore see transaction sys dm tran active transactions able find way get count affected rows given transaction id something similar rowcount perhaps transaction id argument understand sql server select statement ddl dml statement one implicit table creation locking operation still think must clever way obtain kind progress information statement running
129358 need return dependent previous records example table declare tableproductid int failed bit sampledate date levelcode int insert values thing care last record levelcode last record productid whether last record passed failed doesnt matter look records productid records last record failure levelcode last record set islastrunsamelevelaspreviousrun else productid islastrunsamelevelaspreviousrun failures productid islastrunsamelevelaspreviousrun return help tips much appreciate
129504 dug couple hours regarding question didnt get satisfactory answer still doubt found following clustered index data stored order clustered index one clustered index per table primary key created cluster index automatically created well got points questions cluster index exist oracle database since read blogs oracle concept clustered index yes please let know sql statement create cluster index said cluster index automatically gets created primary key defined column table check index type created please find table architecture let know anything else required get answers questions
129522 table tag columns id uuid name text want insert new tag table tag already exists want simply get id existing record assumed could use conflict nothing combination returning id insert tag name values foo conflict nothing returning id returns empty result set tag name foo already exists changed query use noop update clause insert tag name values foo conflict name update set name foo returning id works intended somewhat confusing im setting name already existing value way go problem simpler approach im missing
129659 came across developer code sqlcommand prepare see msdn method extensively used advance execution sql queries wonder benefit sample command prepare command executenonquery command parameters value command executenonquery played around little bit traced execution command calling prepare method makes sql server execute following statement declare p1 int set p1 exec sp prepexec p1 outputn id int desc textninsert dbo testtable id values id id select p1 parameter gets value sqlcommand executenonquery called following gets executed sql server exec sp execute id looks like statement gets kind compiled soon prepare executed wonder benefit mean put plan cache used soon final query executed desired parameter values figured documented another question sqlcommands executed sqlparameters always wrapped sp executesql procedure calls makes sql server able store reuse plans independant parameter values regarding wonder prepare method kind useless obsolete missing something
129694 trouble mysql null columns seems mysql installation accepting null values null columns mysql version dotdeb 1debian take table instance create table cities id int10 unsigned null auto increment name varchar255 null state id int10 unsigned null primary key id engine innodb auto increment insert value like insert citiesstate id values mysql spills warning commits value anyway warning insert citiesstate id values rows affected warnings field name doesnt default value sec remove unique key unique city state get behaviour also tried creating name column default null like name varchar255 null default null spills error would roughly translate default value invalid name tried different mysql installation debian behavior insert cities name state id values null get error meaning column name empty help welcome
129747 question joining two tables schema create table dbo dcstring id bigint identity11 null dcdistributionboxid bigint null currentmpp decimal null constraint primarykey3 primary key clustered id asc alter table dbo dcstring add constraint fk dcstring dcdistributionbox foreign key dcdistributionboxid references dbo dcdistributionbox id create table dbo stringdata dcstringid bigint null timestamp datetime null dccurrent decimal null constraint primarykey4 primary key clustered timestamp desc dcstringid asc stringdata table following storage stats data space mb row count partitioned true partition count usage want join data stringdata table data dcstring table something like declare begin datetime declare end datetime declare dcstringid bigint select dcstring id stringdata timestamp stringdata right outer join stringdata stringdata dcstringid dcstring id stringdata id dcstringid stringdata timestamp begin stringdata timestamp end expect searched date range matching data stringdata table exist id timestamp searched date range matching data stringdata table exist id timestamp null question get searched date range matching data stringdata table exist rows result simply want always get dcstring id whats wrong join mess completely update related answer aaron bertrand tried way already cancel testing query 10min still running looked like declare begin datetime declare end datetime declare dcstringid bigint select dcstring id stringdata timestamp stringdata left join dcstring stringdata dcstringid dcstring id stringdata timestamp begin stringdata timestamp end stringdata id dcstringid
129751 table stores events date time two separate columns create table events pk int serial detail text ev date date ev time without time zone filter dates ev date start date date end date date ev time start date time end date time missing events within two dates occurred outside time range every day thus start time relevant start date end date anyone advice efficiently millions events
129785 making small program users makes posts write blogs posts users like dislike post facebook upvote downvote post stackoverflow would like know good database structure commonly used program works efficiently structure two options first post id head message datepost likes dislikes ab anchdg date way id postid likes column users id liked upvoted post blog id users disliked downvoted post blog second post id head message datepost ab anchdg date likes id postid userid dislikes id postid userid way create two separate tables likes dislikes get posts likes way tables likes dislikes get heavily filled might make table heavy processing slow would like know better standard way achieve task
129827 built application part ug thesis uses mysql database community edition professor wants provide fault tolerance database parity argued wouldnt need anyway searched found mysql built replication engine mechanism provide fault tolerance right along many techniques provide reliability learned master server slave servers provide fault tolerance using replication questions one database server mysql fault tolerance single standalone database servers master slave formation cluster etc need try provide kind fault tolerance whatsoever data stored mysql database kind differences terms fault tolerance community edition enterprise edition mysql servers somehow get feeling dont need anything providing fault tolerance mysql db fine need solid info matter bounty edit second question need try provide kind fault tolerance whatsoever data stored mysql database sensibleness trying provide fault tolerance mysql database using parity bit per byte little details data database data specific collection unicode strings less mb size initialization data never change time transaction read data database update delete application requires full text search strings reason using mysql since provides full text search aware could avoid mysqls ft search using something like elasticsearch instead
129854 varchar column data like imported csv file sql table need convert column datatime alter table track date alter column start time datetime getting error msg level state line conversion failed converting date time character string converting using convert function getting error select convertdatetimestart time5 track date msg level state line conversion failed converting date time character string please help convert varchar data datetime format
130018 possible change password login expired password using sql server management objects smo programming many times working hours got message production server sa level privilege sql server working environment microsoft sql server express windows server r2 vmwareinc vmware virtual platform
130028 piece code performs inserts highly denormalized tables tables numbers columns ranging sql server r2 running windows server insert consists inserting number tables transaction inserts batched nhibernate transaction nonetheless perform inserts say times repeatedly calling piece code performs insert get average ms weird bit run test code simultaneously using processes exe run different command prompts windows server insertion performance per call gets much better see bursts go fast ms almost x4 faster im measuring insertion time code since processes know nothing im assuming something sql server absolutely clue id like know happening configuration would allow get performance inserts frequent suggestions regarding sql server monitoring methods understand going db level equally welcome
130141 trying write query calculate number visits customer taking care overlapping days suppose itemid start date 23rd end date 26th therefore item days add purchase date total count example scenario item id start date end date number days number days candidate visit count output visitdays input table create table items custid int itemid int startdate datetime enddate datetime insert items select union select union select union select union select union select tried far create table visitstable startdate datetime enddate datetime insert visitstable select distinct startdate enddate items items custid order startdate asc exists select top visitstable begin select isnullsumvisitdays1 select distinct abc startdate abc enddate datediffdd abc startdate abc enddate visitdays visitstable abc inner join visitstable bc bc startdate abc startdate abc enddate visits end drop table items drop table visitstable
130321 according post single replica set distribute writes must go primary distribute reads secondaries already via read preferences deem appropriate driver keeps track primary secondary routes queries appropriately according mongo docs may also deploy group mongos instances use proxy load balancer application mongos deployments must configure load balancer client affinity every connection single client reaches mongos basically seems like youve got single replica set nodes cant really use proxy load balancer since writes need go primary need client affinity reads also need go primary im thinking though might possible applications connect load balancer load balancer would route requests primary balanced whatever unless primary went point load balancer would start routing requests new primary im sure possible however since would load balancer know mongo server elected new primary thus route new requests assuming possible would achieve degree redundancy case primary ever goes im also hoping would also side effect avoiding stale writes network partition occurs since load balancer thus db clients would ever connect single primary stupid question
130392 description try insert million rows empty table mssql express script set statistics time drop table t1 create table t1 id int text text go 30s 45s idnumber select number union select number id number insert t1 select number cast number varchar cast number varchar id optionmaxrecursion million rows rows 120s cancel query declare count int set count count begin set count count insert t1 values count cast count varchar cast count varchar end rows 18s 20s temp select row number overorder object id tcount sys columns sys columns object id object id insert t1 select tcount cast tcount varchar cast tcount varchar temp go declare count int set count count begin temp select maxid max id t1 insert t1 select max id cast max id varchar cast max id varchar t1 temp set count count end 3s 4s drop t1 first ak select union select t2 select row number overorder select id cast varchar cast varchar t1 t2 question researching found solutions better solution using copy data files
130399 need pull list stored procedures available instance used following sql statement get stored procedures given database select mydatabase information schema routines routine type procedure script obtain stored procedures check database name stored procedure using stored procedure name
130441 using oracle instance process memory database physical datafiles normally one instance maps one database inside database many tablespaces system users etc however sure sql server seems sql server one instance multiple databases one instance multiple schemas oracle one database contains system sysaux temp tablespaces user tablespace short system user database sql server seems like one system database serve multiple user databases
130606 need determine program version oracle installed oracle homes server may databases created home yet need able outside database without connecting database also would highly preferable able remote program windows program running net matters currently reading remote registry keys using technique https stackoverflow com questions read remote registry keys find oracle homes according method works fine however looked around keys see information exact version release name oracle home course reliable indicator exact version release instance basically looking way figure oracle universal installer tells installed products button clarify servers running windows
130659 getting error report error report sql error ora matching unique primary key column list matching unique primary key column list cause references clause create alter table statement gives column list matching unique primary key constraint referenced table action find correct column names using cons columns catalog view know parent table create table studentinfo student id varchar2 primary key full name varchar2 null contact number number 15not null address varchar2 null nationality varchar2 null ic passportno varchar2 null programme varchar null email address varchar2 null references usernamepasswordusername parents number number 15not null fingerprint template clob child table create table bit sep cit4114 fyp student id varchar2 primary key references studentinfostudent id full name varchar2 null references studentinfofull name nationality varchar2 null references studentinfonationality fingerprint template clob null references studentinfofingerprint template varchar2 null keep nationality fingerprint duplicate time consuming verifying based information stored studentinfo therefore breaking individual class easier faster like table studentinfo consist million record table bit sep cit4114 fyp records keep nationality column column table structure visa renewal calculated based value nationality table
131204 need show average weight product last production runs im sure best describe example lets imagine following table lists product date created average weight product day product date weight jan march july july aug june june end result im looking add column includes average weight last dates product run something like product date weight average weight jan null march null july null july null aug jan1 mar3 july6 july7 aug mar3 july6 july7 aug6 june null june null june null june null june etc nulls since sample cant calculate average last runs data isnt could anyone point direction need looking something like
131310 im moving next level mystery query looks like theres subselect inside exists table think could probably simplified inner join higher using postgresql table definitions https gist github com neezer 879f5d3649ca1903c6f3 cardinalities billing pricequote rows billing pricequotestatus rows billing lineitem rows heres original query without modifications suggested subquery inside exists select quote id acct id account id sumi delta amount amt billing lineitem inner join billing pricequote pq quote id pq id pq date applied time zone pst 02t00 timestamp 03t22 timestamptz exists select s1 quote id billing pricequotestatus s1 inner join select distinct quote id quote id maxcreated max created billing pricequotestatus quote id quote id group quote id created order quote id created desc s2 s1 quote id s2 quote id s1 created s2 max created s1 name adjustmentpaymentbillable group quote id acct id part noticed looking weird select billing pricequotestatus another subselect table inside inner join tried changing modification post select quote id acct id account id sumi delta amount amt billing lineitem inner join billing pricequote pq quote id pq id pq date applied time zone pst 02t00 timestamp 03t22 timestamptz exists select quote id maxcreated max created billing pricequotestatus quote id quote id name adjustmentpaymentbillable group quote id group quote id acct id cut execution time half seconds seconds yielded slightly different results original query returned rows new query returns rows immediately clear modification didnt produce equivalent output needs explain analyze queries explain analysis original query depesz com would really appreciate help guidance tried updating ypercube answer lateral join performance seems equal number wins less second select quote id acct id account id sumi delta amount amt billing lineitem inner join billing pricequote pq quote id pq id left join lateral select name billing pricequotestatus quote id quote id order created desc limit pqs true pq date applied time zone pst 02t00 timestamp 03t22 timestamptz pqs name adjustment payment billable group quote id acct id explain analysis suggestions get seconds
131350 running correlated subquery find listing vendors vendor name different cities states want know vendors common city state vendors seemed like self join thing hints possible please vendors table vendorsvendorid vendorcity vendorstate vendorname select vendorname vendorcity vendorstate vendors v1 vendorcity vendorstate select vendorcity vendorstate vendors v2 v2 vendorid v1 vendorid error message get msg level state line expression non boolean type specified context condition expected near dont see reference boolean types since exists related query
131400 proposed schema first foremost example proposed schema reference throughout post clothes clothesid pk int null name varchar50 null color varchar50 null price decimal52 null brandid int null brand clothesid fk pk int null viewingurl varchar50 null someotherbrand1specificattr varchar50 null brand clothesid fk pk int null photourl varchar50 null someotherbrand2specificattr varchar50 null brand clothesid fk pk int null someotherbrandxspecificattr varchar50 null problem statement clothes table columns like name color price brandid describe attributes particular item clothing heres problem different brands clothing require differing information best practice dealing problem like note purposes necessary find brand specific information starting clothes entry first display information clothes entry user must use brand specific information purchase item summary directional relationship clothes brand tables proposed current solution cope thought following design scheme clothes table brand column may id values ranging particular id corresponds brand specific table example id value correspond table brand might url column id correspond brand might supplier column etc thus associate particular clothes entry brand specific information imagine logic application level look something like clothesid value brand query select brand clothes id clothesid brand get brand attributes given clothesid else brand get brand attributes given clothesid etc comments thoughts im attempting normalize entire database bcnf although came resulting application code makes feel anxious way enforce relations except application level thus design feels hacky anticipate error prone research made sure look previous entries making post heres post near identical problem managed find made post anyway seems like answer provided sql design based solution mentions oop inheritance interfaces im also kind novice comes database design id appreciate insights appears helpful responses stack overflow aaaand key concept class table inheritance referred solutions suggest others finding question well despite provided links still lookout responses would appreciate solutions provided using postgresql
131634 id like know way query ag group failed eg primary replica im pretty sure secondary yesterday find failover took place something specific logs looking tsql script use
131759 sql server implementation longest common substring problem solution checks rows column sql server seen solutions take two strings input sql server solution looks rows column table try things honest think solution goes head moment suggestions welcome real world problem im looking programming problems could solved sql server
131801 result set rows invoice need top last invoices found something like similar select top records category sample data invnr detailline hope get example select distinct top invnr detailline tbl invoice result invnr detailline update need last first example invoices created invoice amount detail lines want detail lines last results
132029 following tables create table users id int primary key already exists data create table message alter messages table new column called sender added sender foreign key referencing users table didnt work alter table message add foreign key sender references users error column sender referenced foreign key constraint exist statement create column well
132155 completely new pl sql written following pl sql script doesnt execute gives compilation error set serveroutput size exists select table begin dbms output put linehas rows end else begin dbms output put lineno rows end anyone tell wrong
132170 previous question sql server changes execution plan using sql server developer edition sql server changes execution plan identical query database sql server checked several times connect management studio dev computer ad account takes seconds finish query time go remote connection server execute query management studio takes seconds finish colleagues machine takes second management studio connects mvc application ado net things restart sql server dbcc freeproccache sp updatestats try different users ad sql users slow execution plan fast execution plan query set ansi nulls go set ansi padding go set ansi warnings go set arithabort go set concat null yields null go set numeric roundabort go set quoted identifier go declare ccode varchar500 declare pagesize int declare pagenumber int set ccode skd set pagesize set pagenumber select distinct classifications abbrev text classifications title text classifications cfn uid klasje dbo classifications inner join klasje dbo cfn versions classifications cfn uid cfn versions cfn uid inner join klasje dbo version category xrefs cfn versions cvn uid version category xrefs cvn uid left outer join klasje dbo veljavnost cfn versions life cycle code veljavnost rv low value category code like ccode descriptor text like ccode definition text like ccode order abbrev text offset pagesize pagenumber rows fetch next pagesize rows execution plans gist select options returns cases slow fast
132293 several databases large number tables created dropped tell sql server conduct internal maintenance system base tables meaning become fragmented time bloated size puts unnecessary pressure buffer pool also negatively impacts performance operations computing size tables database anyone suggestions minimizing fragmentation core internal tables one obvious solution could avoid creating many tables create transient tables tempdb purpose question lets say application flexibility edit research shows unanswered question looks closely related indicates form manual maintenance via alter index reorganize may option initial research metadata tables viewed sys dm db partition stats system base table contains one row every column system select row count reserved page count row count bytes per row reserved page count space mb sys dm db partition stats object id object idsys syscolpars index id row count bytes per row space mb however sys dm db index physical stats appear support viewing fragmentation tables fragmentation data returned sys dm db index physical stats select sys dm db index physical stats db id object idsys syscolpars null null detailed ola hallengrens scripts also contain parameter consider defragmentation ms shipped objects procedure silently ignores system base tables even parameter enabled ola clarified expected behavior user tables system tables ms shipped msdb dbo backupset considered returns code successful work system base tables instead expected commands update statistics reorganize indexes commands generated script seems assume target tables appear sys tables appear valid assumption system tables like sys sysrowsets sys syscolpars declare result int exec result indexoptimize databases test fragmentationlow index reorganize fragmentationmedium index reorganize fragmentationhigh index reorganize pagecountlevel updatestatistics indexes test sys sysrowsets proc works properly targeting non system table instead indexes test dbo numbers msshippedobjects execute print result additional requested info used adaptation aarons query inspect system table buffer pool usage found tens gb system tables buffer pool one database space free space cases compute buffer pool usage system table select object namep object id countb page id pages sumb free space bytes free pages sys dm os buffer descriptors join sys allocation units allocation unit id allocation unit id join sys partitions partition id container id object id loose proxy system tables database id db id group object id order pages desc
132437 interesting question sargability case using predicate difference two date columns heres setup use tempdb set nocount object idtempdb sargme null begin drop table sargme end select top identity bigint id castdateaddday severity getdate date datecol1 castdateaddday severity getdate date datecol2 sargme sys messages alter table sargme add constraint pk whatever primary key clustered id create nonclustered index ix dates sargme datecol1 datecol2 ill see pretty frequently something like definitely sargable select datediffday datecol1 datecol2 sargme datediffday datecol1 datecol2 definitely isnt sargable results index scan reads rows good estimated rows stink youd never put production would nice could materialize ctes would help us make well sargable er technically speaking get execution plan top would nice sargable select datediffday datecol1 datecol2 ddif sargme select ddif course since using constants code changes nothing even half sargable fun execution plan even half sargable select datediffday datecol1 datecol2 sargme datecol2 dateaddday datecol1 youre feeling lucky youre obeying ansi set options connection strings could add computed column search alter table sargme add ddiff datediffday datecol1 datecol2 persisted create nonclustered index ix dates2 sargme ddiff datecol1 datecol2 select id datecol1 datecol2 sargme ddiff get index seek three queries odd man add days datecol1 query datediff clause cte final query predicate computed column give much nicer plan much nicer estimates brings question single query sargable way perform search temp tables table variables altering table structure views im fine self joins ctes subqueries multiple passes data work version sql server avoiding computed column artificial limitation im interested query solution anything else
132673 need return partial result simple select stored procedure finished possible yes workaround edit several parts procedure first part calculate several string use later procedure make addtional operations problem string needed caller soon possible need calculate string pass back somehow select example continue work caller gets valuable string much quickly caller web service
132689 working optimizing queries query set statistics io declare orderstartdate datetime2 feb declare orderenddate datetime2 feb select strbxorderno sintorderstatusid sintorderchannelid sintordertypeid sdtmordcreated sintmarketid strorderkey stroffercode strcurrencycode decbcshipfullprice decbcshipfinal decbcshiptax decbctotalamount decwrittentotalamount decbcwrittentotalamount decbcshipofferdisc decbcshipoverride dectotalamount decshiptax decshipfinal decshipoverride decshipofferdisc decshipfullprice lngaccountparticipantid convertdate sdtmordcreated ordercreateddateconverted tablebackups dbo tblborder sdtmordcreated orderstartdate sdtmordcreated orderenddate exists select tablebackups dbo tblborderitem oi oi strbxorderno strbxorderno oi deccatitemprice option recompile created following filtered index table dbo tblborderitem create nonclustered index ix tblborderitem deccatitemprice incl dbo tblborderitem strbxorderno asc sintorderseqno asc deccatitemprice include blnchargeshipping decbccatitemprice decbccostprice decbcfinalprice decbcofferdiscount decbcoverridediscount decbctaxamount deccostprice decfinalprice decofferdiscount decoverridediscount dectaxamount decwasprice dtmorditemcreated sintorderitemstatusid sintorderitemtype sintquantity stritemno deccatitemprice drop existing fillfactor index used query particular queries use index therefore included columns query particular want check exists order item deccatitemprice sql server index scan see pictures statistics updated item table rows test please note dont select columns items table item table live would like avoid scan questions sql server index seek factors things consider order improve query rows affected table tblborder scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table tblborderitem scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected definition indexes table tblborderitem object id dbo tblborderitem null drop table dbo tblborderitem go create table dbo tblborderitem strbxorderno varchar20 null sintorderseqno smallint null sintorderitemstatusid smallint null sintnamestructureid smallint null stritemno varchar20 null sintquantity smallint null strcurrencycode varchar3 null deccostprice decimal184 null deccatitemprice decimal182 null decofferdiscount decimal182 null decoverridediscount decimal182 null decfinalprice decimal182 null dectaxamount decimal182 null strbccurrencycode varchar3 null decbccostprice decimal184 null decbccatitemprice decimal184 null decbcofferdiscount decimal184 null decbcoverridediscount decimal184 null decbcfinalprice decimal184 null decbctaxamount decimal184 null dtmorditemcreated datetime null blnchargeshipping bit null lngtimeoforderqtyonhand int null sdtmtimeoforderduedate smalldatetime null lngprodsetseqno int null lngprodrelationid int null lngprodrelationmemberid int null decwasprice decimal182 null sintorderitemtype smallint null tsrowversion timestamp null sdtmorderitemstatusupdated smalldatetime null constraint pk tblborderitem primary key clustered strbxorderno asc sintorderseqno asc fillfactor go create nonclustered index ix tblborderitem dtmorditemcreated dbo tblborderitem dtmorditemcreated asc fillfactor create nonclustered index ix tblborderitem sintorderitemstatusid dbo tblborderitem sintorderitemstatusid asc include sdtmorderitemstatusupdated sintorderseqno strbxorderno stritemno fillfactor create nonclustered index ix tblborderitem sintorderitemstatusid decfinalprice sdtmorderitemstatusupdated include strbxorderno dbo tblborderitem sintorderitemstatusid asc decfinalprice asc sdtmorderitemstatusupdated asc include strbxorderno fillfactor create nonclustered index ix tblborderitem strbxorderno dbo tblborderitem strbxorderno asc fillfactor create nonclustered index ix tblborderitem stritemno dbo tblborderitem stritemno asc fillfactor create nonclustered index ix tblborderitem deccatitemprice incl dbo tblborderitem strbxorderno asc sintorderseqno asc deccatitemprice asc include blnchargeshipping decbccatitemprice decbccostprice decbcfinalprice decbcofferdiscount decbcoverridediscount decbctaxamount deccostprice decfinalprice decofferdiscount decoverridediscount dectaxamount decwasprice dtmorditemcreated sintorderitemstatusid sintorderitemtype sintquantity stritemno deccatitemprice fillfactor definition indexes table tblborder object id dbo tblborder null drop table dbo tblborder go create table dbo tblborder strbxorderno varchar20 null uidorderuniqueid uniqueidentifier null sintorderstatusid smallint null sintorderchannelid smallint null sintordertypeid smallint null blnisbasket bit null sdtmordcreated smalldatetime null sintmarketid smallint null strorderkey varchar20 null stroffercode varchar20 null lngshippedtoparticipantid int null lngorderedbyparticipantid int null lngshiptoaddressid int null lngaccountaddressid int null lngaccountparticipantid int null lngorderedbyaddressid int null lngordertakenby int null strcurrencycode varchar3 null decshipfullprice decimal182 null decshipofferdisc decimal182 null decshipoverride decimal182 null decshipfinal decimal182 null decshiptax decimal182 null strbccurrencycode varchar3 null decbcshipfullprice decimal184 null decbcshipofferdisc decimal184 null decbcshipoverride decimal184 null decbcshipfinal decimal184 null decbcshiptax decimal184 null dectotalamount decimal182 null decbctotalamount decimal184 null decwrittentotalamount decimal182 null decbcwrittentotalamount decimal184 null blnproratashipping bit null blnchargewithfirstshipment bit null sintshippingservicelevelid smallint null sintshippingmethodid smallint null sdtmdonotshipuntil smalldatetime null blnholduntilcomplete bit null tsrowversion timestamp null constraint pk tblborder primary key clustered strbxorderno asc fillfactor go create nonclustered index ix tblborder lngaccountaddressid dbo tblborder lngaccountaddressid asc sintorderstatusid asc fillfactor create nonclustered index ix tblborder lngaccountparticipantid dbo tblborder lngaccountparticipantid asc fillfactor create nonclustered index ix tblborder lngorderedbyaddressid dbo tblborder lngorderedbyaddressid asc sintorderstatusid asc fillfactor create nonclustered index ix tblborder lngorderedbyparticipantid dbo tblborder lngorderedbyparticipantid asc fillfactor create nonclustered index ix tblborder lngshippedtoparticipantid dbo tblborder lngshippedtoparticipantid asc fillfactor create nonclustered index ix tblborder lngshiptoaddressid dbo tblborder lngshiptoaddressid asc sintorderstatusid asc fillfactor create nonclustered index ix tblborder sdtmordcreated sintmarketid include strbxorderno dbo tblborder sdtmordcreated asc sintmarketid asc include strbxorderno fillfactor create nonclustered index ix tblborder sdtmordcreated incl dbo tblborder sdtmordcreated asc include decbcshipfinal decbcshipfullprice decbcshipofferdisc decbcshipoverride decbcshiptax decbctotalamount decbcwrittentotalamount decshipfinal decshipfullprice decshipofferdisc decshipoverride decshiptax dectotalamount decwrittentotalamount lngaccountparticipantid lngorderedbyparticipantid sintmarketid sintorderchannelid sintorderstatusid sintordertypeid strbxorderno strcurrencycode stroffercode strorderkey fillfactor create nonclustered index ix tblborder sintmarketid sdtmordcreated dbo tblborder sintmarketid asc sdtmordcreated asc include sintorderchannelid strbxorderno fillfactor create nonclustered index ix tblborder sintorderchannelid sdtmordcreated incl dbo tblborder sintorderchannelid asc sdtmordcreated asc include decbcshipfinal decbcshipfullprice decbcshiptax decshipfinal decshipfullprice decshiptax lngaccountparticipantid sintmarketid sintordertypeid strbxorderno strcurrencycode strorderkey fillfactor create nonclustered index ix tblborder strbxorderno sdtmordcreated incl dbo tblborder strbxorderno asc sdtmordcreated asc include sintorderchannelid sintordertypeid sintmarketid strorderkey lngaccountparticipantid strcurrencycode decshipfullprice decshipfinal decshiptax decbcshipfullprice decbcshipfinal decbcshiptax conclusion applied index live system updated stored procedure use smalldatetime order match data types database columns involved looking query plan see picture exactly wanted think query optimizer case good work get best query plan environments glad add query hints learned answers posted thanks max vernon paul white daniel hutmacher answers
132851 production environment froze morning altering table adding column actually offending sql alter table cliente add column topicos character varying20 login system requires select table one could login alter table actually kill process allow system resume normal operations table structure create table cliente rut character varying30 null nombre character varying150 null razon social character varying150 null direccion character varying200 null comuna character varying100 null ciudad character varying100 null codigo pais character varying3 null activo boolean default true id serial null stock boolean default false vigente boolean default true clase integer default plan integer default plantilla character varying15 default waypoint character varying facturable integer default toolkit integer default propietario integer default creacion timestamp without time zone default codelco boolean null default false familia integer default enabled machines boolean default false enabled canbus boolean default false enabled horometro boolean default false enabled comap boolean default false enabled frio boolean default false enabled panico boolean default false enabled puerta boolean default false enabled rpm boolean default false enabled supervisor integer default demo boolean interno boolean mqtt enable boolean null default false topicos character varying20 constraint pk cliente primary key rut constraint fk cliente familiaid foreign key familia references cliente familia id match simple update action delete action constraint pk pais foreign key codigo pais references pais codigo match simple update action delete action constraint unique id cliente unique id oids false alter table cliente owner waypoint grant table cliente waypoint grant table cliente waypointtx grant select update insert delete table cliente waypointtomcat grant select table cliente waypointphp grant select table cliente waypointpphppublic grant table cliente waypointsoporte grant select insert table cliente waypointsalesforce grant select table cliente waypointadminuser grant select table cliente waypointagenda grant select table cliente waypointmachines grant select table cliente waypointreports grant select table cliente readonly create index index cliente cliente using btree rut collate pg catalog default create index index cliente activo cliente using btree activo create index index cliente id activo cliente using btree id activo create index index cliente rut activo cliente using btree rut collate pg catalog default activo create trigger trigger default admin insert cliente row execute procedure crea default admin create trigger trigger default grupo insert cliente row execute procedure crea default clientegrupo disable constraints triggers something else perhaps db tuning else provide analysis version postgresql x86 unknown linux gnu compiled gcc debian bit
132951 able set current timestamp default value mysql version query alter table downloads add date datetime null default current timestamp working fine local db mysql v5
132966 im sql server need clean whitespace start end columns content whitespace could simple spaces tabs newlines content become content content become content able achieve first case update table set column ltrimrtrimt column cases doesnt work
133208 im issue production environment trying simulate local sql server express instance used ssms change maximum number concurrent connections max restarting service im able connect ssms try open server properties new query window change setting back ssms crashes place change setting without ssms registry
133384 simple would like count number rows sub query note status whether host online bad code select countip address ports select distinct ip address ports status true explained first query run returns select distinct ip address ports status true ip address second query run returns select countip address ports question would like know count list ip addresses looking online possible solutions simple problem getting frustrated thought id ask experts
133546 team designs tables relations software developers organization pretty strict enforcing 3nf normalization honest agree given size organization needs clients change time one area im clear reasons behind design decision addresses mostly focuses addresses united states think could apply country piece address gets column addresses table instance take gnarly address attn jane doe smith st sw apt 300b chicago il would get split database like street number street fraction street pre directional north street name smith street type st street street post directional sw southwest city chicago state il illinois zip code zip4 code country assumed attention jane doe box null dwelling type apt apartment dwelling number 300b would columns related rural routes contract routes furthermore specific application likely international addresses data modelers said would add columns specific international addresses would normal line line fields first thought way overboard researching online repeatedly refers using address line possibly splitting city region postal code one use case new application granularity beneficial validate user creating duplicate business checking address one validations get work address line would difficult specific application need store multiple kinds addresses businesses people physical mailing shipping etc might need generate printable form letters requirement hasnt discussed far things applications organization need support auditing full history tables printing mailing labels generating printed forms reporting national regional governments application might everything every application splitting addresses multiple components enterprise standard work regardless whether application would benefit forced semi related stackoverflow question good address parser closed illustrates difficult parsing addresses order better understand design decision sell client idea problems solved splitting street address individual columns bonus points anyone implemented system like ran problems
133556 tl dr question boils inserting row window opportunity generation new identity value locking corresponding row key clustered index external observer could see newer identity value inserted concurrent transaction sql server detailed version sql server table identity column called checkpointsequence key tables clustered index also number additional nonclustered indexes rows inserted table several concurrent processes threads isolation level read committed without identity insert time processes periodically reading rows clustered index ordered checkpointsequence column also isolation level read committed read committed snapshot option turned currently rely fact reading processes never skip checkpoint question rely property could make true example rows identity values inserted reader must see row value prior seeing one value tests show query contains order checkpointsequence clause checkpointsequence clause reliably blocks whenever row read yet committed even row already committed believe least theory may race condition might cause assumption break unfortunately documentation identity doesnt say lot identity works context multiple concurrent transactions says new value generated based current seed increment new value particular transaction different concurrent transactions table msdn reasoning must work somehow like transaction started either explicitly implicitly identity value generated corresponding row lock taken clustered index based identity value unless lock escalation kicks case whole table locked row inserted transaction committed possibly quite lot time later lock removed think step tiny window concurrent session could generate next identity value execute remaining steps thus allowing reader coming exactly point time read value missing value course probability seems extremely low still could happen could youre interested context implementation neventstores sql persistence engine neventstore implements append event store every event gets new ascending checkpoint sequence number clients read events event store ordered checkpoint order perform computations sorts event checkpoint processed clients consider newer events events checkpoint therefore vital events never skipped theyd never considered im currently trying determine identity based checkpoint implementation meets requirement exact sql statements used schema writers query readers query im right situation described could arise see two options dealing unsatisfactory seeing checkpoint sequence value seen dismiss try later however identity course produce gaps transaction rolled back might never come approach accept gap milliseconds however value assume better ideas
133651 im trying migrate mysql database sql server using sql server migration assistant mysql converting schema synchronizing sql server works fine however clicking migrate data button ssma crashes seconds ssma stopped working might cause problem
133712 simple question cant seem find answer terms performance clause would gain performance replaced condition words performance gain replacing following select mytable select mytable know depend indexes purpose lets say indexes exist arithmetic operator perform better logical operator im impression addition performs better multiple conditions ands ors test results table million rows returning rows rows addition took seconds logical conditions took seconds hand returning rows rows seconds returning rows f65 f67 f64 rows seconds seems significant difference agree gbn false amtwo absa absb absc absd even expect positive values column accepts negative values assume might encounter one results impressive thought seems addition much quicker logical operators float money float query used shown case positive numbers indexes logical mind addition would quicker logical conditions
134016 scenario prod two two node fci mirroring primary disaster dc working fine new hardware coming version upgrade sql server r2 form two two node fci primary async ag get data second fci dr san mirroring identical boxes dr site take r2 primary log ship databases sql server fci primary ag leave ag log ship migration go live setup ag fact thats end world trying see skip setup
134027 following code added one developers delete duplicate records table delete subquery select id fk1 fk2 createddatetime row number overpartition fk1 fk2 order createddatetime rownumber table subquery rownumber reviewing code assumed wouldnt work however testing test environment sql shows sql know resolve sub query delete records table
134129 need perform update insert single transaction code works fine id like able call easily pass required parameters try nest transaction stored procedure run lots syntax errors encapsulate following code easily called begin transaction assignusertoticket go declare updateauthor varchar100 declare assigneduser varchar100 declare ticketid bigint set updateauthor user1 set assigneduser user2 set ticketid update tblticket set ticketassignedusersamaccountname assigneduser ticketid ticketid insert dbo tblticketupdate ticketid updatedetail updatedatetime usersamaccountname activity values ticketid assigned ticket assigneduser getdate updateauthor assign go commit transaction assignusertoticket
134296 sql server instance active directory group add active directory users personal ad account myaccount service account serviceaccount group need grant admin access ad group whole instance means wont need execute grant commands every new table database created user group automatically able create drop insert select etc even trickier must able use windows authentication login myaccount login windows login sql server without needing type username password login using serviceaccount typing username password cant forced login windows serviceaccount run ssms ssdt etc account able login mssql whats best practice configuring
134525 shown using common table expressions msdn define cte expression name column name cte query definition use like select column list expression name lets say following ctes cte1 select name table1 cte2name select name table1 query outputs results ctes inner query difference two cte2 column namename defined declaration execute ctes dont see difference execution plan curious know difference make dont specify column names cte definition specify column names creating cte affect query execution plan chance far seen doesnt make difference
134555 table several hundred columns wide way convert row single concatenated string column title included without list single column query im columns represents fields event report im putting back together person read report logical manner ive done query laborious column seems error prone brief snippet showing three columns concatenated format need done column column approach select concat iifid null null concatid id iifstandardclientid null null concatstandardclientid standardclientid iifclientname null null concatclientname clientname reportline dbo datadecoded thanks
134685 table clustered unique index non clustered primary key structure index object id dbo tblbaccountholder null drop table dbo tblbaccountholder go create table dbo tblbaccountholder lngparticipantid int null sdtmcreated smalldatetime null strusername varchar20 null strpassword varchar20 null tsrowversion timestamp null constraint pk tblaccountholder primary key nonclustered lngparticipantid asc constraint ix tblbaccountholder lngparticipantid unique clustered lngparticipantid asc fillfactor one column see definition create unique clustered index ix tblbaccountholder lngparticipantid dbo tblbaccountholder lngparticipantid asc would like drop unique index alter primary key clustered keep primary key change non clustered clustered table part transaction replication would get done subscriber database publisher table rows mess replication problem drop primary key constraint create clustered would like get done subscriber database drop index ix tblbaccountholder lngparticipantid dbo tblbaccountholder go alter table dbo tblbaccountholder drop constraint pk tblaccountholder go alter table dbo tblbaccountholder add constraint pk tblaccountholder primary key clustered lngparticipantid asc pad index fillfactor sort tempdb ignore dup key statistics norecompute online allow row locks allow page locks primary go
134704 running sql server trying put queries together monitoring using dmvs however looking total elapsed time field sys dm exec requests dmv numbers look way heres example select session id runtime current timestamp start time total elapsed time sys dm exec requests session id session id runtime start time total elapsed time calculations elapsed time around around thats factor difference milliseconds current time start time select datediffmillisecond 07t16 07t16 heres server info select version microsoft sql server x64 apr copyright microsoft corporation enterprise edition core based licensing bit windows nt x64 build service pack ideas could causing discrepancy
134741 start etl stored procedure serialized paralellism concern need assign custom id numbers markers loads use identity field id numbers unique bucket number essentially another numbered field currently use following code declare idrunner smallint select idrunner isnullmax id sim variable bucketref simbucketno declare variable cursor cursor select distinct variable simstg parameter left outer join sim variable variable code bucketref stgbucketno bucketref simbucketno code null open variable cursor declare variable varchar64 fetch next variable cursor variable fetch status begin set idrunner idrunner insert sim variable bucketref variableno code values simbucketno idrunner variable fetch next variable cursor variable end close variable cursor deallocate variable cursor like uses cursors prefer avoid sidenote code untested way efficient without cursor ir numbers must increase highest used new elements added multiple buckets exist bucket numbering always going process data one bucket time one bucket sim one simstg
134828 using microsoft sql server sp3 kb3072779 x64 given table index create table user session sessionid int identity1 null primary key createdutc datetime27 null default sysutcdatetime create nonclustered index ix user session createdutc user session createdutc include sessionid actual rows following queries 1m estimated rows shown comments queries feed another query view optimizer chooses loop join row estimates improve estimate ground level avoid overriding parent query join hint resorting sp using hardcoded date works great select distinct sessionid user session 9m great createdutc hardcoded equivalent queries view compatible estimate row select distinct sessionid user session createdutc dateaddday sysutcdatetime select distinct sessionid user session dateaddday createdutc sysutcdatetime select distinct sessionid user session inner loop join select dateaddday sysutcdatetime mincreatedutc mincreatedutc createdutc also tried reversing join order shown change select distinct sessionid user session cross apply select dateaddday sysutcdatetime mincreatedutc mincreatedutc createdutc also tried reversing join order shown change try hints view select distinct sessionid user session createdutc dateaddday sysutcdatetime option recompile select distinct sessionid user session createdutc select dateaddday sysutcdatetime option recompile optimize unknown select distinct sessionid select dateaddday sysutcdatetime mincreatedutc inner loop join user session createdutc mincreatedutc option recompile try using parameter hints view declare mindate datetime27 dateaddday sysutcdatetime select distinct sessionid user session 2m adequate createdutc mindate select distinct sessionid user session 96m great createdutc mindate option recompile select distinct sessionid user session 2m adequate createdutc mindate option optimize unknown statistics date dbcc show statisticsuser session ix user session createdutc histogram last rows histogram rows total shown
134898 ive never used mongodb read lot think going good project also lots experience mysql even honest clue im ask scenario mysql table profile id pk auto increment smallint user id pk fk varchar category id pk fk smallint role id pk fk tinyint country id pk fk smallint state id pk fk smallint legal document pk varchar unique name pk varchar unique type pk boolean last activity pk date fk see mysql tables course im thinking use mongodb store profile info profile info collection contain documents like id profile id address street state country phone email example example com etc im planning use mongodb project needs public asap may add several new profile info things want alter table migrate tools lots rows said may add pks mysql table thinking migrating project mongodb know good move questions better keep pks mysql trivial info mongodb would fine move mongodb may mongodb faster migrate whole project keep structure like mean like profile profile info collections instead profile im worried many resources mongodb could use table collection many indexes want keep disk space ram minimum use critical difference mysql mongodb ps ssds going used system ps ii tables planned nothing written yet im bit plan ahead person please patient
135032 business requirement record invoice table id looks like yyyynnnnnn nnnnnn part needs restart beginning year first row entered would look like second like etc lets say last record next row look like dont need id primary key store creation date well idea display id unique query human group able year unlikely records would deleted however would inclined code defensively something like way could create id without query max id year every time insert new row ideas createnewinvoicesp gets max value year yucky magical built feature exactly dream right able specify udf something identity default declaration view uses partition row deleted would problematic trigger insert would still need run max query annual background job updated table max year inserted something bit non ideal ideas variations welcome though
135142 successfully granted require ssl single user mysql targetmysqluser targetmysqlpass grant usage dbname dbusername require ssl im failing removing revoking flag user using revoke guess im fighting syntax proper way remove revoke command without revoking whole permission mysql manual site interwebs didnt helped yet finding proper counter way sql statement work update mysql user set ssl type ssl type flush privileges believe grant require ssl must revoke require ssl isnt
135150 process archiving wherein take backup current database restore xxx archive database database contains previous data insert update delete database used reporting thinking shrinking database however increases index fragmentation thinking following steps shrink database organize organize indexes hamper database performance options consider recovering space update process change recovery model simple backup database move database pseudo simple state planning shrink database
135365 im trying get whatever stored procedure returns column names types tables couldnt figure stored procedures tried sp columns managed make work tables also tried something like im sure supposed match select sys procedures nolock aa inner join sys schemas nolock bb aa schema id bb schema id inner join sys columns nolock cc aa object id cc object id example user id varchar200 need names column names stored procedure returns data types sql server version matters ideas thanks
135420 started use sql server recently still dont know best way things created tables column id primary key try insert values get following error insert value null column id table project dbo table column allow nulls insert fails statement terminated good simple solution problem
135455 done digging option fast xxx query hint inside select statement still confused according msdn specifies query optimized fast retrieval first number rows nonnegative integer first number rows returned query continues execution produces full result set make much sense basically query get first xxx rows really fast rest normal speed microsoft dynamics query got thinking select pjproj projectpjproj project descpjproj customerpjproj cpnyid pjproj nolock project like order project optionfast anyone explain exactly query hint advantage using
135478 fairly large 240gb mongo database need transfer across sluggish network onto new server traditionally situations ive found mongodump followed mongorestore much faster db clonecollection method however realized today full mongodump followed mongorestore bit wasteful think since data transfer insertions would prefer transfer data old mongo mongodump step simultaneously inserting available data new database mongorestore step anyone know parallelize dumping inserting process mongodb would actually faster
135645 reading article bbc tells story person named jenifer null faces day day problems using online databases like booking plane tickets net banking etc well versed databases use often made website learning server side form validation used regular expressions remember would happily accept name null tried though could someone explain technicalities situation would occur form validation string null something even think null null
135717 title pretty self explanatory youre curious want want archive log table stores past values active table due dont want data risk compromised way thing ever insert table trigger created active table log changes rare case may need manually edit log table turn exists insert lock using sql server enterprise sql management studio
135720 trying assign select privilege group redshift created group user group create group data viewers create user user password password group data viewers would like allow group able read data table grant select tables schema public group data viewers command returns grant connect redshift newly created user issue select something something get permission denied schema something tried granting permissions something grant select tables schema something group data viewers changed anything allow users group select data table schema
135745 restored database backup database uses replication publish different server assuming database restore would break replication tried delete replication create script create scratch im sure exactly completely messed state cant fix first try get rid subscription publisher server exec sp dropsubscription publication publicationname article nall subscriber subscriberservername seems work select syssubscriptions shows results looking subscriber server ssms subscriberserver replication local subscriptions subscription try delete publication ssms server replication local publications publicationname delete gives following error message could delete publication publicationname could drop article subscription exists changed database context databasename microsoft sql server error ok try drop articles exec sp droparticle publication publicationname article nall get error invalidated existing snapshot publication run snapshot agent generate new snapshot msg level state procedure sp msdrop article line could drop article subscription exists ok try starting snapshot agent get internal sql exception sql command sp msactivate auto sub returned fewer rows expected replication agent tried alternative method deleting article delete sysarticles seems worked got rid articles still get drop publication least one subscription exists publication error try delete publication also restarted sql server didnt help dont know going fix btw happens give software developer knows enough dangerous keys database fortunately isnt production environment
135814 view result dates time current code select db dbo table user id date time date time date order date asc time asc code work know fix doesnt request work
135887 yesterday made serious mistake restoring wrong database background may skip section right clicked test database proceeded restore database section usual selecting media file source browsed latest production database backup performed mistake need date information test database order test however soon hit ok add media dialog ssms detected backup made production db silently changed destination field reflect didnt realize late database changes 01am 30pm lost hours struggling could approach manager deliver unhappy news decided would try best repair damage way possible certain extent luckily succeed steps taken first foremost made sure todays backup performed since contained db entries 30pm 00pm could lost went restore dialog production db clicked timeline option hoping perform point time restore precisely 29pm unzipped previous day backup one accidentally restored previously default backup location made sure suitable log backup present system set desired point time clicked verify backup media proceeded backup im relieved worked expected tables contains records 29pm everything else missing large database tables hand checking inserting everything would take days question possible restore missing records present latest backup current state db steps necessary serious fear bane edit response james anderson concerns backup chain actually backup file changes 30pm till 10pm created job ive set fact even restored backup new temporary database sure getting people involved help manager travelling next couple weeks team really small people im one charge right say ill inform im responsible handling alone even manually tools could help please suggest thank everyone
136225 im new db2 connecting db2 v7r1 database using unixodbc ibm access odbc driver linux query database results include first letter column names example typical query run isql utility give something looks like sql select column1 column2 schema table column1 lorem ipsum dolar sit sqlrowcount returns rows fetched problem try query database applications using pyodbc library python cant access results column name columns named result set questions happening possible change behavior edit happens even try give columns aliases sql select column1 foo column2 bar schema table column1 lorem ipsum dolar sit sqlrowcount returns rows fetched
136235 need convert data two systems first system stores schedules plain list dates date included schedule one row various gaps sequence dates weekends public holidays longer pauses days week may excluded schedule gaps even weekends included schedule years long usually weeks long simple example schedule spans two weeks excluding weekends complicated examples script id contractid dt dowchar dowint mon tue wed thu fri mon tue wed thu fri id unique necessarily sequential primary key dates unique within contract unique index contractid dt second system stores schedules intervals list week days part schedule interval defined start end dates inclusive list week days included schedule format efficiently define repetitive weekly patterns mon wed becomes pain pattern disrupted example public holiday simple example look like contractid startdt enddt daycount weekdays montuewedthufri startdt enddt intervals belong contract overlap need convert data first system format used second system moment im solving client side single given contract id like sql server side bulk processing export import servers likely could done using clr udf stage cant use sqlclr challenge make list intervals short human friendly possible example schedule id contractid dt dowchar dowint thu fri mon tue wed thu fri mon tue become contractid startdt enddt daycount weekdays montuewedthufri contractid startdt enddt daycount weekdays thufri montuewedthufri montue tried apply gaps islands approach problem tried two passes first pass find islands simple consecutive days end island gap sequence days weekend public holiday something else found island build comma separated list distinct weekdays second pass group found islands looking gap sequence week numbers change weekdays approach partial week ends extra interval shown even though week numbers consecutive weekdays change besides regular gaps within week see contractid sample data data monwedfri approach would generate separate intervals day schedule bright side generates one interval schedule doesnt gaps see contractid sample data includes weekends case doesnt matter start end week partial please see examples script get better idea im see quite often weekends excluded days week could also excluded example mon wed fri part schedule besides weekends included example solution treat days week equally day week included excluded schedule verify generated list intervals describes given schedule correctly use following pseudo code loop intervals interval loop calendar dates start end dates inclusive date check day week listed weekdays yes date included schedule hopefully clarifies cases new interval created examples one monday removed middle schedule schedule cant represented single interval example long gap schedule two intervals needed intervals represent weekly patterns schedule pattern disrupted changed new interval added example first three weeks pattern tue pattern changes thu result need two intervals describe schedule im using sql server moment solution work version solution sql server simplified improved using features later versions thats bonus please show well calendar table list dates numbers table list integer numbers starting ok use needed also ok create temporary tables several queries process data several stages number stages algorithm fixed though cursors explicit loops ok script sample data expected results src sample data dst expected result declare src table id int primary key contractid int dt date dowchar char3 dowint int insert src id contractid dt dowchar dowint values simple two weeks without weekend mon tue wed thu fri mon tue wed thu fri partial end week whole week partial start week without weekends thu fri mon tue wed thu fri mon tue mon wed fri included across two weeks plus partial third week mon wed fri mon wed fri mon whole week without weekend second week mon included mon tue wed thu fri tue wed thu fri three weeks without mon second week weekends mon tue wed thu fri tue wed thu fri mon tue wed thu fri long gap two intervals thu fri mon tue wed thu fri mon tue mon tue wed thu fri mon tue wed thu fri two weeks gaps days even weekends included mon tue wed thu fri sat sun mon tue wed thu fri gaps days even weekends included partial weeks sat sun mon tue wed thu fri sat sun mon tue wed thu fri sat mon wed included two weeks plus partial third week mon tue wed mon tue wed mon tue thu sun included three weeks thu fri sat sun thu fri sat sun thu fri sat sun tue first three weeks thu next three weeks tue tue tue thu thu thu one week one week gap one week mon tue wed thu fri mon tue wed thu fri select id contractid dt dowchar dowint src order contractid dt declare dst table contractid int startdt date enddt date daycount int weekdays varchar255 insert dst contractid startdt enddt daycount weekdays values montuewedthufri montuewedthufri monwedfri montuewedthufri tuewedthufri montuewedthufri montuewedthufri montuewedthufri montuewedthufri sunmontuewedthufrisat sunmontuewedthufrisat montuewed sunthufrisat tue thu montuewedthufri montuewedthufri select contractid startdt enddt daycount weekdays dst order contractid startdt comparison answers real table src rows distinct contractids answers produce correct results least data reasonably fast differ optimality less intervals generated better included run times curiosity main focus correct optimal result speed unless takes long stopped non recursive query ziggy crueltyfree zeitgeister minutes answer intervals seconds ziggy crueltyfree zeitgeister loop ziggy crueltyfree zeitgeister recursive michael green recursive geoff patterson weekly gaps islands merging partial weeks vladimir baranov daily weekly gaps islands mikael eriksson weekly gaps islands vladimir baranov cursor
136239 grant select tables starting vvc grant select vvc user1
136268 built hierarchyid clr stores paths efficient binary form provides useful functionality unfortunately limit deep represented paths binary tree would like increase limit complex existing application bound hit limit dont wish change interface type confident could pull changing interface type without introducing subtle bugs code would changed result could theory create binhierarchyid clr udt implements interface hierarchyid supports binary trees get depth still remaining inside byte limit sure big undertaking would source hierarchyid clr available somewhere could create based supports deeper structures
136674 rather big table one columns xml data average size xml entry kilobytes columns regular ints bigints guids etc concrete numbers lets say table million rows gb size noticed table really slow select data want select columns select top table takes around seconds read data disk even though dont impose ordering result run query cold cache dbcc dropcleanbuffers heres io statistics results scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads grabs mb data execution plan shows clustered index scan id expect theres io going disk besides queries ive also checked clustered index fragmentation close consumer grade sata drive however id still think sql server would able scan table faster mb min presence xml field causes table data located lob data pages fact table pages lob data guess question correct thinking lob data pages cause slow scans size also sql server cant scan clustered index effectively theres lot lob data pages table even broadly considered reasonable table structure data pattern recommendations using filestream usually state much bigger field sizes dont really wan na go route ive really found good info particular scenario ive thinking towards xml compression needs done client sqlclr would require quite work implement system tried compression since xmls highly redundant app compress xml 20kb 5kb store varbinary column preventing usage lob data pages speeds selects 20x times tests
136733 values computed columns determined value retrieved value changed time im guessing novice question since im finding anything searches
136894 know last run date last run time stored int coverted datetime examples time gmt converted doesnt match time gui log history displays anyone provide guidance sql code converts value datetime value last run literal dateaddmillisecond sjs last run time convertdatetimecastnullifsjs last run date0 nvarchar10
137045 trying query two tables get results like following section names shoes accountname1 accountname2 accountname3 books accountname1 tables create table dbo tableaid int section varchar64 accountid varchar64 insert dbo tableaid section accountid values shoesa1 shoesa2 shoesa3 booksa1 create table dbo tablebaccountid varchar20 name varchar64 insert dbo tablebaccountid name values a1accountname1 a2accountname2 a3accountname3 saw questions answered saying use xml path stuff query data get results looking think something missing tried query get error message column accountid invalid select list contained either aggregate function group clause dont select clause either query assume error accountid unique tablea query currently trying get working correctly select section names stuff select name tableb accountid accountid xml path tablea group section
137097 specifically want programmable way change recovery model databases server know solution applied alter database commands know smo powershell solve problem easily import module sqlps cd sql servername instancename databases foreach database ls force database recoverymodel full database update im looking efficient sql solution ingrained head avoid cursors costs however cant think set based solution perform alter statements cursor based solution declare sql varcharmax name varchar50 declare cur cursor select name sys databases name tempdb open cur fetch next cur name fetch status begin set sql alter database name set recovery full exec sql fetch next cur name end close cur deallocate cur also done loop solution still goes looping process loops offer significantly better performance paranoid performance say administrative tasks arent done often generally isnt massive amount objects need loop however always think worked large environment thousands objects begin feel guilty may using efficient solution
137200 working sql server looking function like ltrim rtrim also remove leading trailing tabs double spaces carriage returns line feeds etc number functions ones found limitations truncate string characters according comments sql server enhenced trim function remove trailing spaces leading spaces white space tabs carriage returns line feeds one comments proposed better solution causes incorrect syntax error sure create function dbo supertrimleft str varcharmax returns varcharmax begin asciileft str begin set str stuff str patindex char0 char32 str end return str end question best approach accomplish task
137391 sql server database noticed value reason early termination statement optimization queries gave good enough plan found questions possible types reason early termination statement optimization searching msdn get complete list values dmv extended event list queries optimization terminated due reasons good enough plan found referred following two articles list complete list possibilities also give different result database finding query compilation timeout identifying query plans good enough
137472 ive inherited instances sql server part wider acquisition project im process assessing performance dont like way maintenance plans implemented im seeing daily blanket index rebuilds deal one also daily manual updating statistics around half databases set auto update statistics false reasons clear told reduce performance issues always thought worked best practice setting true felt manual update necessary setting true wrong anyone explain benefit would set false daily manual update instead mention databases highly transactional millions inserts deletes updates per day others low terms transaction rates read rhyme reason though auto update setting set false appears lottery
137704 reading examples msdn try catch blocks code listing example follows begin transaction begin try generate constraint violation error delete production product productid end try begin catch select error number errornumber error severity errorseverity error state errorstate error procedure errorprocedure error line errorline error message errormessage trancount rollback transaction end catch trancount commit transaction go dont understand would bother check trancount catch block really possible transaction count code snippet guard clause example principle examples exemplary
137791 reading bbc news article following excerpt caught attention sounds like always availability groups high availability mirroring maybe security automatically included blockchain potentially viable database solution modern high transaction volume applications pretty easy see value low volume transactions like personal medical records high volume databases blockchain blockchains rely cryptography allow set computers make changes global record without needing central actor removing middleman cuts costs almost every sector blockchain ledger records everything happens collection data known block chronological order chain currency important feature allows users sure digital money one kind way note wallet unique blockchain tech way create assets allows transfer digital information without copying says adam ludwin chief executive chain com builds blockchain networks blockchain used track history sorts information maintain value example doctors could use update medical records since change blockchain made simultaneously across whole network information lost changes undone system maintains transparency special key needed make changes block individuals keep records safe protecting key
137911 database hosted sql server instance enabled allow snapshot isolation verified state using select snapshot isolation state descname sys databases however separate sessions run long running select tablock 1st update 2nd vice versa whichever query starts first blocks second query per sp who2 looking select sys dm exec requests queries transaction isolation level read committed per understanding snapshot isolation tempdb usage increase however blocking occur situation missing configuration steps achieve behaviour
138029 clicking take database offline management studio message stays hang wont close click close whats good way deal stuck jobs like management studio kill via activity monitor seek process stopping job going terminate
138080 requirement recent project report resource would fully consumed well exhaustion calendar date asked show remaining time english like format something like year months go built datediff function returns count specified datepart boundaries crossed specified startdate enddate used could produce misleading confusing results example using interval year would show yyyy mm dd one year apart whereas common sense would say dates separated day conversely using interval day separated days people would see years better description starting number days calculating months years would prone leap year size month errors got wondering could implemented various sql dialects example output includes create table testdata fromdate date null todate date null expectedresult varchar100 null exact formatting unimportant insert testdata fromdate todate expectedresult values days day month month month length important month day leap years accounted months days days day leap year year years day catch overflow date calculations years months days mindate maxdate happen using sql server 2008r2 interested learn dialects would handle
138114 run server side profile trace hour produce trc file activities one databases passed trc trace file parameter database engine tuning advisor running dta get recommendations script recommendations using sql server dont seem find way scripting individually overly time consuming
138311 anybody show good example mdxs advantages regular sql analytical queries would like compare mdx query sql query gives similar results wikipedia says possible translate traditional sql would frequently require synthesis clumsy sql expressions even simple mdx expressions neither citation example fully aware underlying data must organized differently olap require processing storage per insert proposal move oracle rdbms apache kylin hadoop context trying convince company querying olap database instead oltp database siem queries make heavy use group sort aggregation besides performance boost think olap mdx queries would concise easier read write equivalent oltp sql concrete example would drive point home expert sql much less mdx helps sample siem related sql query firewall events happened past week select seoul average term substrto charidate hh24 mi event time roundavgtot accept cnt select st event yyyymm 1m idate truncsysdate iw truncsysdate iw stat monitor group query union select st event yyyymm idate truncsysdate iw truncsysdate iw stat monitor group query pm group substrto charidate hh24 mi union select today term substrto charidate hh24 mi event time roundavgtot accept cnt st event yyyymm cm idate truncsysdate stat monitor group query group substrto charidate hh24 mi order term desc event time asc
138315 timestamp stored bigint format turn human readable format points date may 11th however function timestamp turns id like create view could display values dont know function use field written java program eclipselink presume dont source code program
138357 attempting resolve difficulties getting zip codes display properly original spreadsheet zip codes mixed digit formats import process digit zip codes reporting length digits try add hyphen digit zip codes im getting abnormal results errors wrong length various data type conversion issues import performed using openrowset method importing data spreadsheet query newly imported data see zip codes showing spreadsheet length wrong select zip lenltrimrtrimzip ziplength xls import zip ziplength select left characters data everything gets converted float zip codes unreadable select leftzip9 xls import lenltrimrtrimzip zip 32013e 42034e 56637e 41153e 36045e 41133e get zip codes back correct digits add hyphen digit zip codes reporting length end goal simply get digit zip code hyphen middle datatype zip column float discovered spreadsheets like nj ny apostrophe leading zip code need investigate handle 0xxxx zip codes get work spreadsheet imports
138522 differences daily tasks duties mongo dba compared rdbms dba example sites claim mongodb dba would require data modelling designing database would done developer application designer would mean tasks longer needed done wrt mongodb administrations earlier done rdbms dbas tasks would required normally schedule rdbms dba also task rdbms dbas used longer schedule mongodb dbas im new mongodb administration im trying identify task may commit mistake things daily task needed miss something need experienced mongodb dbas help dont foolish mistakes work
138720 running alter column int bigint table size gb hour got version store error tempdb full far know takes memory pages log files sure tempdb someone please explain internals using read committed isolation select name snapshot isolation state desc read committed snapshot sys databases database returns name databasename snapshot isolation state desc read committed snapshot
138724 maintain extend old legacy system contains webservice methods database tables longer used since entirely sure tables really redundant afraid drop way achieve effect tables used without dropping idea transfer different schema deleted current default dbo exists select sys schemas name deleted begin execcreate schema deleted end alter schema deleted transfer dbo tablename option drawbacks schema approach
138800 sql server return row even add whitespace two end clause shouldnt zero records found following example src select cast12345 varchar demo select src demo one needs query find
139021 function keyword allow get current line number stored procedure know theres undocumented lineno function allows set line number affect output system error messages https stackoverflow com questions exactly sql lineno reserved word know theres function error line thats available inside begin catch end catch error line need want use outside catch block anywhere file declare insertsource varchar1000 object name procid exec proc accounting transaction insert parameters insertsource currently im hard coding call appears stored procedure body getting old quickly declare insertsource varchar1000 set insertsource object name procid exec set insertsource object name procid exec
139106 sql equivalent patterns let pull values column contains punctuation example create table test value varchar10 insert test values 123a 456b 12abcab23cd789 select test value like would return values first characters numbers last character letter would return things like 123a 456b wouldnt return value 12abc want know equivalent punctuation numbers letters would return ab23 cd789 could use regular expression might use expression za z0 match alphanumeric characters string value like za z0 sql equivalent know kind thing done regex need sql able load custom assemblies onto server cant use regular expressions real column varchar200 collation latin1 general ci using sql server standard edition
139131 setup master mariadb slave mariadb replication working fine recently point slaves dbs restored dump performed necessary steps dump masters dbs transfer dump slave drop old dbs execute dump restore dbs execute appropriate change master command finally start slave receiving error got fatal error master reading data binary log could find first log file name binary log index file first log file slave needs master mysql bin see present master also see binary log index master seems entry log file still replication working keep getting error im ideas check next updated output show slave status requested mariadb none show slave status show slave status row slave io state master host master user replication master port connect retry master log file mysql bin read master log pos relay log file mysqld relay bin relay log pos relay master log file mysql bin slave io running slave sql running yes replicate db xxx yyyxxx zzz replicate ignore db replicate table replicate ignore table replicate wild table replicate wild ignore table last errno last error skip counter exec master log pos relay log space condition none log file log pos master ssl allowed master ssl ca file master ssl ca path master ssl cert master ssl cipher master ssl key seconds behind master null master ssl verify server cert last io errno last io error got fatal error master reading data binary log could find first log file name binary log index file last sql errno last sql error replicate ignore server ids master server id master ssl crl master ssl crlpath using gtid gtid io pos row set sec additional requested information root master var lib mysql ls var lib mysql mysql bin rw rw mysql mysql may var lib mysql mysql bin root master var lib mysql ls mysql bin mysql bin mysql bin mysql bin yes created root master var lib mysql mysql uroot enter password welcome mariadb monitor commands end mariadb connection id server version mariadb log mariadb server copyright oracle mariadb corporation ab others type help help type clear current input statement mariadb none show binary logs log name file size mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin mysql bin rows set sec mariadb none exit bye root master var lib mysql mysqlbinlog mysql bin tmp somefile txt root master var lib mysql tail tmp somefile txt server id end log pos xid commit server id end log pos rotate mysql bin pos delimiter end log file rollback added mysqlbinlog set completion type old completion type set session pseudo slave mode root master var lib mysql etc cnf server cnf excerpt binary logging log bin var lib mysql mysql bin expire logs days sync binlog edit postion seem exist root master var lib mysql grep end log pos tmp somefile txt server id end log pos binlog checkpoint mysql bin
139213 anyone luck creating using udfs azure data warehouse database middle migrating prem warehouse sql server azure datawarehouse ran issue udfs create function dbo fn getimpliedrate multiple float term int returns float begin declare impint float term set impint select dbo impliedrate multiple multiple term set impint select dbo impliedrate multiple multiple term set impint select dbo impliedrate multiple multiple term set impint select dbo impliedrate multiple multiple return impint end go udf works perfectly sql server create azure data warehouse gets created doesnt work query returns null verified obvious things like whether target table exists etc check looked create function documentation azure data warehouse example udf converts int decimal works flawlessly azure dw moment write simple function select fails unfortunately azures documentation really helpful wondering ran issue yes resolve tested another use case also doesnt work create function dbo fn getnumberbusinessdays startdate datetime enddate datetime returns int begin declare ndays int select ndays isnull datediffdd startdate enddate datediffwk startdate enddate case datenamedw startdate sunday else end case datenamedw enddate saturday else end select ndays ndays count dbo fedholidays dateofholiday startdate enddate return ndays end go
139290 trying get accurate count total days tool rental data sample create table tmptoolrentaldays toolid bigint startdate datetime enddate datetime rentaldays float insert tmptoolrentaldaystoolid startdate enddate rentaldays values select tmptoolrentaldays tool go day return day go back day day trying avoid counting date like twice intention get two columns toolid rental days achieve
139358 maybe community problem easy simple java programmer big problem big db data external db admin create job show temporary table data need create table without primary key java project go read table obtain error cant read table primary key dont exist insert procedure possibility create autoincremental primary key without changing structure complex procedure begin stored procedure code use mydb go set ansi nulls go set quoted identifier go alter procedure dbo spschedula scadenzario begin drop table mydb dbo tmptable select aa mydb dbo tmptable thanks advance
139382 want capitalize first letter word sentence sql column example sentence like movies need output like movies query declare varchar15 set qwerty keyboard select normal text upper uppercase text lower lowercase text upperleft a1 lowersubstring a2len capitalize first letter upper lower capitalize first letter column put random word results possibilities possibilities get results without using user defined function need output qwerty keyboard
139480 know union removes duplicated rows thought removes latter ones doesnt found theres order clause oracle sorts merged dataset first column removes duplicates select dual union select dual union select dual results whereas expect failed many times make problem simple like example keep union sequence without order real case first select full match result second partial matchlike result search roma example full match result roma partial match result aroma course full match result come first said seems order first column union result see select roma dual result comes anyway union select aroma dual result aroma roma aroma alphabetically ahead roma comes first maybe try union remove duplicates
139702 im adding following cross reference table sql server hosted db company id bigint null fk org path nvarchar null company id field refers id field another table primary key given also multiple records company id primary key would use fields however im unable create key using fields org path long sql server org path table exists theres every likelihood queries table asking either entries org path entries company id put another way looks doubtful table ever queried org path furthermore unlikely org path updated likely inserted probably rarely deleted expect total number rows low thousands also reason nvarchar value mimic third party db typical example something like translation providers customer name order name contain diacritics question would efficient add auto increment id field use conjunction company id primary key would add unnecessary overhead fact company id primary key another table effect
139746 availability group set sql server running two node windows server failover cluster setup consists two stand alone instances synchronous automatic failover many microsoft articles ive read advocate using multiple files tempdb increase performance seems recommend using files case configuration improve performance
139758 inherited database systems like currently publisher database sql server compatibility mode windows server r2 sql server 2008r2 sp2 machine distributor machine subscriber 2008r2 sp2 database sql server compatibility mode using transactional replication isolation level read committed distributor resides publisher even though right click publication even though subscription shows pull subscription think wont matter since distributor resides publisher please correct wrong storage system ibm flex shared five servers including publisher subscriber since couple days see latency hours catches morning starts going afternoon followed https www mssqltips com sqlservertip troubleshooting transactional replication latency issues sql server see exactly happening ran following query use distribution go exec sp browsereplcmds xact seqno start seq seq start end xact seqno end seq publisher database id publisher database id different database id see supposedly massive updates done tables involved replication log reader scanning transaction log able replicate anything till transaction completes interestingly cant see blocking either publisher subscriber changing isolation level read committed snapshot isolation rcsi help help change polling interval readbatchsize whats command change setting changed log reader agent default profile follows polling interval readbatchsize brought latency hours zero almost instantly see went back hours replication sync dont single clue actual root cause caused latency went away
139776 im running simple db sql server express today backup database bak file size doubles previous backup minutes done several backups today sql server management studio backup type full one bak file keeps doubling sql server mgmt studio right click db reports backup restore events expand successful backup operations report shows latest backup size recorded 55mb go actual bak file 260mb backup today recorded also 55mb size corresponding bak files multiple times larger growing backup operation could going wrong havent made changes database since started happening
139912 query declare xml item id item id item item select value id int nodes item ix result null null execution plan top branch shreds xml four rows bottom branch fetches value attribute id strikes odd number rows returned stream aggregate operator rows comes filter id attribute first second item nodes xml stream aggregate returns four rows one input row effectively turning inner join outer join something stream aggregate circumstances well something odd going xml queries see hints xml version query plan stream aggregate behave differently stream aggregate noticed
139969 database due silly code issues grown hugely sitting 24gb unnecessary logging information system generated debug information server lives cloud hosted server sitting issues file size pay storage happy pay core business paying silly data seems silly backups huge also nightly full backups ship ftp server process taking longer longer given issues shrinking bad rebuild indexes dry run brought database 6gb guy always trusted sql guru says bad mkay sql server shrinking database bad increases fragmentation reduces performance
139986 run following query database select sys sysfiles get following results run dynamic query gets percent free space get msg level state line arithmetic overflow error converting numeric data type numeric declare command nvarcharmax select command select db name db name casts size castfilepropertys name spaceused int int freespacemb cast100 cast size castfilepropertys name spaceused int size decimal52 varchar8 freespacepct sys sysfiles exec sp executesql statement command struggling find reason arithmetic overflow happening divide sys sysfiles fileproperty give number 8k pages mb convert 8k pages mb divide explained dynamic actually get values database using sp foreachdb see example declare command varchar5000 select command use select db name db name casts size castfilepropertys name spaceused int int freespacemb cast100 cast size castfilepropertys name spaceused int size decimal42 varchar8 freespacepct dbo sysfiles exec sp foreachdb command
140247 following query plan snippet seems obvious row estimate concatenation operator billion rows sum row estimates two inputs however estimate million rows produced leading sub optimal sort stream aggregate strategy spills hundreds gb data tempdb logically consistent estimate case would produced hash aggregate removed spill dramatically improved query performance bug sql server valid circumstances estimate lower inputs could reasonable workarounds might available full query plan anonymized sysadmin access server order provide outputs querytraceon similar trace flags may able get outputs admin would helpful database compatibility level therefore using new sql server cardinality estimator stats updated manually every time data loaded given volume data currently using default sampling rate possible higher sampling rate fullscan could impact
140363 select fullname login user order fullname desc login asc results fullname login mh com ad com null com null ben com null roc com want fullname login ad com mh com null com null ben com null roc com want full name abc order desc login want nulls go bottom
140369 simple one cant seem figure two parameters one parameter passed null value use parameter clause ex select case parameter1 null field2 parameter2 parameter2 null field1 parameter1 end know something simple maybe im using logic wrong help direction appreciated
140493 clustered windows r2 server sql server enterprise upgraded instance sp1 cu4 rtm getting error attempting start sql server agent sql server agent log microsoft sqlserveragent version x64 unicode retail build process id sql server agent startup service account domain username sql server accept connection error waiting sql server allow connections operation attempted verify connection start unable connect server servername instancename sqlserveragent start sqlserver error sql server network interfaces error locating server instance specified xffffffff sqlstate odbc error login timeout expired sqlstate hyt00 sqlserver error network related instance specific error occurred establishing connection sql server server found accessible check instance name correct sql server configured allow remote connections information see sql server books online sqlstate logon server servername instancename failed disableagentxps sqlserveragent terminated normally windows application log sqlserveragent could started reason unable connect server a08sql edi edi sqlserveragent start agent starts runs seconds dies error anyone run issue know resolve
140558 ive digging around adventureworks2012 database see row guid used several tables parts question include row guid column uses benefits row guid column
140568 im trying find listener ora file edit docs say oracle home directory im running windows server
140576 code sums qty certain item itemid product date code proddte select sumqty itemid proddte testtable group itemid proddte want get total qty regardless itemid proddte tried select sumqty itemid proddte sumqty grandtotal testtable group itemid proddte says also qty group clause result equal expected result absolutely need represented separate column value every row representation accepted long display overall total
140604 introduction order question useful future readers use generic data model illustrate problem face data model consists entities shall labeled order keep things simple attributes int type entity following attributes entity following attributes entity following attributes since entities share common attribute decided apply type subtype design important entities mutually exclusive means entity either problem entities yet another common attribute attribute present entity question would like use described characteristic optimize design possible honest idea start trying hence post
140632 researching concept rowguids recently came across question answer gave insight led different rabbit hole mention changing primary key value understanding always primary key immutable searching since reading answer provided answers reflect best practice circumstances would primary key value need altered record created
140756 would get names columns table specific type datetime even better thing multiple tables joined together list column name along table comes
140790 someone reviewing ddl code creating tables suggested saw saw using varchar256 fields text expect pretty small like first name whatever always use varcharmax linked use anything varcharmax read seemed dated focusing didnt seem offer real justification allocate potentially gb per row text fields performance storage etc standpoint one go deciding whether use varcharmax smaller specific type modern versions sql server
140896 first dba se post please inform mistakes thanks new dba pro one else company basic explanation better reading database backup strategies learned call restore strategies understand full differential transaction log backups want know differential backup based recent full backup differential backup everything changed since last full backup cant differential based backup choosing clear im asking specifying base backup taken restoring assuming restoring would choose correct base corresponding differential perform restore using differential made base restore base reason prevents functionality possible figure must reason dont know note understand base specified question im also interested discussion would analogy heres analogy understand differential backup excel file data cells day make copy file store somewhere else full backup day look file compare backup copy made day note cells changed new values differential backup noting every change made cell final value cell a1 started alfred changed betty charlie dave would note a1 dave day compare current file backup file note changes another differential backup base day noting final values per cell time observed values cell throughout day day compare note changes continuing cell a1 says sarah even names throughout day note a1 sarah day file gets messed look backup copy made day final states noted day apply changes noted backup copy file restored day look backup made day see day cell a1 ended sarah change backup cell a1 sarah would matter made another backup copy full file day wouldnt still possible compare read take differential backup file day copy made day understand sql server would require compare taking another differential backup full backup made day one made option
140909 use coalesce check variables different type precedence null without encountering errors declare startdate datetime null enddate datetime null statecode char2 null countycode char3 null producername varchar64 null taxid varchar9 null farm int null select case coalesce startdate enddate statecode countycode producername taxid farm null yes else end output yes adding select statecode gives error msg level state line conversion failed converting date time character string valid select case coalesce startdate enddate null coalesce statecode countycode producername taxid null farm null yes else end id love know theres another clever way accomplish terse manner dont remember separate type family
140943 ive run dbcc checkdb found allocation errors run repair allow data loss need take amount time scan errors attempt use last checkdb ran go faster sql server yes ancient cant upgrade
141092 lot trace flags well documented others found way default behavior status release aside official support channels microsoft employees etc ways find new trace flags ive read couple recent posts aaron bertrand didnt spot anything new trace flags copied data log file mssqlsystemresource new location attached like regular database poke system tables views didnt spot anything immediately considered taking list known trace flags looping numbers list see ones dbcc traceon would allow wanted ask question first assuming dbcc command enable check resource make sure trace flag valid reach dll system file holds list know question casts wide net spurred reading trace flag specific intended behavior alongside new feature described effect initial thought perhaps numbers transposed somehow like becoming hoping get list valid trace flags within range say look permutations testing dbcc traceon flags startup parameters would quite nuisance combined testing results feature behavior
141129 say following schema data create table images id int null insert images values1 want perform query like select id images id exists in4 doesnt work case return since doesnt exist table records
141175 sql server partitioned one large tables weekly defined sliding window scenario switch oldest weeks data archive db create new partition next week result avl system vehicle tracking partitioned positiondate datetime queries positiondate clause many cases vehicleid clause created two aligned indexes vehicleid int one positiondatevehicleid one vehicleid every query contains vehicleid clause neither two non clustered indexes used according query plan performance problem compared query plans partitioned non partitioned table queries like select mynonpart table positiondate select partitinedtable positiondate awesomely see first query costs second one file group two files partitioned table questions number rows partition optimal number rows partitioning partition day hold last days data live help improve performance non clustered indexes well defined remove positiondate clause queries vehicleid many misusing partitioning scenario define good indexes non partitioned table move oldest data month old archive table work well case ddl indexes alter table dbo mytable add constraint pk primary primary key clustered positiondate asc id asc pad index statistics norecompute sort tempdb ignore dup key online allow row locks allow page locks go create nonclustered index nonclusteredindex vehicleid dbo mytable vehicleid asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks go create nonclustered index ncix vehicleid positiondate dbo mytable vehicleid asc positiondate asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks go example queries sps receive datetime type parameters
141239 azure asp net mvc web application uses sql azure db working fine months someday reason azure changed name server set everything works fine work first thought may changed server name opened ssms resetting password connected change password application connection strings test everything worked yes debug tests work fine published published application throws error login failed user username check post azure sql database login failed user application works fine ssms seemed similar without getting errors changed connection string server tcp server name database windows net1433 database db user id username qtdhcrrxmi password password encrypt true trustservercertificate false connection timeout server tcp server name database windows net1433 initial catalog db persist security info false user id username password password pooling false multipleactiveresultsets false encrypt true trustservercertificate false connection timeout shown azure portal database connection strings removed attribute data source server name database windows net also checked publish procedure change connection strings still works debug ssms production
141464 im trying determine apply appropriate time apply compression im posting question get insight community read several articles wanted place addressed db administrators
141527 trying define way working test database sql server integration testing idea steps launch integration test assembly create totally empty database run create database objects script create relevant database objects table views sequences etc fill base data lookup values etc take database snapshot called db basis base line future integration tests every test class containing tests planning simply restore snapshot get back well defined less empty state database works like charm far however set integration tests need operate large test database hoping test fixtures classes individual tests restore database db basis snapshot insert rows data database create another snapshot db testdata snapshot test reset database well defined db testdata snapshot version run tests verify outcome forth trouble seem two db snapshots time restore database either keep getting error msg level state line database reverted either primary snapshot names improperly specified snapshots dropped missing files msg level state line restore database terminating abnormally really sql server database snapshots work seems awfully restricting would understand couldnt go back directly original db basis snapshot maybe two snapshots even go back recent one
141594 query select yearsummarksummaxmark table1 group parameterno yields error message column table1 year invalid select list contained either aggregate function group clause
141789 configuration table sql server database table ever one row help future developers understand id like prevent one row data added opted use trigger alter trigger onlyoneconfigrow dbo configuration instead insert begin declare haszerorows bit select haszerorows case count id else end dbo configuration existsselect id inserted haszerorows begin raiserror add one row config table end end throw error allowing first row go also effective self explaining way limiting number rows inserted table missing built sql server feature
141804 recently inherited environment around databases distributed instances huge physical servers databases distributed different instances based name instances times bigger others schema identical databases data databases mb gb management considering whether try keep many databses possible instance fewer huge instances another idea keep adding small instances existing environment even reduce number databases existing instance increase number instances administration wise probably easier fewer big instances many small instances hand something happens big instance databases affected may safer many small instances would better performance point view factors take account many databases aim keep instance know depends rough estimates example databases one instance many need information please let know forgot mention databses production databses different clients equally important development testing etc different servers
142080 im sql server blast db mail isnt sending im running places look double checked sql account permissions dbmail executable read execute entered rule firewall outbound port tried another mail account profile unsent issues entries logs db mail logs starting ending service errors anywhere find emails appear simply enter send queue never leave accounts send receive email sql server instance another machine ive got queue items sent status unsent checked normal places expected results aside long queue unsent mail select msdb sysmail event log order log id desc select dbo sysmail mailitems select dbo sysmail sentitems use msdb select sent status sysmail allitems select broker enabled sys databases name msdb execute msdb dbo sysmail help status sp tried turning miss dmv etc could shed light situation known issue sql server havent searches possible steps get mail sent
142139 possible retrieve data following single seek scan either modifying query influencing optimizers strategy code schema similar currently sql server repro script setup use tempdb go object iddbo testupload null drop table dbo testupload create table dbo testupload jobrunid bigint null thinganame nvarchar255 null thingatype nvarchar255 null thingagranularity nvarchar255 null thingbname nvarchar255 null thingbtype nvarchar255 null thingbgranularity nvarchar255 null create clustered index ix jobrunid dbo testupload jobrunid go insert dbo testupload jobrunid thinganame thingatype thingagranularity thingbname thingbtype thingbgranularity values go insert dbo testupload jobrunid thinganame thingatype thingagranularity thingbname thingbtype thingbgranularity values go query declare jobrunid bigint select jobrunid thinganame name thingatype type thingagranularity granularity dbo testupload jobrunid jobrunid union select jobrunid thingbname name thingbtype type thingbgranularity granularity dbo testupload jobrunid jobrunid tear object iddbo testupload null drop table dbo testupload think probably modeled ideally im trying get information developer schema chosen curious theres tsql trick im overlooking easier change query schema
142282 designing database exam stuck know relevant information student answers questions question options answers student chooses one one answer correct wrong students take exam try exams one need help database design tried far table students id bigint primary key identity name nvarcharmax table questions id bigint primary key identity textofthequestion nvarcharmax table answers id bigint primary key identity textoftheanswer nvarcharmax questionid bigint foreign key questions id iscorrectanswer bit table studentchoices studentid bigint primary key foreign key students id answerid bigint primary key foreign key answers id personal design learning purposes trying learn entity framework
142305 im wondering happens begin transaction db forgot commit rollback server lets say left days also users using assuming users know unclosed transaction lets assume users inserting data database consequences action
142330 two tables table id name table id lets say oracle 12c query return exception select table name select name table understand oracle sees select table name name dont get
142331 see documentation database backup tools divided four categories hot backups cold backups physical backups logical backups understand important difference cold hot backup latter done database operating receiving read write queries result consistent atomic know mysqldump hot aspect cold aspect documentation places logical backup category clear yes seems mention uses snapshot db beginning mysqldump procedure suggests definitely hot backup tool wanted double check tables use innodb engine
142552 needing find way sum positive values num return sum positive numbers individual row negative number sample ddl create table id int salesid int num decimal164 insert values desired output positive numbers salesid sum negatives get individual line returned salesid num
142714 sql server rdbms systems general limit number concurrent queries made table number users access physical data time update actually generally forgetting limits two users read table time someone explain technical perceptive data stored physical space disk two users processes query physical data time
142825 lookup tables code tables people call usually collection possible values given certain column example suppose lookup table called party meant store information political parties two columns party code idn holds system generated numeric values lacking business domain meaning works surrogate real key party code real natural key table maintains values business domain connotations let us say table retains data follows party code idn party code republican democratic party code column keeps values republican democratic real key table set unique constraint optionally added party code idn defined pk table though logically speaking party code may work primary key pk question best practices pointing lookup values transaction tables establish foreign key fk references either directly natural meaningful value surrogate values option example candidate idn party code city democratic alaska republican memphis following properties1 readable end user easy import export across systems difficult change value needs modification referring tables adding new value costly think almost like pass value draw analogy function call application programming jargon option instance candidate idn party code idn city alaska memphis properties readable end user difficult import export need de reference easy change values storing references transaction tables adding new value costly similar pass reference comparing function call app programming parlance import export also done different way populating look table seed surrogate column hope getting right something heard possibility note indicate benefit properties question quite importantly difference lookup code table fk reference going use latter approach think work related resources important lookup tables best practices code lookup tables lookup tables best practices db tables enumerations
142960 ms access frontend would like install computers access sql server stored shared network drive possible safe data corrupted otherwise users access sql server simultaneously using interface thank much time
143008 table like cookies id user id token expire dki3j4rf9u3e40 erhj5473fv34gv 8u34ijf34t43gf days think guess dont need id column currently id column pk also unique index token column make fast searching want know remove id column make token column pk normal honest ive never created table without id column always pk thats weird choose token column pk
143132 xml structure input param stored procedure contains element escaped xml extract element varchar receive valid xml character need escape converting xml without replace following text param1 xyz para2 dasdasdfdas param3 part query string converted xml send part xml structure zzz xmlns http example com aaa aaa aaa bbb param1 xyz amp para2 dasdasdfdas amp param3 bbb zzz inside stored procedure need extract isnullnullifltrimrtrim xmlinput valuedeclare default element namespace http example com zzz bbb nvarchar250 value contains normal text escaped processing need put string inside xml make cast xml escaped got error
143157 need help deal problem permissions database scenario database schemas schemaa owner dbo schemab owner ownerx schemac owner ownerx schemad owner ownerx schemad view named viewabc gets information tables views allocated schemas schemaa schemab schemac user userx select permission viewabc following command grant permission grant select schemad viewabc userx userx try execute select view way select schemad viewabc get error select permission denied object tablea database mydatabase schema schemaa understand error happens tablea different schema different owner dbo instead ownerx sqlserver applies userx permissions grant deny access userx explicit access tablea query execution returns error solve without grant select permission tablea userx
143342 im process designing new system large geospatial data set require rapid read query performance therefore want see anyone thinks possible experience advice suitable dbmss data structure alternative methods achieve required performance following situation data continuously produced processed satellite radar data global coverage based satellite resolution land coverage globe estimate full data set produce values billion discrete locations globe life span single satellite output produce values locations total data set trillion values one satellite already second orbit another two planned new years lot data single data item simple consist longitude latitude value due number items estimate single satellite produce 100tb written data never need updating grow new satellite acquisitions processed write performance important read performance crucial goal project able visualize data simple interface layer google maps point colored value based average gradient function time demo end post requirements database needs scalable likely look towards cloud solutions system needs able deal geospatial queries points near latlon points within box read performance 1s locating single point polygons contain points although points would preferable far test data set million data items million locations ive trialed postgres postgis instance worked ok without possibility sharding dont able cope data grows also trialed mongodb instance appears ok far sharding might sufficient scale data volume ive recently learnt little elasticsearch comments would helpful new quick animation want achieve full data set gif postgres trial serving 6x3 pre computed raster tiles containing points taking 17s generate clicking point graph made pulling historic values nearest location 1s apologies long post comments advice welcome
143601 tried installing sql server enterprise noticed management studio installed default also noticed separate link ssms installation guide points https msdn microsoft com en us library mt238290 aspx reason decision following noted url generally available release ssms free require sql server license install use perhaps
143861 went least question se must something bad frustration already stored procedure returns xml like pmsg messages pmsg message info blah pmsg messages need get value info declare xmlmessage xml exec procreturnsxml xmlmessage output returns rows xmlnamespacespmsg pmsg select msgs msg value info nvarcharmax xmlmessage nodespmsg messages pmsg message msgsmsg returns null xmlnamespacespmsg pmsg select xmlmessage value pmsg messages pmsg message info nvarcharmax returns null xmlnamespacespmsg pmsg select value pmsg messages pmsg message info nvarcharmax info xmlmessage nodes tx generally dont understand mean provide example exactly case please
143941 created job sets start date end date automatically dynamic value example job run eight days eighth day needs automatically deletes irrespective status way code creating scheduling
144096 need assign db owner users within instance hundred logins number databases within instance would like user get db owner within database user exists know individual users know done well aware good idea give db owner everyone installing specific application every users wants use application need db owner already tried walkarounds aplicaton rather primitive nature application code changed tolerate insane number db owners sensitive data particular instance anyway management approval
144100 ok ive got monitoring process runs following query make sure databases backing regularly process used take seconds connection query execution everything process timeing run query smss takes minute select name database name recovery model bs1 last backup bs1 last duration sys databases left join select bs database name datediffhhmaxbs backup finish date getdate last backup datediffmimaxbs backup start datemaxbs backup finish date last duration msdb dbo backupset bs bs type group bs database name bs1 name bs1 database name order name sub select still takes less second returns rows msdb dbo backupset table 500k rows sys databases table rows im lost query takes minute run problem started drive full minutes thought maybe index corrupted ive rebuilt indexes including pk msdb dbo backupset table cant find sys databases table im guessing virtual table something looked estimated execution plan stuff mostly head suggestions
144214 table columns id category flag want select rows flag least per category expected results id category flag solved using temporary table like select id temptable sometable flag select sometable join temptable sometable id temptable id id prefer solution grouping struggle came help appreciated
144591 team issue need able identify processes blocking processes kill ton scripts freely available perform actions tried various ones scrutinized code someone posted one queries thanks go let tell vendor application modify vendor also willing spend time figure processes getting blocked choice point kill long running processes suggested vendor support killing processes review query running time shows fetch api cursor00000000000a7e1f tells us nothing manual process point want automate killing long running blocking processes instead someone manually killing want test script putting production would like help creating script would intentionally create blocking processes tried test environment application unfortunately luck replicating blocking processes thanks advance assistance
145163 productive work crawled stop try figure red thing cover microsoft sql server internals think surgical electrical tool sort thoughts
145204 comparing execution plan stored procedures second one get warning sign marked red arrow mean
145665 dba im trying back remote dev database unc path im running back operation logged management studio particular windows domain account corp myuser ive checked domain account full control rights unc path nameofmachine backup attempt execute following corp myuser backup database dev disk nameofmachine backup dev bak copy init receive error open backup device nameofmachine backup dev bak operating system error 5access denied seems indicate whatever account sql server using run backup command rights unc path way rdp dev database server find account sql server using execute backup command way find management studio using dynamic management view
145982 difference updating statistics table using sp updatestats resample updating stats table using update statistics without sample optionsfullscansample percentresample exec sp updatestats vs update statistics tablename updating tables using sp updatestats default value update statistics default sampling rate similarly updating statistics table using update statistics without sample optionsfullscansample percentresample also update table statistics default sampling difference methods missing anything update know sp updatestats runs tables using update statistics update statistics specific table
146011 find spending lot time lately examining lists proposed indexes generated index tuning adviser automated process back day circa found suggestions rather awful seemed geared one specific query often merely covering index every column table whether colums already indexes time progressed feel index tuning advisers improved dramatically still built mistrust still want spend time review one trying pessimistic difficult vendor microsoft suggests add multiple overlapping covering indexes improve performance especially paying storage space also dont want spend time needlessly would rather fixing poorly written queries
146543 need increase wal keep segments master server fly require restart
146610 faced strange phenomenon today ran query find requests waits broker receive waitfor select sys dm exec requests session id wait type like broker receive waitfor query ran fine failed list request waits ie wait type nullthere quite lot running queries without waits time happening isnt supposed list records wait type like broker receive waitfor including nulls im running sql server 2008r2 sp3
146750 create following table create table dbo teststructure id int null filler1 char36 null filler2 char216 null created clustered index create clustered index idx cl id dbo teststructureid next populated rows size byte based table declaration declare int begin set insert dbo teststructure id filler1 filler2 values end based information read training kit exam querying microsoft sql server itzik ben gan book sql server internally organizes data data file pages page kb unit belongs single object example table index page smallest unit reading writing pages organized extents extent consists eight consecutive pages pages extent belong single object multiple objects pages belong multiple objects extent called mixed extent pages belong single object extent called uniform extent sql server stores first eight pages object mixed extents object exceeds eight pages sql server allocates additional uniform extents object organization small objects waste less space big objects less fragmented first mixed extent 8kb page populated bytes inserted times byte size row check size run size check proc returns following result index type desc clustered index index depth index level page count record count avg page space used percent name teststructure rows reserved kb data kb index size kb unused kb kb reserved table first kb page root iam page second one leaf data storage page 8kb occupation kb insert new row byte insert dbo teststructure id filler1 filler2 values stored page although space byte still smaller 8kb new data page created new row could fit old page sql server create new page could save space searching time buy inserting existing page note thing happening heap index
146993 need rebuild indexes two large almost table database want prevent users accessing database happens state put database prevents users accessing still allows rebuild indexes reference plan script provided http instadba com quick script defragment sql server indexes rebuild
147039 querying data linked server view origin server view include couple standardized columns created modified deleted case table source server doesnt suitable info columns therefore explicitly cast respective types updated view changing column null modified castnull datetime modified however performing update view triggering following error message msg level state line get current row value column user generated expression expr1002 ole db provider sqlncli11 linked server done explicit cast change generally across origin server without worries suspect issue might related version servers involved dont really need apply cast feels cleaner right im curious happening server version origin microsoft sql server x64 may copyright microsoft corporation enterprise edition bit windows nt build service pack hypervisor server version linked microsoft sql server r2 sp1 x64 jun copyright microsoft corporation enterprise edition bit windows nt build service pack hypervisor edit realized made mistake posting columns question must apologize leaving important detail dont know didnt notice sooner question still remains though erroneous cast happen cast datetime column cast uniqueidentifier culprit castnull uniqueidentifier guid uniqueidentifiers supported sql server r2 mentioned comments query performed view runs fine linked server
147112 im allowing end user define many rows returned query select top value entered rows returned dynamically create query without top want rows returned im using sql server
147775 sql server 2008r2 enterprise edition database support front end application never timeout issues recently company decided upgrade database sql server enterprise edition node always cluster setup new server better cpu memory old server upgrade made necessary modifications checking database consistency run dbcc updateusage update statistics index rebuilding recompiling stored procedures database switching migration went well however users start complaining timeout issues reviewing different articlesblog posts made modification like changing connection string add multisubnetfailover true seems helped lot minimize frequency timeout still issue anyone know cause issue resolve would highly appreciate suggestions recommendation resolve problem
147976 consider following two ways convert datetime varchar string date field select convertdate date needed select cast2012 date date needed return expect date excluding time date datatype question pro cons either way
148386 ive upgraded data warehouse sql im seeing really interesting graphs query store love feature weirdest example ive seen plans query making consider performance tuning etl process pros cons temporary tables could influence execution plan behavior etl process uses number stored procedures use mix standard temporary tables staging tables tables typically used dropped thousand rows millions ssms advises missing indexes smaller tables would make enough difference worth effort adding better statistics sufficient ive read brent ozar blog post statistics temp tables paul whites article temporary tables stored procedures says statistics created automatically table queried presumably used optimizer questions much point benefit creating index table worth explicitly updating statistics step stored procedure using queries given theyre used additional steps overhead worth would result significantly better different execution plans
148395 weve using mongodb several weeks overall trend weve seen mongodb using way much memory much whole size dataset indexes ive already read question question none seem address issue ive facing theyre actually explaining whats already explained documentation following results htop show dbs commands know mongodb uses memory mapped io basically os handles caching things memory mongodb theoretically let go cached memory another process requests free memory weve seen doesnt oom kicks starts killing important processes postgres redis etc seen overcome problem weve increased ram 183gb works pretty expensive mongos using 87gbs ram nearly 4x size whole dataset much memory usage really expected normal per documentation wiredtiger uses ram cache considering dataset size even enough data able take 86gbs ram even memory usage expected wont mongo let go allocated memory case another process starts requesting memory various running processes constantly killed linux oom including mongodb increased ram made system totally unstable thanks
148443 updating release ssms keeps disconnecting automatically brings connect database engine pop screenshot additionally keep getting system outofmemoryexception run queries even though machine 16gb ram currently using 4gb errors happen simple queries like select getdate suggestions could issue
148523 trying understand sql server try estimate greater greater equal clauses sql server think understand cardinality estimation hits step example select charge charge dt cardinality estimation easily calculated 32eq rows 6624range rows eq rows histogram screenshot select charge charge dt increased time step estimate calculated
148641 im trying build history table audit log ultimately build type dimension table unfortunately audit log records specific fields changes heres rough example im talking create table staff id int surname varchar5 firstname varchar4 office varchar9 date varchar10 insert staff id surname firstname office date values smith bill melbourne null null sydney brown mary melbourne jones null adelaide null null sydney null null perth first entry particular staff member record created subsequent record update shows update field updated want fill update row rest employee record currently stands ie result like smith bill melbourne smith bill sydney brown mary melbourne jones mary adelaide jones mary sydney jones mary perth know using loop cursor suspect probably performant option null always means value didnt change rather value changed null
148665 applying service pack production sql server usually planned downtime window around minutes bitten discovering required precondition like patch place add several minutes downtime window maybe taking window forcing reschedule update planning stage move service pack server test check files use ready update cancel update point feel confident update run scheduled downtime window cancel either screen update button ready update location next button check files use accidental double click could accidentally start update validating question stop validation check files use ready update validated everything end check files use going ready update add value validation
148784 table looks like groupid int null somevalue int null id like keep rows groupid together result set groups ordered randomly though somevalue supposed secondary sort criterion like groupid somevalue order groupid somevalue order groups randomly orderby newid totally random order somehashgroupid somevalue comes mind need new random order time done
148788 run following query select engines manufacturer model maxseats planes group engines getting correct engines seats results correct manufacturer model combination addition multiple rows maximum value seats number need getting one result engines seats viewed stack exchange posts elsewhere seem find good solution fix query advice
148858 curious statement updated rows postgres times ran would update way find rows bestsales update keyword set revenue random id castrandom int update id primary key id integer null default nextvalkeyword id seq regclass keyword pkey primary key btree id tried run select bestsales select keyword id castrandom int id keyword seed id source search count country language volume cpc competition modified google violation revenue bing violation vizio m190mv google shiatsu massage mat spyfu granary flour spyfu rows sometimes would return one possible postgresql
148876 function ends insert configuration dates cols values values returning id ret id return ret id would like remove ret id part instead something like return insert configuration dates weekly date configuration id price activity configuration id values wdc id ts ts wdc duration wdc price wdc activity configuration id returning id havent found achieve edit adding entire function create function make date configurationwdc id uuid date date returns integer declare dow int extractisodow date day week wdc weekly date configurations ts timestamp ret id integer begin select wdc weekly date configurations wdc id wdc id found wdc valid date starts date range get bitwdc weekdays dow valid day week ts date wdc start time insert configuration dates weekly date configuration id price activity configuration id values wdc id ts ts wdc duration wdc price wdc activity configuration id returning id ret id return ret id else return null end end language plpgsql
149459 need troubleshoot issue need help understanding sp msforeachdb works order overcome issue happens every time run sp msforeachdb get error msg level state incorrect syntax near example code follows exec sp msforeachdb select database sys objects name like aetna however matter query parameter sp msforeachdb every time get error database starts 61s1d makes think issue db name honestly know going behind scenes sp msforeachdb things note database starts number try use code like database like dont still error test changing database name many things connected create test db starts also get error database overcome
149630 table column named prefix storing aaaa application long string eg aaaabbbbccccdddd want select rows particular column prefix aaaabbbbccccdddd length prefix variable postgres tried select table prefix ilike aaaabbbbccccdddd match
149796 query used search list sub divisions network query executed without filter returns different amount rows every execution select distinct t1 zresubdiv t1 subdiv name stage wp pfunct loc t1 rownum normally filter goes order t1 subdiv name execution zresubdiv subdiv name alexandria allanwater ashcroft bala beachburg bridge caramat central butte chapais chatham chicago execution zresubdiv subdiv name albreda alexandria allanwater ashcroft bala beachburg blackfoot bridge camrose caso central butte also missing data subdivision baton rouge never appears although data remove rownum data correctly returned need leave rownum since query support clause filter subdivision name cause
149811 queries execution plans estimated perform seeks unique index seeks driven ordered scan source table seemingly end seeking values order nested loops nestedloops optimized false withorderedprefetch true anyone know task costed first plan second reason question first query suggested optimisation due apparent much lower plan cost actually looks though work im attempting explain discrepancy setup create table dbo targetkeycol int primary key othercol char32 null create table dbo stagingkeycol int primary key othercol char32 null insert dbo target select top row number order spid leftnewid32 master spt values v1 master spt values v2 insert dbo staging select top row number order spid leftnewid32 master spt values v1 query paste plan link select target keycol select keycol staging merge using staging keycol keycol matched insert keycol othercol valuess keycol othercol matched othercol othercol update set othercol othercol query paste plan link merge target using staging keycol keycol matched insert keycol othercol values keycol othercol matched othercol othercol update set othercol othercol query query tested sql server sp2 kb3171021 x64 joe obbish points comments simpler repro would select staging left outer join target keycol keycol vs select staging left outer join select target keycol keycol row staging table still plan shape nested loops plan without derived table appearing cheaper row staging table target table difference costs change plan shape full scan merge join seeming relatively attractive expensively costed seeks showing cost discrepancy implications making harder compare plans
150158 store date time information couple ways best approach storing datetime information storing date time separate columns one column using datetime explain approach better link mysql docs reference question general specific mysql date time types date time
150207 cte code many times table people get queried impression called time stored memory queries running seem running lot longer leads believe may hitting people table times ctegeneric select person people person dumb select ctegeneric union select ctegeneric union select ctegeneric
151169 following excerpt book db design beginning database design isbn danger using views filtering query view expecting read small portion large table filtering done within view filtering view applied query view completed execution views typically useful speeding development process long run completely kill database performance following excerpt postgresql documentation making liberal use views key aspect good sql database design views allow encapsulate details structure tables might change application evolves behind consistent interfaces two sources seem contradict design views vs design views however pg views implemented using rule system possibly question filtering view rewritten filter within view resulting single query execution underlying tables interpretation correct pg combines clauses view run separately one another short self contained correct compilable examples
151183 ive tried every solution internet mariadb server continue fail continue betray continue destroy tiny devops world attempts smooth situation included sorts satisfaction changing permissions configs removing log files upgrading reinstalling moving internal files around removing dbms removing everything except never resisting much long last hope guys light way critical moment relationships im using vagrant problem datadir option use default path everything ok change vagrant shared folder maria even start copied var lib mysql files new folder windows host centos guest configurations mariadb version mysql ver distrib mariadb linux x86 using readline vagrantfile mode ruby env vagrant default provider virtualbox vagrant configure config config vm box url https github com tommy muehle puppet vagrant boxes releases download centos x86 box config vm box centos7 config vm network private network ip config vm synced folder mysql vagrant mysql owner mysql group mysql config vm provider virtualbox vb vb customize modifyvm id memory vb customize modifyvm id cpus vb customize modifyvm id hwvirtex vb customize modifyvm id audio none vb customize modifyvm id nictype1 virtio vb customize modifyvm id nictype2 virtio end end etc cnf server cnf mysqld user mysql datadir vagrant mysql socket var lib mysql mysql sock symbolic links default storage engine innodb tmpdir tmp character set server utf8 init connect set names utf8 expire logs days skip external locking key buffer size 32m max allowed packet 32m table open cache table definition cache sort buffer size 16m net buffer length 16k read buffer size 8m read rnd buffer size 8m thread cache size thread concurrency query cache size 1024m query cache limit 2m join buffer size 32m max connections max connect errors connect timeout innodb file per table innodb buffer pool size 2048m innodb read io threads innodb write io threads innodb lock wait timeout innodb flush log trx commit innodb flush method dsync innodb log file size 64m innodb log buffer size 32m innodb log files group innodb thread concurrency innodb open files innodb sync spin loops skip name resolve log error var log mariadb mysqld log mariadb error log note innodb using mutexes ref count buffer pool pages note innodb innodb memory heap disabled note innodb mutexes rw locks use gcc atomic builtins note innodb gcc builtin atomic thread fence used memory barrier note innodb compressed tables use zlib note innodb using linux native aio note innodb using sse crc32 instructions note innodb initializing buffer pool size 0g note innodb completed initialization buffer pool note innodb highest supported file format barracuda note innodb rollback segments active note innodb waiting purge start note innodb percona xtradb http www percona com started log sequence number note innodb dumping buffer pools yet started note plugin feedback disabled error cant init tc log error aborting
151199 postgresql given simple table created create table tbl id serial primary key val integer run sql insert value update statement newval insert tblval values returning id update tbl set val newval tbl id newval id result update ignored testdb select tbl id val limitation part sql standard present databases something specific postgresql might fixed future queries documentation says multiple updates supported mention inserts updates
151431 im issue using new upsert feature postgres table used aggregating data another table composite key made columns nullable created smaller version issue im specifically null values create table public test upsert upsert id serial name character varying32 null status integer null test field text identifier character varying255 count integer constraint upsert id pkey primary key upsert id constraint test upsert name status test field key unique name status test field running query works needed first insert subsequent inserts simply increment count insert test upsert tunamestatustest fieldidentifier count values shaun1test valueident conflict namestatustest field update set count tu count tu name shaun tu status tu test field test value however run query row inserted time rather incrementing count initial row insert test upsert tunamestatustest fieldidentifier count values shaun1nullident conflict namestatustest field update set count tu count tu name shaun tu status tu test field null issue need simply increment count value create multiple identical rows null values attempting add partial unique index create unique index test upsert upsert id idx public test upsert using btree name collate pg catalog default status test field identifier however yields results either multiple null rows inserted error message trying insert error unique exclusion constraint matching conflict specification already attempted add extra details partial index test field null identifier null however inserting get constraint error message
151453 using sql server standard edition objective trace history operations tables insert update delete display web users able tell happened data past came know partial support audit feature sql server standard edition able log operations attached question make logs stored inside proper sql table records could accessed retrieved displayed web page currently audit destination allowed file security log application log dont seem able retrieved directly asp net api possible log sql table correct wrong many said standard edition allows server level audit database level audit however unknown reasons added audit types yup none able capture view database level operations
151522 date dimension table need add new column define iteration day week within month second mon tue wed thu fri sat sun etc possible making calculations solely date column table type date
151550 table ntext column called comments second string lets call anothercomment varchar needs placing inside given comments string word updatehere casting nvarcharmax truncates comments string use likes charindex msg level state line string binary data would truncated used datalength check thousand columns characters example want achieve albeit much longer strings comments test updatehere end test anothercomment inserted resulting string test updatehere inserted end test realize trivial normal varchar nvarchar ntext complete utter nightmare work realize deprecated data type write application question
151691 run code select result run code select result msg level state line arithmetic overflow error converting expression data type int run following code select result getting arithmetic overflow error within specific range
151813 lets imagine table definition create table public positions id serial latitude numeric1812 longitude numeric1812 updated timestamp without time zone rows table testing purposes run update like update positions set updated latitude statement update rows specific dataset run query different threads mysql innodb succeed postgresql fail lots deadlocks im comparing latest version mysql innodb vs postgres concurrent update case production cases imagine stocks updated latest price available constantly
152301 problem client running application sql server use sql server analysis services additional reporting based cube thats provided turns one query looking run written sql fairly complex cube doesnt give data looking workaround client dont access directly query database hence send query every week send back results spreadsheet proposed solution believe would able use sql server integration services work around whereby automate creation table results said query would able query using existing access analysis services correct saying believe need create ssis package certain control data flows high level structure needs built looking far see control flow task called execute sql task imagine would build
152488 permanent discussion developers company work say better get rid relationship enforcement via foreign key constraint definitions relational database order speed large queries gain better performance platform consideration mysql foreign key set even primary key constraints relevant tables missing least reasonable maybe right wrong enough arguments discuss situation preferred approach three years new company one month product works hesitation enhance database nevertheles first thing noticed one page taking minute load yes seconds one claims behind current state affairs denormalized database faster normalized one believe true relevant queries include join operations makes run slow large amounts data database contains millions rows commonly handling crud operations implemented application program code level example order delete data let say tablea necessary first check fly relationship rows tablea tableb case said relationship detected app program code allow delete pertinent rows reason app program code fails delete operation succeed matter relationship regarding involved rows tables question could help elaborate good accurate solid answer enrich debate note maybe something like asked answered find anything means google
152501 ive found execsql statements buried code theyre good reason statements couldnt written directly however obvious attack vector safe alternative execsome sql something paremetrised correctly including table names statements
152659 optimize unknown stored procedure able see value database decided optimal
153274 scenario table table primary key constraint pk table table table also index called idx pk table enforces uniqueness constraint pk table disable constraint pk table enabled back index idx pk table get rebuilt
153295 impression using like operator optimise unknown scenarios legacy new ces use estimate assuming relevant statistics available query optimiser doesnt resort selectivity guesses executing query credit database get different estimates different ces new ce receive estimate rows expecting legacy ce receive estimate cant figure estimate derived anyone able shed light new ce estimate declare lastname varchar15 ba select credit dbo member lastname like lastname forcing legacy ce estimate declare lastname varchar15 ba select credit dbo member lastname like lastname option querytraceon querytraceon querytraceon querytraceon scenario already credit database set compatibility level hence second query im using trace flags force legacy ce also provide information statistics used considered query optimiser see column statistics lastname used still cant work estimate derived couldnt find anything online itzik ben gan article states using like predicate optimize unknown scenarios legacy new ces use percent estimate information post would appear incorrect
153392 simple table records may reference parent records table create table foo id serial primary key parent id int null num int null txt text null foreign key parent id references fooid added requirement one field values num must identical parent child records thought composite foreign key trick changed last line foreign key parent id num references fooid num got error unique constraint matching given keys referenced table foo easily add constraint dont understand necessary one referenced columns id already guaranteed unique way see new constraint would redundant
153420 table store forum messages posted users website messages hierarchy strucrue implement using nested set model following simplified structure table id primary key owner id foreign key references id parent id foreign key references id nleft nright nlevel table looking something like id owner id parent id nleft nright nlevel null note first row root message tree post displayed select forumtbl owner id order nleft message id message id message id message id problem occurs try delete rows owner id single query example delete forumtbl owner id order nright query fails following error error code delete update parent row foreign key constraint fails forumtbl constraint owner id frgn foreign key owner id references forumtbl id delete action update action reason first row root node id also value owner id field owner id causing query fail due foreign key constraint question prevent foreign key constraint circularity delete row reference way without first update owner id root row null created demo scenario http sqlfiddle com fd1b1 thank
153458 hoping confirm observation get explanation happening function defined create replace function public post users id coin coins integer userid integer returns table id integer update users set coin coin coins userid users id returning users id language sql cost rows volatile returns null null input security invoker call function cte executes sql command trigger function example test select post users id coin10 select select update performed hand call function cte select result cte call function directly without cte executes sql command trigger function example test select post users id coin10 select test select result update performed select post users id coin101 since dont really care result function need perform update way getting work without selecting result cte
153519 would like implement sql server clustered columnstore indexes large wide tables need ram support determine much
153586 select statement returns several rows select cola tablea cola null get rows null cola within tablea cola null null null etc add aggregate query select cola countcola thecount tablea cola null group cola get cola thecount null happening avoid
153738 know write stored procedure output parameters dont know reason would use using simple select statement normal stored procedure still return output grid see examples anyone give real life example use sp output parameter sp without output parameter examples using output parameter select var count table1 gender gender without output parameter select count table gender gender
153747 wonder sql server use available memory quite sure memory bottleneck example one server administer starts using memory gradually increases increase trend follows restart restart reaches throughout night suppose due overnight back ups taken next day steady trend throughout day memory utilization increases next morning next day stays might causing utilized possible windows preventing prove indeed windows keeping referring overall memory usage server os max memory configuration already set well beyond servers current memory monitoring tool hand tracking memory utilization memory utilization server less dedicated single instance two database sql server services applications etc running sql server might using allocated memory question using rest im sure becoming peevish questioning thanks query determining current memory allocation monitor memory usage confirm memory usedby sqlserver gb gb total ram unable find column max server memory total ram output sys dm os process memory dmv maybe due sql server r2 may confirm gb server max server memory set mb dont know server utilize extra memory put slots trying prove server needs memory make use thus make cause push purchase left awkward position memory bought memory utilization increase stays current state gb seeing gb ram utilized increasing servers memory gb gb waste money want make sure fact server benefit new extra rams indifferent
154032 first create two tables create table xyz id int create table abc id int please observe following sql code delete abc begin tran exec insert xyz values declare int select id xyz insert abc values commit select abc running outputs following error msg level state line subquery returned value permitted subquery follows subquery used expression result expected let us change error syntax error replacing xyz xyz error msg level state line incorrect syntax near xyz time result going
154061 created fresh db dump production server data column inserts flags bunch insert statements insert data performing restore staging server pg dump localhost adminuser data column inserts maindb maindb sql delete data staging server database first restoring data production dump want delete data dont drop create database stuff want remove data insert new data dont option drop create database several reasons remove data insert whatever takes find willing go need help obviously start also need automate process automate dumping data production db deleting data staging db restoring data staging db need help deleting data staging db part running postgresql
154227 large database roughly gb im executing query select table name want show 100th 200th rows want understand happens internally database fetch records disk memory sends back 100th 400th rows querying client exist mechanism records 100th 200th fetched database using indexing mechanism like trees etc found related pagination concept could exactly find happens internally database level
154251 watching brent ozar videos like one instance suggests prefixing tables tbl tbl internet found blogs saying adds nothing documentation also takes longer read questions considerations really problem prefixing tables tbl since first dba job senior dba told organization something need get rid made tests copying really big table giving tbl prefix keeping one without notice performance issue
154262 oracle db working production year listener working oracle base admin lsnrctl status lsnrctl linux version connecting address protocol tcphost port status listener alias listener version tnslsnr linux version production start date nov uptime days hr min sec trace level security local os authentication snmp listener log file app oracle diag tnslsnr base listener alert log xml listening endpoints summary description address protocol tcphost baseport services summary service base instances instance base status ready handlers service service basexdb instances instance base status ready handlers service command completed successfully listener ora ls app oracle product db se dbhome network admin samples shrept lst tnsnames ora content tnsnames ora cat tnsnames ora base description address list address protocol tcphost 19port load balance yes connect data service name base orcl description address protocol tcphost 20port connect data server dedicated service name orcl possible far know listener work listener ora file another oracle database installed execute lsnrctl status output see line containing listener parameter file app oracle product dbhome network admin listener ora seeing also executed locate listener ora nothing
154471 going set alwayson availability group nodes read routing need configure quorum
154574 designing table items potentially contain tens millions records items available use approved administrator use mean items referenced table approved items may unapproved given time records may become approved vice versa consider two design options bit flag separate table unapproved items item approved moved regular table renewal items id issue think second option much better bit flag takes byte per row issue million approved million unapproved records table scan time increases operations approved records question consider first bit flag option instead benefits described situation
154766 load data data warehouse presently script use drop foreign key constraints indexes prior loading data convenience speed big window load dont need worry users accessing data load dont want impact unrelated data tables database done research elsewhere come script wonder things might overlooking could either make performance sub optimal might missing something important dont know calculated columns something maybe im things wrong order etc advice appreciated make robust performant disable constraints indexes edit removed loop commenters helped realise redundant declare schema varchar128 dbo declare sql nvarcharmax indices select list indexes schema generate statements disable select sql sql alter index quotenameidx name quotename schema quotenameobj name disable char13 sys indexes idx join sys objects obj idx object id obj object id obj type idx type non clustered index columnstore table obj type indexes indexed views obj schema id select schema id sys schemas name schema order obj name idx name execute sp executesql sql foreign key constraints build list foreign keys constraints schema generate statements disable constraint checking select sql sql alter table quotename schema quotenameobj name nocheck constraint quotenamefk name char13 sys foreign keys fk join sys objects obj fk parent object id obj object id obj schema id select schema id sys schemas name schema execute sp executesql sql enable constraints rebuild indexes update statistics declare schema nvarchar128 dbo declare sql nvarcharmax indices build list tables schema generate statements enable indices select sql sql alter index quotenameidx name quotename schema quotenameobj name rebuild iifidx type maxdop fillfactor char13 sys indexes idx join sys objects obj obj object id idx object id obj type idx type non clustered index table obj type indexes indexed views obj schema id select schema id sys schemas name schema idx disabled dont rebuild indexes already online idx hypothetical dont rebuild hypothetical indexes order iifidx type obj name idx name execute sp executesql sql foreign key constraints build list foreign keys constraints schema generate statements enable checking select sql sql alter table quotename schema quotenameobj name check check constraint quotenamefk name char13 sys foreign keys fk join sys objects obj obj object id fk parent object id obj schema id select schema id sys schemas name schema order obj name fk name execute sp executesql sql statistics build list tables schema generate statements update statistics select sql sql update statistics quotename schema quotenameobj name columns char13 sys objects obj obj type user defined obj schema id select schema id sys schemas name schema order obj name execute sp executesql sql
154841 database role membership grants permission execute existing stored procedures sql server tried adding user still unable execute stored procedure dont want grant execute stored procedure separately want add user role able execute
155219 reindex rebuild db running take offline also digging around came across article recommends rebuilding fragmentation reindexing anyone verify db quite large slowing
155332 times ago created postgresql user named user1 postgresql want drop user first revoke permissions tables sequences functions default privileges ownership alter default privileges schema public revoke sequences user1 alter default privileges schema public revoke tables user1 alter default privileges schema public revoke functions user1 revoke sequences schema public user1 revoke tables schema public user1 revoke functions schema public user1 reassign owned user1 postgres however seems one object remains linked user databases postgres drop role user1 error role user1 dropped objects depend detail object database db1 object database db2 even seems function postgres db1 connected database db1 user postgres db1 drop role user1 error role user1 dropped objects depend detail privileges function textboolean object database db2 determine object owned related user1 pg dump db1 grep user1 get result could global object identify missing object executed commands database db1 db2 want drop objects owned user1 want reassign remove grants user
155580 update script im locking several tables begin transaction select top null tablea holdlock tablockx select top null tableb holdlock tablockx want suppress results order focus real script results elegant way xlock table without getting result set
155650 consider answer reassures asker operator commenter pipes says true functionally however sql optimizer uses different simply evaluated true false whereas means engine look see value greater less meaning performance overhead something consider writing queries may expensive confident false order address potential skeptics wonder anyone provide authoritative canonical source prove operators functionally identical aspects
155684 im trying insert result set select sys database scoped configurations temp table want check settings databases server wrote code drop table exists create table hdbname sysname configuration id int name sysname value sql variant value secondary sql variant exec sys sp msforeachdb use insert hdbname configuration id name valuevalue secondary select dbname sys database scoped configurations select one row per database four rows expect running plain select database know better ways code using sp msforeachdb tried several still get one row per database ive tried sql server rtm sp1 bug sql server something wrong
155952 enable disable sql server agent service sql script powershell cmd
155998 id value select maxvalue tablename generally know get need next value get value using sql
156028 issue follows im trying create global temp table using data db1 use temp table query executed db2 results imported new table db2 since query bit complicated simple merge join wont need transform data add extra column dense rank based data databases according one colleagues possible ssis simplified query would like execute connection db2 select db2 adb2 bdb2 cdb1 db1 dense rank partition db2 order db1 asc finalrank db2 table db2 left join globaltemp db1 db2 db1 extensive googling different tries db2 source connection wont find temp table globaltemp created db1 operation even possible tldr possible create global temp table ssis session pull data matter database
156068 consider table records visits create table visits person varchar10 ts timestamp somevalue varchar10 consider example data timestamp simplified counter ts person somevalue bob null bob null jim null bob bob null bob jim jim jim null im trying carry forward last non null somevalue person future visits value changes ie becomes next non null value expected result set looks like ts person somevalue carry forward bob null null bob null null jim null null bob bob null bob jim jim jim null attempt looks like select first valuesomevalue partition person order somevalue null ts rows unbounded preceding current row carry forward visits order ts note somevalue null evaluates purposes sorting get first non null value partition doesnt give result im
156164 stored procedure contains business logic inside around variables dont ask engine works try set variable concatenated value variables result creation get error msg level state procedure xxx line yyy internal error server stack limit reached please look potentially deep nesting query try simplify figured error due number variables need use set operation perform assignment splitting two question restrictions area checked find checked error described kb case dont use case expressions inside code use temporary variable prepare list values replaced using clr function updated sql server sp3 cu6 latest date still experience error
156359 sql server find tables either foreign key constraints references tables foreign keys
156545 7daysearlierpartitionintegerid currentpartitionintegerid begin set 7daysearlierpartitionid cast 7daysearlierpartitionintegerid char set sqlcommand select quotename requestusage partition 7daysearlierpartitionid userlogin liker2 rohit kharade exec sqlcommand set 7daysearlierpartitionintegerid 7daysearlierpartitionintegerid end get error unclosed quotation mark character string r2 rohit kh execute exec command userlogin r2 rohit kharade
156553 two tables one titled planning constraints contains sot allowed time intervals one titled planning contains sot contribution time interval schema two tables edited readiability table public planning constraints column type modifiers start time timestamp time zone end time timestamp time zone sot allowed interval table public planning column type modifiers start time timestamp time zone end time timestamp time zone sot contribution interval query separately produce totals want query planning constraints table select date truncday start time interval hours date planning day sumsot allowed minutes allowed planning constraints start time start time comment like group planning day order planning day produces planning day minutes allowed rows query planning table select date truncday start time interval hours date planning day sumsot contribution minutes planned planning start time start time group planning day order planning day produces planning day minutes planned rows would like present results queries adjacent columns along difference attempt select date truncday start time interval hours date planning day sumc sot allowed minutes allowed sump sot contribution minutes planned sumc sot allowed sump sot contribution diff planning constraints planning start time start time comment like start time start time group planning day order planning day produces planning day minutes allowed minutes planned diff rows minutes allowed minutes planned columns present correct values feel like missing something small however unable find solution
156827 difference smallint type bool type storing boolean values question arose comments question geographic information systems stack exchange
157045 whether read cap acid see consistency referred ensure db integrity constraints understand two terms used refer thing difference integrity consistency read anyhow atomic consistent isolated durable properties transactions true atomicity isolation enough roll consistency also roll atomicity roll isolation roll persistence durability roll must pay features blood sweat parentheses dont say properties given us transaction system suggests consistency user application provide top database integrity constraints property provided database aid properties give title system provided aid properties
157334 following table ms sql create table dbo dbip locations ip bigint null ip bigint null country code nvarchar null region name nvarchar null city name nvarchar null latitude float null longitude float null ip ip columns calculated ipv4 addresses return convertbigint parsename ip convertbigint parsename ip convertbigint convertbigint parsename ip convertbigint convertbigint parsename ip convertbigint using ipv4 address converted bigint using calculation search row ip address falls ip ip columns ill always find one row enforced schema reality data query select top1 latitude longitude dbo dbip locations ip int ip ip currently two non clustered non unique indexes ip ip columns query executing pretty quickly performing huge number queries per second would like know could getting better performance usage different indexes perhaps clustered multi column index using unique indexes better indexes could using
157501 postgres database specifically amazonrds instance fwiw easy enough arrange things get last updated created time record information would datetime want achieve imagine integer sequencenumber atomic global database simply every table would sequencenumber field time record ie table updated created gets next sequencenumber know programmer friends know nothing databases wave idiot solution would entire codebase every time create modify record sure remember update sequencenumber course one global system gives next atomic sequencenumber whats sound solution indeed completely available already way dont know
157515 set logical primary key constraint served physical nonclustered index checks certain values constrained indexed column another column relevant table column established foreign key constraint referenced tables im trying basically see remove certain rows parent table without removing rows child table still enforce relationship ids createddatetime removaldate example kind constraint alter table mytable nocheck add constraint pk mytable check id would set column primary key fixed nonclustered index something like following definition alter table mytable nocheck add constraint pk mytable check createdon index column named id
157696 im testing sync vs async auto statistics updates id like quickly invalidate statistic objects headers density vectors histograms ensure next time statistic used updated im trying simulate auto update statistics auto creation ideally dont want change row count ive dismissed insert delete operations ideally dont want change data values either considered using update statements im thinking could take long larger tables looked update statistics rowcount pagecount dont think im hoping maybe trace flag undocumented command would invalidate statistics quick efficient way want achieve havent considered im testing sql server
157790 heres code right begin try insert table f1f2f3 values end try begin catch throw end catch works great unless run machine sql id like catch block check sql version run throw equal higher raiserror keep running syntax errors im wondering even possible even something simple like working begin catch select serverpropertyproductversion throw end catch advice appreciated
157893 going create history table populated trigger insert update delete columns going updated decided log changed values values changed null value going used history table example history table columns sparse going save lot space versus ordinary implementation logging data due test bussness cases sql server sp1 standard edition supports change data capture wondering pros cons differences using trigger based logging check artciles see change data capture give
157912 forgive developer moved world sql thought could improve sql adding variables function like expected someone tell work dont want work around want know reasons doesnt work like imagine sure good reason currently doesnt jump declare databasename varchar150 set databasename myamazingdatabasename create database databasename go use databasename go
158092 often encounter exists insert situation dan guzmans blog excellent investigation make process threadsafe basic table simply catalogs string integer sequence stored procedure need either get integer key value exists insert get resulting value uniqueness constraint dbo namelookup itemname column data integrity isnt risk dont want encounter exceptions identity cant get scope identity value could null certain cases situation deal insert safety table im trying decide better practice use merge like set nocount xact abort declare vvalueid int declare inserted table id int null merge dbo namelookup holdlock using select vname val vname null len vname new item itemname new item val matched update set vvalueid id matched target insert itemname values vname output inserted id id inserted select vvalueid id inserted could witout using merge conditional insert followed select think second approach clearer reader im convinced better practice set nocount xact abort insert dbo namelookup itemname select vname exists select dbo namelookup vname null len vname itemname vname declare vvalueid int select vvalueid id dbo namelookup itemname vname perhaps another better way havent considered search reference questions one https stackoverflow com questions sql server insert exists best practice appropriate could find doesnt seem applicable use case questions exists approach dont think acceptable
158201 experiencing think impossibly high cardinality estimate following query select dm primary id select coalesced1 join id d2 join id d3 join id primary id driving table dt left outer join detail d1 dt id d1 id left outer join detail link lnk d1 link id lnk link id left outer join detail d2 dt id d2 id left outer join detail d3 dt id d3 id dm inner join last table lst dm primary id lst join id estimated plan working statistics copy tables include actual plan however dont think relevant problem sql server estimates rows returned dm derived table estimates rows returned join last table performed join id primary key last time would expect join cardinality estimate rows instead row estimate appears number rows would get cross joining outer inner tables math works rounding rounded primarily looking root cause behavior interested simple workarounds well please suggest changing data model using temp tables query simplification logic within view know coalesce columns joining isnt good practice part goal question figure need recommend data model redesigned testing microsoft sql server legacy cardinality estimator enabled tf others give full list trace flags ends relevant relevant table definition create table last table join id numeric18 null constraint pk last table primary key clustered join id asc also scripted table creation scripts along statistics anyone wants reproduce issue one servers add observations using tf fixes estimate option tf fix estimate removing one tables fixes estimate bizarrely changing join order detail link also fixes estimate changing join order mean rewriting query forcing join order hint estimated query plan changing order joins
158205 problem query put together mysql workbench thought would relatively simple running larger data set rows find taking seconds uses 1gb ram downloading data mysql server rate mb entire time isnt 100kb worth data entire table clearly im creating kind god awful loop somehow im seeing im effectively query taking specified columns row escaping single double quotes contacting together json format exactly needed 3rd party api part query done select last row return seen inserts data cache table quick access api query set rownum set json set rowtotal select count fromselect job1111 civiltrackerdetails group bidid tb select rownum rownum id json concat json concat rownum ctd bidid replacereplacectd description replacereplacectd foundationdescription replacereplacectd engdrawingnumber replacereplacectd detaildrawingnumber ctd takeoffquantity rownum rowtotal jsondata job1111 civiltrackerdetails ctd question see looping badly know better way accomplish task preferably within given methodology arranging data within mysql vs mysql explain shows nothing much derived ctd full table scan expected im using version often wondered json compatibility supposed available may help scenario looked available yet though would interested input well ultimately solution issue implemented stored procedure
158291 heres run im select query every column order clauses single non clustered index ix machineryid daterecorded either part key include columns im selecting columns result bookmark lookup im taking top surely server tell lookup needs done end importantly force query use index ix machineryid daterecorded runs less second let server decide index use picks ix machineryid takes minute really suggests made index right server making bad decision create table dbo machineryreading id int identity null location sys geometry null latitude float null longitude float null altitude float null odometer int null speed float null batterylevel int null pinflags bigint null daterecorded datetime null datereceived datetime null satellites int null hdop float null machineryid int null trackerid int null reporttype nvarchar null fixstatus int default null alarmstatus int default null operationalseconds int default null constraint pk dbo machineryreading primary key clustered id asc constraint fk dbo machineryreading dbo machinery machineryid foreign key machineryid references dbo machinery id delete cascade constraint fk dbo machineryreading dbo tracker trackerid foreign key trackerid references dbo tracker id delete cascade go create nonclustered index ix machineryid dbo machineryreading machineryid asc go create nonclustered index ix trackerid dbo machineryreading trackerid asc go create nonclustered index ix machineryid daterecorded dbo machineryreading machineryid asc daterecorded asc include operationalseconds fixstatus table partitioned month ranges though still dont really understand whats going alter partition scheme partitionschememonthrange next used primary alter partition function partitionfunctionmonthrange split rangen2016 01t00 alter partition scheme partitionschememonthrange next used primary alter partition function partitionfunctionmonthrange split rangen2016 01t00 create unique clustered index pk dbo machineryreadingps machineryreadingdaterecorded id partitionschememonthrangedaterecorded query would normally run select top id location latitude longitude altitude odometer reporttype fixstatus alarmstatus speed batterylevel pinflags daterecorded datereceived satellites hdop operationalseconds machineryid trackerid dbo machineryreading withindexix machineryid daterecorded makes difference machineryid linq daterecorded linq daterecorded linq operationalseconds order daterecorded asc query plan https www brentozar com pastetheplan id r1c rpxnx query plan forced index https www brentozar com pastetheplan id sywwtagve plans included actual execution plans staging database 100th size live im hesitant fiddling live database started company month ago feeling partitioning query typically spans every single partition want get first last operationalseconds ever recorded one machine however queries writing hand running good times faster entityframework generated im going make stored procedure
158602 following query get values corresponding latest date select maxrowaddeddate dbo mytable group fine need get id row query add id though get everything id needs group solve
158617 executing request update table t1 set t1 column t1 column2 getting error column t1 relation table exist request runs fine mysql get error postgresql
158693 using great example https dba stackexchange com bluefeet create pivot transform xml data declaring param declare cols nvarcharmax query nvarcharmax next cte lot code endresult cte put temp db example select staydate date dd mm yyyy guid tempdates baseselection generating cols example select cols stuffselect distinct quotenameconvertchar10 staydate tempdates xml path type value nvarcharmax result set expected set query select guid cols select staydate guid tempdates pivot count staydate staydate cols exec sp executesql query try transform xml attributes partially converted set query select guid cols select staydate guid tempdates pivot count staydate staydate cols xml auto using xml path get error xml path rootroot msg level state line column name contains invalid xml identifier required xml 20x0032 first character fault exec sp executesql query resultset guid 3c3359e3 cfe5 e511 80ca 005056a90901 x0032 x0032 x0032 missed something portion date converted unicode fix
158957 heard robert martin today seems like hes notable figure software world dont mean title appear click bait putting words mouth simply interpreted heard limited experience understanding watching video today software architecture talk robert martin latter half video topic databases main focus understanding said seemed like saying ssds reduce usefulness databases considerably explain came interpretation discussed hdds spinning disks retrieving data slow however days use ssds noted starts ram coming continues mentioning ram disks says cant call ram disk resorts saying ram ram dont need indexes every byte takes time get paragraph paraphrased suggesting ram computer memory replacement dbs thats interpreted statement doesnt make sense thats like saying records memory processed lifetime application unless pull disk file demand resorted thinking ram means ssd case hes saying ssds reduce usefulness databases even says oracle id scared foundation exist evaporating little understanding ssds unlike hdds seek time id think ssds near o1 almost random suggestion interesting ive never thought like first time introduced databases years ago professor describing benefits regular filesystem concluded primary role database essentially indexed filesystem well optimizations caching concurrent access etc thus indexes arent needed ssd kind make databases less useful regardless though prefacing im newb find hard believe become less useful everyone still uses dbs primary point application instead pure filesystem felt oversimplifying role databases note watch till end make sure didnt say something different reference whole database topic comes starts even databases answer say ssds speed dbs considerably question asks optimization changed tl dr question advent widespread ssd use server market whether upcoming happened already reduce usefulness databases seemed like presenter trying convey ssds one store data disk worry slow would retrieve older hdds ssds seek times near o1 think event true would hypothetically lose one advantages indexing advantage indexes faster seek times gone
158988 reviewing commit fest scheduled postgresql saw pg likely going get identity columns sometime soon found mention information schema columns nothing much identity yes applies feature available postgresql identity generation character data applies feature available postgresql identity start character data applies feature available postgresql identity increment character data applies feature available postgresql identity maximum character data applies feature available postgresql identity minimum character data applies feature available postgresql identity cycle yes applies feature available postgresql wikipedia page doesnt say much either identity column differs primary key values managed server usually modified many cases identity column used primary key however always case dont see anything else identity columns work provide new functionality standard method create sequences breakdown new feature works
159069 inherited database varchar column really date theres checking form need fix dates constantly get entered instead forth im pretty sure historically lot bad dates im little skeevy changing data type date im curious would good strategy changing background im front end developer dba get around sql dont know dont know im always afraid ill make mistake corrupts database
159115 table data follows amount need query find maxs according sumamount sumamount need result get desired output using cursor would easier could use query tried query follows select maxs table sumamount doesnt work would appreciate kind help thank
159227 two fields table int int want add two computed fields cf1 cf2 uses two fields cf1 case cf1 else case cf1 else cf1 end end cf2 case cf2 else case cf2 else cf2 end end works fine two fields null cf1 cf2 avoid mean either one fields null cf1 cf2 also null words value cf1 cf2 value null fields cf1 cf2 null null null null null null null null null null
159229 table identity column also primary key currently million rows highest value identity column sitting table lot deletes inserts performed hence high value want change data type int bigint prepare addition rows note references pk column best way minimal downtime two options drop pk alter column copy drop rename method described
159413 whenever need check existence row table tend write always condition like select table exists select normally write another table another table table people write like select table exists select nice seen people use another table another table table condition exists instead exists occasions might write left join extra condition sometimes called antijoin select table left join another table another table table another table primary key null try avoid think meaning less clear specially primary key obvious primary key join condition multi column easily forget one columns however sometimes maintain code written somebody else difference style use select instead select corner case behave way although wrote afaik standard sql difference different databases older versions advantage explicity writing antijoin contemporary planners optimizers treat differently exists clause
159462 administering sweepstakes client guid tied contestant number entries contestant acquired want able draw winners based chance winning corresponding number entries guid entries results would guid basically plan put results spreadsheet use random number generator pick row number total number entries course way easily select winner programmatically im ears eyes case may thanks advance
159710 reviewing old code written pre postgresql saw something really nifty remember custom function back day forgot pre array agg looked like review modern aggregation written like select array aggx order desc foobar however upon time written like select arrayselect foobar order desc tried test data create temp table foobar select generate series11e7 tx results surprising oldschoolcool way massively faster speedup moreover simplifying without order showed slowness explain analyze select arrayselect foobar query plan result cost rows width actual time rows loops initplan returns seq scan foobar cost rows width actual time rows loops planning time ms execution time ms rows test explain analyze select array aggx foobar query plan aggregate cost rows width actual time rows loops seq scan foobar cost rows width actual time rows loops planning time ms execution time ms rows whats going array agg internal function much slower planners sql voodoo using postgresql x86 pc linux gnu compiled gcc ubuntu 5ubuntu12 bit
160216 table looks like id code category mq weight weave show minprice dt450r carbon plain dt450r carbon plain dt450r carbon plain pp120q carbon twill pp120q carbon twill pp120q carbon twill zx300r carbon plain zx300r carbon plain zx300r carbon plain ive created sqlfiddle want min price table code tried using following query select id code category mq weight weave price show minprice total product group code group getting wrong result returning id instead id incorrect output id code category mq weight weave show minprice dt450r carbon plain pp120q carbon twill zx300r carbon plain expected output id code category mq weight weave show minprice dt450r carbon plain zx300r carbon plain pp120q carbon twill
160281 following query select id email first name firstname last name lastname active isactive password access case access select case count true else false end user rating entity ure ure user id id ure rating entity id id else true end isresponsible users id id access field isresponsible directly set true subquery executed used explain analyze cases access get output
160290 ive read potentially damaging stop sql server creates cold cache sucks memory would someone want stop sql server provide links articles read would really appreciate question posed teacher unless trick question absolutely stumped exact question conduct research using internet learn someone would want stop sql server explain answer context us exploring use sql server r2 im sure asking obvious answer something im missing
160343 logging purposes table design want store ip information users logged user logs ipv4 ipv6 ip addresses stored want set constraint null possible standard sql constraints using pl pgsql postgresql business tier
160354 given two numbers want generate series form repeat times instance want sequence following numbers know achieve result postgresql either two methods using following query uses generate series function tricks guarantee order right one parameters values select xi select xi parameters generate series1 parameters xi union select parameters parameters xi parameters generate series1 parameters xi s0 cross join generate series select parameters xj order use function purpose adjoint nested loops create function generate series elements integer repetitions integer returns setof integer body declare integer integer begin repetitions loop elements loop return next end loop reverse elements loop return next end loop end loop end body language plpgsql immutable strict could possibly equivalent either standard sql transact sql sql server
160530 table create table table01 column01 nvarchar100 want create unique index column01 condition lencolumn01 tried create unique index uix table01column01 lencolumn01 got incorrect clause filtered index uix table table01 alter table table01 add column01 length lencolumn01 create unique index uix table01column01 column01 length produces filtered index uix created table table01 column column01 length filter expression computed column rewrite filter expression include column
160794 accfb file access database trying import database sql server developer edition instance found posts online discussing using import export data tools sql server also migration assistant access neither worked anyone know easily move database access sql server specifically accdb file type suggestions greatly appreciated
160872 possible sql server determine whether mixed mode authentication enabled without logging sql server
160924 given hierarchical table like create table dbo btree id int primary key parent id int references dbo btree id name nvarchar20 would like obtain whole tree structure instance using data insert btree values null root insert btree values group insert btree values group insert btree values group insert btree values group insert btree values group insert btree values group insert btree values items insert btree values items insert btree values items insert btree values items insert btree values items insert btree values items insert btree values items would like obtain id parent id description null root group group items items group items items group group items items group items im fetching records using recursive query like tree select c1 id c1 parent id c1 name level dbo btree c1 c1 parent id null union select c2 id c2 parent id c2 name level tree level dbo btree c2 inner join tree tree id c2 parent id select tree level tree id parent id replicate tree level tree name description tree option maxrecursion current result id parent id description null root group group group group items items items group group items items items items cant figure order levels way set rank sub level ive set rextester
161220 sql server management studio offers quite standard reports dont see could change reports dont even see option extracting obtaining sql code behind way achieve specifically interested security reports although itd nice get code thank advance
161586 currently execute two queries get count result pagination filter easily combine single network call anyway single query following dry principle count select count table result pagination select select row number order tbl idn row tbl tbl row row single query lesser maintenance overhead queries used production written like short stories really challenging modify
161752 sql agent job production server keeps failing messages supposed capturing sql server activity using sp whoisactive stored proc regularly scheduled intervals executed user warning null value eliminated aggregate set operation sqlstate message warning null value eliminated aggregate set operation sqlstate message warning null value eliminated aggregate set operation sqlstate message violation primary key constraint pk whoisactive insert duplicate key object monitoring whoisactive duplicate key value jan 25am sqlstate error statement terminated sqlstate error step failed idea may causing steps follow fix error
161824 select value persons join persons2 p2 leftp lastname1 leftp2 lastname1 sql server way make sargable run faster cant create columns persons table create columns persons2
161849 craig freedmans blog nested loops join explains nested loops join support right outer join problem scan inner table multiple times row outer join may encounter inner rows multiple times multiple scans point conclude particular inner row join someone please explain really simple educational way mean loop starts outer table r1 scans inner r2 understand r1 value doesnt join r2 replaced null result set becomes null r2 seems impossible return r2 value r1 join reason know r2 value return thats way explained sql server fact optimize often replaces right join left join question explain technically impossible nested loops join use support right join logic
162042 would like get clarity usage best practices sp send dbmail find answers online developers love use sp send dbmail send application related emails within application say instance user forgets password send password reset email user requests executing sp send dbmail one many types emails send using stored procedure good practice feels like dirty solution many apis handle email sending application dba dont like enabling options production servers dont choice maybe enough motivation proof bad practice potentially dangerous various reasons sway change
162227 moving application oracle sql server pseudo oracle pl sql select ltrimmycolumn mytable im using oracles ltrim second argument specifying characters trim left side string unfortunately sql version ltrim doesnt allow specify characters trim currently im rather clueless migrate ltrim im even thinking processing results hosting application read mycolumn looks rather inelegant question meaningful way getting ltrim like functionality sql pass characters trim away edit need replace beginning string test would result test edit strongly hope isnt xy problem maybe rewriting whole query would remove need ltrim altogether although would rather focus porting possible later question usefulness ltrim
162232 example table part start date end date cost abcd1 bde2 abcd1 output want see part start date end date cost period abcd1 abcd1 abcd1 bde2 bde2 abcd1 want add certain number rows depending range dates also row add column period basically month year
162452 question sql server handle query needs pull volume data buffer cache space available query would contain multiple joins result set exist format already disk would need compile results even compilation still requires space available buffer cache give example suppose sql server instance 6gb total buffer cache space available run query multiple joins reads 7gb data sql server able respond request temporarily store data tempdb fail something reads data disk compiles segments time addition happens trying return 7gb total data change sql server handles already aware several ways address curious sql server handles request internally runs stated also sure information exists somewhere unsuccessful finding
162514 html code stored data base want read xml codes http rextester com rmeho89992 example html code div section h4 span span h4 ul li span ab span ad span ac span li li span ag span span al span li ul h4 span span h4 ul li span bb span bd span bc span li li span bg span span bl span li ul section div example output need category selection value ab ad ag al bb bd bg bl need get value inside h4 tag category first span tag selection rest values concatenated string ive tried following query select isnullt valueh4 span span text nvarcharmax isnullt valueh4 span text nvarcharmax isnullt valueh4 span span text nvarcharmax category isnullc valuespan text nvarcharmax isnullc valuespan span text nvarcharmax isnullc valuespan text nvarcharmax selection isnullc valuespan text nvarcharmax isnullc valuespan span text nvarcharmax isnullc valuespan text nvarcharmax value htmlxml nodesdiv section tv cross apply nodes ul li cg select value nvarcharmax isnullt valueh4 span span text nvarcharmax isnullt valueh4 span text nvarcharmax isnullt valueh4 span span text nvarcharmaxas category isnullc valuespan text nvarcharmax isnullc valuespan span text nvarcharmax isnullc valuespan text nvarcharmaxas selection isnullc valuespan text nvarcharmax isnullc valuespan span text nvarcharmax isnullc valuespan text nvarcharmaxas value htmlxml nodesdiv section h4 span tv cross apply htmlxml nodesdiv section ul li cg gets first category doesnt get values togheter category selection value ab ac ab ac ag al ag al bb bc bb bc bg bl bg bl categories values might might inside span tags get categories corresponding value get category h4 number mean h4 first mean h4 second ul number selection value ab ad ag al bb bd bg bl relation column ul number h4 number cannt
162906 simple test table like create table mytable int within transaction try add column insert newly created column begin transaction print adding column supplementaldividends mytable table alter table mytable add supplementaldividends decimal186 print column added successfully print ready insert mytable insert mytable supplementaldividends values print changes complete committing commit transaction problem error message run code invalid column name supplementaldividends causing error add column different batch outside transaction itll work problem want add column within transaction error
163154 within one web application working database operations abstracted using generic repositories defined entity framework orm however order simple design generic repositories involved tables must define unique integer int32 int sql always pk table also identity foreign keys heavily used reference integer columns required consistency generating navigational properties orm application layer typically following operations initial data load table select table update update table set col1 val1 id idval delete delete table id idval insert insert table cols values less frequent operations bulk insert bulk insert table followed data load retrieve generated identifiers bulk delete normal delete operation bulky orms perspective delete table otherthanidcol somevalue bulk update normal update operation bulky orms perspective update table set somecol someval otherthanidcol othervalue small tables cached application level almost selects reach database typical pattern initial load lots inserts updates deletes based current application usage small chance ever reaching 100m records tables question dbas perspective significant problems run table design limitation edit reading answers thanks great feedback referenced articles feel like add details current application specifics mention current web application want understand model reused applications well however particular case application extracts lots metadata dwh source data quite messy denormalized weird way inconsistencies natural identifier many cases etc app generating clear separated entities also many generated identifiers identity displayed user use business keys besides massive code refactoring excludes usage guids way uniquely identify row aaron bertrand good advice tables also define unique constraint ensure business duplicates allowed front end app driven design vs database driven design design choice caused factors entity framework limitations multiple columns pks allowed values updated custom limitations single integer key greatly simplifies data structures non sql code lists values integer key displayed values important guarantees table marked caching able put unique int key value map complex select queries almost never happen small 30k records tables data cached application level makes life little harder writing application code harder write linq database hit much nicer list views generate select queries load everything cached queries look like select allcolumns bigtable filter1 val1 val2 filter2 val11 val12 required values fetched cache lookups o1 complex queries generated edit views generate select statements like select allcolumns bigtable pkid value1 filters values ints
163448 table status statusid status opened closed reopened pending table claims claimid companyname statusid abc abc abc abc xyz xyz expected result companyname totalopenclaims totalclosedclaims totalreopenedclaims totalpendingclaims abc xyz need write query could get result expected
163528 struggling find documentation sql server actually stores non persisted computed column take following example schema create table dbo invoice invoiceid int identity1 primary key customerid int foreign key references dbo customercustomerid invoicestatus nvarchar50 null invoicestatusid case invoicestatus sent complete received end go index create nonclustered index ix invoice invoice customerid asc include invoicestatusid go get stored leaf level value persisted anything stored index help sql server find rows situation help greatly appreciated many thanks edit thanks brent aaron answering heres pastetheplan clearly showing explained
163557 trying calculate running total reset cummulative sum greater another column value create table reset runn total id int identity11 val int reset val int grp int insert reset runn total values select row numberoverpartition grp order idas rn test reset runn total index details create unique clustered index ix load reset runn total testrn grp sample data id val reset val grp expected result id val reset val running tot greater reset val reset greater reset val reset greater reset val reset query got result using recursive cte original question https stackoverflow com questions reset running total based another column cte select rnid val reset val grp val running total iif val reset val flag test rn union select iifc flag val running total val iifiifc flag val running total val reset val cte join test grp grp rn rn select cte better alternative sql without using clr
163875 table need update names wondering following queries query1 update mytable set name replacenamejeffjoe query2 update mytable set name joe name jeff
164043 given use case tenant data cross talk one tenant need another tenants data tenant could potentially large historical data volume sql server hosted aws ec2 instance tenant geographically distant intention use third party visualization tools powerbi embedded data volume expected grow time cost system constrained solution must maintainable without production dba solution able scale horizontally total number tenants less would recommended architecture reference implementations use case believe many people might already faced problem enterprise software development think different situation handling growing number tenants multi tenant database architecture use case mentioned question deals higher number tenants different large tenants architecture mentioned might solution want know
164046 tables using right join data setup like issue numbers returned inaccurate execute query get returned double triple accurate value vendor totalsales totalcases vendor manually math vendor totalsales totalcases vendor must change query results returned declare bbc table vendor varchar250 vendorcasenum varchar100 casenumdate date declare allvendor table vendor varchar250 declare totalsalesamt table vendor varchar250 saleamt decimal102 insert totalsalesamt vendor saleamt values vendor vendor vendor vendor vendor vendor insert allvendor vendor values vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor vendor insert bbc vendor vendorcasenum casenumdate values vendor a12344 vendor a12311 vendor a12889 vendor a12988 vendor a12931 vendor a12199 vendor e12331 vendor e12391 vendor e12300 vendor e11001 vendor e12301 vendor e12221 select av vendor totalsales sumisnulltsa saleamt0 totalcases countbbc vendorcasenum allvendor av left join bbc bbc av vendor bbc vendor left join totalsalesamt tsa tsa vendor av vendor group av vendor order av vendor asc edit also tried using cte achieve desired outcome came incorrect results tsa select vendor saleamt totalsalesamt bbc select vendor vendorcasenum bbc select av vendor totalsales isnullsumtsa saleamt0 totalcases countbbc vendorcasenum allvendor av left join tsa tsa tsa vendor av vendor left join bbc bbc bbc vendor av vendor group av vendor order av vendor
164166 consider following example declare suppliednumber money set suppliednumber select ah firstname ah lastname accountholders ah join dbo accounts ah id accountholderid group ah firstname ah lastname suma balance suppliednumber see ordering kind query looking execution plan see implicit sorting happening whats technical reason behind im using microsoft sql server rtm cu14 kb3158271 x64 may copyright microsoft corporation express edition bit windows nt build
164260 watching years old webinar done brent ozar https youtu kle3gkahc heard several items recommended time sqldiag utility sqlnexus pal tool database tuning advisor wizard bpa best practices analyzer sql server policy based management still used considered something newer replaced
164329 two tables products products discounts product designated top product missing defined discount products discounts want insert record products discounts missing record inserted values would consist product id two hard coded values insert products id product id name top ten products discounts id product id discount amount discount description following plan manually since ill repeating process times year im looking see done lines sql get list products meet criteria select product id pd discount amount products left outer join products discounts pd product id pd product id top ten pd product id null use text editor construct individual insert statement id use output step get product ids two values would remain hard coded insert products discounts product id discount amount discount description values product id goes top product steps combined lines sql
164382 getting confused choosing index reorganize rebuilding indexes based avg fragmentation percent returned sys dm db index physical stats dm function msdn says also avg fragmentation percent value says percentage logical fragmentation percentage order pages leaf pages index existed index reorganize index always fixes physical ordering pages even avg fragmentation percent greater also consider reorganize index decreasing percentage fragmentation index please look example select database id object id avg fragmentation percent avg page space used percent page count avg fragment size pages sys dm db index physical stats db idbpigtn gal app tst object idnm ppa projection master null null sampled result database id object id avg fragmentation percent avg page space used percent page count avg fragment size pages example see average fragmentation means index logical fragmentationunordering pages going reorganizing index seen image please look example alter index pk nm ppa projection master projection details sid rs contract sid nm ppa projection master reorganize go select database id object id avg fragmentation percent avg page space used percent page count avg fragment size pages sys dm db index physical stats db idbpigtn gal app tst object idnm ppa projection master null null sampled result database id object id avg fragmentation percent avg page space used percent page count avg fragment size pages organized index reorganize average fragmentation reduced percent also space used increased percent percent msdn suggesting avg fragmentation percent value consider reorganize rebuild index avg fragmentation percent value says logical fragmentation amount space used index little bit confused choosing organize build index consider avg fragmentation percent avg page space used percent values choosing rebuild index reorganize index one please suggest exact parameters consider choosing rebuild organize index
164463 read great deal differences temporary tables table variables sql server experimenting switching mostly using temporary tables mostly using table variables seem better fit types queries usually work queries tables hold unique identifiers drive lookup process habit working temporary tables include primary key constraint query optimizer aware wont see duplicates however given optimizer circumstances queries assumes table variable holds single row unique definition query optimizer going make choices differently theres primary key constraint technically assumes rows replaces zero one zero interacts poorly rest estimation process also depends whether table variable populated query compiled background information whats difference temp table table variable sql server im currently using sql server would curious behavior changes newer versions pointed primary key constraint comes clustered index gives query optimizer choices get data table variable aware thinking rest query plan attempting clarify question ive decided question attempting ask broad probably particular extreme situation nothing navigational type queries half trillion row tables expectation sub second performance going leave question
164526 query runs acceptable amount time want squeeze performance possible operation im trying improve index seek right plan node ive added appropriate indexes estimates get operation half supposed ive looked changing indexes adding temporary table writing query couldnt simplify order get right estimates anyone suggestions else try full plan details found non anonymized plan found update feeling initial version question raised lot confusion im going add original code explanations create procedure dbo someprocedure astype int customattrvalids idlist readonly begin set nocount declare dist ca id int select temp customattrvalids id null select dist ca id countdistinct customattrid customattributevalues inner join temp id id select id assortmentid assortments inner join assortmentcustomattributevalues acav id acav assortment id inner join customattributevalues cav cav id acav customattributevalue id assortmenttype astype acav customattributevalue id select id temp group assortmentid id countdistinct cav customattrid dist ca id optionrecompile end answers odd initial naming pastetheplan link answer used anonymize plan sql sentry plan explorer option recompile answer afford recompiles order avoid parameter sniffing data could skewed tested happy plan optimizer generates using option recompile schemabinding answer id really want avoid would use indexed view anyway system function count use schemabinding answers possible questions use insert temp customattrributevalues answer noticed know using variables plugged query estimates come working variable always tested putting data temp table estimated equal actual rows use acav customattributevalue id select id temp answer could replaced join temp developers confused proffered option dont really think would difference even replacing either way problem
164711 looking pivot rows progress check columns check check etc sum totals required display results hopefully anyone help thanks ad
164922 working query order answer question query chart data database agnostic way following tables create table dbo foo creation datetime null value money null dt convert date creation persisted add clustered index dt column create clustered index ci foo foodt go table joining create table bar dt date primary key clustered go loading data tables found running following query radhe select row row number overpartition dt order dt date dt number records day case dt null else count partition dt end total value day coalescesumf value partition dt bar left outer join foo dt dt get rid duplicates present result select date number records day total value day radhe row get something like picture exactly looking execution plan generated several sort nested loops operations see picture full query plan found simple operation left outer join tables indexes already ordered therefore wondering could simplify query plan alternatively could change query code exactly need nested loops times sort times query plan
165230 using always encrypted attempting encrypt one column type varchar50 table contains million rows deterministic encryption wizard returns failure due following error exception type system outofmemoryexception thrown ideas prevent error
165439 ive got database running sql server dbms consider server running sql server part network domain execute sql command alter database mydatabase set trustworthy service broker queue early setted working receives messages activeted stored procedure associated queue doesnt start messages continue flow queue nothing else happens sql server log ive found message activated proc proofschema mysp running queue proofschema myqueue output following database owner sid recorded master database differs database owner sid recorded database mydatabase correct situation resetting owner database mydatabase using alter authorization statement run configuration machine inside network domain everything works cant understand happening trustworthy crush servi broker queue
165798 solved query problem using row number partition general question use columns null values joins cant null equal null sake join
165912 generated trace file sql server really sure unit duration measured millisecond
165966 mainly net developer using entity framework orm however dont want fail using orm trying understand happens within data layer database basically development start profiler check parts code generate terms queries spot something utterly complicated orm generate awful queries even rather simple linq statements carefully written heavy duration cpu page reads take ssms check execution plan works fine level database knowledge however bulk insert seems special creature seem produce showplan try illustrate simple example table definition create table dbo importingsystemfileloadinfo importingsystemfileloadinfoid int null identity1 constraint pk importingsystemfileloadinfo primary key clustered environmentid int null constraint fk importingsystemfileloadinfo references dbo environment importingsystemid int null constraint fk importingsystemfileloadinfo importingsystem references dbo importingsystem filename nvarchar64 null fileimporttime datetime2 null constraint uq importingsystemimportinfo envxis tablename unique environmentid importingsystemid filename fileimporttime note indexes defined table bulk insert catch profiler one batch insert bulk dbo importingsystemfileloadinfo environmentid int importingsystemid int filename nvarchar64 collate latin1 general ci fileimporttime datetime27 metrics items inserted cpu reads writes duration total table count application thats ok although reads seems rather large know little sql server internals comparing 8k page size small record information question investigate bulk insert optimized make sense since arguably fastest way push large data client application sql server
166024 would like create stored procedure create row table every day given date range stored procedure accepts two inputs start date end date date range desired user lets say table like select day currency conversiontable day datetime currency integer keep things simple lets say always want currency column inserted rows someone inputs march start date april end date would like following rows created whats best way code stored procedure using sql server r2 test environment real environment uses sql server upgrade test machine new functionality introduced makes task easier
166117 im building database postgres theres going lot grouping things month year never date could create integer month year columns use could month year column always set day former seems bit simpler clearer someone looking data latter nice uses proper type
166205 need restore sql server database sql server possible way without install complete copy sql server restore change compatibility level restore backup know would work really dont want install r2 single purpose unless choice
166374 situation think solved using window function im sure imagine following table create table tmp date timestamp id type integer insert tmp date id type values id like new group change column id type 1st group 2nd starting finishing works want include criteria define groups moment using query select distinct minmindate begin maxmaxdate end id type tmp group id type window partition id type order begin get following result begin end id type id like begin end id type solve first step ill add columns use rules break groups others nullable postgres version postgres postgis easy upgrade postgis functions changes names problems hopefully already writing everything new version use newer version postgis
166493 query takes hours run server doesnt take advantage parallel processing million records dbo deidentified records dbo namesmultiword server access cores update dbo deidentified tablock set indexedxml dbo replacemultiwordindexedxml de461 dbo replacemultiwordde461 de87 dbo replacemultiwordde87 de15 dbo replacemultiwordde15 inprocess replacemultiword procedure defined select body replace bodynamesreplacement dbo namesmultiword order wordlength desc return body nvarcharmax call replacemultiword preventing forming parallel plan way rewrite allow parallelism replacemultiword runs descending order replacements short versions others want longest match succeed example may george washington university another washington university washington university match first george would left behind technically use clr im familiar
166747 im trying delete bunch rows table matching query general form query delete mytable id select id mytable id column serial primary key run inner select query runs second returns rows add delete call onto seems sit chug away chug away let run minute cancelled assuming progress made added explain analyze onto front see could check taking long call also hangs long period time anybody tell could going quick identify rows id like delete takes indeterminate amount time delete update full query follows delete cards id select id cards left join game results game results card id cards id available game id null simplified version tables would create table cards id integer primary key available boolean create table games id integer primary key create table game results game id integer references games card id integer references cards im sure query would eventually finish running im surprised long taking given retrieving ids delete quick solution problem three fold one earlier slow queries running triggered aborted script query still running even though script aborted operations like trying drop indexes locked waiting query finish manually cancelling query using pg cancel backend allowed experiment dropping indexes foreign key constraints foreign key constraints seem issue slowing everything fact game results table referenced cards made delete take forever funny thing deleting cards explicitly unused game results course didnt stop foreign key checks happening upon delete made things slow dropped foreign key constraint running delete sped things level felt appropriate whatever reason second delete query accepted answer ran much quicker first combining three things able whole delete seconds whereas combined three factors together queries running minutes cancelling thanks help
166792 postgresql support generated columns also know virtual columns talking identity columns find information remarkable feature know available sql server latest versions mariadb mysql feature mentioned sql standard discussion postgresql forums around find anything substantial matter discussion quite old may well date
166843 lets make assumptions table looks like facts set size whole table rows 100k rows value column similar values means 100k distinct values column queries read values given value select sumb table written way consecutive values physically close either written order assume cluster used table column table rarely ever updated concerned read speed table relatively narrow say bytes per tuple bytes overhead question kind index using understanding btree issue btree index huge since far know store duplicate values since cant assume table physically sorted btree huge end read index parts table index points use fillfactor decrease size index bit brin understanding small index expense reading useless pages using small pages per range means index bigger problem brin since need read whole index big pages per range means ill read lot useless pages magic formula find good value pages per range takes account trade offs gin gist sure relevant since theyre mostly used full text search also hear theyre good dealing duplicate keys would either gin gist index help another question postgres use fact table clustered assuming updates query planner binary searching relevant start end pages somewhat related store columns btree drop table altogether achieve something equivalent believe clustered indices sql server hybrid btree brin index would help id rather avoid using arrays store values since query end less readable way understand would reduce cost bytes per tuple overhead reducing number tuples
166877 using sql server management studio windows im tired using shift ctrl right left keys select code want run im wondering whether shortcuts snippets select block code separated code blank lines code example select tab1 select tab2 select tab3 say cursor inside middle block whats best way select middle block
167031 title says strangely cant find result
167036 cleared stats ran query actual execution plan total estimated cost used total worker time column dm exec query stats dmv calculate average microseconds cpu time sumquery stats total worker time sumquery stats execution count plan recommended index created index cleared stats ran query time plan total estimated cost top level checked dm exec query state dmv average cpu time microseconds expecting worker time around half double missing something improvement query plan reflected exec query stats two plans uploaded plan1 plan2
167037 timestamp column used scheduling calendar events would like change time part retaining date part untouched possibly im postgresql current
167086 reviewing sql server physical operators listed technet dont judge know youve done read hash match physical operator sometimes used implement union logical operator never seen done would like learn example query would great used better alternatives usually always
167096 answer erwin brandstetter says countstep null order date shortest syntax also works postgres older count counts non null values modern postgres cleaner equivalent syntax would countstep filter step order date im unsure countstep null preferred though query following renamed variables match maintaining syntax case lagid type order date id type end step counting values returned note case return null two equal returned equal returns null isnt counted erwins answer assumes involved columns null else need im even confused point adding countstep null protecting query could anyone break perhaps show two examples data wherein one one countx null works
167201 im getting started postgres reading document came across query select title ts rank cdtextsearch query rank apod tsqueryneutrino dark matter query query textsearch order rank desc limit understand everything query except apod mean im used joins multiple statements separated comma searched net avail looking thinking seems declaring variable called query use multiple times true
167486 gis se many us use esri geodatabases esri describes geodatabases object relational object relational databases necessary use model spatial databases seems like theyve taken something simple relational database model made something complicated id like understand benefit im dba developer laymans terms would appreciated
167489 inherited sql server databases one table ill call million rows columns wide source database ill call sql server standard gets etld target database ill call table name sql server r2 standard edit people asked source table source target table yes source far etl goes isnt real transformation happening effectively intended copy source data therefore plans add additional sources target table little half columns varchar source table columns varchar80 columns varchar30 columns varchar8 similarly columns nvarchar target table columns widths words length nvarchar columns nvarchar80 columns nvarchar30 columns nvarchar8 design id like alter target columns data types nvarchar varchar want safely without data loss conversion look data values nvarchar column target table confirm whether column actually contains unicode data query dmvs check value loop nvarchar column tell values genuine unicode would ideal solution methods welcome
167709 anyway change column data type accept negative values sql server azure
167727 lets say query select mytable myparam mycolumn myparam myparam parameter optional check mycolumn myparam myparam dba saying makes slow db suffers another option myparam select mytable mycolumn myparam problem approach lot optional parameters query become big another option case guys suggest talking general whether oracle sql server
168022 suppose following queries select count big table col val select count select big table col val previous queries perform better im using postgresql big difference another dbms ps im asking question sqlalchemy python based orm executes count operation default subquery option force execute count directly query
168116 currently indexes allow pagelocks set presumably done order reduce deadlocks however doubt would really effect back trying understand sql server actually chooses start locking pages rather keys clustered index asked jonathan keyhaisas recently told could happen touching rows several subsequent pages however didnt manage get exclusive page locks updating rows clustered index sample query could help understand page locks better sample query table running sql server sp4 thanks advance martin
168134 im using postgres want search rows name column contain space im little murky define space though thought would space bar keyboard ran name like got results like jason falkner sure looks like space probably things going better way scan rows name column doesnt contain space using regexp name still returned columns looked like space using select castname bytea name like like returned x4a41534f4ec2a0424c414b45 however im still little unclear use data figure screen spaces results tried name space returning jason blake byte sequence x4a41534f4ec2a0424c414b45
168276 isnt question catch queries accept user input use variables strictly queries isnull used clause replace null values canary value comparison predicate different ways rewrite queries sargable sql server dont seat example query local copy stack overflow database sql server looks users null age age select count dbo users isnullu age query plan shows scan quite thoughtful nonclustered index scan operator shows thanks additions actual execution plan xml recent versions sql server read every stinkin row overall reads use half second cpu time table users scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads sql server execution times cpu time ms elapsed time ms question ways rewrite query make efficient perhaps even sargable feel free offer suggestions dont think answer necessarily answer enough smart people come alternatives may better want play along computer head download database thanks
168303 want extract complete list node names paths arbitrary well formed json document stored nvarchar value sql server reliable way example json value declare json doc nvarchar4000 name1 value1 name2 value2 get result upon querying json doc node name name1 name2
168402 running postgresql windows seems update monitor use information proxy agent windows corporate proxy also look environment variables http proxy https proxy set add credentials via cntlm corporate firewall useful programs npm git need get past outgoing firewall getting following message every minutes pop program called program files x86 postgresql updatemonitor bin updmanager exe execute program files postgresql bin stackbuilder exe message deceiving tracked program one listed
168590 using fk constraints companys untold rule fk constraints used designing erd used creating tables according senior real practice time consuming obstacles dealing urgent issues says need use insert update delete statements immediately constraints block statements executed writing statements keeping constraints time consuming even heard many companies kinda understand struggles im sure good way since quite opposite understanding db company first job dont know companies dealing practical way opinion justified better ways companies matters update seems quite common approach south korean companies asked seniors worked companies saying like even one worked financial company interesting
168726 way inject cardinality estimation sql server optimizer version something similar oracles cardinality hint motivation driven article good query optimizers really test influence cardinality estimator selection bad plan therefore would sufficient could force sql server estimate cardinalities precisely complex queries leis viktor et al good query optimizers really proceedings vldb endowment
168815 select power2 returns instead seems digits precision rounding 17th even making precision explicit select powercast2 numeric380cast64 numeric380 still returns rounded result seems like pretty basic operation flaking arbitrarily digits precision like highest calculate correctly power2 failing power2 going whats really terrible select actually returns right value much terseness
168833 wanting divide int quantity number output ddl create table orders id int identity11 primary key null partid varchar100 null qtyordered int default orderedby varchar100 null ordereddate date default getdate insert orders partid qtyordered orderedby values ss100 james rr200 bob nn300 jake oo400 blue trired using sql server functions ceiling floor getting desired output query tried need sql server get output select partid ceilingqtyordered first want ceilingqtyordered second want floorqtyordered third want orders partid rr200
169123 beginning provision set physical servers virtual cluster sql server nodes within vmware utilizing enterprise edition licenses plan setting nodes bit debate ideal way provision physical servers regards cpu clock speed versus cpu core count know largely dependent transaction volume number databases stored among software specific factors general rule thumb advised instance dual core ghz physical server cores preferential dual core ghz server cores anyone come across white paper delves type topic
169372 trying run update want step quite bit data dont want blast oracle bit easier select rows want include clause sql include select im wanting write something along lines update instances set thing new thing rownum basically want time syntax possible tsql
169458 trying create column table exist researched lot could find solution yet really possible conditionally create column
170579 sql query given want select multiple value using like operator query correct select top employee id employee ident utc dt rx dt employee inner join employee mdata history employee ident employee mdata history employee ident employee id like emp1 emp3 order rx dt desc anyone correct table large amount data starting emp1 emp3 filter result top emp1 top emp3 based rx dt
170803 made script one time deletes foreign keys database like alter table mytable1 drop constraint fk mytable1 col1 alter table mytable2 drop constraint fk mytable2 col1 alter table mytable2 drop constraint fk mytable2 col2 surprises script takes long time average seconds drop fk understand creating fk may big deal server go check fk constraint infringed beginning dropping server dropping fks takes long curiosity understand way make things faster able remove fk disable would allow much faster migration therefore minimize downtime
170849 use truncate command clause need remove specific rows several tables delete specific data entire database select dimemployee firstname dimemployee lastname salesordernumber shipdatekey dimemployee join factresellersales dimemployee employeekey factresellersales productkey dimemployee firstname like kevin truncate specific name entire db method remove specific data entire db database tables wanted delete specific name corresponding columns entire database name spread across entire database hence want remove single shot instead going table deleting individually
171030 performance tuning skills never seem feel sufficient always wonder optimization perform queries situation question pertains windowed max function nested within subquery data im digging series transactions various groups larger sets ive got fields importance unique id transaction group id batch transactions dates associated respective unique transaction group transactions times group date matches maximum unique transaction date batch times manual adjustments come system unique date operation occurs group transaction date captured manual edit doesnt adjust group date design identify query records unique date falls group date following sample query builds rough equivalent scenario select statement returns records im looking however approaching solution efficient manner takes run fact table loads record counts number upper digits mostly disdain subqueries makes wonder theres better approach im concerned indexes im confident already place im looking alternative query approach achieve thing even efficiently feedback welcome create table example uniqueid int identity11 groupid int groupdate datetime uniquedate datetime create clustered index cx example uniqueid asc set nocount populate test data declare int int uniquedate datetime groupdate datetime begin begin set uniquedate getdate end else begin set uniquedate getdate end set groupdate getdate insert example groupid groupdate uniquedate values groupdate uniquedate set begin set end end set nocount create nonclustered index ix example groupid asc uniquedate asc groupdate asc include uniqueid identify uniquedates greater groupdate within groupid select uniqueid groupid groupdate uniquedate select uniqueid groupid groupdate uniquedate maxuniquedate partition groupid maxuniquedate example calc maxud maxuniquedate groupdate maxuniquedate uniquedate drop table example dbfiddle
171194 several sql objects need take alternate actions based desired state request way create database level constants enumerations passed stored procedures table valued functions used queries without using clr create procedure dbo dosomework param1 integer enumvalue myenumtype use exec dosomework myenumtype enumvalue1 myenumtype enumvalue2 myenumtype would hold enumeration values procedure would able use enumvalue test values myenumtype required work would make values myenumtype bitmask case considering simple example consider expensive process takes huge dataset reduces smaller still large dataset process need make adjustment middle process affect result say filter types records based status intermediate calculation within reduction enumvalue type myenumtype could used test select enumvalue myenumtype enumvalue1 myenumtype enumvalue1 enumvalue myenumtype enumvalue2 myenumtype enumvalue2 sort database level constants possible sql server without use clr seeking database level enumeration set constants passed parameters stored procedures functions
171337 edit sql server im hoping generic enough question need specify version instances im working later good enough mock data actually test im hoping someone could look answer simple experience imagine state table american state abbreviations column indexed like good lookup column writing ad hoc queries users often hit column filter using criteria represents information implicit database example want get big states may include filter ad hoc query shows something like stateabbreviation ak tx aka dreaded business rules query fine performs well makes use index man bear write every time need query big states im tempted create view filter definition make easier problem business rules specific number ad hoc queries supporting line business dont really universal uses creating view filters data way little utility instead writing view criteria filter want write view criteria result calculated select stateabbreviation isbig case stateabbreviation ak tx else end tblstates want write query big states include isbig query question simple view called criteria index stateabbreviation used know kinds things could inside case statement may change answer purposes answering specific question assume case statement ever look like make use multiple fields aggregate simple calculation literals expose complex filter criteria report writers simpler way
171365 script generate create table script see answer question however need script partition functions partition schemes question see answer examples add partition table remove partition table would like look scripts stage found link find partition function text applied table generate scripts create partition function partition schema working script generate create partition function see works pf year partition function tricky get fact sys partition range values sql variant data type value used case got following error msg level state line operand type clash int incompatible date great answer dan guzman showed us sql variant property wonderful thing aware new dba person set transaction isolation level read uncommitted select radhe create partition function space1 quotenamespf name coalescebaset namedata type found char13 range case castspf boundary value right int right else left end char13 values select stuff select text cast case st system type id convert date sprv value126 convert int sprv value else convert int sprv value end nvarchar sys partition range values sprv sprv function id spf function id order sprv boundary id xml path 1n st system type id spf name name spf function id id castspf boundary value right int rangetype spf create date createdate spf fanout numberofpartitions sys partition functions spf inner join sys partition parameters spp spp function id spf function id inner join sys types st st system type id st user type id spp system type id st system type id left outer join sys types baset baset user type id spp system type id baset user type id baset system type id baset system type id spp system type id baset user type id spp user type id baset user defined baset assembly type spf name pf year
171425 inside stored procedure following sql server set transaction isolation level serializable begin transaction getstuff begin try selects updates etc etc commit transaction getstuff end try begin catch end catch since transaction based thought rest database connections affected serializable need implicitly set isolation level read committed commit adversely effect connections application server database server
171510 trying look verbose information maintenance plan task failed open log file viewer check box view logs maintenance plan active filters besides example play waiting game take almost minutes get logs show thought might taking time load logs beginning servers time reduced filter days since needed anyway came faster still took minutes show note first time computer trying view logs might also play factor also tried look logs directly server getting similar time results par course expect viewing logs experience like something checking plan check log age see purged would still affect looking logs short day period
171654 consider following contrived simple query select id case id select top id table else select top id table end id2 heap would expect final row estimate query equal number rows heap table whatever im subquery shouldnt matter row estimate filter rows however sql server see row estimate reduced subquery happen easy reproduce issue right syntax one set table definitions create table dbo heap id int null create table dbo table id int null create table dbo table id int null insert dbo heap tablock select top row number order select null master spt values create statistics heap id heap id fullscan db fiddle link
171855 im looking option create alias command psql console connection allowed setting search path finding option psql util option execute command without exiting idea would like avoid preconditions setting environment options oneliner possible
172275 work insurance company little year sql experience around years including ssis ssrs approximately tb data possible build data warehouse experience lots materials sql groups get help still complicated thanks
172289 table zip codes includes center lat lng zip code use get list zip codes within given mile radius arbitrary point occurred zips center point within given radius mean zip within radius used super advanced art skills illustrate point green stripy blobs represent zip codes red smudges geographic centers zip code fuchsia dot target location lumpy blue circle mile radius target location run query zip codes within mile radius pink smudge zip codes returned center point zip within one mile radius even though pink smudge clearly zip code select distance unit degreesacoscosradiansp latpoint cosradiansz cosradiansp longpoint radiansz sinradiansp latpoint sinradiansz dist standard zip join query parameters select lat latpoint lng longpoint miles radius distance unit latpoint radius distance unit latpoint radius distance unit longpoint radius distance unit cosradiansp latpoint longpoint radius distance unit cosradiansp latpoint order dist heck write query include zip results access spatial geometry zip code add table needed idea would use purpose mysql edit spent day reading oracle mysql docs spatial data managed successfully convert spatial data mysql go writing similar query uses geometry column instead lat long using 2d data geometry polygons multipolygons think sort figured select select minst distancegeom point miles zip zip spatial group zip order miles asc miles ill leave bounty open case someone better efficient solution
172521 inline views allow select subquery different table select selecting query instead table select c1 t1 c1 c1 ive seen referred using different terms inline views clause cte derived tables seems different vendor specific syntax thing wrong assumption technical performance differences
172903 using windows language serbian sql management studio cant use database reports error error occurred local report processing culture supported parameter name culture 0x0c00 invalid culture identifier try different settings windows language english try different settings ssms english got error idea solve windows system locale settings get winsystemlocale lcid name displayname sr latin rs serbianlatin serbia
173190 query selects rows source database databasea inserts target database database collation type differs databases changed need address collation difference query explicitly specifying collation varchar fields currently query looks like insert databaseb dbo users id usernumber firstname surname address1 address2 addresstown addresscity select id usernumber firstname collate sql latin1 general ci surname collate sql latin1 general ci address1 collate sql latin1 general ci address2 collate sql latin1 general ci addresstown collate sql latin1 general ci addresscity collate sql latin1 general ci databasea dbo users question avoid typing collation type every string based field way specify collation type whole query possible shortcuts
173309 bit diversion real problem providing context helps generating data could useful performance testing ways processing strings generating strings need operation applied within cursor generating unique anonymous name replacements sensitive data im interested efficient ways generating data within sql servers please dont ask need generate data ill try start somewhat formal definition string included series consists capital letters first term series series consists valid strings sorted length first typical alphabetical order second strings table column called string col order could defined sql order lenstring col asc string col asc give less formal definition take look alphabetical column headers excel series pattern consider might convert integer base number aa ab analogy isnt quite perfect behaves differently base ten table selected values hopefully make clear row number string aa ab ay az ba bb zzz aaaa zzzy zzzz aaaaa hjunyv goal write select query returns first strings order defined testing running queries ssms result set discarded opposed saving table ideally query reasonably efficient im defining efficient cpu time serial query elapsed time parallel query may use whatever undocumented tricks like relying undefined non guaranteed behavior okay well would appreciated call answer methods efficiently generating data set described martin smith pointed clr stored procedure probably isnt good approach due overhead processing many rows
173335 occasionally see questions asking safely store user passwords web application using rdbms im talking facebook twitter usual answer salt password hash strong algorithm tdes sha512 question rdbms user bother password storing problematic since engines built authentication mechanism example user wants create account user password web application issuing following query wrong create user encrypted password group baseuser within application user open connection database using credentials dont bother password management see multiple advantages method rdbms decides encryption algorithm needs changed dont need touch anything apply security updates easy manage users authorizations user promoted administrators role add user corresponding group sql injections meaningless manage permissions allow exactly want allow user database example forum like adding new posts answering posts commenting editing deleting questions answers comments user account anonymous used unauthenticated connections application user owner data provided virtually every question see topic seems general consensus way things done question note third point allowed policies postgresql security policies microsoft sql server realize concepts newcomers anyway doesnt technique describe become standard way handle users accounts
173367 attempting select 1st row returned query syntax insert temp id salesid select rn row number overorder psuserid psuserid select distinct psuserid rstln bama rusticlines rstln tnr active rn get error msg level state line invalid column name rn need change selects 1st row number
173435 usually design databases following next rules nobody else db owner sysadmin access database tables user roles controlled application layer usually use one db role grant access views stored procedures functions cases add second rule protect stored procedures use triggers initially validate critical information create trigger triggername mytable insert exists select inserted field1 initial value field2 initial value begin update mytable set field1 initial value field2 initial value end dml executed using stored procedures sp mytable insert field1 field2 field3 sp mytable delete key1 key2 sp mytable update key1 key2 field3 think scenario worth use default constraints im adding extra unnecessary job db server update understand using default constraint im giving information someone else must administer database im mostly interested performance assume database checking always default values even supply correct value hence im job twice example way avoid default constraint within trigger execution
173831 using join many many relationship result split multiple rows id like convert right side join array result one row example explain better tables create table items id serial primary key title text create table tags id serial primary key title text create table items tags item id int references itemsid tag id int references tagsid primary key item id tag id selecting items tags way select id title title items inner join items tags item id id inner join tags id tag id result come item n1 sport item n1 soccer item n2 adventure item n2 mountain climbing item n2 sport item n2 nature id like item n1 sport soccer item n2 adventure mountain climbing sport nature
173868 want know possible transform numeric return int column sequence symbols direct mysql select table like id category product product product want sql select like select id mysql fancy funccategory symbol category mytable could returns following id symbol category product product product possible programmatically intention want built even custom function achieve result direct select statement
173895 microsoft doc defines string length value max indicates maximum storage size bytes gb storage size actual length data entered bytes please help understand max characters varchar seems way less 2gb worth data see records varcharmax column specific table lenmycolumn thus know get way characters varcharmax column question characters come play aware question net datareader query column always return full result character
174044 question regarding piece documentation temp tables recently read technet fourth paragraph temporary tables section page reads follows temporary table created named constraint temporary table created within scope user defined transaction one user time execute statement creates temp table example stored procedure creates temporary table named primary key constraint stored procedure executed simultaneously multiple users work environment make significant use handful stored procedures use indexed temp tables weve never encountered issue users wait one execution complete next begins hope continue case im concerned could become issue caveat properly understood specifically unclear following points apply global temp tables local ones well seems strange table isnt visible outside session latter case would prevent another session executing simultaneously qualifies named constraint dont constraints names even system generated referring constraints user defined alias seems like poor phrasing multiple users actually mean multiple sessions procedures called application using single service account calls scripts made db single account im unconcerned occasional call admin may make backend service account run sproc multiple sessions simultaneously issue moot purposes
174069 english might talk relation say bob tim perhaps theyre cousins term relation context makes sense context relational databases understand term refers dont understand used figure understanding used help better understand field id like understand used example person considered relation english relation noun describes two entities associated doesnt refer entities context relational databases relation refers entities understand relational model came hierarchical network models ex parent neighbor models entities also relations one another call model relational model specific phrase term maybe say three models relational models hierarchical network models specific types relational models standalone entities dont relate one another say person door tree term relational still applicable perhaps multiple questions figured answers highly related perhaps theres one answer figured itd make sense single question im wrong let know ill create separate questions instead edit diagram may useful visualize relation relating different domains one another
174219 im trying create trigger alter collation database creation catch database name use inside trigger use master go create trigger trg ddl changecollationdatabase server create database declare databasename varchar200 set databasename db name alter database databasename collate xxxxxxxxxxxxxxxxxxx go obviously working
174249 im using sql server enterprise ive come across sql plan exhibiting behavior dont find entirely intuitive heavy parallel index scan operation parallelism repartition streams operation occurs killing row estimates returned index scan object10 index2 reducing estimate ive done searching havent come across anything explains behavior query quite simple though tables contain records low millions part dwh load process intermediate data set touched times throughout question related row estimates particular someone explain accurate row estimates go within parallelism repartition strems operator also something concerned particular situation ive posted full plan paste plan heres operation question including plan tree case adds context could running variation connect item filed paul white depth explination blog least thing ive found seems even remotely close im running even though top operator play
174353 run command sum select count records sumt amount total dbo t1 id id im getting arithmetic overflow error converting expression data type int idea cause im following instructions answer
174694 ill try make graph data sql server database ill streets count users living street even count zero ive tried query create table streets id int identity primary key name varchar100 create table users id int identity primary key username varchar100 streetid int references streetsid insert streets values 1st street 2nd street 3rd street 4th street 5th street insert users values pol doortje marc bieke paulien fernand pascal boma goedele xavier select name street counts name count users inner join streets streetid id group name gives output street count 1st street 2nd street 3rd street 4th street problem ill 5th steet lives one could sql server youve got fiddle update right join ive got result street count 1st street 2nd street 3rd street 4th street 5th street see fiddle
174739 post connect item regarding lack documentation someone confirm simply missing something docs page format listed string function built string functions deterministic string functions transact sql also mention format nondeterministic related pages deterministic nondeterministic functions format transact sql however attempting create persisted computed column create table date col date insert values getdate alter table add date formatted formatdate colyyyy persisted returns following error computed column date formatted table persisted column non deterministic documentation states culture argument provided language current session used adding culture argument doesnt change things also fails alter table add date formatted formatdate col en us persisted rextester demo http rextester com zms22966 dbfiddle uk demo http dbfiddle uk rdbms sqlserver next fiddle 7fc57d1916e901cb561b551af144aed6
175073 troubleshooting server high cpu utilization finding queries werent really causing started looking compilations performance monitor showing less compilations sec less recompilations sec running xe session looking compilations seeing thousands compilations per second system using triggers audit changes compilations due triggers triggers reference sys dm tran active transactions first thought maybe referencing dmv trigger would cause compile time maybe specific dmv would cause started testing theory compile time hadnt checked trigger compiles time triggered doesnt reference dmv instead hardcodes value still compiling time got triggered dropping trigger stops compiles using sqlserver query pre execution showplan xe session track compilations discrepancy perfmon counter normal get compilation event time trigger runs repro script create table t1 transaction id int column2 varchar100 create table t2 column1 varcharmax column2 varchar100 go create trigger t2 ins t2 insert insert t1 select select top transaction id sys dm tran active transactions column2 inserted go show compilation events insert t2 values row1 value1 insert t2 values row2 value2 go alter trigger t2 ins t2 insert insert t1 select column2 inserted go show compilation events insert t2 values row3 value3 insert t2 values row4 value4 drop trigger t2 ins show compilation events insert t2 values row5 value5 insert t2 values row6 value6 drop table t1 t2
175674 often see statements like sql server log records every transction opeation confused happens transaction eventually rolled back say explicit transaction statements statement statement statement finally rollback statement say execution reached rollback statement modifications resulting statements get recorded sql server log understanding statements get recorded sql server records everything matter understanding modifications stored somewhere memory recorded log sql server see commit statement turns rollback statement sql server simply ignore transacrion writing log happens serves purpose words sql server logs net result transactions seems logical least cant right thanks help
175682 working demo involving ccis noticed inserts taking longer expected table definitions reproduce drop table exists dbo stg create table dbo stg id bigint null insert dbo stg select top row number order select null rn master spt values t1 cross join master spt values t2 drop table exists dbo cci bigint create table dbo cci bigint id bigint null index cci clustered columnstore tests im inserting rows staging table thats enough fill exactly one compressed rowgroup long doesnt get trimmed reason insert integers mod takes less second truncate table dbo cci bigint insert dbo cci bigint tablock select id dbo stg option maxdop sql server execution times cpu time ms elapsed time ms however insert integers mod sometimes takes seconds truncate table dbo cci bigint insert dbo cci bigint tablock select id dbo stg option maxdop sql server execution times cpu time ms elapsed time ms repeatable test done multiple machines seems clear pattern elapsed time mod value changes mod num time ms want run tests feel free modify test code wrote couldnt find anything interesting sys dm os wait stats mod insert wait type diff wait ms xe dispatcher wait qds persist task main loop sleep lazywriter sleep logmgr queue dirty page poll hadr filestream iomgr iocompletion sqltrace incremental flush sleep request deadlock search xe timer event sleep task broker flush checkpoint queue sos scheduler yield insert id take much longer insert id
176023 support application big enterprise one roles clean data query need execute every hour would like automate due organization policies cant create sql server agent jobs modify schema manipulate data endless while1 begin waitfor delay work end job shrug thought perma open connection ideally would script ms ss execute given piece code every hour im sure possible solution problem
176246 sql server table contains columns like id int null eventdate datetime null columns table half billion rows across range distinct id values table unique clustered index like create unique clustered index myindex dbo mytable id asc eventdate asc need find earliest per id eventdate obtain using query select id mineventdate dbo mytable group id however query takes minutes complete cant share specifics query plans etc problem im looking due nda constraints advise im seeing clustered index scan checking rows table given data organised eventdate sequence id expect retrieval could much quicker im sure quite id specific range query responds milliseconds table recently rebuilt reindexed dont think statistic updates would help anyone suggest better method determining minimum per id eventdate value avoids scanning entire clustered index table thousand distinct id values
176666 sql server instance accessible seems fine microsoft sql server sp1 cu2 kb4013106 x64 mar copyright microsoft corporation enterprise edition bit windows server r2 standard build hypervisor white question mark mean icons dont go away refresh sysadmin inside sql server outside administrator box another thing noticed see picture different management studio sessions top one logged dba sysadmin second one use management studio run different user use domain account use replication sysadmin second one blue icon servers well whilst mine normal green one
176935 would need track products price changes query db product price given date information used system calculates historical audits must return correct price correct product based date purchase would prefer use postgres building db need design database best practice suggestions also welcome
177009 tables may may employee names listed problem way knowing table1 hold names table2 hold names thinking union would solve issue however see syntax produces lines since exists tables desired output empname totalsw totalsnt ddl query written produce output create table test1 empname varchar100 swas varchar100 create table test2 empname varchar100 swont varchar100 insert test1 empname swas values res1 tim1 run34 insert test2 empname swont values er12 nn12 23rw select empname totalsw countswas totalsnt test1 group empname union select empname totalsw totalsnt countswont test2 group empname
177022 may setting query completely incorrect expected result set need returned nuestra nosotros since fall date range respectively nuestra feeduedate fj feeduedate nosotros fe violationdate fe violationdate fall place however run query attempting return result get returned result set incorrect query sample data ddl create table dbo fei violatorsname varchar null violationnumber varchar null violationdate date null primary create table dbo fji violatorsname varchar null vin varchar null vfees1 float null vfees2 float null vfees3 float null vfees4 float null vfees5 float null vfees6 int null feeduedate date null totalvfees float null totalvfeespaid float null vfeesremaining float null vfee7 float null vfee8 float null vfee9 float null vfee10 float null vfee11 float null vfee12 float null vfee13 float null vfee14 float null vfee15 float null vfee16 float null primary insert dbo fei violatorsname violationnumber violationdate values nnostra n3244 cast0xe63c0b00 date insert dbo fei violatorsname violationnumber violationdate values nnuestra n408 cast0xe53c0b00 date insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n41 cast0x353b0b00 date insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n211 null cast0x2d3b0b00 date insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n211 null cast0x2d3b0b00 date insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n311 null insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n811 null insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n11111 null insert dbo fji violatorsname vin vfees1 vfees2 vfees3 vfees4 vfees5 vfees6 feeduedate totalvfees totalvfeespaid vfeesremaining vfee7 vfee8 vfee9 vfee10 vfee11 vfee12 vfee13 vfee14 vfee15 vfee16 values nnosotros n77711 null select isnullfe violatorsnamefj violatorsname totalsw countfe violationnumber totalsnt countfj vin totalvfees sumtotalvfees calculatedvfee sumcoalescetotalvfees0 coalescevfee90 adminfee sumcoalescevfee120 secfee sumcoalescevfee130 fei fe full outer join fji fj fj violatorsname fe violatorsname fe violationdate fe violationdate fj feeduedate fj feeduedate group isnullfe violatorsname fj violatorsname strong edit strong br select isnullfe violatorsnamefj violatorsname totalsw countfe violationnumber totalsnt countfj vin totalvfees sumtotalvfees calculatedvfee sumcoalescetotalvfees0 coalescevfee90 adminfee sumcoalescevfee120 secfee sumcoalescevfee130 fei fe full outer join fji fj fj violatorsname fe violatorsname fe violationdate fe violationdate fj feeduedate fj feeduedate group isnullfe violatorsname fj violatorsname
177032 putting test sets data together noticed funny behavior temp tables working large sets data clustered temp tables populated via parallel execution plan clustered key look honored selecting data issue also seems affect versions sql server ive tested include vnext heres dbfiddle uk example test may execute couple times get result finding shouldnt take one two executions yield results additionally local execution plan im getting environment shows difference large small data sets way data fed tables parallel vs serial plan want play home heres test im running large data set create table tmp id int primary key clustered insert tmp purposely insert reverse order select top percent rn select top row number order select null rn master spt values t1 cross join master spt values t2 order rn desc smaller data set create table tmp2 id int primary key clustered insert tmp2 purposely insert reverse order select top percent rn select top row number order select null rn master spt values t1 cross join master spt values t2 order rn desc large record set clustered key honored select top tmp small record set clustered key honored select top tmp2 drop table tmp drop table tmp2 ive found references indicating expected behavior submit connect item first wanted reach confirm isnt localized problem someone either point documentation identifying expected behavior alternatively confirm fact bug edit response comments including order clause always assumption top keyword returned data order inserted case order dictated clustered key running statement formal table expected behavior returned large data set formal data table create table tmp id int primary key clustered insert tmp purposely insert reverse order select top percent rn select top row number order select null rn master spt values t1 cross join master spt values t2 order rn desc large record set clustered key honored select top tmp drop table tmp rows affected rows affected id rows affected rows affected even execution plans different result sets temp table formally defined table finally shout joe obbish gratuitously ripped cross join approach build large sets test data quite efficient
177083 trying optimize procedure different update queries present procedure update resultset set majorsector case charindex sector rtrimltrimsubstringsector charindex sector else ltrimrtrimsector end update resultset set majorsector substringmajorsector lenmajorsector leftmajorsector4 update resultset set majorsector substringmajorsector lenmajorsector leftmajorsector3 abcdefghijklmnopqrstuvwxyz complete three update queries takes less seconds execution plan three update queries https www brentozar com pastetheplan id r11blfq7b planned change three different update queries one single update query reduced resultset select case lefttemp majorsector substringtemp majorsector lentemp majorsector lefttemp majorsector de hi lm pq tu xy substringtemp majorsector lentemp majorsector else temp majorsector end temp majorsector majorsector select temp majorsector case charindex sector rtrimltrimsubstringsector charindex sector else ltrimrtrimsector end majorsector resultseta update resultset set majorsector temp majorsector takes around minute complete checked execution plan identical first update query execution plan query https www brentozar com pastetheplan id sjvttz9qw somebody explain slow dummy data testing object idtempdb resultset null drop table resultset lv0 select union select lv1 select lv0 cross join lv0 lv2 select lv1 cross join lv1 lv3 select lv2 cross join lv2 lv4 select lv3 cross join lv3 lv5 select lv4 cross join lv4 tally select row number order select null lv5 select convertvarchar255 newid sectorcast varchar1000 majorsector resultset tally original table record count order note since original data timings mentioned could little different still single update query much slower first three tried executing queries times make sure external factors affect performance times first three updates ran much faster last single update
177114 similar questions answers forums think problem simpler two quesries eg select count agent select count agent active would like output single row bonus points would nice scan table update counters get result like active agents total agents guess two questions neatest clearest way fastest way large tables
177162 table station logs postgresql database column type id bigint bigserial station id integer null submitted timestamp without time zone level sensor double precision indexes station logs pkey primary key btree id uniq sid sat unique constraint btree station id submitted im trying get last level sensor value based submitted station id around unique station id values around 20k rows per day per station id creating index explain analyze select distinct onstation id station id submitted level sensor station logs order station id submitted desc unique cost rows width actual time rows loops sort cost rows width actual time rows loops sort key station id submitted desc sort method external merge disk 681040kb seq scan station logs cost rows width actual time rows loops planning time ms execution time ms creating index create index station id submitted station logsstation id submitted desc creating index query unique cost rows width actual time rows loops index scan using station id submitted station logs cost rows width actual time planning time ms execution time ms way make query faster like sec example sec still much
177369 would like monitor transaction log usage regarding following aspects task job query making fill drive file log file usage percentage time transaction happened relevant way tested would helpful
177463 page describing whats new postgres mentions transition tables triggers transition tables triggers feature makes statement triggers useful performant exposing appropriate old new rows queries feature statement triggers direct access workarounds byzantine poor performance much trigger logic written statement avoiding need expensive context switches row row triggers require transition table
177518 users able run reports reports became slow sometimes users didnt patience wait troubleshooting found column causing delay computed column uses function order bring result approximately time got another complain slow running report always working fine troubleshooting found columns causing delay amount ptd amount column computed column question sudden computed columns always part reports started slow performance significantly could really happen approx disadvantage make columns persisted thank function bring column alter function dbo calcinvoiceamtptd sinvnum int entityguid uniqueidentifier returns money begin declare amt money declare toplevel uniqueidentifier set toplevel select dbo gettoplevelentity entityguid declare table guid uniqueidentifier insert select dbo getlinkedentities toplevel guid null declare tbl table amount money glacctid int select amt isnullsumamount tblfin journalpostings jp inner join tblfin journal transactnum jp transactnum voiderfor null voidedby nulland transdescid inner join tblfin glaccounttypes glt glt glacctid jp glacctid glt accounttype inner join guid jp entityguid invoicenum sinvnum return isnull amt end
177622 quite lengthy discussion rick james came idea composite key replace autoincrement pk int limited close billion table reach limit months easily monthly capturing close hundred million data table looks like key table gdata composite primary using fields primary key alarmtypeidvehicleidgdatetime another table called alarm table link one many meaning one data gdata zero alarms related link vehicleid gdatetime create table gdata alarmtypeid tinyint4 null default fleetid smallint11 null fleetgroupid smallint11 default null fleetsubgroupid smallint11 default null deviceid mediumint11 null vehicleid mediumint11 null gdatetime datetime null insertdatetime datetime null latitude float null longitude float null speed smallint11 null see full text alter table gdata add primary key alarmtypeidvehicleidgdatetime add key gdatetime gdatetime add key fleetid fleetidvehicleidgdatetime commit alarm table create table alarm alarmtypeid tinyint4 null vehicleid mediumint9 null gdatetime datetime null insertdatetime datetime null alarmvalue varchar5 null readweb enumny null default readwebdatetime datetime null readmobile enumny null default readmobiledatetim datetime null engine innodb default charset latin1 alter table alarm add primary key alarmtypeidvehicleidgdatetime commit looks good recently googling related topic found discussion https www quora com bad idea primary key columns composite primary key would prefer go autoincrement mainly insert purpose one shed light maintain composite key primary move back autoincrement
177652 added script task ssis project vs2015 deployed sql server got error message version script supported version come reading similar questions stack overflow see set target version project sql server eventual deployment target sql server also tried deleting recreating script task information script says using v10 resolve script task error exception loading script task xml system exception script task st a1ad9dc5972c42b68c12a13155f10b6d uses version script supported release integration services run package use script task create new vsta script cases scripts converted automatically use supported version open sql server integration services package sql product short name integration services microsoft sqlserver dts tasks scripttask scripttask loadfromxmlxmlelement elemproj idtsinfoevents events also opened project ssdt rebuilt different name error seems must reference wasnt deleted something none solutions question https stackoverflow com questions ssis script task vs15 work deploy sql server worked looking xml package script easily find task reference version anywhere edit copying project machine hosts database opening vs2015 deploying package executes going back machine building doesnt bug something stupid expecting build produce deployment wizard using wizard vs sql server ssisdb schema version using integration services package created visual studio script component path program files x86 microsoft sql server dts binn vsta14 st cs template vstax wont let execute package integration services catalog due message experienced zach however appears let execute file system using sql agent unsure working update package completed
177803 imagine running multiple batches management studio separated go command id like know implicit transactions behave transaction committed per batch basis entire execution
178056 ive got query want retrieve distinct child rows ordered column parent following get error column specified order included distinct list select distinct foo bar parent join child parentid id order createddate however add createddate select list lose distinctness child rows createddate makes distinct use cte subquery first ordering select distinct rows outer query doesnt guarantee maintain order inner cte query way achieve
179500 alter index rebuild operation sql server failed transaction log ran space indexes never reorganized rebuilt fragmentation nearly db uses simple recovery model assumed following index operation performed form command transaction log data would flushed prior next index rebuild actually works index rebuilds logged part single transaction words could reduce transaction log growth writing script perform rebuild individually factors consider
179623 experimenting effect giving sql server small amount memory thought going recover configured sql server use 200mb memory want start searches internet advised start sql server single user mode however get error login failed user reason server single user mode one administrator connect time microsoft sql server error stopped sql server agent
180006 id value id parent id dropdown id name bbb comprable comprable rrr ttt table data using query get data table select d0 name name0 d1 name name1 d2 name name2 d3 name name3 table d0 inner join table d1 d1 parent id d0 value id inner join table d2 d2 parent id d1 value id inner join table d3 d3 parent id d2 value id d0 dropdown id using inner join get value id parent id basically check parent available current record get data get correct data number parents record number inner join like query get details like name0 name1 name2 name3 ttt comprable rrr comprable want get table name0 name1 name2 name3 ttt comprable rrr comprable bbb null null last row d2 d3 tables available want include data null value help appreciated
180136 database size gb vlfs hand one size tb vlfs indicate smaller database high count vlfs actually problem also decide number big within ok range please suggest
180197 table party columns party id party type use queries get two different types result select party party type null returns nothing select party party type null returns possible rows need query accept null values
180461 ive playing around investigating sampling thresholds statistics updates sql server noticed curious behaviour basically number rows sampled seems vary circumstances even set data run query drop table exists object iddbo test null drop table dbo test create table testing create table dbo testid int identity11 constraint pk test primary key clustered textvalue varchar20 null insert enough data 8mb threshold sampling kicks insert dbo testtextvalue select top blahblahblah sys objects sys objects sys objects sys objects create index textvalue create index ix test textvalue dbo testtextvalue update statistics without specifying many rows sample update statistics dbo test ix test textvalue view statistics dbcc show statisticsdbo test ix test textvalue stat header look output show statistics im finding rows sampled varies full execution table gets dropped recreated repopulated example rows sampled expectation figure would time table identical way dont get behaviour delete data insert critical question id interested understanding whats going
181593 client agreed rpo one day data loss going change back strategy eliminate space constraints database full recovery mode existing backup plan daily taking full back database thinking change like every week sunday saturday going take full back database planning take transaction backup differential backup every day database avoid space constraint take transaction log back rto larger since taking daily one transaction backup anyways need perform transaction log backup make free space log files people suggest back type good either differential transaction log going wrong direction please suggest backup strategy based rpo thanks
181594 im trying execute query times minutes experience know query takes minutes execute ideal worked however need execute changed remote query timeout parameter however query still timing minutes get message statement terminated msg level state line execution timeout expired timeout period elapsed prior completion operation server responding using ssms remote computer timeout setting taking effect need restart server isnt possible right
181598 two reasons prompts ask question tsqlt sql testing framework tsqlt considers issue high severity exists columns non default collation author test states following suggesting every string column collation matches default collation database instead suggesting different good reason yet severity failed test mentioned considered high octopus deploy configuring octopus deploy server setup fails fatal error initialization octopusserver instance article related error message explain requirement simply states requirement future deployments including octopus version side note redgates ci tool package dlm automation suite supports deployments varying collations without complaints recommendation keeping column collations database default seems like guidelines best practices considered serious error
181732 examples ive seen online imply optimize unknown applied specific query optimize unknown applied stored procedure whole specific query yes would syntax
182189 running ubuntu installed postgresql postgresql used work rebooted nmap commands show port open postgres seems working correctly service postgresql status postgresql service postgresql rdbms loaded loaded lib systemd system postgresql service enabled vendor preset enabled active active exited since sat edt 1min 4s ago process execstart bin true code exited status success main pid code exited status success memory 0b cgroup system slice postgresql service ran psql got psql could connect server file directory server running locally accepting connections unix domain socket var run postgresql pgsql file listed seem exist get postgresql normally id run psql sudo postgres psql commands working keep getting error could connect server several reboots helped update ran command dpkg grep postgres rc postgresql 0ubuntu0 amd64 object relational sql database version server ii postgresql client front end programs postgresql supported version ii postgresql client 0ubuntu0 amd64 front end programs postgresql ii postgresql client common manager multiple postgresql client versions ii postgresql common postgresql database cluster manager
182227 upgrading sql server server keeps resetting cached execution plans dm views like dm exec query stats etc every couple hours someone executes dbcc freeproccache dbcc dropcleanbuffers manually except one happens automatically database worked fine sql server windows server things went south moving sql server windows server things checked database auto close flag sql server ad hoc optimized set true thought would help didnt query store server gb memory nothing helpful sql server log either weekly backup message also checked article https docs microsoft com en us sql sql statements alter database transact sql set options scroll examples section right list situations plan cleared automatically none apply update unfortunately none suggestions helped granting lpim permissions detecting fixing non parameterized queries generated tons plans query lowering max server memory plans keep resetting randomly every couple hours every minutes server memory pressure come version working fine machine heres sp blitz output requested priority performance query store disabled new sql server query store feature enabled database xxx priority server info instant file initialization enabled consider enabling ifi faster restores data file growths priority performance resource governor enabled resource governor enabled queries may throttled make sure understand classifier function configured priority query plans implicit conversion affecting cardinality one top resource intensive queries implicit conversion affecting cardinality estimation missing index one top resource intensive queries may dramatically improved adding index rid key lookups one top resource intensive queries contains rid key lookups try avoid creating covering indexes priority file configuration system database drive master master database file drive putting system databases drive runs risk crashing server runs space model model database file drive putting system databases drive runs risk crashing server runs space msdb msdb database file drive putting system databases drive runs risk crashing server runs space priority backup msdb backup history purged msdb database backup history retained back jun 47pm priority informational backup compression default uncompressed full backups happened recently backup compression turned server level backup compression included sql server 2008r2 amp newer even standard edition recommend turning backup compression default ad hoc backups get compressed priority non default server config agent xps sp configure option changed default value set max server memory mb sp configure option changed default value set optimize ad hoc workloads sp configure option changed default value set show advanced options sp configure option changed default value set xp cmdshell sp configure option changed default value set priority performance buffer pool extensions enabled buffer pool extensions enabled one lives sql buffer pool bpe currently gb know bpes provide single threaded access 8kb one page time cost threshold parallelism set default value changing sp configure setting may reduce cxpacket waits priority wait stats significant waits detected server might sitting around idle someone may cleared wait stats recently priority informational sql server agent running nt service account im running nt service sqlserveragent wish active directory service account instead sql server running nt service account im running nt service mssqlserver wish active directory service account instead priority server info default trace contents default trace holds hours data aug 55am aug 59pm default trace files located program files microsoft sql server mssql13 mssqlserver mssql log hardware logical processors physical memory 15gb hardware numa config node state online online schedulers offline schedulers processor group memory node memory vas reserved gb locked pages memory enabled currently gb pages locked memory memory model unconventional memory model lock pages server last restart aug 32pm server name xx services service sql full text filter daemon launcher mssqlserver runs service account nt service mssqlfdlauncher last startup time shown startup type manual currently running service sql server mssqlserver runs service account nt service mssqlserver last startup time aug 32pm startup type automatic currently running service sql server agent mssqlserver runs service account nt service sqlserveragent last startup time shown startup type automatic currently running sql server last restart aug 33pm sql server service version patch level sp1 edition enterprise edition bit alwayson enabled alwayson mgr status virtual server type hypervisor windows version youre running pretty modern version windows server 2012r2 era version priority rundate captains log stardate something something
182233 sql server stored procedure create procedure passenger details begin select full name age nationality category airline name class type passenger ticket airline class passenger passenger ticket passenger airline airline ticket airline class class ticket class end execute passenger details stored procedure sql server works successfully tried execute stored procedure oracle pl sql shown create replace procedure passenger details passenger details sys refcursor begin open passenger details select full name age nationality category airline name class type passenger ticket airline class passenger passenger ticket passenger airline airline ticket airline class class ticket class end passenger details stored procedure oracle pl sql compiled successfully tried execute shown set serveroutput execute passenger details trying execute stored procedure im getting following error message shown error starting line command begin passenger details end error report ora line column pls wrong number types arguments call passenger details ora line column pl sql statement ignored line column cause usually pl sql compilation error action
182275 need come best approach possible enable page compression table gb size rows database size tb holds archive data understand correctly needs disk space possibly amount safer side create copy table page compression enabled release space full recovery model heavily logged spoken capacity planning resource agreed give additional temporary required space maintenance take back space activity complete said think best approach take full backup restore backup onto new temp drives change recovery model simple enable page compression take full backup compression restore original database change recovery model full also instead enabling page compression step truncate largest table enable page compression select replicadb dbo replicatbl enable page compression existing indexes test environment test steps alternatively better approach available please let know goal minimize future disk space required current growth erp software company licensed enterprise edition table archive checks performed data resides table indexes ci non ci none columns varchar max either nvarchar int date type
182331 clause want use case expression however case expression needs check field null userrole variable value analyst supervisorapprovedby column value must null otherwise saying return data supervisorapprovedby supervisorapprovedby need change supervisorapprovedby case userrole analyst null else supervisorapprovedby end use null tested work would want rows returned including supervisorapprovedby null
182410 table like create table updates updateid int null identity11 primary key objectid int null essentially tracking updates objects increasing id consumer table select chunk distinct object ids ordered updateid starting specific updateid essentially keeping track left querying updates ive found interesting optimization problem ive able generate maximally optimal query plan writing queries happen want due indexes guarantee want select distinct top objectid updates updateid fromupdateid fromupdateid stored procedure parameter plan select top hash match flow distinct rows touched index seek due seek updateid index used results already nice ordered lowest highest update id like want generates flow distinct plan want ordering obviously isnt guaranteed behavior dont want use trick also results query plan though redundant top ids select objectid updates updateid fromupdateid order updateid offset rows select distinct top objectid ids though im sure suspect truly guarantees ordering one query hoped sql server would smart enough simplify ends generating bad query plan select top objectid updates updateid fromupdateid group objectid order minupdateid plan select top sort hash match aggregate rows touched index seek im trying find way generate optimal plan index seek updateid flow distinct remove duplicate objectids ideas sample data want objects rarely one update almost never one within set rows im flow distinct unless theres something better dont know however guarantee single objectid wont rows table table rows expected grow rapidly assume user another way find appropriate next fromupdateid need return query
182420 university professor taught year sql statement select countlength product return following dataset product id length code x00 c02 a31 justified saying count doesnt count duplicates told professor thought made error answered dbms may may count duplicates trying lot dbms ive never found one behaviour dbms exist reason professor teach behaviour without even mentioning dbms may behave differently fyi course support available french concerned slide lower left corner page
182580 table like create table aggregated master user bigint type text date timestamp operations bigint amount numeric primary key user type date table master lot partitions inherit partitions done month date field example partition aug would agg pk would pk agg usual trigger insert redirect insert proper partition thing want upsert table conflict part working code first like insert aggregated master user type date oeprations amount select user type date sumops sumamt group user type date conflict constraint pk aggregated update set operations excluded operations amount excluded amount noticed constraint pk aggregated one master table child table insert really performed due trigger changed clause conflict conflict user type date fields pk doesnt work either idea make work
182728 ive come across multiple times im sure good reason avoid im sure quirks around isnumeric english view filters isnumericsomefield try query using int clause field table character values whole thing fails created sql fiddle shows error tried cast convert select view query engine seems ignore happen clean way deal original fiddle similar error due missing quotes insert problem trying highlight fixed view adding quotes values inserted
182731 im getting error thought impossible sql server ver table looks like create table idmaster id int null constraint pk idmaster primary key clustered id asc primary primary basically supposed identity around used get new unique integer values used tables sql statement selects max value adds inserts value table inside one statement theory possible get pk violation statement although think could possibly get deadlock somehow getting one violation primary key constraint pk idmaster insert duplicate key object idmaster duplicate key value dont know possible apparently happened imagine crazy odd mixture ways try generating new id value table probably arent far exists system cant think way could cause particular error understanding transaction locking used sql server enforces within one sql statement doesnt nolock anything cant interference rows referencing factor dont think could related knows sql wrapped try options set heres sql got error set xact abort set implicit transactions begin try insert idmaster id select coalesce make sure new value odd case maxcoalesceid0 maxcoalesceid0 else maxcoalesceid0 end1 idmaster end try begin catch trancount rollback throw end catch trancount commit please explain possible get error possible prevent ever happening without altering table
182860 apologies havent used correct terminology dba right situation last week database server misbehaving years old hosting company built new server moved current data across new server running well however somehow new server missing hours data hosting company provided us backup contains data amongst things tables auto generated keys type integer way restoring set data date range back live database obviously cant cut paste integrity data lost thoughts windows server microsoft sql server
183046 use sql spotlight environment pretty handy use particularly output sys dm exec requests sys dm exec query stats spotlight pulls query plan plan cache using hash nice problem unless youre experienced code base quite difficult know query came idea could parse codebase pull sql queries hash way microsoft way could quick matches hash able see codebase particular query came alternatively id slow regex
183087 given following data create table histories username varchar10 account varchar10 assigned date insert histories values philaccount12017 peteraccount12017 daveaccount12017 andyaccount12017 daveaccount12017 fredaccount12017 jamesaccount12017 daveaccount22017 philaccount22017 joshaccount22017 jamesaccount22017 daveaccount22017 philaccount22017 represents given user assigned account looking establish owned given account last day month assigned date date account transferred ownership missing month ends populated possibly created handy dates table available useful columns datekey date lastdayofmonth courtesy aaronbertrand desired results would peter account1 peter account1 dave account1 dave account1 fred account1 fred account1 fred account1 james account1 phil account2 phil account2 phil account2 james account2 phil account2 initial part windowing function trivial adding missing rows im struggling
183891 im playing postgres table validation rules trying set check constraint array column idea allow arrays length want implement create table words table id serial primary key words varchar20 check array lengthwords looks like doesnt work insert words table words values insert implement constraint
183984 database detached instance permanently cleanup tasks done
184149 stumbled upon question twitter conversation lukas eder although correct behavior would apply order clause outermost query using distinct group join clause outermost query wouldnt rdbms pass incoming data sorted inner query select select table order time desc running example postgresql least get execution plan inner query derived table example well result set would assume planner simply discard outermost query redundant simply pass results inner table anyone think might case
184288 im trying better understand numeric types sql read decimal type always require bytes however ms docs list table indicating amount space used depends decimals precision tried test using datalength function create table tbl testdecdec1 decimal194 dec2 decimal204 dec3 decimal94 insert tbl testdec select select datalengthdec1 datalengthdec2 datalengthdec3 tbl testdec outputs expecting either im using sql server decimals vardecimal misunderstanding datalength function
184525 using sql server several tables pk field int also uniqueidentifier field need query field always unique adding indexes option choosing index unique key benefit choosing one
184617 im setting saas system planning give customer database system already set easily scale additional servers load becomes great hoping thousands even tens thousands customers questions practical limitation number micro databases one sql server affect performance server better databases mb one database tb additional information say micro databases dont really mean micro mean aiming thousands customers individual database would thousandth less total data storage reality database would around 100mb mark depending much usage gets main reason use databases scalability fact v1 system one database uncomfortable moments db straining load straining cpu memory even though fixed problems made us realize point even best indexing world successful hope simply cant put data one big honkin database v2 sharding split load multiple db servers ive spent last year developing sharded solution one license per server anyway thats taken care since using vms azure reason question comes previously offering large institutions setting one next order business self service model anyone browser sign create database databases much smaller much numerous large institutions tried azure sql database elastic pools performance disappointing switched back regular vms
185044 im unclear true meaning definitions immutable volatile stable functions read documentation specifically definitions immutable indicates function modify database always returns result given argument values database lookups otherwise use information directly present argument list option given call function constant arguments immediately replaced function value stable indicates function modify database within single table scan consistently return result argument values result could change across sql statements appropriate selection functions whose results depend database lookups parameter variables current time zone etc inappropriate triggers wish query rows modified current command also note current timestamp family functions qualify stable since values change within transaction volatile indicates function value change even within single table scan optimizations made relatively database functions volatile sense examples random currval timeofday note function side effects must classified volatile even result quite predictable prevent calls optimized away example setval confusion comes condition immutable stable function always consistently returns result given arguments immutable definition states function database lookups otherwise use information directly present argument list means functions used manipulate data provided client select statements although sounds bit odd stable definition similar says consistently return result means everytime function called arguments return results exact rows every single time means function performs select table tables updated volatile doesnt sound right bringing back use case writing functions perform select statements multiple joins tables constantly added function calls would expected return different results time called even arguments mean functions volatile even though documentation indicates relatively database functions volatile sense thank
185123 need able locate missing element table tens millions rows primary key binary64 column input value calculate values mostly inserted order occasion want reuse previous value deleted infeasible modify deleted records isdeleted column sometimes row inserted many millions values ahead currently existing rows means sample data would look something like keycol binary64 0x 0x 0x ffffffffffff inserting missing values 0x000000000002 0xffffffffffff infeasible amount time space used would undesirable essentially run algorithm expect return 0x000000000003 first opening ive come binary search algorithm would query database value position test value expected context terrible algorithm https codereview stackexchange com questions binary search missing default value given formula algorithm would run example sql queries table items doesnt seem like lot going occurring frequently currently table approximately rows performance becoming noticeable first alternative thought translate stored procedure hurdles write binary64 binary64 algorithm well slew things would painful infeasible ive also considered implementing translation algorithm based row number really bad gut feeling bigint nearly big enough values im suggestions really need quick possible worth column selected query keycol others irrelevant portion also worth current query fetches appropriate record along lines select keycol table order keycol asc offset value rows fetch first rows value index supplied algorithm also havent bigint issue offset yet rows right means never asks index value point itll get bigint range additional data deletions gap sequential ratio last rows table values bigints maximum
185376 xml response structure different nodes xml version encoding utf orders order orderid orderid amountpaid currencyid eur amountpaid userid marc58 userid shippingaddress name marc jupp name address rue address city paris city stateorprovince stateorprovince country fr country phone phone postalcode postalcode shippingaddress shippingcosts shippingcosts items item details itemid itemid store store title mcpu dda010 title sku mmx sku details quantity quantity price currencyid eur price item item details itemid itemid store store title mcpu dfz42 title sku mmy sku details quantity quantity price currencyid eur price item items order orders need store info different tables item table need create record different item inserting also order node details like itemid store title sku quantity price orderid amountpaid userid shippingcost dda010 mmx marc58 dfz42 mmy marc58 write different tables required info automatically built great help community query set t1 orders set f1 orderid set select iif charindex valuelocal name nvarchar100 concat isnull quotenamet valuelocal name nvarchar100 iif charindex valuelocal name nvarchar100 cp concat isnull valuentext nvarcharmax iif charindex valuelocal name nvarchar100 cp concat isnull quotename valuelocal name nvarchar100 valuentext nvarcharmax iift valuelocal name nvarchar100 f2 valuetext nvarchar100 xml nodes countchild tx valuenlocal name nvarchar500 select name db1 sys columns object id object id t1and identity select stuff select stuff select stuff set nif exists select t1 f1 insert t1 values else update t1 set f2 print exec sp executesql set t1 users ok better use loop query although surely improved optimized working well since item node item nodes returns first one tried modify clause trying refer item collection without success think even succeed iterating items nodes idea get order node details parent item node suggest solution thanks
185662 situation need change relationship tables need create cross reference table two tables migrating existing data child table cross reference table would bad idea delete original foreign key column child table leave basically technical debt im dba dont good grasp implications deleting column table know possible bad idea database hate thanks
186257 trying return multiple records using record data type way append record add append new value iteration record want append rec rec becomes set rows loop return end function currently select temp table col1 temp table col2 temp table col3 rec temp table temp table col3 false full code create replace function validation returns record declare rec record temp row record begin create temporary table temp table col1 text col2 integer col3 boolean commit drop temp row select staging validation loop raise notice sql temp row sql execute formatinsert temp table temp row sql select distinct temp table col3 temp table temp table col3 false false raise notice false value select temp table col1 temp table col2 temp table col3 rec temp table temp table col3 false end end loop return rec end language plpgsql current output select validation validation crea ddf8095f desired output validation crea ddf8095f source systemsome countf source systemsome countf
186339 database sql server several queries exactly ways except value one filter terms table copy schema another server therefor indexes resources etc everything absolutely identical query runs one second select maxmessageid maxid boothcomm universalmessagequeue messageplatform linux query runs one second select maxmessageid maxid boothcomm universalmessagequeue messageplatform linux messagecategory accounting query runs one second select maxmessageid maxid boothcomm universalmessagequeue messageplatform windows one take nearly seconds run select maxmessageid maxid boothcomm universalmessagequeue messageplatform windows messagecategory accounting colleague mine added another index table resolved business problem latency index reduced seconds full second speeding queries instantaneous execution plans exactly index scan taken advice forums made sure column order query matched order stored index create nonclustered index messageid platform category boothcomm universalmessagequeue messageid asc messageplatform asc messagecategory asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary go also providing table schema event helpful create table boothcomm universalmessagequeue messagequeueid bigint identity11 null messageid bigint null messageplatform nvarchar null assetnumber nvarchar null messagestate int null messagestatelabel nvarchar null messagetype int null messagetypelabel nvarchar null messagecategory nvarchar null messagesource int null messagesourcelabel nvarchar null messagesourceserialnumber nvarchar null messagecreatedate datetime null messagetransmitdate datetime null messagereceiveddate datetime null messagestoreddate datetime null xmlpayload nvarchar max null jsonpayload nvarchar max null semanticxml nvarchar max null semanticjson nvarchar max null messagesequencenumber int null erpimportdate datetime null erpimportstatus int null erpmsg nvarchar max null normalizationdate datetime null normalizationstatus int null normalizationdesc nvarchar max null semanticdate datetime null semanticstatus int null semanticdesc nvarchar max null createddate datetime null default getdate createdby nvarchar null default etl updateddate datetime null default getdate updatedby nvarchar null default etl etl id uniqueidentifier null primary key clustered messagequeueid asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary constraint ck etl unique messageid platform unique nonclustered messageid asc messageplatform asc messagetype asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary textimage primary go provide enough code reproduce problem fill table million records see problem since brought couple times even thought check looked see many windows records versus linux records select count boothcomm universalmessagequeue messagecategory accounting messageplatform linux returned select count boothcomm universalmessagequeue messagecategory accounting messageplatform windows returned guessing recordcount issue
186597 single instance sql server sp1 running vmware virtual machine contains databases different application applications separate virtual servers none production use yet people testing applications reporting performance issues though stats server gb ram 110gb max memory sql server cores ghz gbit network connection storage ssd based program files log files database files tempdb separate partitions server asd users performing single screen access via based erp application stress test sql server microsofts ostress using either many small queries big query get max performance thing throttling client cant answer fast enough barely users sql server barely anything yet people wait forever save anything application according paul randals tell hurts query wait events async network io could either mean network issue performance issue application server client neither even remotely using resources maximum capacity time cpu around machines client appserver db server latency network connection around 3ms io db server max 20mb write speed normal usage application avg 9mb stress test get around max 5gb buffer cache size 60gb db erp system 20gb financing software 1gb quality assurance software 3gb document archiving system gave sql server account right use instant file initialization didnt increase performance slightest page life expectancy around 15k normal use drops around 05k end heavy stress testing expected batches sec around 8k depending workload id say erp app badly written cant applications affected even minimal workload yet cant pinpoint causing tips hints tutorials applications best worst practices documents anything else guys mind regarding problem results sp blitzfirst ran seconds started high workload app time async network io also tested network connection ntttcp psping ipferf3 pathping nothing unusual response times max 3ms avg 3ms throughput around mb investigation always results async network io number one waitstat investigated result disabling large receive offload feature vmware still testing results seem inconsistent first benchmark resulted duration minutes top result minutes achieved app running vm sql server second result minutes really bad first result benchmark minutes good top result minutes achievable application benchmarks vm sql server strongly hints network related issue issue vmware configuration currently lost methods use nail bottleneck maximum performance app achievable app running vm sql server app executed vm virtual desktop duration benchmark gets tripled minutes duration minutes endpoints vm sql server vm app server virtual desktop using physical hardware weve moved endpoints hardware edit seems like problem back setting energy savings mode balanced high performance actually improved response times dramtically today ran sp blitzfirst seconds sample result shows second wait time async network io seconds sp blitzfirst ran
186631 use following statement monitor activity sql server book select des session id des status des login name des host name der blocking session id db nameder database id database name der command des cpu time des reads des writes dec last write des program name der wait type der wait time der last wait type der wait resource case des transaction isolation level unspecified readuncommitted readcommitted repeatable serializable snapshot end transaction isolation level object namedest objectid der database id object name substringdest text der statement start offset case der statement end offset datalengthdest text else der statement end offset end der statement start offset executing statement deqp query plan sys dm exec sessions des left join sys dm exec requests der des session id der session id left join sys dm exec connections dec des session id dec session id cross apply sys dm exec sql textder sql handle dest cross apply sys dm exec query plander plan handle deqp des session id spid order activities shown create index alter table monitor activities sql server activity monitor profiler option plain sql sysadmin view server state
186638 query runs much faster select top much slower without top number returned records could explain difference query plans share links difference explained query without top text select top inventtrans join inventdim inventdim dataareaid dat inventdim inventdimid inventtrans inventdimid inventtrans dataareaid dat inventtrans itemid inventdim inventlocationid inventdim ecc businessunitid query plan without top https pastebin com cbtjpxff io time statistics without top sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms rows affected table inventdim scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table inventtrans scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms used indexes without top inventtrans 177transididx keys dataareaid inventtransid inventdimid recid inventtrans 177itemidx keys dataareaid itemid datephysical inventdim 698dimididx keys dataareaid inventdimid query top select top inventtrans join inventdim inventdim dataareaid dat inventdim inventdimid inventtrans inventdimid inventtrans dataareaid dat inventtrans itemid inventdim inventlocationid inventdim ecc businessunitid query plan top https pastebin com 0dyu6qzd query io time stats top sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms rows affected table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table inventtrans scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table inventdim scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads rows affected sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms sql server execution times cpu time ms elapsed time ms used indexes top inventtrans 177transididx keys dataareaid inventtransid inventdimid recid inventtrans 177dimididx keys dataareaid inventdimid itemid inventdim 698dimididx keys dataareaid inventdimid inventdim 698ecc busunitlocidx keys dataareaid ecc businessunitid inventlocationid deeply appreciate help topic
186778 recently issue transaction log grew maxed storage space happened maintenance window ola hallengren index optimize scripts used reason someone past set transaction log backups stop hours seems indexing jobs running set run hours organization recently migrated sql server 2008r2 person worked migration changed window transaction logs min shorter start 30am think believed stopped full backup believe stopped let index maintenance run necessary either case seems like stopping tlog back ups would harm helping sql server 2008r2 schedule 00am transaction log backups stopped 00am weekly index optimize job starts failed hours min due log space 00am full backup 00am changed 30am transaction log backups start log remains full additional info organization recently upgraded sql server 2008r2 2008r2 never experience enterprise edition could coincidence could upgrade changed something one offer advice check cause server admin set jobs back original schedule tran log back ups 3am 6am believing overlap index maintenance transaction log backups causing issue could true research subject transaction logs seems like actually log backups maintenance window shutting im bit confused stopped first place original admin longer company im even confused seems issue migration
187090 reviewing question seems like thats lot work shouldnt needed theyre trying extend range date databases would use greatest least leastextenddatemin greatestextenddatemax try use though get least recognized built function name greatest recognized built function name would cover extension either direction purposes question would still exclusive range replacement im wondering sql server users implement query patterns mimic least greatest functionality postgresql greatest least mysql greatest least mariadb greatest least db2 greatest least oracle greatest least unroll conditions case statements extension third party add license microsoft enables functionality
187207 sql server r2 running virtual windows r2 server upgrading cpu core ram gb gb weve noticed performance worse observations see query took seconds run taking seconds cpu pegged sqlservr exe culprit select count table million rows took seconds processes running server havent changed change increase cpu ram sql servers static paging file server set manage anyone run issue per sp blitzerik ran exec dbo sp blitzfirst sincestartup giving results
187342 much written perils scalar udfs sql server casual search return oodles results places scalar udf option though example dealing xml xquery cant used computed column definition one option documented microsoft use scalar udf encapsulate xquery scalar udf use computed column various effects workarounds executes row row table queried forces queries table run serially get around row row execution schemabinding function either persisting computed column indexing neither methods prevent forced serialization queries hitting table even scalar udf isnt referenced known way
187369 column delimiter looks like abc efg hij want query turns three columns col1 col2 col3 wondering fastest way far havent able well limited database experience ive got function create function dbo split delimited nvarcharmax delimiter nvarchar100 returns table id int identity11 val nvarcharmax begin declare xml xml set xml replace delimited delimiter insert tval select value varcharmax item xml nodes recordsr return end im right believe could made go much faster im also open significantly better function outside box ideas splitting strings believe im running dbo splitname three times could running select col1 select val dbo splitname id col2 select val dbo splitname id col3 select val dbo splitname id mains help would greatly appreciated
187568 sql server standard ed windows core 128gb machine vm actually max prod db 122gb instance cores instance setting 2nd db spindle set slower disks want impact prod db vm understand use existing sql license way must 2nd db served sql instance order restrict ram consumed little gb restrict cpu cores restrict db within main instance note express edition option db gb
187688 implement always encrypted feature sql server mdf files ldf files bak files get encrypted well would like know data log backup files gets encrypted
187807 im curious say table million records rows select order value store orders make difference whether table field fields fields actual query time mean fields order value right im pushing data data warehouse sometimes dump fields table may used future someday arent queried right anything would extraneous fields affect select statements include directly indirectly mean
188016 finished reading excellent article isolation levels company soon start development rewrite expansion current product desire oltp database separate denormalized reporting database assuming somewhat disciplined ad hoc reporting type queries actually go reporting database sound appropriate oltp database default isolation level read committed wont need stringent isolation level oltp reporting database snapshot isolation probably rcsi thinking oltp database actually true oltp database serving double duty reporting db wont need snapshot isolation associated overhead entails snapshot isolation would desirable reporting database readers blocked constant flow data coming reading last saved version row would acceptable
188044 im training one scripts following command select sumcol2 clust table col1 would like know snippet clause col1 research internet found references command
188203 ive deep dive sql server query store often see references ad hoc queries however havent seen query store determines ad hoc query ive seen places could inferred query without parameters query executed one time formal definition exist dont mean general mean relates query store example page shows example removing ad hoc queries query store appears criteria using execution count one seems odd definition ad hoc query btw go page search delete ad hoc queries
188231 interested terminology characters put around table names column names etc referencing query name microsoft sql server would mysql would possibly unable find generic term anywhere wondering one exists
188335 sorry probably basic question literature online came across two different definitions weak entities may sometimes contradictory weak entity entity exist without owner entity weak entity primary key rather partial key uniquely identified combining partial key foreign key owner entity one true let us take example customers orders relationship orders unique orderid order exist without customer however still primary key would strong weak entity
188667 writing application needs store analyze large amounts electrical temperature data basically need store large amounts hourly electricity usage measurements past several years many years come tens thousands locations analyze data complex manner information need store location id timestamp date time temperature electricity usage amount data needs stored approximation something along lines locations records per month hourly measurements approximately hours per month months years back many years future simple calculations yield following results locations records months years back records past records new records imported monthly thats approximately new records per month total locations steadily grow well data following operations need executed retrieve data certain date time period records certain location id dates simple mathematical operations certain date time range min max avg temperature electricity usage certain location id years data written monthly read hundreds users least constantly read speed significantly importance experience nosql databases ive gathered best solution use ive read popular nosql databases since quite different also allow different table architecture able decide best database use main choices cassandra mongodb since limited knowledge real experience comes large data nosql certain also read postresql also handles amounts data well questions following use nosql database large amounts data stick mysql database use keep date time separate indexed possible columns retrieve process data quickly certain time date periods done keeping timestamp single column time series data modeling approach appropriate could give pointers good table design thank
188793 plan plan almost identical tables small difference row count one indexing identical vms exact environment upgraded os sql server versions number vcores memory server settings max degree parallelism cost threshold parallelism drop dead simple query single record using single column filter single column return column filter sole column index version rows version rows queries missing index full table scan apparent reason rid lookup heap table index scan tried index contact rc nui1 server cost jumped cost tried adding select made difference tried removing parameter sniffing possible problem using option recompile made difference dba ran index rebuilds restoring database servers fairly recent index stats updates run olas index update script sure rebuilt index effect explain plan added hint query select address1 stateorprovince dla dcrm contact rc index contact rc nui1 wv partyid resulted taking cost even though shows almost identical explain plan added parallelism gather streams appears costing index rid lookup reversed appears used index scan entries looked every rid table could true think optimizer smoking something seriously strong wv party id nvarchar100
189484 dynamics ax caching mechanism tables configured loaded memory cached cache limited certain amount kb prevent memory issues setting im talking called entiretablecache loads whole table memory soon single record requested recently relied scripts verify size tables setting see table size limit however compression comes play things like sp spaceused sys allocation units seem report space actually used compressed data obviously application server working uncompressed data data size disk sql server irrelevant need actual size uncompressed data know sp estimate data compression savings name says estimate would prefer size correct possible way could think convoluted dynamic sql creating uncompressed tables structure compressed tables inserting compressed data shadow table check size shadow table needless say bit tedious takes run database several hundreds gb powershell could option wouldnt like iterate tables perform select check size script would flood cache would probably take long time short need way get size table uncompressed fragmentation equation presented application thats possible im open different approaches sql preferred im opposed powershell creative approaches assume buffer application size data bigint always size bigint character data type bytes per character unicode blob data takes size data enum basically int numeric data numeric3812 datetime size datetime also null values either stored empty string zero documentation implemented assumptions based testing scripts used pfes support team also ignore compression apparently since check built application app cant tell underlying data compressed also check table sizes link example states avoid using entiretable caches large tables ax kb pages ax entire table cache size application setting default 32kb pages move record caching instead
189607 delete millions records million row table going extremely slowly appreciate share suggestions make code faster set transaction isolation level read committed declare batchsize int iteration int totalrows int msg varchar500 set deadlock priority low set batchsize set iteration set totalrows begin try begin transaction batchsize begin delete top batchsize mysourcetable output deleted mybackuptable exists select null empty dbo vendor vendorid id set batchsize rowcount set iteration iteration set totalrows totalrows batchsize set msg castgetdate varchar iteration cast iteration varchar total deletes cast totalrows varchar next batch size cast batchsize varchar print msg commit transaction checkpoint end end try begin catch error trancount begin print error occured database update failed rollback transaction end end catch go execution plan limited iterations vendorid pk non clustered clustered index use script non unique non clustered indexes task removing vendors exist another table back another table tables vendors specialvendors specialvendorbackups trying remove specialvendors exist vendors table backup deleted records case im wrong put back week two
189676 would like understand cyber security teams general one organization ive dealt dead set granting bulk insert tsql rights applications database programmers cant believe filling disk abuse excuse unless im missing something end result different application something like long long max executesql insert table values insert common dml command anyone basic write permission execute applications benefit bulk insert far efficient faster relieves programmer need parse files outside sql edit originally asked question information security site reason dbas using bulk insert information assurance ia short cybersecurity folks forcing issue ill let question stew another day two bulk operation indeed bypass constraints triggers see issue
189928 im trying backup restore mongodb database gz files sample script create gz backup ok r3 r3 mongodump db db name gzip archive backup file gz restore gz file ok r3 mongorestore gzip archive backup file gz nsfrom db name nsto db name restore step back good mongodb version r3 r3 though step works r3 get mongorestore version r3 restore gz file able rename database solution requires backup folder backup files huge 1gb 2gb extraction much time consuming
190073 hi im trying truncate tables db related foreign key constraints every time try sql server throws error like truncate table table referenced foreign key constraint dont want drop tables delete friend told truncate cascade case havent found info related also user told try try im still getting tables truncated also read script foreign keys drop create use truncate script supposed affect db least thought running unable truncate tables threw error im using sql server r2 running queries version ssms
190090 suggestions deal error title microsoft sql server setup following error occurred vs shell installation failed exit code help click https go microsoft com fwlinklinkid prodname microsoft 20sql 20server evtsrc setup rll evtid prodver evttype 0x5b39c8b9 buttons ok new laptop running sql server express visual studio ssms tried uninstalling anything related sql server visual studio log 03t16 e000 error 0x80070666 install product newer version installed detailed results feature full text semantic extractions search status failed reason failure error occurred dependency feature causing setup process feature fail next step use following information resolve error try setup process component name microsoft visual redistributable component error code component log file program files microsoft sql server setup bootstrap log vcruntime140 x64 cpu64 log error description vs shell installation failed exit code error help link https go microsoft com fwlinklinkid prodname microsoft sql server evtsrc setup rll evtid prodver evttype vcruntime140 x64 40install 400x1638 feature database engine services status failed reason failure error occurred dependency feature causing setup process feature fail next step use following information resolve error try setup process component name microsoft visual redistributable component error code component log file program files microsoft sql server setup bootstrap log vcruntime140 x64 cpu64 log error description vs shell installation failed exit code error help link https go microsoft com fwlinklinkid prodname microsoft sql server evtsrc setup rll evtid prodver evttype vcruntime140 x64 40install 400x1638
190782 environment network storage low space time would like make sure take transaction log backups every minutes instead current every hours question changing log backup interval hours every minutes consume disk space
191146 writing batch processing insert statement would like use temp table keep track inserted ids instead looping items calling scope identity inserted row data needs inserted temporary ids linking data also inserted another table need cross reference actual id temporary id example far existing table declare mytable table id int identity11 name nvarcharmax data want insert declare myinsertdata table id int name nvarcharmax insert myinsertdata idname values bla 2test 3last declare mycrossref table newid int oldid int insert mytable name output inserted id ins id mycrossref select name myinsertdata ins check result select mycrossref problem get output clause accept id ive tried myinsertdata id tricks joining table nothing seems work
191393 recently upgraded localdb version using sql server express installer instruction installation stopped existing default instance mssqllocaldb version created new one automatically used v14 server engine often use localdb database integration tests xunit tests create temporary database deleted test finishes since new version unfortunately tests fail following error message create file encountered operating system error 5access denied attempting open create physical file users kepfldbd0811493e18b46febf980ffb8029482a mdf odd thing target path mdf file incorrect backslash missing users kepfl dbd0811493e18b46febf980ffb8029482a mdf random database name single test databases created via simple command create database databasename nothing special ssms see target locations data log backup following however try update location get another error message update default locations localdb able create databases obvious localdb correctly combine default location directory database file name registry entry edit anything else update dougs answer sepupics comment according stackoverflow question default locations also changeable via registry however try find corresponding keys defaultdata defaultlog backupdirectory find registry sql server v14 rename registry keys moved information registry
191440 even possible use case ledger table requirement record created read one able edit delete applies ledger table tables direct relation tables schema updated deleted normal understanding data integrity purposes sorts constraints applied database layer cant find clean widely accepted way use case id better application layer ideal would way plain sql agnostic db platform used since may subject change realise may much ask platform dependent flavour mysql preferred thank
191552 requirement find potentially matching customer records table logic per however seems perform anyway improve performance ive tried setting indexes hashing columns comparing etc performance remains terrible large dataset ive also added query plan select c1 customerid customer1 c2 customerid customer2 customer c1 inner join customer c2 c1 customerid c2 customerid c1 firstname c2 firstname c1 birthdate c2 birthdate c1 emailaddress c2 emailaddress c1 mobilephonenumber c2 mobilephonenumber c1 homeaddressline1 c2 homeaddressline1 c1 homepostcode c2 homepostcode c1 homesuburb c2 homesuburb
191595 given table create table test id int null description nvarchar100 collate modern spanish ci null insert test id description values co2 ive realised cant fix typographic issue select test id update test set description co id select test id update matches effect id description co2 affected rows affected rows id description co2 affected rows sql server determines since obviously tiny final value wont change worth changing could someone shed light maybe suggest workaround updating intermediary value
191803 move tempdb data log files wherever different drive folder
191825 ive noticed server running sql server sp1 cu6 sometimes extended events session shows select query causing writes example execution plan shows obvious cause writes hash table spool sort could spill tempdb variable assignment max type automatic statistics update could also cause neither cause writes case else could writes
192208 read json objects json object type want select return json necessarily want store json object serialization per se question columns regular varchar int etc columns json objects normal database rows regular old select return json mysql isnt json sql server rows json postgresql seemed ahead didnt want fool found question https stackoverflow com questions mysql return row json using new json features
192364 following configuration host machine runs three docker containers mongodb redis program using previous two containers store data redis mongodb used store huge amounts data know redis needs keep data ram fine unfortunately happens mongo starts taking lot ram soon host ram full talking 32gb either mongo redis crashes read following previous questions limit mongodb ram usage apparently ram used wiredtiger cache mongodb limit memory apparently problem log data limit ram memory usage mongodb suggest limit mongos memory uses smaller amount memory cache logs data mongodb using much memory say wiredtiger caching system tends use much ram possible provide faster access also state completely okay limit wiredtiger cache size since handles operations pretty efficiently option limit mongodb memory usage caching also add mongodb uses lru least recently used cache algorithm determine pages release find information two questions mongodb index ram relationship quote mongodb keeps indexes ram theyll swaped lru basis youll often see documentation suggests keep working set memory portions index youre actually accessing fit memory youll fine release caching used mongodb answer appear understand answers faster access would better mongo fit indices ram however case fine indices partially residing disk quite fast ssd ram mostly used caching mongo considering expecting mongo try use much ram space possible able function also ram space fetching things disk however limited mongo docker containers memory 8gb instance using memory memory swap instead fetching stuff disk mongo crashed soon ran memory force mongo use available memory fetch disk everything fit memory
192524 best way flatten tables single row example following table id hprop idayofmonth dbltargetpercent would like produce following table hprop idatetarget1 dblpercenttarget1 idatetarget2 dblpercenttarget2 idatetarget3 dblpercenttarget3 idatetarget4 dblpercenttarget4 managed using pivot rejoining original table several times im fairly sure better way works expected select x0 hprop x0 idatetarget1 x1 dbltargetpercent dblpercenttarget1 x0 idatetarget2 x2 dbltargetpercent dblpercenttarget2 x0 idatetarget3 x3 dbltargetpercent dblpercenttarget3 x0 idatetarget4 x4 dbltargetpercent dblpercenttarget4 select hprop max idatetarget1 max idatetarget2 max idatetarget3 max idatetarget4 select rank partition hprop order iweek rank table pivot maxiweek rank pv group hprop x0 left join table x1 x1 hprop x0 hprop x1 iweek x0 idatetarget1 left join table x2 x2 hprop x0 hprop x2 iweek x0 idatetarget2 left join table x3 x3 hprop x0 hprop x3 iweek x0 idatetarget3 left join table x4 x4 hprop x0 hprop x4 iweek x0 idatetarget4
192901 note understand risks involved possibility destroying production system im interested anyway whenever try play system catalogs gets weird errors update sys sql logins set password hash pwdencryptpass name sa error produced msg ad hoc updates system catalogs allowed ive tried numerious ways take training wheels sp configure allow updates go reconfigure go cant figure right option even says answer longer possible least without jumping ton additional hoops beyond sp configure option something ever want production system system catalog exposed read views like sys objects well want jump hoops
193138 user ls readonly supposed db datareader privileges several databases thought set right connect server ls readonly try open db object explorer get error database wtest accessible objectexplorer open query window master try run use wtest responds msg level state line server principal ls readonly able access database wtest current security context missing update heres clue delete ls readonly user databases security context go user servers security context user mapping grant access database starts working could database originally restored different server also ls readonly user guess user identification based username
193154 table like id date name score erin erin emil erin paul john john erin want data back years based year provide using select tblstdnt date dateaddyeardatediffyear0 gives data starting fix ideas give data year period regardless month day update dbfiddle link
193287 im working project using instagram key format tl dr bit integer ids theyll used lookups also like sorting batching since naturally sort creation time values big fit inside bigint seems options storage numeric20 varchar varchar ideal since wed zero pad sorting work would performance hit using numeric lookups
193362 problems queries similar select counta dbo oinv t0 inner join dbo ocrd t2 t2 cardcode t0 cardcode t0 cardcode p2 t2 fathercard p3 query plan indexes hitting defined nonclustered index ocrd father dbo ocrd fathercard asc include cardcode nonclustered index oinv customer dbo oinv cardcode asc theyre currently taking seconds run returns count expecting im incredibly surprised filtering nonclustered indexes feeds hash match feeding every single row vendor software queries unfortunately theres way us rewrite way change filter hash match without rewriting query example data setup create table dbo ocrd fathercard nvarchar50 cardcode nvarchar50 insert dbo ocrd select top newid newid master spt values v1 master spt values v2 master spt values v3 create table dbo oinv cardcode nvarchar50 insert dbo oinv select top newid master spt values v1 master spt values v2 master spt values v3 create nonclustered index ocrd father dbo ocrd fathercard asc include cardcode create nonclustered index oinv customer dbo oinv cardcode asc
193394 say table car one one relationship tables electric car gas car hybrid car car electric car longer appear gas car hybrid car etc anything wrong design problems may occur road
193777 im trying run recursive alter table reading couple parameters sys table declare altercmd nvarcharmax select top altercmd alter table dbo table alter column column name nvarchar character maximum length information schema columns table name table name data type like char print altercmd sample code want validate command coming right possible run due error concatenate according error message get msg level state line conversion failed converting varchar value data type int
193783 onward sql server docs show support offset fetch im trying use instead limit following works fine postgresql sample result set select values tx offset rows fetch next rows however sql server get msg level state line invalid usage option first fetch statement whats going sql server support standardized offset fetch
193875 found postgresql create function drop function locking used inside different transactions answers isnt exactly question though similar lets say following create function myfunc start transaction client start transaction client transaction use create replace function revise definition myfunc commit transaction call myfunc transaction happens step calling original function defined step modified form step committed step function dropped step rather modified step fail succeed probably question modifications may work differently documentation
194131 table storing parent child records custid custname deptid company parentcustid enrolled sally ab1 comp1 null ajit ab7 comp2 rahul de1 comp3 uday tg6 comp4 john hy7 comp5 netaji hy5 comp6 prakriti gt6 comp7 sachin kl7 comp8 santosh kk5 comp9 ravi pp0 comp10 possible return records parent record enrolled related child record enrolled returns need specific customer select custid custname deptid company parentcustid enrolled customer company comp1 enrolled union select custid custname deptid company parentcustid enrolled customer parentcustid enrolled custid custname deptid company parentcustid enrolled sally ab1 comp1 null sachin kl7 comp8 structure query return type result set parent child records table
194222 recently upgraded postgresql postgresql one nifty features postgresql new identity column type alternative postgresql serial pseudo type official documentation identity column found one create table page however inserting multiple rows table generated default identity column using keyword default get next id value default value coming back null example lets say table create table test id int generated default identity text create table inserting single row default keyword seems work fine insert test id values default insert inserting multiple rows insert test id values default default error null value column id violates null constraint detail failing row contains null inserting multiple rows using implicit default also works insert test values insert problem specified appear present using serial column pseudo type create table test2 id serial text create table insert test2 id values default default insert question missing something default keyword expected work new identity column bug
194315 im ideas im asking help weird problem find cause matter much search internet thing two laptops l1 hdd kingston hyperx fury sata iii ssd 240g l2 hdd samsung evo nvme ssd 500g procedure test performance database inserts selects deletes different tables numbers l2 bought l1 tried migrate everything l1 l2 including databases running performance procedure noticed something weird l2 taking way l1 taking example insertion lines table l1 would take second l2 would take seconds course didnt patience try insertions l2 l1 would take seconds tried find root cause opened task manager im using windows performance tab found insert ssd writing 200kb whereas l1s ssd writes 4mb course took possibility ssd might defected used benchmarks see first one used samsung magician crystaldiskmark ssd benchmark benchmarks said problem ssd working speed working note drivers date firmware ssd latest one tried reinstalling sql server tried changing editions enterprise developer developer one use l1 another thing tried detaching database moving drive attaching back find works better ssd results performance check inserts select delete incepela startsat seincheiela endsat l2 ssd l2 hdd l1 ssd end question sql server perform significantly worse piece supposed superior hdd edit edit added another image shows interesting thing regarding stall time ugly code declare id test int declare name test nvarchar50 declare ctest cursor select codtest nume teste open ctest fetch next ctest id test name test fetch status begin name test insert name test testetabele begin declare cte int declare cta int declare nr int declare int insert rulariteste descriere incepela seincheiela values add table sysdatetime null declare cursor select testetabele open fetch next cte cta nr fetch status begin insert rularitestetabele codrularetest codtabel incepela seincheiela values cte cta sysdatetime execaddfields cta nr update rularitestetabele set seincheiela sysdatetime codrularetest cte codtabel cta fetch next cte cta nr end close deallocate update rulariteste set seincheiela sysdatetime id test codrularetest end else name test select name test testeviewuri begin declare ct int declare cv int insert rulariteste descriere incepela seincheiela values select view sysdatetime null declare cursor select testeviewuri open fetch next ct cv fetch status begin insert rularitesteviewuri codrularetest codview incepela seincheiela values ct cv sysdatetime select select nume viewuri codview cv aview update rularitesteviewuri set seincheiela sysdatetime codrularetest ct codview cv fetch next ct cv end close deallocate update rulariteste set seincheiela sysdatetime id test codrularetest end else name test delete begin insert rulariteste descriere incepela seincheiela values delete table sysdatetime null delete topic follows delete topics delete users update rulariteste set seincheiela sysdatetime codrularetest select top1 codrularetest rulariteste order codrularetest desc end fetch next ctest id test name test end close ctest deallocate ctest addfields functions supposed add fields tables edit make matters clear algorithm used ill demonstrate making add values db ssd db hdd ill use l2 test image consisting last one post dont reputation post images noticed db hdd executes inserts seconds whereas ssd inserts seconds
194684 understand distinction scalar functions set returning functions srfs internal functions window functions aggregate functions sorts user implemented functions postgresql implement language etc sql server stored procedures permitted exec provide function executed select returns null postgresql gets stored procedures bring formal distinction function stored procedure spec read question seems predate announcement implementation
194975 discovered insert values type postgresql column type text drop table exists cascade create table text insert values insert values true select pg typeof pg typeof text true text rows intentional feature done something wrong setting avoid doesnt violate assumption rdbmss typesafe know text acts like catch postgresql often convenient write string representations arbitrary types surely sometimes want make sure strings get inserted given column exclusion implicitly cast values anything avoid casual type casts
195085 used working secure environments design permissions fine degree granularity one thing normally explicitly deny users ability update columns never updated example create table dbo something created varchar50 null created datetimeoffset null two columns never changed value set therefore would explicitly deny update permission recently team meeting developer raised point logic ensure fields never get updated contained within application layer database layer event need update values reason sounds like typical dev mentality know used one senior architect company always worked principle least amount privileges required get app work permissions audited regularly best practice scenario
195338 little backstory time ago started experience high cpu system time one mysql databases database also suffering high disk utilization figured things connected since already plans migrate ssd thought solve issues helped long couple weeks migration cpu graph like back happened nowhere without apparent changes load application logic db stats mysql version os debian db size 2tb ram 700gb cpu cores peek load 5kq read 600q write although select queries often pretty complex threads running connected tables innodb mysql config client port socket var run mysqld mysqld sock mysqld safe pid file var run mysqld mysqld pid socket var run mysqld mysqld sock nice mysqld user mysql pid file var run mysqld mysqld pid socket var run mysqld mysqld sock port basedir usr datadir opt mysql data tmpdir tmp lc messages dir usr share mysql explicit defaults timestamp sql mode strict trans tablesno zero dateno zero dateerror division zerono auto create userno engine substitution log error opt mysql log error log replication server id gtid mode enforce gtid consistency true relay log opt mysql log mysql relay bin relay log index opt mysql log mysql relay bin index replicate wild table dbname log bin opt mysql log mysql bin log expire logs days max binlog size 1024m binlog format row log bin trust function creators log slave updates disabling symbolic links recommended prevent assorted security risks symbolic links important additional settings override file files must end cnf otherwise theyll ignored includedir etc mysql conf goes skip name resolve general log slow query log slow query log file opt mysql log slow log long query time max allowed packet 16m max connections max execution time open files limit table open cache thread cache size innodb buffer pool size 550g innodb buffer pool instances innodb log file size 15g innodb log files group innodb flush method direct max heap table size 16m tmp table size 128m join buffer size 1m sort buffer size 2m innodb lru scan depth query cache type query cache size innodb temp data file path ibtmp1 12m autoextend max 30g observations perf mysql process peak load mysqld kernel kallsyms raw spin lock raw spin lock 0x7fd118e9dbd9 0x7fd118e9dbab mysqld libc 0x00000000000f4bd9 mysqld libc 0x00000000000f4bab mysqld libpthread start thread mysqld mysqld pfs spawn thread mysqld mysqld handle connection mysqld mysqld commandthd mysqld mysqld dispatch commandthd com data const enum server command mysqld mysqld mysql parsethd parser state mysqld mysqld mysql execute commandthd bool mysqld mysqld handle querythd lex query result unsigned long long unsigned long long mysqld mysqld 0x0000000000374103 mysqld mysqld join exec mysqld mysqld sub selectjoin qep tab bool mysqld mysqld row search mvccunsigned char page cur mode row prebuilt unsigned long unsigned long mysqld mysqld ha innobase general fetchunsigned char unsigned int unsigned int mysqld unknown 0x00007f40c4d7a6f8 mysqld mysqld 0x0000000000828f74 mysqld mysqld handler ha index next sameunsigned char unsigned char const unsigned int shows mysql spending lot time spin locks hoping get clue locks coming sadly luck query profile high load shows extreme amount context switches used select mytable pk mytable 90m rows profile output status duration cpu user cpu system context voluntary context involuntary block ops block ops messages sent messages received page faults major page faults minor swaps source function source file source line starting checking permissions check access sql authorization cc opening tables open tables sql base cc init handle query sql select cc system lock mysql lock tables lock cc optimizing optimize sql optimizer cc statistics optimize sql optimizer cc preparing optimize sql optimizer cc executing exec sql executor cc sending data exec sql executor cc end handle query sql select cc query end mysql execute command sql parse cc closing tables mysql execute command sql parse cc freeing items mysql parse sql parse cc cleaning dispatch command sql parse cc peter zaitsev made post recently context switches says real world though would worry contention big issue less ten context switches per query shows switches cause symptoms done ill appreciate pointers info matter everything come across far rather old inconclusive gladly provide additional information required output show global status show variables post contents exceed post size limit show global status show variables iostat avg cpu user nice system iowait steal idle device rrqm wrqm rkb wkb avgrq sz avgqu sz await await await svctm util fd0 sda sdb avg cpu user nice system iowait steal idle device rrqm wrqm rkb wkb avgrq sz avgqu sz await await await svctm util fd0 sda sdb avg cpu user nice system iowait steal idle device rrqm wrqm rkb wkb avgrq sz avgqu sz await await await svctm util fd0 sda sdb update show global status like uptime uptime uptime since flush status show global status like rollback com rollback com xa rollback handler rollback handler savepoint rollback
195763 want store coordinate points latitude longitude table variable tried declare coordinates tablelatitude1 decimal129 longitude1 decimal129 latitude2 decimal129 longitude2 decimal129 select latitude longitude coordinates loc locations place name delhi mumbai select coordinates showing error msg level state line incorrect syntax near coordinates result select query select latitude longitude loc locations place name delhi mumbai latitude longitude store values table datatype ran query select version got result microsoft sql server rtm x64 apr copyright microsoft corporation standard edition bit windows enterprise build
195775 function dbo fn calcaerialdistance accepts parameters returns result parameters come table want hit database multiple times bring data tried select dbo fn calcaerialdistance select latitude loc locations place name delhi select longitude loc locations place name delhi select latitude loc locations place name mumbai select longitude loc locations place name mumbai way optimise code also tried access table datatype like array
195923 sometimes store object names identifiers databases example parameter tables select records tables using like comparison operators must take care store names always without brackets exists select mytable obj name table name exists select mytable obj name table name however ms sql functions use object names without brackets example object id function ive set minimal example dbfiddle uk create table test id int identity11 primary key object sysname null go insert test values obj1 obj2obj3 obj4 go use object id check table test exists way object idtest null begin select test exists object id end go object id test exists object id test null begin select test exists object id end go object id test exists doesnt matter pass identifier test without brackets parser smart enough remove brackets well simulate adding scalar function remove brackets one string create function unquotename txt nvarcharmax returns nvarcharmax begin return iifleft txt right txt substring txt len txt txt end go use way select dbo unquotename field name1 nfield name2 go name1 name2 field field select id object test object like obj go id object obj2 obj3 select id dbo unquotenameobject test dbo unquotenameobject like obj go id column name obj1 obj2 obj3 obj4 question hidden built function removes brackets using sql dbfiddle
195937 recently noticed companys application using addwithvalueto pass parameter values dynamic parameterized queries example cmd parameters addwithvalue vehicleid vehicles vehicleid database data type vehicleid int understand addwithvalue deprecated specify data type length vehicleid converted potentially converted incorrectly conversion affect sql server performance case int would cause issues beyond plan cache pollution performance hit caused conversion
196030 quick easy filter question would difference output impact would moving filter condition clause join condition example select a1 name a2 state student a1 left join location a2 a1 name id a2 name id a1 name like a2 state new york select a1 name a2 state student a1 left join location a2 a1 name id a2 name id a2 state new york a1 name like thanks
196158 im process rewriting queries longer pull required data question regard practice ive never seen havent found question stackexchange specifically addresses issue know point statement introduce conditions aggregations like introduces conditions individual rows however im seeing code used lieu queries aggregations conditions applied aggregations non aggregated columns example select id filedate sumamount sales group id filedate id filedate opposed select id filedate sumamount sales id filedate group id filedate performance implications advantages disadvantages strategy havent tried running diagnostics priority id time however think may isnt clear answer concern optimizer views query aggregate data restrict result set based clause realize apply conditions individual rows since specifically referencing non aggregated columns edit example queries actual sql im rewriting plans identical queries similar complexity im yet knowledgeable enough draw conclusions identical plans
196219 sql system database master model msdb tempdb query store used msdb looked dont find documentation query store msdb cant see gui validated sql instance validate query store use msdb select sys database query store options turn query store use master go alter database msdb set query store go alter database msdb set query store operation mode read write interval length minutes max storage size mb query capture mode auto go validate query store use msdb select sys database query store options system database msdb one option use query store value add stop query store use master go alter database msdb set query store go
196220 beginner question expensive function fx two columns database table want execute query gives result function column puts constraint something like select fx func table name func however doesnt work write something like select fx func table name fx run expensive function twice whats best way
196330 docker installed running mongodb container local development mac problem cant connect said db easily cli robo 3t installed would prefer use cli client instead known way install mongo shell command mongo full db distribution os
196570 table varchar column allowing trademark copyright unicode characters shown create table varcharunicodecheck col1 varchar100 insert varcharunicodecheck col1 values mycompany insert varcharunicodecheck col1 values mycompany insert varcharunicodecheck col1 values mycompany insert varcharunicodecheck col1 values mycompany insert varcharunicodecheck col1 values mycompany select varcharunicodecheck definition varchar says allows non unicode string data trademark registered symbols unicode characters definition contradicts property varchar datatype read couple links like first one second one still could understand allows unicode string definition says allows non unicode string values
196600 im testing resilience injection attacks sql server database table names db lower case collation case sensitive latin1 general cs string send forced uppercase maximum characters length cant send drop table table name would uppercase thus statement would fail due collation whats maximum damage could characters edit know parameterised queries forth lets imagine person developed front end builds query send didnt use params case im also trying anything nefarious system built somebody else organisation
196931 installed postgresql centos environment service started postmaster pid file present var lib pgsql data need reload configuration restart server following change pg hba conf however trying different commands get following pg ctl reload var lib pgsql data bash pg ctl command found service postgresql reload redirecting bin systemctl reload postgresql service failed reload postgresql service unit found
196938 way link two tables order table actual ex status dlv actual fee expected fee act mail act email act pickup non mail non email non pickup table expected ex status dlv expected fee act mail act email act pickup non mail non email non pickup table expected result ex status dlv actual fee expected fee act mail act email act pickup non mail non email non pickup want incorporate follow logic within join ex ex join first combination since unique tried course didnt work dbo claims left outer join dbo pricing ex ex status status dlv dlv hoping link table table get expected fee ex regardless status dlv ex depend two columns im sorry confusing
197142 read article quite recently performance issues functions im currently development phase new database azure sql database platform wont go live new months yet im using variety scalar valued functions one convert utc local date specified config table aus eastern standard time function called following select dbo fngetlocaldatedatecolumn datecolumn table anyone suggestions avoid functions cases find useful code reuse im sure avoid im also wondering whether vnext fixing performance issues functions azure platform im better continuing work functions create function dbo fngetlocaldate datetoconvert datetimeoffset null returns datetimeoffset begin declare timezone varchar50 return case datetoconvert null null else convertdatetimeoffset datetoconvert time zone select value lookup config property timezone end end
197360 script file local machine open ssms open query ssms execute query opening ssms query used following powershell script ssms exe powershell prod screenshot serverdetails sql localhost run query using powershell close query window reason im take evidence sql server properties information powershell script capture screenshot im preparing powershell script runs every query ssms captures outcome save specified path able open query ssms capture screenshot im unable run query
197363 scientific names well accepted unique identifiers species however scientific names special characters spaces dots good unique identifier databasing one assign implement unique numerical identifiers latter globally known numeric identifier one assign identifiers rows
197789 bunch sql servers registered within ssms lots different sql versions editions db compatibilities want check servers sp blitz sp whoisactive stored procedures installed versions know right click registered servers group open one query window connects servers group reliable way check sprocs versions
197870 using vendor app running sql server enterprise rather annoying quirk executing count statements items table processing financial documents orders invoices etc select counta dbo items t0 im sure would normally fine theres million records takes 400ms count constitute substantial portion overall processing time table already extremely narrow nonclustered index tinyint plus clustered key sql using table scan dont think better regard theres solutions im aware wed like avoid possible indexed view using count big use faster processors using cloud servers theres limited options regard deleting records really option case options speed heres gist showing setup https gist github com elvishfiend 5094f120b14f8ecfb325623edcb5f3eb
197937 working setting secondary copy prod db data warehousing even something possibly use offload processes reporting basically read copy prod issues running options breaks point time backup strategies reliably handle tb data reading post always availability groups looks promising questions new dba microsofts documentation subject another language point always availability groups mean database basically mirrored use server offload heavy reporting break point time transaction logs backup prod server cause strain prod server cause prod traffic redirected server want become ha db server want read copy prod dbs
198170 want install sql server linux ms site read red hat suse ubuntu supported want use debian since ubuntu based debian chance succeed installation https docs microsoft com en us sql linux sql server linux setup
198408 loading data table get following error error row big size maximum size table columns appears problem general internet advice refactor normalize instance post unfortunately dont believe advice applies situation table store data collected device device produces png image part analysis png consists pixels pixel associated numeric value along pixel data various fields related analysis breaking table parts doesnt really make sense fields logically associated particular object analyzed postgres doesnt seem like pixel field table fields form pixel pixel pixel note fundamentally different usual example phone number phone number etc pixel unique object virtue location pixel different position pixel pixel associated value common aspect used describe analysis object quantitative analog visual representation given png way increase row size table simply columns could refactor assuming first two answers stick columns xml throw text field hope made context clear tried boil problem essence suspect clarification may needed please let know clarification needed edit experiment tried breaking pixels separate table seems possible way refactor columns produces error
198473 sure go query select name city salary employee get sum grouping select name city sumsalary total salary employee group name city get total per city separate row city expected sample result name city salary n1 c1 n2 c1 t1 c1 n3 c2 n4 c2 t2 c2
198513 problem sql query supposed find authors published least one book priced supposed display first last name sorted last name long author published least one book priced query far select authors au fname authors au lname titles price authors titles order au lname asc titles price first picture shows dbs first table authors second shows titles holds price column wrong figure wrong syntax thanks
198611 appears setting filegroup read prevents dbcc checkdb entire database filegroup contains columnstore index attempting run checkdb checkfilegroup filegroup database including read write secondaries primary error returned msg level state line check terminated failure detected collecting facts possibly tempdb space system table inconsistent check previous errors supported method columnstore data read filegroup precluded integrity checks scenario repro create database check fg ro go use check fg ro go exec sp changedbowner sa go alter database check fg ro add filegroup check fg ro alter database check fg ro add file name check fg ro filename check fg ro ndf filegroup check fg ro go create table foo int null primary key check fg ro go create columnstore index ccix foo fooi go use master go alter database check fg ro modify filegroup check fg ro read go dbcc checkdb check fg ro infomsgs errormsgs extended logical checks msg level state line check terminated failure detected collecting facts possibly tempdb space system table inconsistent check previous errors go disclaimer cross posted technet forums
198789 postgres im thinking query pg type date list enumerations im using regular basis id using something like select pg type typname enum type pg enum enumlabel enmu label pg type join pg enum pg enum enumtypid pg type oid select distinct pg type typname enum type pg type join pg enum pg enum enumtypid pg type oid bad practice
199144 quarterly check vlf servers cms query tigertoolbox fixing vlfs github includes suggestions code correcting found always try get full understanding going making adjustments time vlf solution apply recommendation though usually close using dbcc loginfo find several vlfs used sequential order trying understand highly voted answer dbcc shrinkfile log file reducing size even backup log disk says happen virtual log files always allocated order would seem conflict jonathan kehayias xevent day works multiple transaction log files see vlf two line currently used largest fseqno subtract dont see fseqno lower presumably used last vlf rollovers look lines see line written first line line also parity sure adds scenario lsn show created opposite order would expect whatever caused disruption sequence order passed next time vlfs would written order created notice line images show consistency example sql server database currently full recovery year server part node ag results taken secondary server logs backed hourly last grows occurred auto grow 1000mb creates 1vlf log file currently initial size 115000mb autogrow 1000mb edit max vernon thank link answer understood got written order making assumption continued written order blocking event cleared following fsegno backwards recreate occured line current vfl fseqno line fseqno fseqno line last line presumably vfl created fseqno written events writing next vlf vlf would cycles log couple hours later list looks
199202 using temporal tables within database right click table management studio v17 see select top rows context menu problem non temporal tables ideas get context menu back feeling version sql server running sql express edition
199226 scheme id uid content user decided doesnt need rows id better make set content null delete row process occur many time maybe use null slots still use update set null case change future delete entire row question like better delete row insert delete insert delete insert update row insert update null update value update null update value
199487 table created contains rows expect last query use nonclustered index key lookup however instead uses clustered index scan single row returned expected scan rather use nonclustered index table contains rows create table dbo testindexsample code char4 null name nvarchar200 null modifieddate datetime null constraint df testindexsample modifieddate default getdate constraint pk testindexsample code primary key clusteredcode go create nonclustered index ix testindexsample name dbo testindexsamplename go insert dbo testindexsamplecode name select codename fullname dbo sourcetest go select dbo testindexsample select dbo testindexsample code x132ey select dbo testindexsample name user
199842 querying sys dm tran locks dmv shows us sessions spids holding locks resources like table page row lock acquired way determine sql statement delete insert update select caused lock know recent query handle column sys dm exec connections dmv gives us text last query executed several times queries ran session spid still holding locks already use sp whoisactive procedure adam machanic shows query input buffer moment think dbcc inputbuffer spid always case usually never query acquired lock example open transaction session exec statement holds lock resource exec another statement session open another transaction session try modify resource locked step sp whoisactive procedure point statement step responsible lock thus useful question came analysis using blocked process reports feature find root cause blocking scenarios production transaction runs several queries time last one shown input buffer bpr rarely one holding lock follow question framework effectively identify blocking queries
199853 two select statements result different sort order use tempdb create table dbo oddsort id int identity11 primary key col1 nvarchar2 col2 nvarchar2 go insert dbo oddsort col1 col2 values ne nea go select dbo oddsort order col1 collate latin1 general cs id col1 col2 ea id select dbo oddsort order col2 collate latin1 general cs id col1 col2 ea
199961 question logic could help understand iterate dbs server several adventureworks databases query cold help iterate databases adventureworks create table list db name nvarchar128 insert list db select name sys databases database id state select list db drop table list db adventureworks database want list awbuildversion next db point im puzzled problems dont know solve run select database version awbuildversion database database awbuildversion table found query declare sql nvarcharmax set sql stuff select union select quotenamename db name name collate sql latin1 general cp1 ci table name quotenamename sys tables name tablename sys databases order name xml path type value nvarcharmax print sql execute sp executesql sql tablename varchar30 tablename awbuildversion brings close goal shows table name awbuildversion need column database version
200161 little stumped cte update stmt declare table id int value int declare table id int value int insert values insert values cte select update cte set value value cte inner join id id select go result table rows thought id id get expected results use table instead common table expression updates declare table id int value int declare table id int value int insert values insert values select update set value value xx inner join id xx id select results table arent supposed get values based previous explanation referencing issue update done table referenced xx
200269 getting ready perform large upgrade sql servers noticing unusual behavior distributed availability groups im trying resolve moving forward last month upgraded remote secondary server sql server sql server server part multiple distributed availability groups dags separate availability group ag upgraded server unaware would get unreadable state past month weve solely relying primary server part upcoming upgrade applied cu patch server rebooted server came back online patched secondary showed dags ags syncing without issues however primary showing different story reporting separate ag syncing without issues dags synchronzing healthy state initially panicking attempted following things get things synchronizing dags primary stopped resumed data movement start syncing data secondary one patched ran alter database database set hadr resume execute without errors resume syncing last attempt syncing data login secondary manually restart sql server service manually restarting service seems bit extreme id expect server rebooted would enough anyone run issue dag doesnt start syncing secondary reboot resolved checked sql server error log event viewer secondary server nothing ordinary could see
200279 couple sql server express databases running windows server r2 vps couple websites access local connections right website connections use integrated security also connect using remote desktop sql server express accessible remotely port remote desktop problem logs showing failed login attempts every seconds ip minutes another ip usually try user sa dont one variation blocked several hundred using windows firewall keep coming else something worrying
200352 trying ignore duplicate rows cte able seems like cte allow use rownum variable clause showing invalid column name numrows error trying ignore duplicate rows using select cte sql query declare batchid uniqueidentifier newid declare clusterid smallint declare batchsize integer declare mytablevariable table eventid bigint hotelid int batchstatus varchar50 batchid uniqueidentifier pendingextressvceventsdata batch select top batchsize eventid hotelid batchstatus batchid row number partition eventid order eventid numrows extressvcpendingmsg nolock clusterid clusterid numrows exclude extressvceventid hotelid partly included progress batch exists select extressvcpendingmsg t2 t2 batchstatus batched t2 eventid eventid t2 hotelid hotelid update pendingextressvceventsdata batch set batchstatus batched batchid batchid output inserted mytablevariable numrows select extressvceventid hotelid id1 id2 extressvceventtype hostid statuscode channelid requestattime processtime datebegin dateend statusmsg em msgbodyout em msgbodyin channelresid extressvcevent nolock inner join mytablevariable extressvceventid eventid inner join extressvceventxml em nolock eventid em extressvceventid order extressvceventid
201598 works create database go use go create schema go create table nvarchar20 go create unique clustered index go insert values go create view vw select go create proc sp shrug nvarchar20 select vw shrug go exec sp shrug go probably see im going dont want shrug want neither work version create proc sp nvarchar20 select vw go create proc sp nvarchar20 select vw go way use unicode stored procedure parameter names
201719 table courses fields also field coursestring favoritedbool favoriteddatedatetime dateupload teacher uploads course date stored dateupload field teacher flag course favorite information number field favorited date flagged stored field favoriteddate need retrieve courses specific teacher order list date course flagged favorited ordered favoriteddatedateupload desc favorited ordered dateupload desc far working select courses teacherid order case favorited favoriteddate dateupload else dateupload end desc idea solve
202000 found script sql server agent job create script starts use msdb assume jobs stored msdb database best way add sql server jobs visual studio database project added msdb database database solution doesnt seem reference jobs would like jobs deployed updated along database seems like possible
202086 third party application sends sql statements batches database hosted sql server enterprise sp1 cu7 cores 256gb memory optimize ad hoc enabled dummy example queries executed exec sp executesql trancount set transaction isolation level snapshot select field1 field2 table1 field1 optionkeep plan keepfixed loop join select field3 field4 table2 field3 optionkeep plan keepfixed loop join nvarchar6 ntest monitor database look batches sec compiles sec notice always heavy load batches sec compiles sec average load batches sec analyze query cache recently compiled plans select top qs creation time databasename db namest dbid qs execution count st text qs plan handle qs sql handle qs query hash sys dm exec query stats qs cross apply sys dm exec sql textqs plan handle st order creation time desc run query see new query plans sec like every sp executesql call triggers compile queryplan cached cause batches sec equal compiles sec
202211 im trying see theres way trick sql server use certain plan query environment imagine data shared different processes suppose experiment results take lot space process know year month experiment result want use object iddbo shareddata null drop table shareddata create table dbo shareddata experiment year int experiment month int rn int calculated number int primary key experiment year experiment month rn go every process parameters saved table object iddbo params null drop table dbo params create table dbo params session id int experiment year int experiment month int primary key session id go test data lets add test data insert dbo params session id experiment year experiment month select union select go insert dbo shareddata experiment year experiment month rn calculated number select row number overorder v1 name abschecksumnewid master dbo spt values v1 cross join master dbo spt values v2 go insert dbo shareddata experiment year experiment month rn calculated number select row number overorder v1 name abschecksumnewid master dbo spt values v1 cross join master dbo spt values v2 go fetching results easy get experiment results experiment year experiment month create alter function dbo getshareddata experiment year int experiment month int returns table return select rn calculated number dbo shareddata experiment year experiment year experiment month experiment month go plan nice parallel select calculated number count dbo getshareddata2014 group calculated number query plan problem make usage data bit generic want another function dbo getshareddatabysession session id int straightforward way would create scalar functions translating session id experiment year experiment month create alter function dbo fn getexperimentyear session id int returns int begin return select experiment year dbo params session id session id end go create alter function dbo fn getexperimentmonth session id int returns int begin return select experiment month dbo params session id session id end go create function create alter function dbo getshareddatabysession1 session id int returns table return select rn calculated number dbo getshareddata dbo fn getexperimentyear session id dbo fn getexperimentmonth session id go query plan plan except course parallel scalar functions performing data access make whole plan serial ive tried several different approaches like using subqueries instead scalar functions create alter function dbo getshareddatabysession2 session id int returns table return select rn calculated number dbo getshareddata select experiment year dbo params session id session id select experiment month dbo params session id session id go query plan using cross apply create alter function dbo getshareddatabysession3 session id int returns table return select rn calculated number dbo params cross apply dbo getshareddata experiment year experiment month session id session id go query plan cant find way write query good one using scalar functions couple thoughts basically id want able somehow tell sql server pre calculate certain values pass constants could helpful intermediate materialization hint ive checked couple variants multi statement tvf cte top plan good one scalar functions far know coming improvement sql server froid optimization imperative programs relational database im sure help though wouldve nice proven wrong though additional information using function rather selecting data directly tables much easier use many different queries usually session id parameter asked compare actual execution times particular case query runs 500ms query runs 1500ms query runs 1500ms query runs 2000ms plan index scan instead seek filtered predicates nested loops plan bad still work works slower plan lets assume dbo params changed rarely usually around rows lets say ever expected around columns dont expect add column often number rows params fixed every session id therell row number columns fixed one reasons dont want call dbo getshareddata experiment year int experiment month int everywhere add new column query internally id glad hear opinions suggestions even restrictions
202254 relationship create table auth user id integer null primary key username character varying150 null unique create table auth group id integer null primary key name character varying80 null unique create table auth user groups id integer null primary key user id integer references auth userid null group id integer references auth groupid null constraint user groups uniqueuser id group id insert auth user values user1 insert auth user values user2 insert auth group values group1 insert auth group values group2 insert auth user groups values insert auth user groups values insert auth user groups values select usernames group group1 use postgresql sql works everywhere preferred
202419 basic useractivity table captures activitytypeid per userid activitydate activity occurred writing query stored procedure allows input userid fortypeid well durationinterval durationincrement dynamically return results based number seconds minutes hours days months years given datepart argument within dateadd datediff allow parameters revert bit trickery order get desired results within clause initially wrote query using datediff immediately writing taking peek execution plan remembered sargable function along fact precision levels could offer dates falling leap year wrote query utilize datepart thinking would hit index seek instead index scan generally perform better unfortunately ive found writing query dateadd offers results index scan occurring query optimizer leveraging non clustered index activitydate read aaron bertrands blog post performance surprises assumptions dateadd implemented changes described convert dateadd portion equivalent datetime2 column definition due weird trickery involved datetime2 however issue still present even better illustrate scenario comparable table definition drop table exists dbo useractivity object id dbo useractivity null begin create table dbo useractivity userid int null useractivityid bigint identity11 null activitytypeid tinyint null activitydate datetime2 null constraint df useractivity activitydate default getdate constraint pk useractivity primary key clustered useractivityid asc index ix useractivity userid nonclustered userid asc index ix useractivity activitytypeid nonclustered activitytypeid asc index ix useractivity activitydate nonclustered activitydate asc end go populate table dummy data recursively different users random activitytypeid new activitydate every minutes declare userid int select isnullselect top userid dbo useractivity order userid desc useractivityseed select convertdatetime20 activitydate union select dateaddminute activitydate useractivityseed activitydate insert dbo useractivity userid activitytypeid activitydate select userid abschecksumnewid activitydate useractivityseed option maxrecursion go alter index dbo useractivity rebuild first query wrote datediff note excluding userid fortypeid predicates intentionally avoid key lookups reduce noise within plans attached youll find pastetheplan query performing index scan expected given datediff sargable declare userid int declare fortypeid int declare durationinterval varchar6 hour declare durationincrement int select countua useractivityid activitytypecount dbo useractivity ua exclude userid fortypeid predicates ua userid userid ua activitytypeid fortypeid case durationinterval year yy yyyy datediffsecond ua activitydate getdate durationinterval month mm datediffsecond ua activitydate getdate durationinterval day dd datediffsecond ua activitydate getdate durationinterval hour hh datediffsecond ua activitydate getdate durationinterval minute mi datediffsecond ua activitydate getdate durationinterval second ss datediffsecond ua activitydate getdate end durationincrement dateadd query pastetheplan unfortunately index seek occurring may incorrect assumption part im perplexed isnt occurring declare userid int declare fortypeid int declare durationinterval varchar6 hour declare durationincrement int select countua useractivityid activitytypecount dbo useractivity ua exclude userid fortypeid predicates ua userid userid ua activitytypeid fortypeid durationinterval year yy yyyy ua activitydate convertdatetime20 dateaddyear durationincrement getdate durationinterval month mm ua activitydate convertdatetime20 dateaddmonth durationincrement getdate durationinterval day dd ua activitydate convertdatetime20 dateaddday durationincrement getdate durationinterval hour hh ua activitydate convertdatetime20 dateaddhour durationincrement getdate durationinterval minute mi ua activitydate convertdatetime20 dateaddminute durationincrement getdate durationinterval second ss ua activitydate convertdatetime20 dateaddsecond durationincrement getdate cause behavior im seeing result usage negating potential even get using index overlooking something painstakingly obvious update second question lead perform query foregoing operations query performed index seek something occurring comparisons sql server like pastetheplan declare durationincrement int select countua useractivityid activitytypecount dbo useractivity ua ua activitydate convertdatetime20 dateaddhour durationincrement getdate update solution shared
202707 application query performs search files table table files partitioned created see table definition million rows client cid im using query answer previous question slow order sql server partitionnumbers partition table select partition number sys partitions object id object idndbo files nu index id select ff id ff name ff year ff cid ff created vnve0 keywordvaluecol0 numeric partitionnumbers pn cross apply select f100 rows order year select id name year cid created dbo files grapado null masterversion null year cid eid partition pf files partitioningf created pn partition number order name offset rows fetch first rows union rows order year select id name year cid created dbo files grapado null masterversion null year cid eid partition pf files partitioningf created pn partition number order name offset rows fetch first rows f100 ff outer apply lookup distinct values select keywordvaluecol0 numeric case vn value null vn value convertdecimal28 vn value else convertdecimal28 end dbo value number vn vn id file ff id vn id field group vn value vnve0 order ff name offset rows fetch first rows point query performing well change eid eid query becomes slow minutes execution plan using eid https www brentozar com pastetheplan id hj fbb2qm execution plan using eid https www brentozar com pastetheplan id b1 zmbnqz ive tried join entidades table whose id referenced eid files table execution plan join entidades https www brentozar com pastetheplan id rjarhzh5m could improve performance additional info partition function pf files partitioning create partition function pf files partitioning datetime27 range left values partition scheme ps files partitioning create partition scheme ps files partitioning partition pf files partitioning primary note around million rows partition table files create table dbo files id bigint identity11 null cid tinyint null eid bigint null cat id bigint null tip id bigint null sub id bigint null year smallint null caducidad smallint null grapadopri int null grapado bigint null name nvarchar null extension tinyint null size bigint null id doc bit null observaciones nvarchar null indexed bit null signed bit null created datetime2 null name lower nvarchar null modified datetime2 null related bit null masterversion bigint null versioned bit null hwsignature tinyint null blockeduserid smallint null constraint pk files id primary key clustered id asc created asc pad index statistics norecompute ignore dup key allow row locks allow page locks ps files partitioning created constraint files estructure unique unique nonclustered cat id asc tip id asc sub id asc year asc name asc grapado asc created asc pad index statistics norecompute ignore dup key allow row locks allow page locks alter table dbo files nocheck add constraint fk files entidad foreign key eid references dbo entidades id update cascade delete cascade alter table dbo files check constraint fk files entidad table value number create table dbo value number id bigint identity11 null id file bigint null default id field bigint null default value nvarchar null default null id doc bigint null default null constraint pk value number id primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks also table value number partitioned partition function create partition function pf value number bigint range left values partition scheme create partition scheme ps value number partition pf value number primary create table dbo value number id bigint identity11 null id file bigint null default id field bigint null default value nvarchar null default null id doc bigint null default null constraint pk value number id primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks ps value number id file table entidades create table dbo entidades id bigint identity11 null cid bigint null mid bigint null id doc bigint null name nvarchar null sincro tinyint null comprobar tinyint null op1 tinyint null op2 tinyint null op3 tinyint null index tinyint null parent tinyint null accounting nchar null nota nvarchar null alias nvarchar null element type tinyint null size bigint null constraint pk entidades id primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks constraint codigo unique nonclustered cid asc name asc pad index statistics norecompute ignore dup key allow row locks allow page locks alter table dbo entidades check add constraint fk entidades entidad foreign key mid references dbo entidades id go indexes files table create nonclustered index files clientes dbo files cid asc include id pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index files grapado dbo files grapado asc include id name pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index files mv dbo files masterversion asc year asc cat id asc cid asc eid asc grapado asc sub id asc tip id asc include id name pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index files ocr dbo files cid asc grapado asc indexed asc masterversion asc extension asc include id eid cat id tip id sub id year name pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index files ocr2 dbo files cid asc eid asc grapado asc indexed asc masterversion asc extension asc include id cat id tip id sub id year name pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index files ocr3 dbo files cid asc cat id asc grapado asc indexed asc masterversion asc extension asc include eid tip id sub id year name pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index busqueda name dbo files cid asc eid asc grapado asc year asc include id cat id tip id sub id grapadopri name size id doc signed created modified related masterversion pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index busqueda2 dbo files cid asc eid asc cat id asc grapado asc masterversion asc year asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index cid dbo files cid asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index eid dbo files eid asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index extension dbo files extension asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index fk files archivo dbo files grapado asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index fk files tipo dbo files tip id asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index grapadopri dbo files grapadopri asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index index dbo files cid asc eid asc grapado asc masterversion asc include cat id tip id sub id year grapadopri name size id doc signed created modified related versioned pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index missing index dbo files cid asc eid asc grapado asc name asc year asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index ocrcloudclients dbo files grapado asc indexed asc extension asc include cid eid cat id tip id sub id pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index searchentity dbo files cid asc eid asc grapado asc masterversion asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index sub id dbo files sub id asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index ix dbo files cid year eid grapado null masterversion null dbo files cid asc year asc eid asc include grapado masterversion grapado null masterversion null pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index ix dbo files cid year name grapado null masterversion null dbo files cid asc year asc name asc include grapado masterversion grapado null masterversion null pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created create nonclustered index ix dbo files cid year eid name grapado null masterversion null dbo files cid asc year asc eid asc name asc include grapado masterversion grapado null masterversion null pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps files partitioning created indexes value number table create nonclustered index searchvalues dbo value number id field asc include id file value pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps value number id file create nonclustered index search dbo value number id file asc id field asc include value pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps value number id file create nonclustered index id field dbo value number id field asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps value number id file create nonclustered index fk valueesn documento dbo value number id doc asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps value number id file create nonclustered index fk valueesn archivo dbo value number id file asc pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks ps value number id file
203130 internal web application running everytime user goes search view queries three different tables db generate values three dropdowns view basically running select distinct portname ports order portname asc table contains rows quite heavy load means time time loading time page due loading dropdowns data upwards seconds better way example running script certain intervals creating table view whatever different location offload querying big table rows returned main table
203402 question installation sql server installed trial version tha made according script execute database expiration date still use without problems sharepoint site uses db give errors warnings legends expired features longer available also enter msqlserver management studio execute scripts create new db etc exactly know expiration date select servername servername create date instalaltiondate serverpropertyedition version dateadddd create date expiry date sys server principals sid 0x010100000000000512000000 servername installationdate version expiry date saharcvsps02 enterprise evaluation edition bit
203499 recently seeing unknown netowrk error saves full back ups file share servers back ups happens different times ola halengren scripts used currently sql server edition used enterprise edition see suggestions create dword name sesstimeout value hklm system currentcontrolset services lanmanworkstation parameters question create target server file share server sql server resides
203612 following image describes format gst identification number first digits denote unique state code accordance indian census instance state code new delhi karnataka next characters denote pan permanent account number taxpayer 13th digit denotes registration number entity number tax payer pan 14th digit default intending anything currently 15th digit check sum digit number alphabetical character perhaps carry validation means patindex regex
203877 queries hit execute shows rows keeps growing query yet yet sometimes waits end query happen way control
203981 installed pgadmin version macos sierra replacing pgadmin came bundled postgres running locally mac opened pgadmin app app icon caused safari browser come front tab showing usual pgadmin user interface good closed tab safari open pgadmin app icon either double clicking choosing file open nothing happens pgadmin supposed launch browser window rather apps window open pgadmin
204011 consultants working expanding inhouse data warehouse code review ran across pattern load procs merge edhub customer class target using select columns dbo vw customerclass jhapostingdate postingdate source target bankid source bankid join business keys target code source code matched target insert statement matched target islatest exists select source hash except select target hash update statement gist new business key insert business key exists hash attributes dont match current row update old row insert new one later code works fine paused got code exists select source hash except select target hash seems overly complicated compared source hash target hash except accurate null comparison case hashes never null bigger problems want code easy read someone maintain doesnt confuse asked consultants speculated might faster set operations decided write simple test test code first thing noticed exists except complicated query plan thats always bad ran select client statistics join yielded total execution time vs exists except want take consultants request refactor statement wanted get feedback good test missing anything case exists except would better comparison test script create table hash varbinary8000 create table hash varbinary8000 set nocount declare int begin insert dbo hash select hashbytessha2 256castnewid varchar200 insert dbo hash select hashbytessha2 256castnewid varchar200 set end insert dbo hash values null insert dbo hash values null select count1 dbo cross join dbo isnullr hash0 isnulll hash0 select count1 dbo cross join dbo existsselect hash except select hash
204087 analysis services cube project company received outside contractor im trying get developers work local machines im pretty sure original developers generated schema backend database cube project worked therefore id like generate schema visual studio rather exporting database sql server management studio currently im receiving error saying dimensions bound user tables try generate relational schema approach reasonable would go approach isnt reasonable note id asked question days ago stackoverflow came back occurred would better place moved
204096 run odd issue sql server standard edition bit seemed capped precisely half total memory allocated towards 64gb 128gb output version microsoft sql server sp1 cu7 gdr kb4057119 x64 dec copyright microsoft corporation standard edition bit windows server r2 datacenter build hypervisor output sys dm os process memory query sys dm os performance counters see target server memory kb total server memory kb half scenarios would understand normal behavior sql server yet determined needs allocate memory however stuck 64gb months timeframe performed significant amount memory intensive operations databases added close databases instance sitting databases total pre allocatted data files 4gb 256mb autogrowth rate 2gb log files 128mb autogrowth rate perform full backup nightly 00am begin transaction log backups monday friday starting 00am 00pm interval every minutes databases relatively low overall throughput im skeptical something awry given sql server hasnt crept towards target server memory naturally new database additions normal query executions well memory intensive etl pipelines ran sql server instance sitting atop virtualized vmware windows server 2012r2 server cpu 144gb memory 128gb sql server 16gb reserved windows total virtual disks sit atop vsan 15k sas drives windows sits naturally 64gb disk page file 32gb data files sit 2tb disk log files sit top 2tb disk tempdb sits 256gb disk 8x16gb files autogrowth verified instances sql server running server besides mssqlserver server entirely dedicated sql server instance applications services running might consume memory utilize redgate sql monitor analysis history past days total server memory see memory utilization remained entirely stagnant aside single uptick 300mb early april might cause take closer look order determine sql server isnt wanting use additional 64gb memory allocated towards output running sp blitz sp blitz outputtype markdown checkserverinfo priority performance cpu schedulers offline cpu cores accessible sql server due affinity masking licensing problems memory nodes offline due affinity masking licensing problems memory may available priority reliability remote dac disabled remote access dedicated admin connection dac enabled dac make remote troubleshooting much easier sql server unresponsive priority performance many plans one query plans present single query plan cache meaning probably parameterization issues server triggers enabled server trigger rg sqllighthouse ddltrigger enabled make sure understand trigger less work better server trigger ssmsremoteblock enabled make sure understand trigger less work better priority performance queries forcing join hints instances join hinting recorded since restart means queries bossing sql server optimizer around dont know theyre cause harm good also explain dba tuning efforts arent working queries forcing order hints instances order hinting recorded since restart means queries bossing sql server optimizer around dont know theyre cause harm good also explain dba tuning efforts arent working priority file configuration system database drive master master database file drive putting system databases drive runs risk crashing server runs space model model database file drive putting system databases drive runs risk crashing server runs space msdb msdb database file drive putting system databases drive runs risk crashing server runs space priority informational agent jobs starting simultaneously multiple sql server agent jobs configured start simultaneously detailed schedule listings see query url tables master database master commandlog table master database created end users jul 22pm tables master database may restored event disaster traceflag trace flag enabled globally trace flag enabled globally trace flag enabled globally priority non default server config agent xps sp configure option changed default value set backup checksum default sp configure option changed default value set backup compression default sp configure option changed default value set cost threshold parallelism sp configure option changed default value set max degree parallelism sp configure option changed default value set max server memory mb sp configure option changed default value set optimize ad hoc workloads sp configure option changed default value set show advanced options sp configure option changed default value set xp cmdshell sp configure option changed default value set priority reliability extended stored procedures master master sqbdata extended stored procedure master database clr may use master database needs part backup recovery planning master sqbdir extended stored procedure master database clr may use master database needs part backup recovery planning master sqbmemory extended stored procedure master database clr may use master database needs part backup recovery planning master sqbstatus extended stored procedure master database clr may use master database needs part backup recovery planning master sqbtest extended stored procedure master database clr may use master database needs part backup recovery planning master sqbtestcancel extended stored procedure master database clr may use master database needs part backup recovery planning master sqbteststatus extended stored procedure master database clr may use master database needs part backup recovery planning master sqbutility extended stored procedure master database clr may use master database needs part backup recovery planning master sqlbackup extended stored procedure master database clr may use master database needs part backup recovery planning priority non default database config read committed snapshot isolation enabled database setting default redgate redgatemonitor snapshot isolation enabled database setting default redgate redgatemonitor priority wait stats sos scheduler yield hours waits minutes average wait time per hour signal wait waiting tasks ms average wait time priority informational sql server running nt service account im running nt service mssqlserver wish active directory service account instead priority server info default trace contents default trace holds hours data apr 21pm apr 13am default trace files located program files microsoft sql server mssql13 mssqlserver mssql log drive space 00mb free drive drive space 00mb free drive drive space 00mb free drive drive space 00mb free drive hardware logical processors physical memory 144gb hardware numa config node state online online schedulers offline schedulers processor group memory node memory vas reserved gb node state offline online schedulers offline schedulers processor group memory node memory vas reserved gb instant file initialization enabled service account perform volume maintenance tasks permission power plan server 60ghz cpus balanced power mode uh want cpus run full speed right server last restart mar 27am server name redacted services service sql server mssqlserver runs service account nt service mssqlserver last startup time mar 27am startup type automatic currently running service sql server agent mssqlserver runs service account localsystem last startup time shown startup type automatic currently running sql server last restart mar 27am sql server service version patch level sp1 cumulative update cu7 edition standard edition bit availability groups enabled availability groups manager status virtual server type hypervisor windows version youre running pretty modern version windows server 2012r2 era version priority rundate captains log stardate something something
204302 alter table xxx alter column yyy varchar max null suppose gb data space 2gb index space million rows table column yyy varchar8000 updated writable table columns 3000g data database tables machine information rows null varchar8000 web application may hit table times per minute hardware enterprise level core cpu 256gb ram tables database machine 3000gb data relevant version details microsoft sql server x64 enterprise edition bit
204339 working sql server r2 table benefit insert update trigger named tiu benefit want write update statement table update row dont want trigger fire know disable trigger update enable trigger update disable trigger tiu benefit benefit go update benefit set editor srh benefit id go enable trigger tiu benefit benefit go disable enabling trigger affect users logged currently possibility another user run update insert trigger disabled script good thats want disable enabling trigger current session possible yes please tell thanks
204532 aggregate query lot columns generate huge data set select column1 column2 column20 sumcolumn21 sumcolumn40 output ledger group column1 column20 input table ledger 18m rows result table output 600k rows query took minutes anything make faster heres execution plan theres index ledger table exclamation point sort gives following warning operator used tempdb spill data execution spill level spilled threads sort wrote pages read pages tempdb granted memory 3752160kb used memory 3681824kb
204545 working programmers database solution want add computed column mimic old keys older queries procedures systems index new keys guids want create function computed column creates value persist let persist column dont warm fuzzies idea also find info web technique technique thinking need add trigger instead anyone ideas function run select int identity field table guid column guidkey returns int identity field based guid run ever insert related table table one holds primary key related table two update using guid passed get key table one insert table two
204565 salutations check one well trained professional casual reader hapless wanderer check apply query stored procedure database thing maybe running fine applicable yesterday recent memory point suddenly slower ive already checked make sure blocked victim long running maintenance task report band process problem information provide get help insert appropriate closing remarks
204597 consider table tbl id date get rows id different date right get ids count like select id date tbl group id countid get id along date
204757 scenario looks like mysql taking largest decimal value tries cast values problem query generated external library dont control code level least idea fix select union select null union select null expected result doesnt matter really case null adding context im using entity framework extension library http entityframework extensions net save changes batches specifically method context bulksavechanges library creates queries using select union
204920 consider following simple xml xml customer name max email address com customer customer name erik email address erik mom com customer customer name brent email address brentcom customer xml want get list customer sequences address attribute email item contain want output looks like customer name brent email address brentcom customer mcve declare xml xml customer name max email address com customer customer name erik email address erik mom com customer customer name brent email address brentcom customer xml query select withvalidemail query xml customer email contains address withinvalidemail query xml customer email contains address false returns withvalidemail withinvalidemail email address com email address erik mom com false query select withinvalidemail query xml customer email exist xml customer email contains address returns withinvalidemail results clause query eliminating entire set xml least single sequence exists email address contains sign
205012 count may true false field public postgresql user table tried query select sumcase false else end false sumcase true else end true public user getting value remove public query get correct counts value true table name dob public values bb true op true false getting answer make public false table name dob public values bb false op true false someone please help solve
205026 im looking good resource gives breakdown feature differences sql server enterprise standard editions want make sure theres gotchas miss anything truly beneficial going standard ive read licensing guide microsoft notable feature differences doesnt cover vaguely described feature differences like advanced adaptive query processing enterprise data management advanced security etc
205065 knocking socks mysql db weight defined double insert xxx weight values db store
205073 ive got bunch simple ssis packages output sql data excel rename files move end user use file paths spaces arent excited using new folders heres code im using declare date varchar25 sql varchar1000 set date castdatepartmonth current timestamp varchar2 castdatepartday current timestamp varchar2 castdatepartyear current timestamp varchar4 print date set sql copy data ed xlsx ehsintra3 ed weekly ed date xlsx print sql exec xp cmdshell sql wouldnt work without underscores question make work without underscores
205190 read microsofts editions supported features sql server doc compare feature differences enterprise standard edition two things available standard caught eye online indexing online schema change literally mean cant create modify indexes tables objects without taking database offline first microsoft mean specific operations cant learn operations require taking database offline
205341 trying tune query table valued function tvf called columns first thing convert scalar function inline table valued function using cross apply best performing way execute function multiple columns query simplistic example select col1 val col2 val col3 val columns col21 col22 col23 cross apply dbo function1col1 cross apply dbo function1col2 cross apply dbo function1col3 columns better alternatives function called multiple queries number columns heres function create function dbo convertamountverified tvf amt varchar60 returns table schemabinding return ctelastchar select lastchar rightrtrim amt select amountverified castret numeric182 select outer apply select cast case charindexl lastchar collate latin1 general cs abcdefghi charindexl lastchar collate latin1 general cs abcdefghi charindexl lastchar collate latin1 general cs jklmnopqr charindexl lastchar collate latin1 general cs jklmnopqr charindexl lastchar collate latin1 general cs pqrstuvwxy charindexl lastchar collate latin1 general cs pqrstuvwxy else null end varchar1 ctelastchar num outer apply select case charindexl lastchar collate latin1 general cs abcdefghi charindexl lastchar collate latin1 general cs jklmnopqrpqrstuvwxy else end ctelastchar neg outer apply select amt case num null amt else substringrtrim amt1 len amt num end tp outer apply select case neg casttp amt numeric neg cast tp amt numeric end ret go heres scalar function version inherited anyone interested create function dbo convertamountverified amt varchar50 returns numeric begin declare return variable declare amount numeric18 declare tempamount varchar declare num varchar1 declare lastchar varchar1 declare negative bit get last character select lastchar rightrtrim amt select num case lastchar collate latin1 general cs ascii else end select negative case lastchar collate latin1 general cs ascii else end add sql statements compute return value num begin select tempamount amt end else begin select tempamount substringrtrim amt1 len amt num end select amount case negative cast tempamount numeric cast tempamount numeric end return result function return amount end sample test data select dbo convertamountverified00064170 select dbo convertamountverified tvf00064170 select dbo convertamountverified00057600a select dbo convertamountverified tvf00057600a select dbo convertamountverified00059224y select dbo convertamountverified tvf00059224y
205342 result null empty would like add comma front string achieve update companies set address4 concataddress4 eircode companies inner join temptbl1 comp id comp id address4 update make clear make update v05 ttx1 waterfordx01 b234 b90 e902 co wexfordtd2 pve2 adds comma regardless empty want get back v05 ttx1 waterfordx01 b234 b90 e902 co wexfordtd2 pve2 value add string without comma case v05 ttx1 without start string create table dbo companies comp id int null address4 varchar null insert dbo companies comp id address4
205587 question improve query increase speed query shown seconds milliseconds using postgresql context time series table buildings hispoint stores historical data data points table buildings point need aggregate maxvalue minvalue aggregation value different time ranges year date large collection data points proves slow needs improvement table structure buildings hispoint rows create table buildings hispoint id int value float datetime timestamp point id constraint foo foreign key point id references buildings point point id query select countdatetime id maxvalue minvalue aggregation value buildings hispoint point id buildings hispoint datetime query plan aggregate cost rows width actual time rows loops buffers shared hit read dirtied bitmap heap scan buildings hispoint cost rows width actual time rows loops recheck cond point id rows removed index recheck filter datetime timestamp time zone datetime timestamp time zone rows removed filter heap blocks exact lossy buffers shared hit read dirtied bitmap index scan buildings measurementdatapoint ffb10c68 cost rows width actual time rows loops index cond point id buffers shared read planning time ms execution time ms
205684 table tables gets referenced foreign key several tables would like select rows table referenced table afaik possible generic way introspection magic
205727 recently school district upgraded several servers version physical servers vm servers infrastructure team presented vm servers sql server installation single core attempting explain head department sql server hates single core wants see proof none data presented satisfied need proof asked articles vm sql server wont operate efficiently single core articles use help making case would appreciated
205790 im developing sql server stored procedure want get last characters varchar38 column know always least characters dont know exact length column variable think get length column subtract use substring cant im set externalcodes select serial aggregationlevel externalcode productionorderid productionorderid json path im generating json dont know get length serial column inside select question get substring string without first characters without knowing length one solution could substringserial always return substring end string even string doesnt length
206055 question postgresql version question mysql originally one question rdbmss suggested given different capabilities two systems split question particular think ctes clause make query far elegant readable suppose list tumours data simulated real data create table illness nature illness varchar25 created datetime insert illness values cervix insert illness values cervix insert illness values cervix insert illness values cervix insert illness values cervix insert illness values lung insert illness values lung insert illness values lung insert illness values lung insert illness values cervix cervix lung month jan tie insert illness values cervix insert illness values lung insert illness values lung insert illness values lung insert illness values lung insert illness values cervix want find particular tumour common given month far good notice month tie makes sense whatsoever randomly pick one give answer ties included makes problem much challenging solution quite complex id like know solution optimal postgresql fiddle query fiddle cumbersome ill look using ctes first answer works postgresql mysql included fiddle wont post believe superceded postgresqls superior capabilities would copy answer mysql question
206170 following foo table id name qty john john mary mary gary gary gary would like select id name minimal qty grouped name result id name john mary gary way could means following operation select id name select id name minqty foo group name beautiful less redundant way
206241 developer would like select statement order rows table order inserted developer suggested changing clustered non clustered index changing index clustered non clustered make guarantees order rows would appear table question mostly curiosity going suggest using identity column instead request got thinking timestamp could used chance rows inserted simultaneously thanks advance help
206426 im trying write query delete rows based two columns delete us test cell ca001018611 ca001135126 date however matches cell ca001018611 either modify delete ca001018611 date ca001135126 date edit 300k rows delete based similar criteria
206481 writing custom json parser sql purpose parser using patindex function calculates position token list tokens tokens case single characters include usually need find first position several given characters use patindex function like patindex abc sourcestring function give first position whichever happens found first sourcestring problem case seems connected character soon specify character list like patindex sourcestring intended pattern apparently becomes broken function never finds match looks like need way escape first patindex treats one lookup characters rather special symbol found question asking similar problem need help like operator square brackets however case simply need specified brackets one character specified without brackets around alternative solution use escaping works like patindex uses escape subclause supported former latter question way look patindex using wildcard way emulate functionality using transact sql tools additional information example query need use patindex pattern pattern works albeit somewhat include character need work well data select cast f1 v1 v2 f2 v3 varcharmax responsejson parser select level openclose substringd responsejson nullifp substringd responsejson nullifp responsejson substringd responsejson nullifp data cross apply select patindex responsejson union select level isnulld openclose level isnulloc openclose openclose oc openclose substringd responsejson nullifp responsejson substringd responsejson nullifp parser cross apply select patindex collate latin1 general bin2 responsejson cross apply select substringd responsejson nullifp cross apply select case end oc openclose select parser option maxrecursion output get level openclose responsejson f1 v1 v2 f2 v3 null f1 v1 v2 f2 v3 v1 v2 f2 v3 null v1 v2 f2 v3 null v2 f2 v3 null f2 v3 v3 see included part one rows level column indicates level nesting meaning bracket braces nesting see level becomes never returns would could make patindex recognise token expected output example level openclose responsejson f1 v1 v2 f2 v3 null f1 v1 v2 f2 v3 v1 v2 f2 v3 null v1 v2 f2 v3 v2 f2 v3 null f2 v3 null f2 v3 v3 play query db fiddle using sql server unlikely soon upgrade version supports json parsing natively could write application job results parsing need processed implies work application parsing kind work would much easier probably efficiently done sql script could apply directly results unlikely use sqlclr solution problem however dont mind someone decides post sqlclr solution since could useful others
206678 trying get disk space report bunch servers insert sql table sample trying doserver names populated table passed comma seperated list even passing one server also result set ps powershell exe noexit computers get wmiobject class win32 volume servernames foreach computer computers pscomputername computer pscomputername name computer name capacity computer capacity freespace computer freespace label computer label insertquery insert dbo temp disksdata servername diskname capacitygb freespacegb label values pscomputername name capacity freespace label go invoke sqlcmd query insertquery serverinstance someserver database dbname try pass variable xp cmdshell like execute xp cmdshell ps invoked ssmsabove returns nullbut works powershell ideas things tried accountadmin used shell ssms tried multiple things like import modules xp cmdshell worksbut returns null query tried add nowaitbut doesnt help well trying get done daybut doesnt work use xp cmdshell writing app allowed bat file doesnt help server names passed comma seperated list modifying code told rewrite asked please let know need info repro entire command printif remove powershell exe run powershell powershell exe computers get wmiobject class win32 volume servername foreach computer computers pscomputername computer pscomputername name computer name capacity computer capacity freespace computer freespace label computer label insertquery insert dbo temp disksdata servername diskname capacitygb freespacegb label values pscomputername name capacity freespace label invoke sqlcmd query insertquery serverinstance servername database dbname
206815 sql query trying optimize declare id uniqueidentifier cec094e5 b312 4b13 997a c91a8c662962 select id minsometimestamp maxsomeint dbo mytable id id somebit group id mytable two indexes create nonclustered index ix mytable sometimestamp includes dbo mytable sometimestamp asc includeid someint create nonclustered index ix mytable id somebit includes dbo mytable id somebit include totallyunrelatedtimestamp execute query exactly written sql server scans first index resulting logical reads second duration inline id variable execute query sql server seeks second index resulting logical reads second duration basically instant need variable want sql use good plan temporary solution put index hint query query basically instant however try stay away index hints possible usually assume query optimizer unable job something stop help without explicitly telling sql server come better plan inline variable
206832 wrote case statement choices using statement places simple query query twice union also count therefore group also contains case statement relabel company names different records company spelled differently tried declare variable varcharmax declare caseforaccountconsolidation varcharmax set caseforaccountconsolidation case ac accountname like air new air new zealand ac accountname like air bp air bp ac accountname like addiction advice addiction advice ac accountname like aia aia went use select statement query returned case statement text didnt evaluate also unable use group got error message group expression must contain least one column outer reference ideally would like case single place chance updating one line replicating elsewhere way open ways like maybe function sure use like sample select currently using select sumc charge amount gstexcl dl firstdateofmonth monthbilled dl firstdateofweek weekbilled case ac accountname like air new air new zealand ac accountname like air bp air bp ac accountname like addiction advice addiction advice ac accountname like aia aia else ac accountname end accountname dl financialyear convertdatec date charged date charged accession left join account code ac account code id ac account code id left join charge accession id accession id left join datelookup dl convertdatec date charged dl date datecreated convertdatenow group dl firstdateofmonth dl financialyear dl firstdateofweek convertdatec date charged case ac accountname like air new air new zealand ac accountname like air bp air bp ac accountname like addiction advice addiction advice ac accountname like aia aia else ac accountname end union select sumc charge amount gstexcl dl firstdateofmonth monthbilled dl firstdateofweek weekbilled case ac accountname like air new air new zealand ac accountname like air bp air bp ac accountname like addiction advice addiction advice ac accountname like aia aia else ac accountname end accountname dl financialyear convertdatec date charged date charged accession left join account code ac account code id ac account code id left join charge accession id accession id left join datelookup dl convertdatec date charged dl date datecreated dateaddyear 1convertdatenow group dl firstdateofmonth dl financialyear dl firstdateofweek convertdatec date charged case ac accountname like air new air new zealand ac accountname like air bp air bp ac accountname like addiction advice addiction advice ac accountname like aia aia else ac accountname end purpose union return data timeperiod also return data timeperiod months previously edit added missing catch edit2 added second union statement edit3 corrected group include necessary elements
206934 two tables mysql database posts reasons post row belongs many reason rows reason weight associated post therefore total aggregated weight associated increment points weight etc want get count posts total weight less equal increment id expect results look something like weight post count total weights approximately normally distributed low values high values maximum currently majority middle rows posts around reasons post average reasons relevant parts tables look like create table posts id bigint primary key create table reasons id bigint primary key weight int11 null create table posts reasons post id bigint null reason id bigint null constraint fk posts reasons posts post id references postsid constraint fk posts reasons reasons reason id references reasonsid far ive tried dropping post id total weight view joining view get aggregated count create view post weights select posts id sumreasons weight reason weight posts inner join posts reasons posts id posts reasons post id inner join reasons posts reasons reason id reasons id group posts id select floorp1 reason weight weight countdistinct p2 id cumulative post weights p1 inner join post weights p2 floorp2 reason weight floorp1 reason weight group floorp1 reason weight order floorp1 reason weight asc however unusably slow let run minutes without terminating cant production efficient way case youre interested testing entire dataset downloadable file around 60mb expands around 250mb alternately rows github gist
206975 please help understand pros cons using ola solution maintenance plan prepared presentation based sql pass http www pass org downloadfile aspxfile ebae1b31 present also preparing scenarios ola solution addresses maintenance plan solution please help explain technically way managing almost servers mix ola solution least liked article brent ozar one comments brent recommended use script based solution number servers https www brentozar com archive maintenance plans roombas suck good way
207262 im using sqlserver trying create storedprocedure inside try catch block like begin try create procedure ammeghezi1 int select end try begin catch end catch fails run error incorrect syntax near select expecting external changed sp like create procedure ammeghezi1 int begin select end cover sp begin end block error change also add go begin try statement got worst im getting conclude creating sp inside try catch block practical even possible create sp inside try catch block
207371 code converting subjectscolumns english hindi sanskrith rows declare colsunpivot nvarcharmax query nvarcharmax select colsunpivot stuff select quotename name sys columns object id object iddbo result2 xml path type value nvarcharmax print colsunpivot select query select name subjectmarks result2 unpivot marks subject colsunpivot tab exec sp executesql query please explain xml path type value nvarcharmax
207456 create table script create table temp id int identity11 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 decimal62 insert script insert temp abcdefghijklmnopqrstu values insert temp abcdefghijklmnopqrstu values expected result median first row second row non working solutions tried query working fine sql server issues sql server r2 select id avgval select id val count partition id row number partition id order val rn temp unpivot val col abcdefghijklmnopqrstu rn group id ran query version working properly working r2 get error sql server r2 incorrect syntax near keyword reason must databases compatibility level change compatibility level affect application cant ive also tried query select id select castavgtotavgas decimal62 median values convertdecimal62 aconvertdecimal62 convertdecimal62 convertdecimal62 dconvertdecimal62 convertdecimal62 fconvertdecimal62 gconvertdecimal62 hconvertdecimal62 convertdecimal62 jconvertdecimal62 kconvertdecimal62 lconvertdecimal62 convertdecimal62 nconvertdecimal62 oconvertdecimal62 pconvertdecimal62 convertdecimal62 rconvertdecimal62 sconvertdecimal62 tconvertdecimal62 totalavgtotavg median tempone obviously calculates average need median
207496 way determine whether user defined type postgresql enum essentially following create type foo enum sometimes wan na go everybody knows name table instantiated create table bar lyrics foo default wan na foo im able determine type foo column lyrics however im trouble finding way determine whether foo enum context need information programmatically get list possible values foo given column lyrics
207671 im struggling understand row estimation terribly wrong case simple join using sql server sp2 issue sp1 dbcompatiblity select amount transactioncurrency id currencyshareds id currencyshareds inner join annexes amount transactioncurrency id currencyshareds id option querytraceon querytraceon sql estimates row whereas chooses nested loop link plan statistics updated currencyshareds estimation fine merge join chosen link new plan soon one record added currencyshareds statistics become stale sql goes back wrong estimation wouldnt worry much simple query part larger one begining domino adding one row records table causes damage looking output cardinality estimation trace see warning warning badly formed histogram couldnt find anything topic output full output cardinality estimation begin selectivity computation input tree logop join cstcollbasetableid card tbl annexes cstcollbasetableid card tbl currencyshareds scaop comp cmpeq scaop identifier qcol test masterdata dbo currencyshareds id scaop identifier qcol test masterdata dbo annexes amount transactioncurrency id plan computation cselcalcexpressioncomparedtoexpression qcol test masterdata dbo annexes amount transactioncurrency id cmpeq qcol test masterdata dbo currencyshareds id loaded histogram column qcol test masterdata dbo annexes amount transactioncurrency id stats id loaded histogram column qcol test masterdata dbo currencyshareds id stats id warning badly formed histogram selectivity 59503e stats collection generated cstcolljoinid card jtinner cstcollbasetableid card tbl annexes cstcollbasetableid card tbl currencyshareds end selectivity computation estimating distinct count utility function input stats collection cstcollbasetableid card tbl annexes columns distinct qcol test masterdata dbo annexes amount transactioncurrency id plan computation cdvcplanleaf multi column stats single column stats guesses covering multi col stats id using ambient cardinality combine distinct counts combined distinct count result computation estimating distinct count utility function input stats collection cstcollbasetableid card tbl currencyshareds columns distinct qcol test masterdata dbo currencyshareds id plan computation cdvcplanuniquekey result computation update statistics currencyshareds part badly formed histogram changes cardinality calculated correctly plan computation cselcalcexpressioncomparedtoexpression qcol test masterdata dbo annexes amount transactioncurrency id cmpeq qcol test masterdata dbo currencyshareds id loaded histogram column qcol test masterdata dbo annexes amount transactioncurrency id stats id loaded histogram column qcol test masterdata dbo currencyshareds id stats id selectivity stats collection generated cstcolljoinid card jtinner cstcollbasetableid card tbl annexes cstcollbasetableid card tbl currencyshareds end selectivity computation stats info currencyshareds id stats id warning histogram looks fine name updated rows rows sampled steps density average key length string index filter expression unfiltered rows persisted sample percent pk currencyshareds id may 43pm null row affected density average length columns id row affected range hi key range rows eq rows distinct range rows avg range rows info second index name updated rows rows sampled steps density average key length string index filter expression unfiltered rows persisted sample percent ix fk amount transactioncurrency may 29pm null row affected density average length columns amount transactioncurrency id 932801e amount transactioncurrency id id rows affected range hi key range rows eq rows distinct range rows avg range rows
207706 table named articles column named price user web app selects price min price max need perform query like pricemin pricemax query select articles price pricemin pricemax however selected price min price max million dont output price greater even though rows values exist table defined like create table articles id int11 null auto increment name varchar100 null price varchar100 null source varchar255 null primary key id engine innodb auto increment default charset utf8
207984 select json array elements one two json gives result json array elements one two would like without quotes one two looks like cant use dont field names json array strings postgres version postgresql x86 apple darwin compiled i686 apple darwin11 llvm gcc gcc based apple inc build llvm build bit
208170 ive got following working select info1 info2 tablea id select xid tableb userid active works fine tableb also team column id like select return outermost select statement something like pseudo query course doesnt work select info1 info2 team tablea id select xid team tableb userid active read around thought maybe could help dont really know sure anybody suggest solution even possible
208178 got programming task area sql task people want get inside elevator every person certain weight order people waiting line determined column turn elevator max capacity lbs return last persons name able enter elevator gets heavy return type table question efficient way solve problem looping correct room improvement used loop temp tables solution set rowcount source table line schema result temp use northwind go declare sum int declare curr int set sum declare id int object idtempdb tempu null drop table temp object idtempdb resultu null drop table result create table result id int null name varchar255 null weight int null turn int null create table temp id int null name varchar255 null weight int null turn int null insert temp select line order turn exists select temp begin get top record select top curr weight temp order turn select top id id temp order turn print curr print sum sum curr begin print entering print curr set sum sum curr print sum insert result select temp id id id name turn delete temp id id end else begin print breaaaking break end end select top name result order turn desc create script table used northwind testing use northwind go object table dbo line script date set ansi nulls go set quoted identifier go create table dbo line id int null name varchar null weight int null turn int null primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary unique nonclustered turn asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary go alter table dbo line check add check weight go insert dbo line id name weight turn values gary jo thomas mark james
208372 im tracking waits sp blitzfirst get detail clicktoseedetails seconds last seconds sql server waiting particular bottleneck read times last seconds finding clr semaphore
208487 backstory im trying restore copies several sql databases different environment application needs roughly synchronized time course ideal way using full recovery mode using full log backups point time restores using timestamp case dont need perfectly synchronized within minutes id rather deal full backups restores control full backups run problem databases different sizes full backups run different lengths time question synchronize start time full backups finish time words restore full backup end looked backup started finished
208520 given band table json column holding array id people john thomas john james james george list number bands name part desired output name count john james thomas george
208731 ive added solution without using window functions benchmark large data set martins answer followup thread group using columns select list practical elegant powerful solution challenge use query groups expression part select list frequently used window functions logical grouping element involves data rows perhaps overkill example thought may find challenge interesting right ill wait posting solution maybe come better ones challenge table sensors periodically logs reading values guarantee sample times monotonous intervals need write query report exceptions meaning times sensors reported threshold reading either low high period time sensor reporting threshold values considered exception reading got back normal exception ends sample tables data script sql part training materials link sqlfiddle sensor thresholds setup example create table sensors sensor nvarchar10 null lower threshold decimal72 null upper threshold decimal72 null constraint pk sensors primary key clustered sensor constraint ck value range check upper threshold lower threshold go insert sensors sensor lower threshold upper threshold values nsensor nsensor nsensor go create table measurements sensor nvarchar10 null measure time datetime20 null measurement decimal72 null constraint pk measurements primary key clustered sensor measure time constraint fk measurements sensors foreign key sensor references sensors sensor go insert measurements sensor measure time measurement values nsensor n20160101 nsensor n20160101 nsensor n20160101 nsensor n20160101 nsensor n20160102 nsensor n20160102 nsensor n20160101 note exception range nsensor n20160101 nsensor n20160101 nsensor n20160102 nsensor n20160102 nsensor n20160101 nsensor n20160101 nsensor n20160101 nsensor n20160101 nsensor n20160101 go expected result sensor exception start time exception end time exception duration minutes min measurement max measurement lower threshold upper threshold maximal delta thresholds sensor sensor sensor sensor
209084 encountered interesting issue sql server consider following repro example create table test guid uniqueidentifier primary key insert test guid values 7e28eff8 a80a 45e4 bfe0 c13989d69618 select guid test guid 7e28eff8 a80a 45e4 bfe0 c13989d69618 guid newid drop table test fiddle please forget moment guid newid condition seems entirely useless minimal repro example since probability newid matching given constant value extremely small evaluate true every time doesnt running query usually returns row sometimes quite frequently time returns rows reproduced sql server system reproduce line fiddle linked sql server looking execution plan reveals query analyzer apparently splits condition guid newid guid newid completely explains fails sometimes first generated id smaller second one larger given id sql server allowed evaluate even one expressions non deterministic yes documented find bug interestingly guid newid yields execution plan random result found issue developer wanted optionally exclude particular row used guid isnull someparameter newid shortcut someparameter null guid someparameter looking documentation confirmation bug code relevant workarounds required
209384 way functions dmvs sql server provide executed stored procedure particular database
209546 vendor requires data warehouse database case sensitive need case insensitive queries case sensitive database would write case insensitive name like hospitalist
209583 working reporting system require large select queries based database filled database management system microsoft sql server probably better way design system like lets approach theoretically theoretically speaking large database 150m rows several tables assume database populated could indexing every possible column combination negative performance impact select query
209695 unused ctes queries affect performance alter generated query plan
209989 following table structure accountid property value status active city los angeles registrationdate status active city las vegas registrationdate status inactive city toronto registrationdate want able select rows property status value active property registrationdate value im figuring need kind group select aggregation cant get head around itmy sql really rusty want following output query accountid status registrationdate active active columns existed row would write something like select accountid property status active registrationdate
210066 order operation place ltrim rtrim matter used conjunction isnull instance take following example user potentially enters bunch spaces field trim input actual null value avoid storing empty strings performing trim operations outside isnull declare test1 varchar16 ltrimrtrimisnull test1 begin set test1 null end select test1 appropriately returns true null value lets place isnull outside declare test2 varchar16 isnullltrimrtrim test2 begin set test2 null end select test2 also returns null value work well intended usage im curious difference sql query optimizer handles
210249 notwithstanding blindly creating suggested missing indices less ideal way copy paste suggested missing indices execution plan tab sql server management studio get tool tip mouse hovering appear right click menu copy years ive typed needed curious base form easily gotten tab using ssms
210865 trying set sql server query lists count people signed tours conference event displays total sum sql code coming close ignoring clause grand total individual totals select sitetour countsitetour count tblconference registrationtype like cancellation group sitetour union select total sitetour countsitetour expr1 tblconference tblconference producing tour1 tour2 tour3 total tour1 count correct one registrationtype cancellation however total also getting initial row guess based counting nulls shows way prevent please help correct thank
211352 need migrate premises sql server database azure sql database im facing challenges since theres quite bit limitations go particular since azure sql database works utc time time zones need local time change use getdate everywhere database proven work anticipated created user defined function get local time works correctly time zone create function dbo getlocaldate returns datetime begin declare datetimeoffset set convertdatetimeoffset sysdatetimeoffset time zone pacific sa standard time returnconvertdatetime end issue im trouble actually change getdate function every view stored procedure computed columns default values constraints etc would best way implement change public preview managed instances still issue getdate doesnt help problem moving azure requirement database used used always time zone
211700 recently rebuild indexes uisng ola hallengreen script fragmented rebuilt noticed physical reads reduced lot anything index rebuilt
212003 wanting compare distinct sn hmi temp sn table hmi sn exists want update values got syntax check sn exist want insert data hmi temp hmi tried syntax get errors invalid column name cb invalid column name lp invalid column name cn invalid column name stn syntax write accomplish desired result merge hmi target using select distinct sn hmi temp source target sn source sn matched insert lp cb cn sn stn values source lp source cb source cn source sn source stn ddl create table dbo hmi temp sid int identity11 null stn float null sn nvarchar null cn nvarchar max null lp nvarchar max null cb nvarchar max null primary key clustered sid asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary textimage primary go set identity insert dbo hmi temp go insert dbo hmi temp sid stn sn cn lp cb values ntest ntest ntest123 ntest456 values nsecondtest nsecondtest nsecondtest123 nsecondtest456 go update statement using worked throwing wrench insert exists update set lp lp cb cb cn cn hmi inner join hmi temp stn stn sn sn cn cn
212435 pcs running sql server sp4 sp1 regularly lose power obviously sometimes leads index corruption sql server database need restore afterwards aware sql server designed scenarios correct solution fix cause power loss curious nevertheless tuning options sql server set reduce risk database corruption power loss background pc windows tablet mounted forklift user turns forklift tablet loses power tried teach users properly shut windows turning forklift failed probably turning works time also currently investigating options adding ups signals tablet shut power loss
212533 im dba ive googled msdb basically db sql agent job history im running space cloud server year worth msdb year okay delete keep backup purposes msdb 93gb 250gb hdd
212707 im using mysql three tables every table time column single query want count number rows two given dates need connection tables although related join necessary possible failed attempt select counta time countb time countc time tbl1 tbl2 tbl3 time time time
212742 first trigger alter trigger dbo price modified dbo stock recieve update set nocount update stock begin update set value new item price new stock stock recieve join inserted new new bill bill join deleted old old bill bill end second trigger alter trigger dbo newval dbo stock recieve update set nocount update stock begin update set uservalue new item price new stock stock recieve join inserted new new bill bill join deleted old old bill bill end result obtained first stock update item price stock stock value uservalue result obtained second stock update item price stock stock value uservalue first trigger suppose want second trigger uservalue add instead replace result hope clear ypercube
212770 cursor generates one record json text group tables cursor making ssms crash script runs time ssms fails code written causing crash declare row id int create variable contain id row declare json cursor cursor prepare cursor give select statement iterate select select statement whatever work wish row number order name 1name 2field 1field rowid select field field name name select field 1field 2namevalue table name name 1name src pivot maxvalue name field field pvt t0 left join table t0 name name open json cursor charges results memory fetch next json cursor row id fetch first result fetch status fetch went well go begin select select select statement whatever work wish field field field field t0 name row number order field 1field 2field 1field rowid select field field name name select field 1field 2namevalue table name name 1name src pivot maxvalue name field field pvt t0 left join table t0 name name t1 rowid row id regards latest fetched id order field 1field 2field 1field json path rootfield fetch next json cursor row id work done fetch next result end arrive fetch status shows results treat close json cursor deallocate json cursor close deallocate remove data memory clean process windows log following net runtime error happened first error pm net runtime none application ssms exe framework version v4 description process terminated due unhandled exception exception info system componentmodel win32exception system windows forms nativewindow createhandlesystem windows forms createparams system windows forms control createhandle system windows forms textboxbase createhandle system windows forms control createcontrolboolean system windows forms control createcontrolboolean system windows forms control createcontrol system windows forms control wmshowwindowsystem windows forms message byref system windows forms control wndprocsystem windows forms message byref system windows forms scrollablecontrol wndprocsystem windows forms message byref system windows forms containercontrol wndprocsystem windows forms message byref system windows forms updownbase wndprocsystem windows forms message byref system windows forms control controlnativewindow onmessagesystem windows forms message byref system windows forms control controlnativewindow wndprocsystem windows forms message byref system windows forms nativewindow debuggablecallbackintptr int32 intptr intptr second application error error pm application error faulting application name ssms exe version time stamp 0x5b304116 faulting module name kernelbase dll version time stamp 0x5abda7d6 exception code 0xe0434352 fault offset 0x000daa12 faulting process id 0x3f6c faulting application start time 0x01d4205466d2b650 faulting application path program files x86 microsoft sql server tools binn managementstudio ssms exe faulting module path windows system32 kernelbase dll report id 03b3b0c6 a71f f5b4fc0a3029 faulting package full name faulting package relative application id purpose script output single entry json posted data service cloud also ssms sending results grid full query stored procedure creating object storedprocedure dbo sp acq zerion post http script date set ansi nulls go set quoted identifier go fill db alter procedure dbo sp acq zerion post http id varchar50 define variables declare hr int declare object int declare responsetext varchar8000 declare src varchar255 desc varchar255 status int msg varchar255 cursor pt declare row id int create variable contain id row declare json cursor cursor prepare cursor give select statement iterate select select statement whatever work wish row number order name 1name 2field 1field rowid select field field name name select field 1field 2namevalue table name name 1name src pivot maxvalue name field field pvt t0 left join table t0 name name name truefalse open json cursor charges results memory fetch next json cursor row id fetch first result fetch status fetch went well go begin declare records varchar8000 cursor pt select select select statement whatever work wish field field field field t0 name row number order field 1field 2field 1field rowid select field field name name select field 1field 2namevalue table name name 1name src pivot maxvalue name field field pvt t0 left join table t0 name name name truefalse t1 rowid row id regards latest fetched id order field 1field 2field 1field json path rootfield wrap records json object declare body varchar8000 records create xmlhttp object send object via http post exec hr sp oacreate msxml2 serverxmlhttp object hr begin raiserrorsp oacreate msxml2 serverxmlhttp failed return end exec hr sp oamethod object open null posthttps dataflownode zerionsoftware com domain solutions services webhooks 4b9b0f4b8a4b4387ec1642fdaabec7b400d5c938 7be9d5a63b5cba8ab72cd3410429e2635f68a687 false hr begin set msg sp oamethod open failed goto eh end exec hr sp oamethod object setrequestheader null content type application json hr begin set msg sp oamethod setrequestheader failed goto eh end exec hr sp oamethod object send null body hr begin set msg sp oamethod send failed goto eh end status begin set msg sp oamethod http status str status goto eh end exec hr sp oamethod object responsetext responsetext put select responsetext cursor pt fetch next json cursor row id work done fetch next result end arrive fetch status shows results treat close json cursor deallocate json cursor close deallocate remove data memory clean process hr begin set msg sp oamethod read response failed goto hr begin exec sp oageterrorinfo object return goto eh end clean data sent exec hr sp oadestroy object return eh raiserror msg return hr begin exec sp oageterrorinfo object src desc raiserrorerror creating com component 0x s161 hr src desc return end go
212781 road age test table create table road age test surface year int base year int insert road age test surface year base year values insert road age test surface year base year values 30null insert road age test surface year base year values null40 insert road age test surface year base year values nullnull insert road age test surface year base year values commit select road age test surface year base year null null null null would like select greatest value column even one values null greatest year null whats simplest way note values null want return null
212797 view grabs lot data want able search view set following columns part number description information supplier manufacturer category subcategory currency price discount looking create stored procedure lets search view data specifically looking something like select partsdata part number first thought set procedure parameter looking varchar would essentially contain whatever entire clause sounds like would work however would able instead set stored procedure optional parameters sure something sql though initial idea implementation best bet seems like better way go sometimes clauses rather long description like cap supplier like a2a systems manufacturer like vario
213010 check memory usage sql server production box using sql server ever check task managerit shows dont think real memory usage sql server sql performance tool grafana shows cpu usage less see task manager checked resource monitorthere see average cpu value confused sql server memory usage trying determine memory pressure issue problem someone direct good proper explanation
213199 currently using sql server sp standard edition want install services documentation said stand alone installation allowed enterprise machine learning server standalone also found post guy talking standard able use parallel operations memory limitations could anyone tell exact memory processors limitations need details going use heavy calculations tests show implementation standard edition working hoped
213317 incarnations explained answer another question site answer mentions orphaned incarnations factors result orphaned incarnations obsolete backups see oracle docs database incarnation includes status column values orphan current parent must related orphaned incarnations steps would result row status orphan database incarnation
213608 puzzled issue almost week hopefully someone community experienced issue already found solution problem per company policy want database mail able send emails port tls enabled tls tls disabled mail server exchange server sql server developer enterprise editions boxes os windows server standard editions sql server version select version microsoft sql server sp1 cu7 gdr kb4057119 x64 dec copyright microsoft corporation developer edition bit windows server datacenter x64 build hypervisor db mail configuration shown issue whenever turn ssl use msdb exec dbo sysmail update account sp account id enable ssl send db mail matter whether smtp authentication windows authentication basic authentication anonymous authentication error message db mail log follows message mail could sent recipients mail server failure sending mail using account 30t10 exception message send mails mail server failure sending mail turn ssl problem db mail sent enable ssl uses tls db mail enabled tls adding registry shown details link see faq section
213791 need confirm particular table ever existed sql server existing script method one use list dropped databases sql server instance
213922 consider following relation instance mytable num1 num2 null null null null query select mytable num1 null query select mytable num1 null know null values looked using null null want know two queries evaluated number tuples outputted q1 q2 ansi standards
214757 clustered index primary key column im range query problem scan uses first range part seek predicate leaving side range residual predicate causes read rows upper limit im using two parameters range declare lower numeric180 upper numeric180 select messages msg id lower upper case actual execution plan shows predicate messages msg id lower seek predicate messages msg id upper rows read table definition simplified create table dbo messages msg id numeric identity01 null col2 varchar null constraint pk message primary key clustered msg id asc information used constants instead variables predicates seek tried option optimize lower without success
214863 list constraints primary key check unique mutual exclusive table postgresql
215043 im using code get mix date time use like unique id datetime tostring yyyymmddhhmmssfffff sql server im confused best smallest size data type would use store string best smallest data type bigint timestamp varchar19
215078 two tables identically named typed indexed key columns one unique clustered index one non unique test setup setup script including realistic statistics drop table exists left drop table exists right create table left char4 null char2 null varchar13 null bit null char4 null char25 null char25 null char25 null columns create unique clustered index ix left update statistics left rowcount pagecount create table right char4 null char2 null varchar13 null bit null char4 null char25 null char25 null char25 null columns create clustered index ix right update statistics right rowcount pagecount repro join two tables clustering keys expect one many merge join like select left left join right query plan want never mind warnings fake statistics however change order columns around join like select left left join right used third used first used second happens sort operator seems order streams according declared order join adds blocking operation query plan things ive looked ive tried changing columns null results original table created ansi padding creating ansi padding affect plan tried inner join instead left join change discovered sp2 enterprise created repro developer current cu removing clause leading index column generate good plan kind affects results finally get question intentional eliminate sort without changing query vendor code id really rather change table indexes
215172 sql server sp1 data ready share partner developer except columns example email varchar64 masked function email null give partner credentials logging test copy database certain user without unmask permission understand reasonably safe considering sharing database backup partners reload server environment would probably need contained users partner create new users connect existing logins sure create user user name password strong password way share database backup still trust masked columns safe physically delete data
215212 writing query returns single record parent table would like also return query children one many relationship parent parent id name child child id name parent id first instinct write following query select name select countchild id child parent id parent id children parent name like name wondering efficient way since dont actually care count whether children pointers
215382 trouble understanding exactly expect cleanuptime option ola hallengren server maintenance solution im finding related questions elaborate answers explanations still puzzle bit specifically weekly full backup daily diff backup hourly log backup full backup using default cleanuptime 24h diff log backup null cleanuptime documentation cleanuptime paramter fail understand setting cleanuptime setting backup backuptype full also delete older diff log backup files full backup files specify time hours backup files deleted time specified backup files deleted latter paragraph makes think setting cleanuptime backups backuptype full also delete older transaction logs yet unclear paragraph applies backups backuptype log also backups backuptype full databasebackup check verify transaction log backups newer recent full differential backup deleted trying achieve point time recovery week slowly changing database feasible way understand would require week old full backup weeks worth transaction log backup since full differential backups used restore one specific point time set cleanuptime option full backup job im guessing setting 24h cause next full backup delete older full diff transaction log backup files leaving point time recovery window hours right
215491 table contains sparse columns along column set column brief example drop table exists columnset go create table columnset id int null value1 varchar100 sparse null value2 varchar100 sparse null value3 varchar100 sparse null value4 varchar100 sparse null allvalues xml column set sparse columns go insert columnset id value1 value2 value3 value4 values positive null null null negative null negative null null null negative positive negative null positive result null go want query column set identify rows columns value positive using value method column set concatenate values together one string could use like dont want results value within another string select columnset allvalues value nvarchar4000 like positive alternative methods querying column set achieve using apply along nodes method provides concatenated string output though syntax could incorrect required output id
215534 using mongodump mongo tools download backup server however run command command returns unrecognized field snapshot full error failed error reading collection failed parse find data skip snapshot true readpreference mode secondarypreferred db xxx unrecognized field snapshot mongodump version returns mongodump version built without version string git version built without git spec go version go1 os linux arch amd64 compiler gc openssl version openssl 2g mar might need downgrade version otherwise unsure go
215699 tables implement exists exists folows table exists drop object idau null drop table table exists create object idau null create table key varchar20 value varcharmax quite working views triggers exists drop object idvav null drop view va im trying oposite exists create object idvav null create view va select im getting following error incorrect syntax near keyword view triggers exists create object idtrigger instr null create trigger trigger ins instead insert insert select inserted im getting error incorrect syntax near keyword trigger exists drop object idtrigger instr null drop trigger trigger ins working missed anything anyone explain difference tables triggers views note im using sql server
215868 imagine following situation person passport person owns one passport one passport owned single person clear case one one relationship sake simplicity let us imagine person name passport nationality bothering seems everyone differently tell four strategies taken map relationship everything table foreign key owner side references owned side value primary keys tables foreign key owned side unique key top number pretty self explanatory see problem entities small lot fields gigantic table number seems fine way seen people frameworks entity framework hibernate also way taught school big problem referential integrity deletion logic upside able delete passport without problem case able delete without deleting person well make sense number seem pretty much identical foreign key passport side able delete passports without deleting people makes sense remove person remove passport main advantage see using option number instead number others ever reason decide want user multiple passports remove unique key constraint incredibly easy lot less hassle changing keys tables question basically reduced following many advantages number people keep using strategies biggest grip orms hibernate opinion things opposite way owning side relation tracked hibernate side relation owns foreign key database tried java hibernate relationship would swapped included foreign key passport person table like wants would ruin deletion logic like explained impression ef also works way people keep preferring disadvantageous approaches
216417 running select sys server principals public role column fixed role shown documentation states fixed server role documentation link although stated public little bit different roles assign permissions anyway mentioned fixed role anyone explain dilemma
216816 ive started new job involves looking bunch big numbers easy way add commas int decimal field make readable example sql server outputs column left sanity need look like one right would write heinous leftrightvandalized data63 rightleftvandalized data63 function perfect thing would commas display grid plain integers output
216919 piece sql seems run really fast environment exact query runs really slow environment environments supposed look order see query doesnt perform
216999 sp msforeachdb undocumented sp designed run sql every database server instance appear need use use keyword exec sp msforeachdb command1 select db name prints database name sp msforeachdb command run times number databases instance exec sp msforeachdb command1 use select db name prints name database necessary use use statement shouldnt behavior inherent procedure
217019 want create bible verse table one field representing range bible verses currently represent range pair values versebegid verseendid want something like sql server spatial data type instead create table bibleverse table versebegid int null verseendid int null want create table bibleverse table verserange null
217419 run ola hallengrens checkdb job secondary asynchronous replica dr readable business hours currently asynchronous replica readable first question possible secondly safe primary server live checkdb secondary server business hours hours
217424 example im creating view name 4aii sql server care starts could call table fouraii ivaii additionally behind scenes allow string used name strings string amirite
217653 dbo programs table column id primarykey par composite key also quite indexes table im running simple query select id dbo programs execution plan question using pk index instead performance issue table rows find odd want understand sqlserver right im wrong assumed would better
217788 dont clear understanding query optimization database happens ive seen medium post discusses pitfalls using postgresql cte terms optimization since cte evaluated optimizations may applied terms cte used database cant apply example blog post seems trivial optimize select foo id vs cte select foo select cte id calculation cte done lazily first requirement would imagine two queries could optimized way think least made wonder would sql server able optimize query better postgres known differences databases extent ability optimizing queries
218315 im stuck way sum column lets say first column table result another query without knowing column name something like column position id something like select sumwhat employid select count employid table1 union select count employid table2 union select count employid table3 single query single simple select query using sum like select employname sumwhat employid tablex tell sum function sum based column position index table like sum2 note dont want use column alias possibility sum based column name know use column name aliases really want know possibility using im asking question possible ways accept correct answer
218479 sql server microsoft introduces utf support char varchar data types says feature may provide significant storage savings depending character set use example changing existing column data type ascii strings nchar10 char10 using utf enabled collation translates nearly reduction storage requirements reduction nchar10 requires bytes storage whereas char10 requires bytes unicode string utf seems support every script basically start storing unicode data varchar char columns said documentation reduce size tables indexes get even better performance smaller amount data read wondering mean stop use nvarchar nchar columns implements utf anyone point scenario reason use char data types utf encoding continue use chars ones
218871 two tables mysql database t1 column c1 t2 column c2 run query select t1 c1 select c1 t2 query give error c1 present t2 instead returns rows t1 another version query delete much disastrous delete t1 c1 select c1 t2 query deletes rows t1 supposed give error noticed behavior occurs column subquery name outer one meaning select t1 c1 select c3 t2 throw error expected error 42s22 unknown column c3 field list way checked issue postgresql behavior exactly explanation strange behavior
218962 say production system several databases encrypted using tde self generated certificate regularly need take database refresh non production systems process involves backing source database restoring pre production obfuscating personal data number items key fact pre production system copy encryption certificate production looking ways make process secure im happy certificate sat pre production environment another way never unencrypted backup saved anywhere allow propagation personal data production non production systems
219936 full data backup using ssms ui bottom window option specify destination disk also add multiple files question adding multiple files create duplicate copies full backup create split backup split full backup specified files book suggests duplication link suggests split please someone clarify
220266 cant find documentation whether agent jobs sql server backed back order restore future recovery case instance failure
220270 historically recommended use default ports connections sql server part security best practice server single default instance following ports would used default sql server service port tcp sql server browser service port udp dedicated admin connection port tcp questions advice still relevant ports changed
220363 data warehouse comprised four clustered columnstore index tables cci nine rowstore tables tables used analytics cci data inserted staging tables every minutes looking optimize query performance adding partitions sorting queries data predicated integer field distinct values leftmost cci 100m records columns three child ccis integer field cci 15m records columns cci 30m records columns distinct integers distribution record count leftmost table follows greater 1m greater 100k greater 10k additionally nine rowstore tables also join ccis trickle inserts children ccis contain integer field rowstores similar smaller record volumes columns two contain lobs two undergo mass updates frequently updates also predicated id field many partitions make partition rowstore tables also important considerations overlooking note regarding sorting mentioned earlier date field leftmost cci often secondary predicate queries therefore looking sorting cci date every four weeks maintenance achieve sort dropping cci adding clustered rowstore index date dropping index adding cci maxdop also looking sorting child ccis join key parent
220560 know first time type question asked following scenario persisted computed column created non deterministic answer always right create table dbo test id int eventtime datetime null posixtime int null go declare eventtime datetime declare gpstime int datediffsecond eventtime insert dbo testid eventtime posixtime values eventtime gpstime null gpstime go select dbo test go alter table dbo test add utctime convertdatetime2isnulleventtime dateaddsecond posixtime convertdate19700101112 persisted go msg level state line computed column utctime table test persisted column non deterministic think im following deterministc rules possible create persisted computed column
221191 short question use use master create database example microsoft documentation use master go create database sales name sales dat filename program files saledat mdf size maxsize filegrowth log name sales log filename program files salelog ldf size 5mb maxsize 25mb filegrowth 5mb
221290 im working code golf puzzle need add int number column result maintaining current order lets say source data select value string splitonetwothreefourfive returns items original desired order value one two three four five try use row number rank im forced specify order value legal choice select value row number overorder value string splitonetwothreefourfive expected sorts value alphabetically instead leaving desired original order value five four one three two joining number table doesnt work since without clause ill get full outer join best could come using temp table identity field create table argg int identity11 varchar99 insert argg select value string splitonetwothreefourfive select argg drop table argg really long annoying better ideas
221349 debug button present version ssms present version preview tried several ways add debug button ssms successful way add debug button ssms v18
221531 im already quite comfortable using compress decompress internal forum software company currently sql server trying make database efficient possible advantage adding utf current collation latin1 general ci sc utf8 upon future migration sql server
222987 given next example object iddbo table null drop table dbo table go create table dbo table id int identity null primary key foo int null bar int null nki int null go insert random data insert dbo table foo bar nki select top abschecksumnewid abschecksumnewid convertint row number order s1 object id sys objects s1 cross join sys objects s2 go create unique nonclustered index ix table dbo table nki asc go fetch records ordered nki non clustered index set statistics time select id foo bar nki table order nki set statistics time sql server execution times cpu time ms elapsed time ms optimiser chooses clustered index applies sort algorithm execution plan force use non clustered index set statistics time select id foo bar nki table withindexix table set statistics time sql server execution times cpu time ms elapsed time ms uses non clustered index key lookup execution plan obviously non clustered index transformed covering index create unique nonclustered index ix table dbo table nki asc include id foo bar go uses index set statistics time select id foo bar nki table order nki set statistics time sql server execution times cpu time ms elapsed time ms execution plan question sql server use clustered index plus sort algorithm instead using non clustered index even execution time faster latter case
223392 one last lessons university im student lecturer asked us develop database mysql server matters tiny client app would consume database data source one requirements identity column pk every table must sequential good practice per lecturer words table row deleted pk must reused subsequent inserts average knowledge rdbms pks identity columns understand identity column way let db auto generate pks inserting rows nothing identity column value shall related row attributes way long natural key requirement strictly sequential identity column suspicious tried ask lecturer wrong identity sequential gaps caused deletions got abstract answer like convenient users useful db administrators maintain database specific examples argument convenient users sounds silly doesnt meaning business domain therefore im curious reasons real think one case identity column reseed required identity space exhausted design issue identity column type chosen incorrectly say simple int instead bigint uniqueidentifier table contains billion rows suppose identity column clustered index gaps identity column affect index performance maybe real world reasons automatic identity column seed delete im aware thanks advance
223496 im inserting xml data xml column sql server data inserted changed sql server data insert xsl value select name given xsl text xsl text xsl value select name family read back looks like xsl value select name given xsl text xsl value select name family pay attention second line problem changes xslt transformation output first example create space given family name second create space like johnjohnsen first one like john johnsen way solve
223906 trying get count ids orders table yesterday hardcode date table corresponds order placed table looks like orders order id int primary key user id int date created date order value float city id int used code get todays date table select dateadddd datediffdd getdate today orders works fine try attempt clause select dateadddd datediffdd getdate today orders today date created receive error invalid column name today question simply get table recognise date added new column allow perform work thanks advance
224871 non binary tree customer need obtain ids tree given node table simple join table parent id child id representation tree stored db example search node need return search need return order important need id avoid circularity adding children node created query ancestor part works fine retrieve parent nodes descendants trouble im able retrieve part tree example node retrieve right part tree missing recursive starting nodes starting parent child select parent child public customerincustomer child node parent node ancestors parent child select parent child public customerincustomer parent select parent starting union select parent child public customerincustomer join ancestors child parent descendants parent child select parent child public customerincustomer parent select parent starting child select child starting union select parent child public customerincustomer join ancestors parent child table ancestors union table descendants update see many examples included tree table also root form root id null case dont record example taking smallest tree table one record parent child
224913 query always filters status performance benefit one ways context ad hoc query datatype userstatus int userstatus declare userstatus int userstatus userstatus please dont talk params literals different values unknown changing thats different topic
225240 looking legacy sql query bit able get inner joining table twice columns talking table1 table1 joined alias table1alias select distinct othercolumns table1alias columna maintable inner join secondarytable maintable id1 secondarytable id1 inner join table1 secondarytable id2 table1 id3 inner join table1 table1alias secondarytable id2 table1alias id3 inner join thirdtable table1 id4 thirdtable id5 inner join fourthtable thirdtable id6 fourthtable id7 inner join fivetable thirdtable id8 fivetable id9 inner join sixthtable table1alias columna sixthtable id10 left join seventhtable thirdtable id11 seventhtable id12 leftsecondarytable type123 secondarytable type456 cate table1 type table1alias columna conn
225274 person table created column references primary id table could employee adds another employee database works fine people also add signup value created column auto incremented value id column value obviously available insert could either make reference check values add default value beginning make column nullable options seem bad mysqls dialect set foreign key checks insert employee values12345678906789012345 set foreign key checks could find something similar sql servers sql
226356 wonder sql server makes wrong estimations simple case scenario create partition function pf test int range right values create partition scheme ps test partition pf test primary create table datekey int null type int null constraint pk primary key datekey type ps testdatekey insert datekey type select datekey n1 type n2 dbo numbers n1 cross join dbo numbers n2 n1 n2 update statistics pk fullscan incremental create table datekey int null subtype int null type int null constraint pk primary key datekey subtype ps testdatekey insert datekey subtype type select datekey subtype type type cross join dbo numbers update statistics pk fullscan incremental setup pretty straightforward statistics place sql server produce correct estimates query one table select count datekey select count datekey simple select estimates way see explanation select datekey type join datekey datekey type type datekey right clustered index seek estimation actual real world query even worse estimate actual numbers table reproduce setup declare upperbound int ctennumber select row number order s1 object id sys columns s1 cross join sys columns s2 select number dbo numbers cten number upperbound create unique clustered index cix number dbo numbersn fillfactor event server default changed data compression row enterprise table large enough matter pps scenario non partitioned works perfectly
226610 im trying trouble shoot slow performing query using show plan analysis ssms actual execution plan analysis tool points estimates number rows returned results places plan gives implicit conversion warnings dont understand implicit conversions int varchar fields referenced part parameter filter query tables involved column data types get cardinalityestimate warnings type conversion expression convert implicitvarchar12 ccd profileid may affect cardinalityestimate query plan choice field integer everywhere db type conversion expression convert implicitvarchar6 ccd nodeid may affect cardinalityestimate query plan choice field smallint everywhere db type conversion expression convert implicitvarchar6 ccd sessionseqnum may affect cardinalityestimate query plan choice field smallint everywhere db type conversion expression convert implicitvarchar41 ccd sessionid may affect cardinalityestimate query plan choice field decimal everywhere db edit query actual execution plan reference https www brentozar com pastetheplan id sysyt0nzn table definitions object table dbo agentconnectiondetail script date set ansi nulls go set quoted identifier go create table dbo agentconnectiondetail sessionid decimal null sessionseqnum smallint null nodeid smallint null profileid int null resourceid int null startdatetime datetime2 null enddatetime datetime2 null qindex smallint null gmtoffset smallint null ringtime smallint null talktime smallint null holdtime smallint null worktime smallint null callwrapupdata varchar collate sql latin1 general cp1 ci null callresult smallint null dialinglistid int null convertedstartdatetimelocal datetime2 null convertedenddatetimelocal datetime2 null constraint pk agentconnectiondetail primary key clustered sessionid asc sessionseqnum asc nodeid asc profileid asc resourceid asc startdatetime asc qindex asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary go object table dbo contactcalldetail script date set ansi nulls go set quoted identifier go create table dbo contactcalldetail sessionid decimal null sessionseqnum smallint null nodeid smallint null profileid int null contacttype smallint null contacttypedescription varchar collate latin1 general ci null contactdisposition smallint null contactdispositiondescription varchar collate latin1 general ci null dispositionreason varchar collate latin1 general ci null originatortype smallint null originatortypedescription varchar collate latin1 general ci null originatorid int null originatordn varchar collate latin1 general ci null destinationtype smallint null destinationtypedescription varchar collate latin1 general ci null destinationid int null destinationdn varchar collate latin1 general ci null startdatetimeutc datetime2 null enddatetimeutc datetime2 null gmtoffset smallint null callednumber varchar collate latin1 general ci null origcallednumber varchar collate latin1 general ci null applicationtaskid decimal null applicationid int null applicationname varchar collate latin1 general ci null connecttime smallint null customvariable1 varchar collate latin1 general ci null customvariable2 varchar collate latin1 general ci null customvariable3 varchar collate latin1 general ci null customvariable4 varchar collate latin1 general ci null customvariable5 varchar collate latin1 general ci null customvariable6 varchar collate latin1 general ci null customvariable7 varchar collate latin1 general ci null customvariable8 varchar collate latin1 general ci null customvariable9 varchar collate latin1 general ci null customvariable10 varchar collate latin1 general ci null accountnumber varchar collate latin1 general ci null callerentereddigits varchar collate latin1 general ci null badcalltag char collate latin1 general ci null transfer bit null nextseqnum smallint null redirect bit null conference bit null flowout bit null metservicelevel bit null campaignid int null origprotocolcallref varchar collate latin1 general ci null destprotocolcallref varchar collate latin1 general ci null convertedstartdatetimelocal datetime2 null convertedenddatetimelocal datetime2 null altkey concat sessionid sessionseqnum nodeid profileid collate database default persisted null prvseqnum smallint null constraint pk contactcalldetail primary key clustered sessionid asc sessionseqnum asc nodeid asc profileid asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary go object table dbo contactqueuedetail script date set ansi nulls go set quoted identifier go create table dbo contactqueuedetail sessionid decimal null sessionseqnum smallint null profileid int null nodeid smallint null targetid int null targettype smallint null targettypedescription varchar collate latin1 general ci null qindex smallint null queueorder smallint null disposition smallint null dispositiondescription varchar collate latin1 general ci null metservicelevel bit null queuetime smallint null constraint pk contactqueuedetail primary key clustered sessionid asc sessionseqnum asc profileid asc nodeid asc targetid asc targettype asc qindex asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary go object index name missing index sysname script date create nonclustered index name missing index sysname dbo contactcalldetail convertedstartdatetimelocal asc include sessionid sessionseqnum nodeid profileid pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary go object index idx ccd contacttype desttype stdtlocal script date create nonclustered index idx ccd contacttype desttype stdtlocal dbo contactcalldetail destinationtype asc contacttype asc convertedstartdatetimelocal asc include sessionid sessionseqnum nodeid profileid convertedenddatetimelocal pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary go set ansi padding go object index idx cqd profile traget targettype script date create nonclustered index idx cqd profile traget targettype dbo contactqueuedetail profileid asc targetid asc targettype asc include targettypedescription queueorder disposition dispositiondescription queuetime pad index statistics norecompute sort tempdb drop existing online allow row locks allow page locks primary go
226792 sql server temporary tables prefixed supported localdb instances
226838 ive got bunch financial reports want able pass two inputs year quarter variables im way really dont like declare quarter int year int date date set quarter set year set date cast year varchar4 set date dateaddquarter quarter date print date question best way reconstruct date integer inputs desired result
226946 coming sql programming languages structure recursive query looks rather odd walk step step seems fall apart consider following simple example create table nums bigint insert nums values select nums union select select order lets walk first anchor member executes result set put initialized execution drops union recursive member executed first time executes currently hand results new result append existing label resulting union carry recursion redefine new result union ing later neither choice makes sense execute next iteration recursion end weve lost mislabeling problem understood union anchor member result set subsequent recursive member result sets whereas component full accrued far therefore write recursive member selecting makes sense certainly appreciate max vernon michael detailed namely components created recursion limit null set components unioned together understand sql recursion actually work redesigning sql maybe would enforce clear explicit syntax something like select nums union select select order sort like inductive proof mathematics problem sql recursion currently stands written confusing way way written says component formed selecting mean full appears constructed far means previous component
227267 tmp table shown table ignore dup key set id column primary key said table one key inserting lots data get duplicate key ignored message redundant data want check redundant row tried insert checked origin message sys messages store row failed insertion attempt took place duplicate primary key value
227288 server 32gb running sql server sp2 max memory 25gb two tables find simplified structure tables create table dbo settings id int identity11 null resourceid int null typeid int null remark varchar max null constraint pk settings primary key clustered id asc primary go create table dbo resources id int identity11 null resourceuid int null constraint pk resources primary key clustered id asc primary go following non clustered indexes create nonclustered index ix uid dbo resources resourceuid asc create nonclustered index ix test dbo settings resourceid asc typeid asc database configured compatibility level run query spills tempdb execute query exec sp executesql select idremark resources inner join settings resourceid id resourceuid uid order typeid uid int uid dont select remark field spills occurs first reaction spills occurred due low number estimated rows nested loop operator add datetime integer columns settings table add select statement execute query spills happening spills happening remark selected probably something fact varcharmax avoid spilling tempdb adding option recompile query makes difference
228561 dont see index rebuild would require sch lock given index
228597 help debugging batch sql run inside transaction inside transaction dump data global temporary table global temporary table created inside transaction choice reasons going thought might able select temp table outside transaction different connection using withnolock however select blocked completing way select temp table outside transaction
228695 limit content filter handle example select name people job values goes microsoft docs says explicitly including extremely large number values many thousands values separated commas within parentheses clause consume resources return errors work around problem store items list table use select subquery within clause exact approximate number many thousands values
228789 part etl process compare rows staging reporting database figure columns actually changed since data last loaded comparison based unique key table kind hash columns currently use hashbytes sha2 algorithm found scale large servers many concurrent worker threads calling hashbytes throughput measured hashes per second increase past concurrent threads testing core server test changing number concurrent maxdop queries testing maxdop showed scalability bottleneck workaround want try sql clr solution attempt state requirements function must able participate parallel queries function must deterministic function must take input nvarchar varbinary string relevant columns concatenated together typical input size string characters length max chance hash collision roughly equal better md5 algorithm checksum work us many collisions function must scale well large servers throughput per thread significantly decrease number threads increases application reasons assume save value hash reporting table cci doesnt support triggers computed columns problems well dont want get scalable way simulate hashbytes using sql clr function goal expressed getting many hashes per second large server performance matters well terrible clr dont know accomplish motivates anyone answer plan adding bounty question soon able example query roughly illustrates use case drop table exists changed ids select stg id changed ids select id cast hashbytes sha2 castfk1 nvarchar19 castfk2 nvarchar19 castfk3 nvarchar19 castfk4 nvarchar19 castfk5 nvarchar19 castfk6 nvarchar19 castfk7 nvarchar19 castfk8 nvarchar19 castfk9 nvarchar19 castfk10 nvarchar19 castfk11 nvarchar19 castfk12 nvarchar19 castfk13 nvarchar19 castfk14 nvarchar19 castfk15 nvarchar19 caststr1 nvarchar500 caststr2 nvarchar500 caststr3 nvarchar500 caststr4 nvarchar500 caststr5 nvarchar500 castcomp1 nvarchar1 castcomp2 nvarchar1 castcomp3 nvarchar1 castcomp4 nvarchar1 castcomp5 nvarchar1 binary32 hash1 hb tbl tablock stg inner join select id casthashbytes sha2 castfk1 nvarchar19 castfk2 nvarchar19 castfk3 nvarchar19 castfk4 nvarchar19 castfk5 nvarchar19 castfk6 nvarchar19 castfk7 nvarchar19 castfk8 nvarchar19 castfk9 nvarchar19 castfk10 nvarchar19 castfk11 nvarchar19 castfk12 nvarchar19 castfk13 nvarchar19 castfk14 nvarchar19 castfk15 nvarchar19 caststr1 nvarchar500 caststr2 nvarchar500 caststr3 nvarchar500 caststr4 nvarchar500 caststr5 nvarchar500 castcomp1 nvarchar1 castcomp2 nvarchar1 castcomp3 nvarchar1 castcomp4 nvarchar1 castcomp5 nvarchar1 binary32 hash1 hb tbl tablock rpt rpt id stg id rpt hash1 stg hash1 option maxdop simplify things bit ill probably use something like following benchmarking ill post results hashbytes monday create table dbo hash id bigint null fk1 bigint null fk2 bigint null fk3 bigint null fk4 bigint null fk5 bigint null fk6 bigint null fk7 bigint null fk8 bigint null fk9 bigint null fk10 bigint null fk11 bigint null fk12 bigint null fk13 bigint null fk14 bigint null fk15 bigint null str1 nvarchar500 null str2 nvarchar500 null str3 nvarchar500 null str4 nvarchar500 null str5 nvarchar2000 null comp1 tinyint null comp2 tinyint null comp3 tinyint null comp4 tinyint null comp5 tinyint null insert dbo hash tablock select rn rn rn rn rn rn rn rn rn rn rn rn rn rn rn rn replicatechar65 rn replicatechar65 rn replicatechar65 rn replicatechar65 rn replicatechar65 rn select top row number order select null rn master spt values t1 cross join master spt values t2 option maxdop select maxhashbytessha2 castn nvarcharmax castfk1 nvarchar19 castfk2 nvarchar19 castfk3 nvarchar19 castfk4 nvarchar19 castfk5 nvarchar19 castfk6 nvarchar19 castfk7 nvarchar19 castfk8 nvarchar19 castfk9 nvarchar19 castfk10 nvarchar19 castfk11 nvarchar19 castfk12 nvarchar19 castfk13 nvarchar19 castfk14 nvarchar19 castfk15 nvarchar19 caststr1 nvarchar500 caststr2 nvarchar500 caststr3 nvarchar500 caststr4 nvarchar500 caststr5 nvarchar2000 castcomp1 nvarchar1 castcomp2 nvarchar1 castcomp3 nvarchar1 castcomp4 nvarchar1 castcomp5 nvarchar1 dbo hash option maxdop
228868 suppose table orders containing columns order id total discount write query similar following select countorder id num orders sumtotal countorder id avg total sumdiscount countorder id avg discount orders value countorder id preserved across columns computed eg performance hit better determine computed values first used query example declare order count int select order count countorder id orders select order count num orders sumtotal order count avg total sumdiscount order count avg discount orders note writing question noticed since sql server avg supported however continued question intend general wanting understand sql server handles identical aggregates across columns sometimes run forms
229012 im trying make stored procedure return rowid matching parameters lets say table rowid documentid employeeid companyid null null send lets say values documentid employeeid comanyid return second row since documentid companyid exist situation would send documentid employeeid companyid return first table little information problem clear feel free ask detail
229064 background im working website movie theather chain currently located four different cities might expand future use single database website cities means column certain tables holds id city row belongs right three different tables cinemas contains citys cinema id name movies contains movies shown cinema showtimes contains showtimes movies cities structure showtimes table following column name column type description id bigint primary unique id showtime perhaps unnecessary cinemaid tinyint foreign key bound cinemas id movieid bigint foreign key bound movies id showtime datetime date time movie show contain multiple rows movie one row showtime table used user website must able view current upcoming movies showtimes sorted date selected city example query backend select movieid showtime showtimes cinemaid order showtime select single movie view showtimes specific title selected city example query select showtime showtimes cinemaid movieid order showtime select single day view movies showtimes day selected city example query select movieid showtime showtimes cinemaid showtime date date pm naturally decided needed create indexes columns problem im trouble deciding determining index columns properly one index column seems quite expensive started looking composite indexes seems right choice also led even confusion understanding based ive read add columns index order selectivity making selective im guessing means unique cardinality column first composite index case would showtime column problem index used database first column included search query currently isnt either queries question kind indexes apply columns order cover usage scenarios last scenario may omitted first two required use composite index columns columns need separate index column table updated times per week add new showtimes footnotes mysql indexes best practices indexing every column table important order columns indexes question important order columns indexes top voted answer use composite index
229070 query need cross join small table rows table roughly 31k rows execution plan sql server came index scans tables joins nested loops inner join however checking execution plan noticed scan smaller table produced 31k 155k rows following step mean sql server scanning index smaller table 31k times small reproduction problem im create table id int primary key create table id int primary key insert aid values insert bid values select cross join query live statistics select command question whether index scan smaller table performing multiple operations one row bigger table opposed result fed following step
229103 currently process migrating data oracle sql server im encountering issue trying validate data post migration environment details oracle al32utf8 character set client nls lang we8mswin1252 varchar2 field sql server latin1 general ci collation nvarchar field im using dbms crypto hash oracle generate checksum whole row copying sql using hashbytes generate checksum whole row im comparing validate data matches checksums match rows except multibyte characters example rows character match checksums even though data transferred correctly use dump oracle convert varbinary sql server data matches exactly except bytes character sql server bytes 0xe625 oracle 0x25e6 ordered differently reliable way convert one ensure checksum end matches strings multi byte characters
229559 table created populated following code create table dbo examplegroupkey int null recordkey varchar12 null alter table dbo example add constraint iexample primary key clusteredgroupkey asc recordkey asc insert dbo examplegroupkey recordkey values archimedes newton euler euler gauss gauss poincar ramanujan neumann grothendieck grothendieck tao rows finite collaboration distance based recordkey another row would like assign unique value dont care data type unique value correct result set meets im asking generated following query select supergroupkey groupkey recordkey dbo example groupkey in1 union select supergroupkey groupkey recordkey dbo example groupkey union select supergroupkey groupkey recordkey dbo example groupkey in5 order supergroupkey asc groupkey asc recordkey asc better aid im asking ill explain groupkeys supergroupkey groupkey contains recordkey euler turn contained groupkey thus groupkeys must supergroupkey gauss contained groupkeys must supergroupkey leads groupkeys supergroupkey since groupkeys dont share recordkeys remaining groupkeys ones assigned supergroupkey value add solution needs generic table result set merely example addendum removed requirement solution non iterative would prefer solution believe unreasonable constraint unfortunately unable use clr based solution want include solution feel free likely accept answer though number rows real table large million days number rows around ten thousand average recordkeys per groupkey groupkeys per recordkey imagine solution exponential time complexity interested solution nonetheless
229784 table col1 col2 acaabsphr phr mcm abc want filter data filter parameter say absmcm want get rows least one matching code case get filtered result col1 col2 acaabsphr mcm use query select mytable col2 absmcm wont retrieve first row acaabsphr one please tell text search codes long one code matches col2 get row pass directly delimited list long finds single match row retrieved thanks
230074 process inserting data sql server since manual one time load bothered spending lot time writing efficient way however loads takes much longer initially anticipated question somehow tell server execute nother query immediately current one finalises would done manually hitting f5 next part code since load takes longer expected would like server somehow execute next part code automatically first part finalises possible without either waiting current query finalise cancelling current query running whole lot including next steps code hope makes sense thanks
230303 discovered sql sa account used way changing sa passwords sql instances sql servers running mixed authentication mode users applications using either domain accounts non sa sql accounts connect monitoring found apps users non internal spids using sa account questions q1 changing sa password require sql restart found references say sql service restart required changing sa account password dba se changing sa password sqlauthority change password sa login using management studio true im changing authentication mode routinely log sa sql server central thread even suggests changing could impact existing sql agent jobs stuff concern someone hard coded sa account ssis package something case matters use domain accounts sql service sql agent service domain proxy accounts jobs call ssis packages powershell scripts q2 change sa password normal way reset like would account using ssms likely via alter login sa password newpass would enter single user mode something would require planned downtime note id running domain account connected sa q3 try password rotation regular basis find issue recommended best practice
230328 saw concise tsql statement effectively splits string constituent characters one per line purpose evaluating ascii value character reading query correctly effectively ctes used prepare table column containing rows value fourth cte defined follows ctetallyn select row number overorder select null e4 subsequently cte joined table containing column strings interest following select select substringlastname ascii substringlastname row number nth character lastname ascii value character questions relate clause cte essentially exactly querying row number identical rows need order clause order put clause rather order clause select statement especially clause isnt even specifying partition presume means window row number operates full rows mean order select null
230491 today discovered harddrive stores databases full happened usually cause quite evident usually bad query causes huge spills tempdb grows till disk full time bit less evident happened tempdb wasnt cause full drive database facts usual database size gb grew gb log file normal size datafile huge datafile available space interpret air space used freed sql server reserves space allocated tempdb size normal found likely cause one query selects much many rows bad join causes selection billion rows couple hundred thousand expected select query made wonder whether following scenario could happened select executed target table created data inserted selected disk fills causing insert fail select aborted rolled back rollback frees space data already inserted removed sql server doesnt release freed space situation however wouldnt expected table created select still exist dropped rollback tested begin transaction select tmp test values1tx rollback select tmp test results row affected msg level state line invalid object name tmp test yet target table exist actual query wasnt executed explicit transaction though explain existence target table assumptions sketched correct likely scenario happened
230722 consider following query inserts rows source table arent already target table insert dbo halloween coming early year tablock select maybe new rows id dbo heap mostly new rows maybe new rows exists select dbo halloween coming early year halloween maybe new rows id halloween id option maxdop querytraceon one possible plan shape includes merge join eager spool eager spool operator present solve halloween problem machine code executes ms repro code create tables included bottom question im dissatisfied performance might try load rows inserted temp table instead relying eager spool heres one possible implementation drop table exists consultant recommended temp table create table consultant recommended temp table id bigint primary key id insert consultant recommended temp table tablock select maybe new rows id dbo heap mostly new rows maybe new rows exists select dbo halloween coming early year halloween maybe new rows id halloween id option maxdop querytraceon insert dbo halloween coming early year tablock select new rows id consultant recommended temp table new rows option maxdop new code executes ms get actual plans use actual time statistics examine time spent operator level note asking actual plan adds significant overhead queries totals match previous results operator first query second query big scan little scan sort merge join spool temp insert temp scan insert query plan eager spool seems spend significantly time insert spool operators compared plan uses temp table plan temp table efficient isnt eager spool mostly internal temp table anyway believe looking answers focus internals im able see call stacks different cant figure big picture sql server cu case someone wants know code populate tables used queries drop table exists dbo halloween coming early year create table dbo halloween coming early year id bigint null primary key id insert dbo halloween coming early year tablock select top row number order select null master spt values t1 cross join master spt values t2 cross join master spt values t3 option maxdop drop table exists dbo heap mostly new rows create table dbo heap mostly new rows id bigint null insert dbo heap mostly new rows tablock select top row number order select null master spt values t1 cross join master spt values t2
230993 first sql server would using sp add trusted assembly wanted clarify asking question register assembly system directoryservices accountmanagement dll without using trustworthy get work using asymmetric key generated system directoryservices dll accountmanagement dll signed differently system directoryservices dll ive even tried creating separate asymmetric key system directoryservices accountmanagement dll results msg level state line xxxxx error occurred generation asymmetric key test script written try create assembly use master db idclr test null begin create database clr test end go use clr test go exec sp configure configname clr enabled configvalue go reconfigure go drop objects found first drop system directoryservices accountmanagement existsselect sys assemblies name system directoryservices accountmanagement begin raiserror drop assembly system directoryservices accountmanagement nowait drop assembly system directoryservices accountmanagement end drop system directoryservices protocols existsselect sys assemblies name system directoryservices protocols begin raiserror drop assembly system directoryservices protocols nowait drop assembly system directoryservices protocols end drop system directoryservices existsselect sys assemblies name system directoryservices begin raiserror drop assembly system directoryservices nowait drop assembly system directoryservices end go existsselect sys database principals dp dp name msft clr login begin raiserror drop user msft clr login nowait drop user msft clr login end go use master go existsselect master sys syslogins name msft clr login begin raiserror drop login msft clr login nowait drop login msft clr login end go existsselect master sys asymmetric keys name msft clr key begin drop asymmetric key clrkey raiserror drop asymmetric key msft clr key nowait drop asymmetric key msft clr key end go create objects use master go existsselect master sys asymmetric keys name msft clr key begin drop asymmetric key clrkey raiserror create asymmetric key msft clr key nowait create asymmetric key msft clr key executable file windows microsoft net framework v4 system directoryservices dll end go existsselect master sys syslogins name msft clr login begin raiserror create login msft clr login nowait create login msft clr login asymmetric key msft clr key end go raiserror grant unsafe assembly nowait grant unsafe assembly msft clr login go raiserror grant external assembly nowait grant external access assembly msft clr login go use clr test go existsselect sys database principals dp dp name msft clr login begin raiserror create user msft clr login nowait create user msft clr login login msft clr login end go create clr objects use clr test go system directoryservices create assembly system directoryservices windows microsoft net framework v4 system directoryservices dll permission set unsafe system directoryservices protocols create assembly system directoryservices protocols windows microsoft net framework v4 system directoryservices protocols dll permission set unsafe system directoryservices accountmanagement create assembly system directoryservices accountmanagement windows microsoft net framework v4 system directoryservices accountmanagement dll permission set unsafe create assymetric key system directoryservices accountmanagement dll create asymmetric key msft sda clr key executable file windows microsoft net framework v4 system directoryservices accountmanagement dll results msg level state line error occurred generation asymmetric key
231228 situation developers update permissions work applications see connection strings know passwords sql accounts example sqllogin1 update permissions operations currently perfect sometimes production data needs modified gui yet instead contacting dba asking modify data developer would improperly use sql account sqllogin1 permission modify data connect sql server management studio modify data dba change password sqllogin1 without developer seeing new connection string new password since application connection string uses sqllogin1 maintained developer question way deny access sqllogin1 sql login connecting ssms time sqllogin1 connecting net sqlclient data provider program name sys dm exec sessions must allowed login way want let developer connect ssms using sqllogin1 application using sqllogin1 would still able connect
231460 using example predicates however top statement correctly returns rows bottom statement returns even though predicates match declare barcode nchar22 nrecb012zuki449m1vbjz declare tableid int null declare total decimal10 select dbo transaction index ix transaction transactionid paymentstatus deviceid datetime barcode barcode statusid tableid tableid total total select dbo transaction barcode barcode statusid tableid tableid total total could happening info non clustered index top statement filtered checkdb returns issues server version microsoft sql azure rtm dec copyright microsoft corporation paste plan link https www brentozar com pastetheplan id s1w ru68e info ran dbcc checktable transaction errormsgs extended logical checks data purity indicates issues reliably reproduce issue table restoring backup database
231474 microsoft technet article recommends creating secondary file group default file group see reference secondary file group number files say four placed separate disks added rule thumb colleague number files equal number cpu cores understanding setup ideal mechanical spinning disk drives performance boost streaming data multiple heads spinning disk drive much slower solid state drive understanding correct yes question whether cost based optimizer takes account newer solid state drives seems like performance bottlenecks spinning hard drives goes away switching new solid state drive operations groups informed currently allocated one virtual drive data really stored iscsi san multiple solid state drives question geared trying answer optimal setup large database magnitude default secondary file group one file default secondary file group number files equals number cores cpu performance boost partitioning database table using solid state drives current project working requires scaled database terabytes size stores massive amounts log data one week sample approximately million records need store rolling years logs looking long running queries find data tuned indexes point nearly work attributed non clustered index seeks optimizer recommend adding missing index note licensing microsoft sql server currently cpu core sensitivity throwing cores problem especially boost performance additionally currently developing sql server migrating sql server development production update project loading logs nightly expect perhaps none updates deletes logs expected change loaded everything else reads analytic purposes primary file group system tables secondary default file group everything else reason explained link referenced bottom question separate file groups created table partition tables within database small enough reside within secondary file group partitioning two tables one exceeds million records partitioned identity row number go billions records partitioned time monthly plan partitioning month years partitions create file groups year place files corresponding yearly file groups partition strategy reduce read times lot data scanning analytic purposes annual file group strategy strictly ease maintenance dbas remove years worth data removing single file group reference sql server best practices setting default file group
231628 team inherited application associated database previous developers appear enforced rule every index every table include clause always add every column isnt otherwise part key tables average anywhere two five indexes unique constraints well foreign keys intent looks improve select performance regardless query thrown database access via orm default always retrieves columns expect side effects increased storage requirements possibly significantly additional overhead time insert update delete question sensible strategy team history sql server members would consider experts internal behaviour though question raised strategy optimal wouldnt default side effects database server cpu memory tempdb usage etc expecting assumptions incorrect additionally application installed sql server premise versions since well azure sql prepared differences two additional side effects azure result approach
231647 want create efficient index sparsely populated column need equality operations hash index beneficial im wondering partial hash index isnt smaller full hash index create index full hash mytable using hashmy id mb create index partial hash mytable using hashmy id id null mb create index full btree mytable id mb create index partial btree mytable id id null mb hash indices take exactly amount space shown pghero however using standard btree indices partial index takes space full index partial hash indices supported postgresql
231682 sql new execution metric log memory added finding anything execution metric sql cpu time duration execution count logical reads logical writes memory consumption physical reads clr time degree parallelism dop row count log memory tempdb memory wait times believe understand metrics might care ran metrics top resource consuming queries several specific periods recorded examining results know large values log memory kbs exactly metric log memory edit received two answers checked answer lowlydba suggests combination related fields sys query store runtime stats using code validate provided jadarnel27 answer created database ran test query fields got results similar summed used sum excel values got bytes looked query store log memory used kb shows value kb number orders magnitude larger also kb compared bytes bytes would bytes summed totals fields got byte select sys query store runtime stats qsrs qsrs avg log bytes used suspect answer question log memory metric sql real value value presented small experiment would 354gb unrealistically high
231862 told data files backup operate extent level log file backup operates page level know file type data file always rows data stored form extenteither mixed uniform extent whereas logs stored form log vlfvirtual log files please somebody shed light concept bit detailed level bit puzzled backup distinguishes data log full backup would store committed change written data file differential changes since last full backup data file log backup changes committed however written data file appreciate valuable input
232048 size log files evenly split entire drive reside leaving extra space available log backups still able occur successfully several databases one log file per database good practice leave space drive available allocate log files drive dedicated log files case data os live partitions
232120 production system sql server ids mostly pks tables generated automatically informed unique globally mean ids database even tables different want know done multiple ways please list thanks
232943 know question asked number times also answers still need bit guidance subject details cpu ssms cpu tab task manager db server kept setting maxdop following formula declare hyperthreadingratio bit declare logicalcpus int declare htenabled int declare physicalcpu int declare socket int declare logicalcpupernuma int declare noofnuma int declare maxdop int select logicalcpus cpu count logical cpu count hyperthreadingratio hyperthread ratio hyperthread ratio physicalcpu cpu count hyperthread ratio physical cpu count htenabled case cpu count hyperthread ratio else end htenabled sys dm os sys info option recompile select logicalcpupernuma countparent node id numberoflogicalprocessorspernuma sys dm os schedulers status visible online parent node id group parent node id option recompile select noofnuma countdistinct parent node id sys dm os schedulers find numa nodes status visible online parent node id noofnuma htenabled set maxdop logicalcpupernuma else noofnuma htenabled set maxdop round noofnuma physicalcpu else htenabled set maxdop logicalcpus else htenabled set maxdop physicalcpu maxdop set maxdop maxdop set maxdop print logicalcpus convertvarchar logicalcpus print hyperthreadingratio convertvarchar hyperthreadingratio print physicalcpu convertvarchar physicalcpu print htenabled convertvarchar htenabled print logicalcpupernuma convertvarchar logicalcpupernuma print noofnuma convertvarchar noofnuma print print maxdop setting convertvarchar maxdop still seeing high wait times related cxpacket using query get waits select wait type wait time ms waits wait time ms signal wait time ms resources signal wait time ms signals waiting tasks count waitcount wait time ms sum wait time ms percentage row number overorder wait time ms desc rownum sys dm os wait stats wait type nbroker eventhandler nbroker receive waitfor nbroker task stop nbroker flush nbroker transmitter ncheckpoint queue nchkpt nclr auto event nclr manual event nclr semaphore ndbmirror dbm event ndbmirror events queue ndbmirror worker queue ndbmirroring cmd ndirty page poll ndispatcher queue semaphore nexecsync nfsagent nft ifts scheduler idle wait nft iftshc mutex nhadr clusapi call nhadr filestream iomgr iocompletion nhadr logcapture wait nhadr notification dequeue nhadr timer task nhadr work queue nksource wakeup nlazywriter sleep nlogmgr queue nondemand task queue npwait components initialized nqds persist task main loop sleep nqds cleanup stale queries task main loop sleep nrequest deadlock search nresource queue nserver idle check nsleep bpool flush nsleep dbstartup nsleep dcomstartup nsleep masterdbready nsleep mastermdready nsleep masterupgraded nsleep msdbstartup nsleep systemtask nsleep task nsleep tempdbstartup nsni http accept nsp server diagnostics sleep nsqltrace buffer flush nsqltrace incremental flush sleep nsqltrace wait entries nwait results nwaitfor nwaitfor taskshutdown nwait xtp host wait nwait xtp offline ckpt new log nwait xtp ckpt close nxe dispatcher join nxe dispatcher wait nxe timer event waiting tasks count select max w1 wait type waittype cast max w1 waits decimal wait cast max w1 resources decimal resource cast max w1 signals decimal signal max w1 waitcount waitcount cast max w1 percentage decimal percentage cast max w1 waits max w1 waitcount decimal avgwait cast max w1 resources max w1 waitcount decimal avgres cast max w1 signals max w1 waitcount decimal avgsig waits w1 inner join waits w2 w2 rownum w1 rownum group w1 rownum sum w2 percentage max w1 percentage percentage threshold go currently cxpacket wait stands server referred multiple articles recommendation experts also looked maxdop suggestions microsoft however really sure optimum value one found one question topic however go suggestion kin maxdop question go max vernon kindly provide valuable suggestion version microsoft sql server sp3 kb4022619 x64 sep enterprise edition core based licensing bit windows nt build hypervisor cost threshold parallelism set ctfp set testing values ranging default respectively default5 maxdop wait time close cxpacket executed sp blitzfirst seconds expert mode output findings wait stats
233382 came across table like create table table1 cd1 int cd2 varchar16 cd3 varchar21 cd4 decimal140 cd5 varchar4 cd6 decimal182 cd7 left cd3 table billion rows totally unnecessary another topic see last column use left cd3 think pretty useless since almost never select table using space isnt better select field select needed
233610 following input id value null null null null null null expect following result id value trivial solution would join tables relation selecting max value group tmp select t2 id maxt1 id lastknownid t1 t2 t1 value null t2 id t1 id group t2 id select tmp id value tmp id tmp lastknownid however trivial execution code would create internally square count rows input table expected sql optimize block record level task easy linear essentially loop however experiments latest ms sql cant optimize query correctly making query impossible execute large input table furthermore query run quickly making similarly easy different cursor based solution infeasible using memory backed temporary table could good compromise sure run significantly quicker considered example query using subqueries didnt work also thinking dig windowing function sql docs could tricked want example cumulative sum similar couldnt trick give latest non null element sum elements ideal solution would quick query without procedural code temporary tables alternatively also solution temporary tables okay iterating table procedurally
233642 postgresql column structure looks like id want result looks like res first rows permuted second column omitted due distinct operation
233674 way find sql server backup file msdb tables backup encrypted tde without trying restore backup file thanks
233716 im currently designing transaction table realized calculating running totals row needed might slow performance created table million rows testing purposes create table dbo table seq int identity11 null value bigint null constraint pk table primary key clustered seq asc pad index statistics norecompute ignore dup key allow row locks allow page locks primary primary go tried get recent rows running totals took seconds 1st attempt select top seq value sumvalue order seq total table order seq desc rows affected table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads row affected sql server execution times cpu time ms elapsed time ms suspected top reason slow performance plan changed query like took seconds think still slow production wondering improved 2nd attempt select select sumvalue table seq seq total select top seq value table order seq desc order seq desc rows affected table table scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads row affected sql server execution times cpu time ms elapsed time ms questions query 1st attempt slower 2nd one improve performance also change schemas clear queries return result
233783 application running sql enterprise cluster hosted client dont administrative access saying database generating deadlocks sent us huge trace file clip shows deadlock encountered paragraph paragraphs relating database id dont see identifiers connecting deadlock encountered paragraph use read committed mode read committed snapshot isolation mode turned sql simple question log tell deadlock encountered related database elsewhere log file deadlocks clearly identified databases cluster weve asked extended event tracing dont know long take thanks 58spid3sunknown 58spid3sunknowninput buf rpc event proc database id object id 58spid3sunknownspid ecid statement type select line 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x00000003e0f2be20 value 0x5380c188 cost 58spid3sunknownport 0x00000002221a7400 xid slot wait slot task 0x000000015380c188 consumer exchange wait type waitpipegetrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x0000000141f060a0 value 0x72f3c188 cost 58spid3sunknownport 0x000000066ed0f160 xid slot wait slot task 0x0000000772f3c188 producer exchange wait type waitpipenewrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x00000003e0f2bac0 value 0x59403498 cost 58spid3sunknownport 0x00000001fc9157d0 xid slot wait slot task 0x0000000759403498 producer exchange wait type waitpipenewrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x0000000141f06100 value 0x11dc1868 cost 58spid3sunknownport 0x000000018a587f20 xid slot wait slot task 0x0000000511dc1868 producer exchange wait type waitpipenewrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x00000003e0f2be80 value 0x72f3d868 cost 58spid3sunknownport 0x00000004a9a250e0 xid slot wait slot task 0x0000000772f3d868 producer exchange wait type waitpipenewrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x00000003e0f2bee0 value 0x11dc0cf8 cost 58spid3sunknownport 0x00000012f70769f0 xid slot wait slot task 0x0000000511dc0cf8 producer exchange wait type waitpipenewrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownwait graph 58spid3sunknowndeadlock encountered printing deadlock information 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x0000000141f06160 value 0xb8ebdc38 cost 58spid3sunknownport 0x00000001fc914160 xid slot wait slot task 0x00000001b8ebdc38 producer exchange wait type waitpipenewrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x00000003e0f2bf40 value 0x59402188 cost 58spid3sunknownport 0x000000066ed0fcc0 xid slot wait slot task 0x0000000759402188 consumer exchange wait type waitpipegetrow merging 58spid3sunknownnode 58spid3sunknown 58spid3sunknowninput buf rpc event proc database id object id 58spid3sunknownspid ecid statement type select line 58spid3sunknownrestype exchangeid stype spid batchid ecid taskproxy 0x00000003e0f2bdc0 value 0x59402558 cost 58spid3sunknownport 0x0000000225f57790 xid slot wait slot task 0x0000000759402558 consumer exchange wait type waitpipegetrow merging
233851 something odd happening query looks like select castft dop smallint tracking data date mydate identifier run raw query returns data fine place stored procedure alters clause throws error msg level state procedure myprocedure line batch start line conversion varchar value overflowed int2 column use larger integer column oddity go possible data clause query like select distinct dop tracking data identifier select distinct castdop smallint tracking data identifier get back nowhere anything remotely large smallint thought ok maybe non printable ascii character cant find im little perplexed moment runs find raw query explodes procedure possible data based valid suspicion query plan something odd filtering maybe runs different validation run procedure
233861 working sql server database includes lot nulls analyse data want extract rows database table include less null marks database similar structure c1 c2 c3 c4 c5 null null null null null null null null null tried query doesnt return error rows selected select test123 isnullc11 isnullc21 isnullc31 isnullc41 isnullc51 expect query return 1st fifth row result contains rows cant test following code dont rights write database pseudo code creating table like mine create table test123 c1 float c2 float c3 float c4 float c5 float go insert test123c1c2c3c4c5 values 23null12 2nullnull12 23nullnull2 null3null1null 23null12
233884 id like know general replacement cursor general implementation cursor see declare variable int sqlstr nvarcharmax declare cursor name cursor select statement essentially get array variable usually subset unique ids accounts clients parts etc open cursor name fetch next cursor name variable fetch status begin set sqlstr query uses str variable dirty work go accounts subset possible new cursor go accounts connect way map fields add big uniform table exec sp executesql sqlstr fetch next cursor name variable end close cursor name deallocate cursor name since many people anti cursor nod people hate cursors general replacement general implementation preferably sql server
234086 sql server allows create multiple foreign keys column time using different name create another key referencing object basically keys defining relationship want know whats use multiple foreign keys defined column reference column another table whats benefit sql server allows us thing like
234144 create stored procedure master database want execute databases follow link making procedure available databases give code example following example call procedure database create table data type master use databases use master exists select sys types name thereplicatedtables create type thereplicatedtables table obj id int null primary key clustered obj id use apia repl sub go declare tables dbo thereplicatedtables
234221 cant seem figure answer ive seen multiple answers like transaction log keep growing run space everyone talks running back ups log file shrinks doesnt shrink anything also dont believe running super long transactions server sql server recovery mode full maintenance plan store days worth backups task backups databases backup type full task backs transaction logs verify backup integrity checked tasks dbs normal ldf file 22gb run task bak file 435mb trn file 22gb ldf successfully running ldf doesnt shrink despite everything ive read telling going doesnt log file ever shrink ive also tried running command mentioned another answer select name log reuse wait desc sys databases says log backup db huge log file based answer confusing allocated used space stats reasons clue initial size set 22gb
234303 supporting vendor based application filled blocking deadlock deadlocks occur mostly involving two three processes however noticed yesterday involving spids somebody please help understanding deadlock graph solution avoid deadlock victim list victimprocess id process2ff017c28 victimprocess id process2f1538108 victimprocess id process2f618d088 victimprocess id process2f6d828c8 victimprocess id process2f6d83848 victimprocess id process2da9b5468 victimprocess id process2efac7468 victimprocess id process2efac7848 victim list process list process id process2ff017c28 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0x2a785f800 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2f1538108 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0xdacf54e0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2f618d088 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0x20df303b0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2f6d828c8 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0x25090c6d0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2f6d83848 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0xb83c63b0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2da9b5468 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0x20d4683b0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2efac7468 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0x184e789f0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2efac7848 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0x2420aab80 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process id process2efac7c28 taskpriority logused waitresource object waittime ownerid transactionname implicit transaction lasttranstarted 08t15 xdes 0xab9103b0 lockmode ix schedulerid kpid status suspended spid sbid ecid priority trancount lastbatchstarted 08t15 lastbatchcompleted 08t15 lastattention 01t00 clientapp jtds hostname appname hostpid loginname irb app user isolationlevel repeatable read xactid currentdb currentdbname database name locktimeout clientoption1 clientoption2 executionstack frame procname adhoc line stmtstart stmtend sqlhandle 0x02000000b6b6e728e6bf289c908196a1f4e56b8892a5eab10000000000000000000000000000000000000000 unknown frame executionstack inputbuf p0 bigint p1 bigintupdate table name set status id p0 id p1 inputbuf process process list resource list objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2f6d828c8 mode owner id process2da9b5468 mode owner id process2f6d828c8 mode ix requesttype convert owner id process2da9b5468 mode ix requesttype convert owner list waiter list waiter id process2ff017c28 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f6d828c8 mode owner id process2da9b5468 mode owner id process2ff017c28 mode ix requesttype convert owner id process2f6d828c8 mode ix requesttype convert owner id process2da9b5468 mode ix requesttype convert owner list waiter list waiter id process2f1538108 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f6d828c8 mode owner id process2da9b5468 mode owner id process2ff017c28 mode ix requesttype convert owner id process2f6d828c8 mode ix requesttype convert owner id process2da9b5468 mode ix requesttype convert owner list waiter list waiter id process2f618d088 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f618d088 mode owner id process2da9b5468 mode owner id process2f618d088 mode ix requesttype convert owner id process2ff017c28 mode ix requesttype convert owner id process2da9b5468 mode ix requesttype convert owner list waiter list waiter id process2f6d828c8 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f618d088 mode owner id process2da9b5468 mode owner id process2f618d088 mode ix requesttype convert owner id process2ff017c28 mode ix requesttype convert owner id process2da9b5468 mode ix requesttype convert owner list waiter list waiter id process2f6d83848 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f6d83848 mode owner id process2efac7848 mode owner id process2ff017c28 mode ix requesttype convert owner id process2efac7848 mode ix requesttype convert owner id process2f6d83848 mode ix requesttype convert owner list waiter list waiter id process2da9b5468 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f6d83848 mode owner id process2efac7848 mode owner id process2ff017c28 mode ix requesttype convert owner id process2efac7848 mode ix requesttype convert owner id process2f6d83848 mode ix requesttype convert owner list waiter list waiter id process2efac7468 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f6d83848 mode owner id process2efac7468 mode owner id process2ff017c28 mode ix requesttype convert owner id process2efac7468 mode ix requesttype convert owner id process2f6d83848 mode ix requesttype convert owner list waiter list waiter id process2efac7848 mode ix requesttype convert waiter list objectlock objectlock lockpartition objid subresource full dbid objectname database name schema name table name id lock2149d8800 mode associatedobjectid owner list owner id process2ff017c28 mode owner id process2f6d83848 mode owner id process2efac7468 mode owner id process2ff017c28 mode ix requesttype convert owner id process2efac7468 mode ix requesttype convert owner id process2f6d83848 mode ix requesttype convert owner list waiter list waiter id process2efac7c28 mode ix requesttype convert waiter list objectlock resource list deadlock isolation level set read committed snapshot opened deadlock graph sentry one plan explorer scary version microsoft sql server sp3 kb4022619 x64 sep copyright microsoft corporation enterprise edition bit windows nt build hypervisor
234368 would like order table find way make work help table need table documents listed first field id document second field represents father must show list see orderly manner first document generated query select table name order col1 asc col2 asc doesnt work query select fr1 report id fr1 report parent fara reports fr1 fr1 report delete fr1 report tmp order fr1 report id asc fr1 report parent desc first image
235085 thing trigger availability group failovers want certain action happen ag fails specifically want turn database setting turning rcsi want failover order minimize disruption workloads scheduled maintenance windows hard come know sp procoption used mark procedures startup procedures seems like could work failover clusters availability groups consider adding alert sp add alert message id order respond failover actions sql agent job seems less direct practice seems slow
235153 need recycle apppool iis server sql server service starts route taking startup stored procedure runs agent job powershell job step created grabbed internet powershell script recycles app pool load iis module import module webadministration set name site want recycle pool site default web site get pool name site name pool get item iis sites site select object applicationpool applicationpool recycle application pool restart webapppool pool works os level powershell run administrator even though account logged windows admin group sure enough create job agent powershell step containing code upon execution get error job step received error line powershell script corresponding line pool get item iis sites site select object applicationpool applicationpool correct script reschedule job error information returned powershell retrieve dynamic parameters cmdlet filename redirection config error read configuration file due insufficient permissions process exit code step failed need way run administrator sql server agent success os level creating new script runs original script elevated permissions security principal windowsprincipal security principal windowsidentity getcurrent isinrole security principal windowsbuiltinrole administrator relaunch elevated process start process powershell exe file myinvocation mycommand path verb runas exit running elevated launch script path script ps1 allows run new script either non elevated cmd prompt non elevated powershell prompt however try run agent either powershell step cmd step get machine default permission settings grant local activation permission com server application clsid longguidhere appid longguidhere user nt service sqlserveragent sid longguidhere address localhost using lrpc running application container unavailable sid unavailable security permission modified using component services administrative tool also tried start process powershell verb runas filepath path script ps1 os level worked run agent gives error get either recycle app pool without requiring elevated priveleges run script recycle app pool elevated priveleges sql server agent
235197 written stored procedure makes use temporary table know sql server temporary tables session scoped however able find definitive information exactly session capable particular possible stored procedure execute twice concurrently single session significantly higher isolation level required transaction within procedure due two executions sharing temporary table
235227 one query running serial execution mode release noticed two new functions used view referenced linq sql query generated application converted scalar functions tvf functionsbut still query running serial mode earlier scalar tvf conversion queries solved problem forced serial execution scalar function create function dbo findeventreviewduedate eventnumber varchar20 eventid varchar25 eventiddate bit returns datetime begin declare currenteventstatus varchar20 declare eventdatetime datetime declare reviewduedate datetime select currenteventstatus select cis eventstatus currenteventstatus cis inner join event1 nolock cis event1id id eventnumber eventnumber eventid eventid select eventdatetime select eventdatetime event1 eventnumber eventnumber eventid eventid currenteventstatus eventiddate begin set reviewduedate dateaddday eventdatetime reviewduedate getdate set reviewduedate dateaddday reviewduedate declare eventdatejournaldate datetime select eventdatejournaldate select top ij date eventpage eventjournal ij inner join eventjournalpages ij pageid id inner join journal formid id inner join event1 nolock event1id id eventnumber eventnumber eventid eventid ij reviewtype supervisor monthly review order ij date desc ifdateaddday eventdatetime getdate eventdatejournaldate null dateaddday eventdatejournaldate getdate dateaddday reviewduedate dateaddday getdate set reviewduedate dateaddday reviewduedate else eventdatejournaldate null dateaddday eventdatejournaldate reviewduedate set reviewduedate dateaddday reviewduedate end return reviewduedate end converted tvf function create function dbo findeventreviewduedate test eventnumber varchar20 eventid varchar25 eventiddate bit returns functionresulttablevairable table currenteventstatus varchar20 event1datetime datetime reviewduedate datetime begin declare currenteventstatus varchar20 declare eventdatetime datetime declare reviewduedate datetime select currenteventstatus select cis eventstatus currenteventstatus cis inner join event1 nolock cis event1id id eventnumber eventnumber eventid eventid select eventdatetime select eventdatetime event1 eventnumber eventnumber eventid eventid currenteventstatus eventiddate begin set reviewduedate dateaddday eventdatetime reviewduedate getdate set reviewduedate dateaddday reviewduedate declare eventdatejournaldate datetime select eventdatejournaldate select top ij date eventpage eventjournal ij inner join eventjournalpages ij pageid id inner join journal formid id inner join event1 nolock event1id id eventnumber eventnumber eventid eventid ij reviewtype supervisor monthly review order ij date desc ifdateaddday eventdatetime getdate eventdatejournaldate null dateaddday eventdatejournaldate getdate dateaddday reviewduedate dateaddday getdate set reviewduedate dateaddday reviewduedate else eventdatejournaldate null dateaddday eventdatejournaldate reviewduedate set reviewduedate dateaddday reviewduedate insert functionresulttablevairable select currenteventstatus eventdatetime reviewduedate end return end go anything wrong implementation tvf function preventing query run parallel mode use tvf function query select reviewduedate dbo functionresulttablevairableabc actual query uses view quite complex comment function part view executing query runs parallel function forcing query run parallel actual query format select dv column1 dv column2 select reviewduedate dbo functionresulttablevairableabc columnx demoview dv condition1 conditon help appreciated
235412 using one reports check status ifi enabled sql server works well using dmv sys dm server services sql2016 however sql2014 sql2012 see difficulties rendering check via sql query example use exec sys xp readerrorlog ndatabase instant file initialization guarantee show status file sometimes keep querying error log manually find achieve ifi check using better way show ssrs report
235465 need write stored procedure receive numbers insert table ive developed far declare int int int int create table tempnum int declare char1 begin insert temp select set end select temp drop table temp know directly statically insert inputs table want know better way wanted use statement problem numbers variable inserted table mean output want
235469 post sqlservercentral com mentioned several people files resource database mssqlsystemresource mdf ldf placed folder master database file sql server still recommendation comes sql server tried looking bol could find mention
236675 suppose stored procedure duplicated modifications several databases want reference database stored procedure stored even executed another database way retrieve full path otherwise retrieve database stored procedure stored rather current database
236768 application creates millions tables sql server database non clustered looking upgrade sql server clustered hitting error message load already object named pk tablenameprefix 179e2ed8f259c33b database system generated constraint name looks like randomly generated bit number possible seeing collisions due large number tables assuming million tables calculate less trillion chance collision adding next table assumes uniform distribution possible sql server changed name generation algorithm version increase odds collision significant difference instance clustered pair struggling form hypothesis would generate error yes know creating millions tables insane black box 3rd party code control despite insanity worked version version edit closer inspection generated suffix always seems start 179e2ed8 meaning random part actually bit number odds collisions mere every time new table added much closer match error rate seeing
237128 im creating sql server database someone else one tables small rows data probably remain constant remote possibility new row added table looks something like create table sometable id int primary key identity11 null name varchar128 null unique insert sometable values alice bob something charles dance dugan im looking char length name column think values probably never going larger say characters maybe even larger advantage changing column example varchar32 also advantage keeping default column sizes multiples etc
237312 job sql server server know ideal issue addressed agent runs nt authority network service want add step runs job sits another sql server server would use exec server msdb sp start job njobname ran server manually executes job server fine expected add task job server fails message executed user nt authority network service execute permission denied object sp start job database msdb schema dbo sqlstate error step failed assigned nt authority network service server targetserverrole msdb granted execute permission concern user sp start job sp stop job server server linked server tried setting local server login remote server login mappings local login nt authority network service impersonate job still fails error need thanks
237418 wondering way select query made matched value found within consider table contains records values included referenced inoperator id like returned match select top column table column efficient way way could think execute query value within would way slow considering actual query retrieves many column various tables
237475 xml value like want concatenate values return single string abc know shred xml aggregate results back nodeless xml apply valuestext result select select valuetext varchar50 text myxml nodes xml path type valuetext varchar50 however would like using xpath xquery methods something like select myxml way reason looking solution direction actual xml contains elements instance would like able extract values single string values single string without use unwieldy script
237494 server cache get wiped similarly restart sql instance machine restart sql services
237509 im running microsoft sql server sp2 cu6 vcpu vm max degree parallelism set cost threshold parallelism set mornings trying display estimated execution plan select top query run massive waits operation render estimated plan takes minutes often times minute range actual execution query process display estimated execution plan sp whoisactive show either pageiolatch sh waits latch ex access methods dataset parent waits run paul randals waitingtasks sql script operation shows cxpacket waits worker threads showing pageiolatch sh waits resource description field exchangeevent id port5f6069e600 waittype waitportopen waitertype coordinator nodeid tid owneractivity notyetopened waiteractivity waitforallownerstoopen worker threads look bringing entire stats table memory page numbers well subsequent page numbers shown paul randals query point back clustered key stats table plan come back basically instantaneous remainder day even see stats table attrition cache various records remaining assume pulled due seek operations similar queries would expect initial behavior query actually executing plan used scan operators evaluating execution plans arrive seek operator shown plan linked aside running statement office hours data appropriately cached help improve performance im assuming pair covering indexes would beneficial would really guarantee changes behavior work within storage maintenance window limitations query generated vendor solution suggestions besides better indexing would welcome point
237671 ive got node ag setup follows vm hardware configuration nodes microsoft sql server enterprise edition rtm cu14 kb4484710 vcpus gb ram long story one max degree parallelism required app vendor cost threshold parallelism max server memory mb gb ag configuration node primary synchronous commit non readable secondary configured automatic failover node primary synchronous commit non readable secondary configured automatic failover node readable secondary set asynchronous commit configured manual failover node readable secondary set asynchronous commit configured manual failover query question theres nothing terribly crazy query provides summary outstanding work items various queues within application see code one execution plan links execution behavior primary node executed primary node execution time generally around second mark execution plan stats captured statistics io statistics time primary node rows affected table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table workitemlc scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table workfile scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table schedulertask scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table wfschedulertask scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table schedulerservice scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table schedulerworkerpool scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table itemlc scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads row affected sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms execution behavior read secondary node executing either read secondary node node node query uses execution plan different plan link roughly execution stats shown may page scans results always changing exception cpu time look similar stats captured statistics io statistics time read secondary node rows affected table worktable scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table workitemlc scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table workfile scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table schedulertask scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table wfschedulertask scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table schedulerservice scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table schedulerworkerpool scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads table itemlc scan count logical reads physical reads read ahead reads lob logical reads lob physical reads lob read ahead reads row affected sql server execution times cpu time ms elapsed time ms sql server parse compile time cpu time ms elapsed time ms details ive also run sp whoisactive paul randals waitingtasks sql script secondary query executing see waits occurring ever frankly frustrating also doesnt look case ag latency synchronization status actually quite good https sqlperformance com monitoring availability group replica sync select ar replica server name adc database name ag name ag name drs local drs synchronization state desc drs synchronization health desc drs last hardened lsn drs last hardened time drs last redone time drs redo queue size drs redo rate drs redo queue size drs redo rate est redo completion time min drs last commit lsn drs last commit time sys dm hadr database replica states drs inner join sys availability databases cluster adc drs group id adc group id drs group database id adc group database id inner join sys availability groups ag ag group id drs group id inner join sys availability replicas ar drs group id ar group id drs replica id ar replica id order ag name ar replica server name adc database name query seems worst offender queries also take sub second times primary node may take seconds secondary node behavior severe look causing issues finally also looked servers checked external processes scans external jobs generating unexpected etc come empty handed dont think caused anything outside sql server process question noon im already long day suspect im missing something obvious either weve got something misconfigured possible weve number calls vendor ms related environment investigation cant seem find causing difference performance would expect see sort wait occurring secondary nodes nothing troubleshoot identify root cause anyone seen behavior found way resolve update swapping states third node one read replicas non readable back readable test replica still held open transaction client queries displaying hadr database wait transition versioning wait running dbcc opentran command yields following results oldest active transaction spid server process id 420s uid user id name qds nested transaction lsn start time may 753pm sid 0x0 dbcc execution completed dbcc printed error messages contact system administrator looking spid sp who2 shows background process query store back listed command able take tlog backups suspect running similar functionality resolved bug plan opening ticket ms particular issue today depending outcome ticket try capture call stack trace per joes suggestion see go final update issue self resolved eclipsing hour mark query store transaction open identified ag decided automatically failover happened pull additional metrics per link provided sean database question large version store dedicated database specifically one point recorded pages reserved page count field reserved space kb value per errorlogs failover occurred minute deluge transaction hardening failures related qds base transaction qds nested transaction transactions failover cause outage minutes case database 6tb size active actually pretty good opinion new primary node online time client queries could complete waiting qds loaddb wait type failover version store numbers reduced reserved page count reserved space kb queries secondary read replicas also began execute quickly run primary looks like behavior disappeared entirely result failover
237684 part workload uses clr function implements spooky hash algorithm compare rows see column values changed clr function takes binary string input need fast way convert rows binary string expect hash around billion rows full workload id like code fast possible tables different schemas purposes question please assume simple table structure nullable int columns ive provided sample data well way benchmark results bottom question rows must converted binary string column values rows must converted different binary strings column value different example code simple following work castcol1 binary4 castcol2 binary4 handle nulls correctly col1 null row col2 null row rows converted null string believe correct handling nulls hardest part converting entire row correctly allowed values int columns possible preempt questions matters significant majority time columns wont null use clr hash many rows persist hashes believe use batch mode conversion due presence clr function fastest way convert nullable int columns binaryx varbinaryx string sample data code promised create sample data drop table exists dbo table ints create table dbo table ints col1 int null col2 int null col3 int null col4 int null col5 int null col6 int null col7 int null col8 int null col9 int null col10 int null col11 int null col12 int null col13 int null col14 int null col15 int null col16 int null col17 int null col18 int null col19 int null col20 int null col21 int null col22 int null col23 int null col24 int null col25 int null col26 int null col27 int null col28 int null col29 int null col30 int null col31 int null col32 int null insert dbo table ints tablock select null select top row number order select null rn master spt values t1 cross join master spt values t2 option maxdop go procedure test performance create alter procedure begin set nocount declare counter int dummy varbinary8000 counter begin select dummy code clearly incomplete handle nulls castcol1 binary4 castcol2 binary4 castcol3 binary4 castcol4 binary4 castcol5 binary4 castcol6 binary4 castcol7 binary4 castcol8 binary4 castcol9 binary4 castcol10 binary4 castcol11 binary4 castcol12 binary4 castcol13 binary4 castcol14 binary4 castcol15 binary4 castcol16 binary4 castcol17 binary4 castcol18 binary4 castcol19 binary4 castcol20 binary4 castcol21 binary4 castcol22 binary4 castcol23 binary4 castcol24 binary4 castcol25 binary4 castcol26 binary4 castcol27 binary4 castcol28 binary4 castcol29 binary4 castcol30 binary4 castcol31 binary4 castcol32 binary4 dbo table ints option maxdop set counter counter end select cpu time sys dm exec requests session id spid end go run procedure exec still using spooky hash binary result workload uses hash joins hashed value used one hash builds dont want long binary value hash build requires much memory
237935 postgresql create table test data transaction migrate new column different type resulting one table rewrite upon commit create table foo int insert foo values followed begin alter table foo add column varchar update foo set casta varchar alter table foo drop column commit however thing microsofts sql server seems generate error compare working db fiddle add column command outside transaction txn1 begin transaction alter table foo add varchar commit txn2 begin transaction update foo set cast varchar alter table foo drop column commit db fiddle doesnt work txn1 begin transaction alter table foo add varchar update foo set cast varchar alter table foo drop column commit instead errors msg level state line invalid column name anyway make transaction visible regard ddl behave like postgresql
238263 naming tables sql try stay away sql reserved keywords today colleague questioned use events table name said anything turns green ssms shouldnt used table name conflicts gotchas concerned using events table name ms sql server
238350 logon trigger allow certain users log oracle database even correct password enter database create replace trigger sys logon trigger logon database declare user varchar250 begin select osuser user session sid sys contextuserenvsid user list users raise login denied endif end works preventing users entering schemas sys system schemas still entered regardless user logon trigger seemingly completely bypassed way lock users even sys type schemas bit context due decisions made way got involved logins database password additionally users use login many processes read write database automatically dont want simply change passwords would large effort see impact changing passwords actually system would modify code processes use access database many easier solution us lock based usernames possible
238714 case expression im trying search inside text column identify hyphen case substringal alt address11 in157 al new address contains concatal alt addressal new address hyphen located anywhere column need know exists regardless actually column im currently using exact code josh provided like doesnt work doesnt return correct data several specific instances know exact text alt address churchill circle exact text new address however results returned include new address confirmed dash new address really matches dash im using search ascii
238783 created sample table create table dbo statisticsdemo id int identity11 null name nvarchar null primary inserted data select namecount count statisticsdemo group name name count aabbcc xxyyzz created non clustered index create nonclustered index nci statisticsdemo name dbo statisticsdemo name asc ran query select name dbo statisticsdemo name aabbcc expected returning rows index seek non clustered index per knowledge index scan data satisfied filter criteria mentioned select query please tell index seek instead index scan purpose entire activity proveas give presentation statistics sql server looks statistics identify number records matches filter criteria query preparing execution plan based records matches total records table either decide scan seek records matches approximately equal total number records table scan happening case using adventureworks2016 database running query select sales salesorderheader salesorderid salesorderid query returning records still clustered index seek getting terribly confused shaking concepts please help ps cleaned plan cache well luck sql server version
238873 created maintenance plans sql server say generate databse backup times daily read full recovery good need point time recovery exact question generating multiple daily backup simple recovery model similar full recovery backup longer period
239314 seems like ive misunderstood concept order table structure data create table testtest value1 int value2 int insert testtest values query select value1 value2 testtest order value1 descvalue2 desc expect columns value1 value2 use desc columns see output isnt value2 also descending order
239400 work get subquery return lowest course weight lecturer currently returns lowest subquery wrong outer query question show lecturer lowest coursework weighting displaying staff id module id weighting selected select m1 moduleid m1 cwweight staffid dbo module m1 inner join dbo lecturer m1 moduleconvenor staffid m1 cwweight select minm2 cwweight dbo module m2
239646 im trying write function receive number return binary format ive developed far ok inputs return correct binary format numbers could find problem wondering could find problem create replace function show binaryi number number return varchar2 binary varchar250 number2 number number begin number2 loop binary binary remainderi number2 number2 number2 end loop binary binary chari number2 select reverse binary binary dual return binary end
239788 table two columns want count distinct values col conditioned col mytable col col expected result col col result tried following code select count distinct col partition col result mytable count distinct col working rewrite count function count distinct values
240469 production sql server following config dell poweredge r630 servers combined availability group connected single dell san storage unit raid array time time primary seeing messages similar sql server encountered occurrences requests taking longer seconds complete file data mydatabase mdf database id os file handle 0x0000000000001fbc offset latest long 0x000004295d0000 duration long ms novice performance troubleshooting common ways best practices troubleshooting particular issue related storage performance counters tools monitors apps etc must used narrow root cause messages might extended events help kind audit logging
240503 im trying understand performance impact selecting data view one columns view function data original table computation get performed irrespective whether computed column list selected columns table view declared like create table price data ticker text ticker stock ddate date date price price float8 closing price date factor float8 factor convert price usd create view prices select ticker ddate price factor price factor price usd price data would multiplication performed query like one select ticker ddate price factor prices reference guarantees one way reading documentation rule system postgres think answer really lies optimiser since nothing rule system documentation indicated wouldnt selected suspect case computation isnt performed changed view use division instead multiplication inserted factor price data query didnt fail query modified select computed column modified query failed way understand computations done select carried guess im looking something like explain also tells computations performed
240540 documentation sys dm exec query stats states following initial query sys dm exec query stats might produce inaccurate results workload currently executing server accurate results may determined rerunning query sometimes query dmv active workload would prefer accurate results know apply warning practice always query dmv twice use second result set accurate feels bit far fetched need aware ways dmv inaccurate factor analysis kind inaccuracies appear missing rows outdated values inconsistent rows something else best practices using sys dm exec query stats active workload
240742 following query using mariadb innodb select id sender id receiver id thread id date created content user message thread id placeholder false order date created desc limit query fetches messages according given conditions sorts date created covering index thread id date created running explain correct index used get output using although query using column middle statement index use value placeholder result change sorting use another column explain correctly indicates using using filesort im head scratching moment could anyone please shed light would expect see additional filesort would needed covering index could completely used due additional column
241302 way find events system health extended event files rolling rather manually monitoring events medium load server stay upto days heavy loaded servers files rolling every mins fixed pattern timings know reason working filter unwanted events ones reported issues curious way query time would roll files happening see much documentation ms docs well cant find info please suggest possible
241607 consider declare stringsvar varchar1000 declare emp id int declare strvar sysname employee test set stringsvar select strvar emp id emp id print stringsvar query giving error mentioned msg level state line conversion failed converting nvarchar value select employee test emp id data type int needs done case
241656 table like tb1 cod a001 a002 a003 cars baby nasa second table tb2 cod col tb1 description a001 something a002 lasagna im trying something like obviously doesnt work select a001 select description tb2 col tb1 a001 a002 select description tb2 col tb1 a002 tb1 tried inner joins dynamic sql cant think logic theres questions none could help think impossible single statement possible dynamic sql edit correct result would select cod tb1 a001 something tb1 a002 lasagna tb1 result would cod something lasagna cars baby
242187 application written php laravel regularly prepares executes statements like parameters varchar10 select c1 c2 c3 c4 mybigtable active c1 p1 p2 p3 p4 p250 c2 null users big data grid select many rows even button select select rows statement happens takes one minute run unacceptable table mybigtable millions rows estimated execution plan shows time spent index seek non clustered deduce situation improved using indexes issue use prepared statements think wrong let know moreover understand prepared statements prepared used discarded dont think really beneficial recommendation give developers tell stop using prepared statements hardcode values query give workaround like use temporary tables make temporary table insert values make query mybigtable joined temp idea edit execution plan https www brentozar com pastetheplan id rj b2xalh
242649 table ids repeating id num null null null null null null want get table ids null non null values column labelled num like id num null null
242813 say two relations tuples page accesses tuples page accesses assuming outer relation many tuple comparisons page accesses done many page accesses inner relation tuple tuple satisfy join condition output tuple rs order find many tuple comparisons done need algorithm tuple total tuples tuples thus comparisons total know page accesses outside tuples page accesses page accesses page accesses inside page accesses im sure correct like done correctly pleaseee
242908 ive ongoing debate various developers office cost index whether uniqueness beneficial costly probably crux issue competing resources background previously read discussion stated unique index additional cost maintain since insert operation implicitly checks fits tree duplicate found non unique index appends uniquifier end key otherwise inserts directly sequence events unique index additional cost coworker combats statement saying unique enforced second operation seek new position tree thus costly maintain non unique index worst seen tables identity column inherently unique clustering key table explicitly stated non unique side worst obsession uniqueness indexes created unique possible define explicitly unique relation index append pk table end index ensure uniqueness guaranteed im frequently involved code reviews dev team need able give general guidelines follow yes every index evaluated five servers thousands tables many twenty indexes table need able apply simple rules ensure certain level quality question uniqueness additional cost back end insert compared cost maintaining non unique index secondly wrong appending primary key table end index ensure uniqueness example table definition create table test index id int null identity1 dt datetime null defaultcurrent timestamp val varchar100 null deleted bit null default0 primary key nonclusteredid desc unique clustereddt desc id desc create index nonunique nonclustered example test index deleted include val create unique index unique nonclustered example test index deleted dt desc id desc include val example example would add unique key end index one fact tables primary key identity column however clustered index instead partitioning scheme column followed three foreign key dimensions uniqueness select performance table abysmal frequently get better seek times using primary key key lookup rather leveraging clustered index tables follow similar design primary key appended end considerably better performance date int equivalent convertint convertvarchar current timestamp existsselect sys partition functions name npf date int create partition function pf date int int range right values go existsselect sys partition schemes name nps date int create partition scheme ps date int partition pf date int primary go existsselect sys objects object id object idndbo bad fact table create table dbo bad fact table id int null identity implemented elsewhere cdc populates date int int null dt date null group id int null group entity id int null member group fk id int null tons columns primary key nonclusteredid date int index ci bad fact table clustered date int group id group entity id fk id ps date intdate int go existsselect sys objects object id object idndbo better fact table create table dbo better fact table id int null identity implemented elsewhere cdc populates date int int null dt date null group id int null group entity id int null member group tons columns primary key nonclusteredid date int index ci better fact table clustereddate int group id group entity id id ps date intdate int go
243115 transactional database used booking things vendor asked replace temptables tablevariables heavy compile locks instead replaced actual table adds spid column ensure stored procedure acts applicable rows see risk method operation transactions isolated within transaction worried may end locking table bunch opinion sql uses row level locking wont create locks sql server version enterprise create table dbo qrytransactions id int identity null constraint pk qrytransactions primary key clustered spid int null orderid int itemid int timetransactionstart datetime timetransactionend datetime fields create index idx qrytransactions spidid qrytransactions spid id include itemid orderid timetransactionstart timetransactionend
243484 possible capture queries sent ms sql server without third party tooling without using deprecated features im looking something similar general query log mysql heres example using third party tool https blog devart com capturing sql server trace data html heres alternative using deprecated features https docs microsoft com en us sql tools sql server profiler sql server profilerview sql server non deprecated native solution
244000 database administration strong point mine questions relates performance website im looking spent fair bit time researching diagnosing two sites test site live site noticed page load times much longer live site opposed test site specs test site really low vps virtual processors 14gb ram sql website running vps specs live website dedicated servers virtual processors 16gb ram live site uses separate dedicated server sql virtual processors 112gb ram website averages concurrent users average one time fluctuate send email campaign hit hit cpus would expect hit depending actions users website hold fairly well ram would expect live website actually perform faster test website case looked code strongly believe due database database size live website 50gb backed test site 4gb databases quite fragmented im wondering likely fragmentation affect performance also live website many times larger test site high fragmentation affect performance live site much test site capture one indexes products table never dealt tips around rebuilding refreshing indexes put website maintenance mode one interact tables im rebuilding refreshing indexes long would take table indexes products thanks
244345 query producing text creating values text put sql file inserting rows get blank line results postgres select obj id obj type il2 objects obj id order obj id column sciencedomain pis instrument rows select pretty clear caused obj type null obj id postgres select il2 objects obj id obj id obj type instrument sciencedomain pis rows confirming null postgres select il2 objects obj type null obj id obj type result first select giving blank row even casting obj type text still gave blank row additional info schema worth postgres il2 objects table il2 objects column type collation nullable default obj id integer null generated default identity obj type character varying indexes objects pkey primary key btree obj id
244756 field may start end quotes want remove quotes string starts ends quotes quotes exists inside string wish retain used reverse stuff works field start end quotes returns null ensure still get field result start quotes reversestuffreversestufffieldname charindex fieldname len charindex reversestufffieldname charindex fieldname len
245148 every query run ssms append annoying message completion time disable text
245178 lot large tables around million wide rows need regularly loaded sql server read reporting would like tables small possible disk matters performance improvements either loading querying tables require indexing create table data compression page use bcp bulk insert data flat file new table column types tables varchar never max float tinyint date datetime columns created nullable primary foreign keys defined dont matter querying tables never updated directly default collation everything sql latin1 general cp1 ci see sys allocation units page data compression applied heap see sys partitions fill factor correctly since tables much smaller uncompressed tables would thought compression accomplished however rebuild option data compression page supposedly already compressed table gets smaller looks like going rows per data page rows per page though rebuilding doesnt make smaller first rebuild questions questions going way get extra small compressed size directly load table without rebuild data loaded
245699 im trying use cursor clean temp tables longer needed small table names temp tables along identifier cursor stuck infinite loop execute certain statements print values fetch works perfectly code declare id bigint declare table name varcharmax declare st cursor local fast forward select id tablename searchtables customerid null open st fetch next st id table name fetch status begin ifobject id table name null execdrop table table name update searchtables set deleted id id print cast id varcharmax table name fetch next st id table name end close st deallocate st comment lines ifobject id table name null execdrop table table name update searchtables set deleted id id print outputs ids table names dont comment get first row cancel query also tried changing line execdrop table exists table name didnt work either
245781 want run sql server vulnerability assessment sql server agent job currently attempting job powershell script running command like one invoke sqlvulnerabilityassessmentscan serverinstance escape dquotesrvr database adventureworks confirmed invoke sqlvulnerabilityassessmentscan available sql server run powershell command prompt run job receive error stating term invoke sqlvulnerabilityassessmentscan recognized name cmdlet looking microsoft article wondering sql agent subset powershell cmdlets access run vulnerability assessment scan sql job
245983 way seeing details sessions past fully expect answer trying find server certain application running application accessing certain database know application runs point friday evening hoping sql server maintains session history could look sp like details hours question like say dont expect possible right absolutely clutching straws thanks advance edit found server question means end job executed sql statement create file ftpd another site site ftp logging could give name ip address source server thanks answers wish could accept make good points give good suggestions
246015 im trying set test environment learn apply production environment ive created installed windows cluster cluster manager im going install sql server enterprise machines create ha availability groups failover manual synchronized data transfer question normally install stand alone installarion add sql server need use new sql server failover cluster installation cant find anything internet im going install sql server nodes configured cluster
246372 environment servers always availability group standalone normally backup network share recently observed databases growing bigger time taken getting longer slows whole network ola hallengrens script used compression also splitting backup files performing daily full backups backups going network share emc isilon drive never comfortable emc dd boost alternative local backup copy network share efficient way
246448 talking bossman prefers subqueries ctes personally loathe subqueries mentioned subqueries faster convinced ran short test classes select top classkey dimclass group classkey order count1 desc policies select carrierkey policykey periodeffectivedate dimpolicy exposure select policykey classkey dimexposure select policies inner join exposure policykey policykey inner join classes classkey classkey excution plan https www brentozar com pastetheplan id sjyjuznhs select carrierkey policykey periodeffectivedate dimpolicy inner join select policykey classkey dimexposure policykey policykey inner join select top classkey dimclass group classkey order count1 desc classkey classkey execution plan https www brentozar com pastetheplan id rjs lbvsr question always case weird wonderful world sql server answer always seems depends
246495 table names table john jim jason table xml strings table example show title showtitle false showline false showdescription false showexpandcollapse false isvisible true description pagebreakafter false pagecaption applink infolink imagelink pause false pausemessage pausemessagestyle pausetitle screenstyle showoption sequence name jim caption test selectoptionsimagelinkfieldexpression imagelink show example vars var name matrixname value lockexitpaircompatability value var var name jason value ifexistsminute value min tonumberminute value min value var var name minnum value ifexistsagency agency cert minnum value var var name value site root site hwtype tosqlarrayroot components activedoor hardwaretype value var var name where2 value hwsubtype tosqlarrayroot components activedoor locksubtype value var var name compatiblelist value usr fetchmatrix value var vars example rule property name collectionvariable displayname collection variable valuetype rvalueexpression john property property name keyvariable displayname key variable valuetype lvalueexpression nextlock property rule search find names table arent xml strings data shown examples xml database different formats xml data might root name would still want find even root attached
246649 following query declare linq uniqueidentifier set linq guid select top eventid eventid datecreated datecreated locationid locationid sourcename sourcename sourcestate sourcestate priority priority eventdescription eventdescription firsttrigger firsttrigger dbo watchdog locationid linq firsttrigger order datecreated desc watchdog table defines indecies clustered index eventid primary key column unclustered index datecreated column actual execution plan query reading posts eliminate key lookup added another non clustered index includes columns select create nonclustered index locationid firsttrigger dbo watchdog locationid asc firsttrigger asc include eventid datecreated sourcename sourcestate priority eventdescription statistics norecompute drop existing online primary go however didnt help actual execution plan look key lookup output actually included newly added non clustered index question still key lookup instead index scan seek update following suggestions comments dropped newly created non clustered index instead recreated non clustered index datecreated column including columns select execution plan following also query execution time dropped minute seconds table million rows mean key lookup done due order non clustered index
246734 using recursive cte tree structure list descendants particular node tree write literal node value clause sql server seems actually apply cte value giving query plan low actual rows counts et cetera however pass value parameter seems realize spool cte filter fact could reading plans wrong noticed performance issue worried realization cte could cause issues larger data sets especially busier system also normally compound traversal traverse ancestors back descendants ensure gather related nodes due data set related nodes rather small realization cte make sense sql server seems realize cte giving quite large numbers actual counts way get parameterized version query act like literal version want put cte reusable view query literal create procedure begin descendants select parentid id id descendantid tree parentid null union select id id descendantid descendants join tree descendantid parentid select descendants id order id descendantid end go exec query parameter create procedure id bigint begin descendants select parentid id id descendantid tree parentid null union select id id descendantid descendants join tree descendantid parentid select descendants id id order id descendantid end go exec setup code declare count bigint create table tree id bigint null primary key parentid bigint create index tree 23lk4j23lk4j tree parentid number select cast1 bigint value union select value number value count union select value number value count insert tree id parentid select value case value value end number
246804 noticed error occasionally sql error log spid20sunknownappdomain master sys runtime marked unload due memory pressure using sql server sp1 cu5 pushing patching company resistant everything read points non clr specific memory pressure suggestions around changing memtoleave setting start parameters still case newer versions sql server recommendations
246832 database sql server enterprise cu16 recently tried switching default index rebuild maintenance jobs ola hallengren indexoptimize default index rebuild jobs running couple months without issues queries updates working acceptable execution times running indexoptimize database execute dbo indexoptimize databases user databases fragmentationlow null fragmentationmedium index reorganizeindex rebuild onlineindex rebuild offline fragmentationhigh index rebuild onlineindex rebuild offline fragmentationlevel1 fragmentationlevel2 updatestatistics onlymodifiedstatistics performance extremely degraded update statement took 100ms indexoptimize took 000ms afterwards using identical plan queries also performing several orders magnitude worse since still test database migrating production system oracle reverted backup disabled indexoptimize everything returned normal however would like understand indexoptimize differently normal index rebuild could caused extreme performance degradation order make sure avoid go production suggestions look would greatly appreciated execution plan update statement slow indexoptimize actual execution plan coming asap havent able spot difference plan query fast actual execution plan
246888 want atomically reserve inventory objects users two inventory tracking tables one global inventory one personal inventory global inventory table columns objectid uniqueidentifier count int personal inventory table columns userid nvarchar64 objectid uniqueidentifier count int two tables enforce maximum allowed reservations object general well per user example object may restricted reserved overall maximum object per user global inventory table uniquely keyed objectid personal inventory table uniquely keyed userid objectid primary key index table locks taken rows never index key global inventory table always reside single database personal inventory table may sharded across multiple databases transaction updates global one personal tables may distributed reserve inventory transaction transaction ever performed tables sample request reserve inventory objects looks like objects restrictions others objectid quantitytoreserve objectid quantitytoreserve globalmax personalmax objectid quantitytoreserve request reserve inventory multiple objects completed atomically must succeed objects complete set locks always taken global table attempting take personal table atomic reservation achieved starting transaction updating rows global inventory table first object ids ascending order update statement object without restrictions looks like update globalinventory rowlock xlock holdlock set count count quantitytoreserve objectid objectid update statement object restriction looks like update globalinventory rowlock xlock holdlock set count count quantitytoreserve objectid objectid count quantitytoreserve globalmax similar update statements later used update lock rows personal inventory table addition userid predicate specifically join userids table updating rows order object id effectively takes exclusive row locks records order held remainder transaction believe happens even without holdlock hint update statements concurrent transactions block waiting transaction commit updated rows others obtain locks required update rows row locks taken ascending order locks set acquired guarantees transaction holds exclusive locks well established fact locking order matters unlocking order ask linus https yarchive net comp linux lock ordering html first question update statements work intended question multiple parts predicate identify rows update predicate hold true time exclusive row lock held rows updated correct lock hints since weve established transaction holds locks current one holds logically follows transaction would attempting update lock records object ids personal inventory table point think need force database engine use row level locks updating personal inventory rows well reason escalates page lock could inadvertently lock records happen page dont belong set object ids transaction working example suppose concurrent transaction locks global record seems totally unrelated first transaction working records objects none global personal inventory records overlap lock contention personal inventory records working either however concurrent transaction takes page level locks personal inventory table pages happen contain records object transaction could inadvertently hold page locks records belonging likewise first transaction may also hold page level locks contain records neither transaction proceed one locked pages waiting words page level locks destroy established locking order locking unrelated records arbitrary order updating records personal inventory table bit complex update multiple rows update statements still run one object id time joined temporary table establishes set user ids update pi rowlock xlock holdlock set count count quantitytoreserve personalinventory pi inner join userids uids pi userid uids userid objectid objectid count quantitytoreserve personalmax second question update statement join userids table take right exclusive row locks records actually updated result satisfying predicate critical correct functioning system case id like know id like know expected locks arent held locks held please assume disabled lock escalation table notes concerned whether forcing row level locks even possible discovered theres table option disable lock escalation im concerned correctness performance using database row locks going many orders magnitude faster locking solution involves multiple round trips server using sp getapplock also work would redundantly perform function locks global inventory table achieve simultaneously nothing prevent page lock creep mentioned using database row level locks multiple concurrent transactions complete quickly simultaneously minimal lock contention result atomic high throughput inventory reservations without worry managing transactions application level ultimately would complex less reliable page locks would acceptable way force one part composite key reside different data pages dont think thats possible example keyed personal table objectid userid id ensure page contains records single object id many users
247090 someone said preferable craft queries avoid duplicate key exceptions im convinced thats performant setting ignore dup key index goal ensure row set rows exists one users attempting update rows attempt update row update statement like one rows affected count portion predicate wasnt satisfied opposed row existing id portion predicate satisfied update inventory set count count id count maxinventory could run existsselect inventory id check single row insert row exist simply avoids unnecessary inserts insert necessary would still contend concurrent transactions duplicate key exceptions still occur im curious whether performant turn ignore dup key scenario rather allowing error thrown caught specifically im curious fast possibly even faster running exists check attempt insert record let ignore duplicate keys becomes even important im checking initializing multiple records example need ensure records thousands users exist single update statement logic would much simpler ran insert statement front letting ignore duplicate keys avoiding duplicates would complex id first query table records dont exist attempt add records ignoring duplicate keys inserting may faster even records exist could meet halfway check whether records missing left join count comparison bother insert ignoring duplicate keys faster good idea use ignore dup key attempt inserts instead bothering checking row existence ahead time
247411 possible group elements column like value pivot table table dbt status contains various statuses databases instances etc dont want pivot query prod test values single values group instead columns statuses prod prod acc prod app etc would one column containing values name like prod name like test far table definition create table dbt status id int identity11 null name nvarchar null constraint pk status primary key clustered id asc pad index statistics norecompute ignore dup key allow row locks allow page locks fillfactor primary constraint ix status unique nonclustered name asc pad index statistics norecompute ignore dup key allow row locks allow page locks fillfactor primary primary go table values insert dbt status id column value auto generated name values test acc test app test dba prod acc prod app prod dba prod test migrated offline reserved pivoted status table select database status db status test acc test app test dba prod acc prod app prod dba prod test migrated offline reserved select id name dbt status source pivot countname id pivottable output far db status test acc test app test dba prod acc prod app prod dba prod test migrated offline reserved database status db fiddle dbfiddle far question instead multiple rows various test prod values would prefer grouped similar following db status test prod migrated offline reserved database status dont clue go solving question honest grasped pivot yesterday extensive trial errors question loosely related question create sums counts grouped items multiple tables already asked tables dbt instance dbt database contain column statusid corresponds table looking
248503 two tables trying write query joins tables returns source title destination title given source id result map table tried written query solve one part puzzle whole thing select title sourcetitle result map rm inner join table result tr rm sourceid tr id query gives title source destination title
248587 availability group ag multiple databases db db db multiple secondaries sec sec one databases resume synchronization one secondaries example db synchronizing sec amount restarting sql server resuming hadr get start dont want remove replica secondary sec ag would resync databases db db db would take time necessary also dont want completely remove database db ag secondaries sec problem dont want resync temporarily lose hadr secondary working remove one secondary database ag resynchronize add back ag
248610 need use sql server database mail feature project however database mail seems available development instance database mail node object explorer screenshot cant seem find also shown sql server version database mail supported sql server version sql server version edition required use database mail documentation find online always assume feature already installed go explaining configure sql server version supports database mail install enable feature
249465 scenario generate backup database sql server restore new server sql server taking backup data changed case two options sure work everything using sql job set read database restore new db server possible restore read db new server destination server already read write online database name set offline database restore onto new db server possible restore offline db new server destination server already online read write database name
249520 requirement come reporting indexes whole production environment found script online modified according requirement trying execute using cursor also tried sp msforeachdb get result databases instance script show exact duplicate indexes particular database although wrapped query double quotes keep getting many errors run script without loop returns result correctly please see script errors im getting script struggling past days looked exhaustively online many posts figure need send result email body distribution list servers appreciate someone better idea establish script declare db name nvarcharmax declare db names cursor select name sys databases name inmaster model msdb tempdb state open db names fetch db names db name fetch status begin object idtempdb indextemp null drop table indextemp exist drop temp table exec begin use db name cte index data select schema data name schema name table data name table name index data name index name stuffselect column data key cols name case index column data key cols descending key desc else asc end include column order asc desc sys tables inner join sys indexes index data key cols object id index data key cols object id inner join sys index columns index column data key cols index data key cols object id index column data key cols object id index data key cols index id index column data key cols index id inner join sys columns column data key cols object id column data key cols object id index column data key cols column id column data key cols column id index data object id index data key cols object id index data index id index data key cols index id index column data key cols included column order index column data key cols key ordinal xml path key column list stuff select column data inc cols name sys tables inner join sys indexes index data inc cols object id index data inc cols object id inner join sys index columns index column data inc cols index data inc cols object id index column data inc cols object id index data inc cols index id index column data inc cols index id inner join sys columns column data inc cols object id column data inc cols object id index column data inc cols column id column data inc cols column id index data object id index data inc cols object id index data index id index data inc cols index id index column data inc cols included column order index column data inc cols key ordinal xml path include column list index data disabled check index disabled determining dupe drop applicable sys indexes index data inner join sys tables table data table data object id index data object id inner join sys schemas schema data schema data schema id table data schema id table data ms shipped index data type desc nonclustered clustered insert records temp table indextemp appropriate filters select indextemp cte index data dupe1 exists select cte index data dupe2 dupe1 schema name dupe2 schema name dupe1 table name dupe2 table name dupe1 key column list dupe2 key column list isnulldupe1 include column list isnulldupe2 include column list dupe1 index name dupe2 index name index name like pk return duplicate tbale names select indextemp table name select table name indextemp group table name count order table name end fetch db names db name end close db names deallocate db names database get errors msg level state line incorrect syntax near keyword msg level state line incorrect syntax near keyword order msg level state line expression non boolean type specified context condition expected near
249593 im accessing creating reports vendor via replicated sql server database theyve done absolutely insane things ive trying solve one takes cake table many standard columns table also column called data column legacy text data type contains giant hundreds list key value pairs pair separated crlf key value separated equal sign example select mytable data mytable tblkey result key value key value key value key value im trying determine efficient way break column usable table data end goal would able query table way returns table key along specified key values column fields tblkey key key key value value value value value value value value value way mold column view cant imagine function would particularly efficient im sure could parse things way using string split something sort anyone run type atrocity found good way manipulate usable data edit add dbfiddle sample data data replicated vendors source cant create new tables create views procedures functions thats im looking advice decent way accomplish
249617 postgresql table billion rows developed nasty habit missing proper indices primary key scan certain limit operations problem generally manifests order limit clause common pattern django pagination limit relatively small subset results matched index extreme example select mcqueen base imagemeta2 image id order id desc limit items clause total rows matched index image id explain shows misses image id index instead pk scan 5b rows limit cost rows width index scan backward using mcqueen base imagemeta2 pkey mcqueen base imagemeta2 cost rows width filter image id bigint limit increased works expected limit cost rows width sort cost rows width sort key id desc index scan using mcqueen base imagemeta2 image id 616fe89c mcqueen base imagemeta2 cost rows width index cond image id bigint also happens queries index matches rows limit set something easily happens real world rest api pagination table definition mcqueen mcqueen base imagemeta2 table public mcqueen base imagemeta2 column type modifiers id bigint null default nextvalmcqueen base imagemeta2 id seq regclass created timestamp time zone null image id bigint null key id smallint null source version id smallint null indexes mcqueen base imagemeta2 pkey primary key btree id mcqueen base imagemeta2 image id 616fe89c btree image id mcqueen base imagemeta2 key id a4854581 btree key id mcqueen base imagemeta2 source version id f9b0513e btree source version id foreign key constraints mcqueen base imageme image id 616fe89c fk mcqueen foreign key image id references mcqueen base imageid deferrable initially deferred mcqueen base imageme key id a4854581 fk mcqueen foreign key key id references mcqueen base metakeyid deferrable initially deferred mcqueen base imageme source version id f9b0513e fk mcqueen foreign key source version id references mcqueen base metasourceversionid deferrable initially deferred im novice best comes tuning figure defaults statistics tables size naively thinks pk scan faster index scan
249715 default collation type sql server allows indexing case insensitive strings yet case data persisted actually work im looking actual nuts bolts bits bytes good resource explains detail create table casetest fruitnames nvarchar50 null create unique index ix fruitnames casetestfruitnames insert casetest values apples insert casetest values pears insert fails insert casetest values pears yields pears result select casetest forceseek fruitnames pears update casetest set fruitnames pears fruitnames pears yields pears result select casetest forceseek fruitnames pears questions sql server collations shy ask robert sheldon covers use collation cover collation works im interested index efficiently created queried caring case simultaneously storing case data
249838 colleague mine discussed implications use serializable isolation level said locked entire table disagreed telling potentially could tries apply range locks doesnt apply true serialization explained serializable isolation level cant find anything docs either locks entire table set transaction isolation level doc states bunch things regarding range locks theory could lock entire table simply range lock locks entire range possible values table doesnt lock table completely wrong fact lock entire table tables
250166 could please give little clarification sql server backup message example backup database successfully processed pages seconds mb sec example disk database separate disk backup mean mb sec one disk reads data backup speed mb sec another disk writes data speed mb sum gives us speed mb sec correct
250395 example tables exist database work data isnt actually around schools structure identical four tables school school id school name clubtype clubtype id clubtype name club club id school id clubtype id student student id name club id knowing club table never additional columns real data isnt actually school clubs believe clearly better design eliminating club table avoid joins would school school id school name clubtype clubtype id clubtype name student student id name school id clubtype id edit also know club id may one type relationship club clubtype question first example violate known rule database normalization mathematical principle case poor design
250490 recently audit database went one terabyte since storage problems management looking options proposal end year take backup truncate tables keep database manageable beneficial archive database consume space would like expert opinion options propose management either allocate space truncate whole database every year
250573 table like sql server id start mile end mile want split miles thousandths per id like id start mile end mile ideas go trying stay away cursors unless thats way able get query together sure incorporate id mile limits runs whole table without declared variables declare decimal15 declare decimal15 cte select value union select convertdecimal15 value cte value select cte option maxrecursion
251034 recently accidentally shrunk tempdb log almost getting alerted log drive filling told lead slowness someone please explain lead slowness
251805 using windows authentication way prohibit users connecting via odbc database
251988 know logical order execution sql query join group cube rollup select distinct order top happen one join query instance query like select user branch t1 inner join dimcustomer2 t2 t1 branch code t2 branch code inner join customer guarantee t3 t3 customer num t2 customer num example data customer guarantee customer num branch code user branch user id branch code u1 dimcustomer2 customer num branch code execute join executed first different kind joins query would order executing joins case thanks advance
252191 say running log backup log backup takes minutes complete minute window transactions run given example transactions log backup actually contain transaction commits transaction opens log backup begins transaction opens transaction commits log backup completes transaction commits
252661 take following example select calculationa cola calculationb colb calculationa calculationb colc tablea would calculationa calculationb calculated twice would optimizer clever enough calculate use result twice would like perform test see result however sure could check something like assumption would perform calculation twice case depending upon calculations involved might better use derived table nested view consider following select tableb cola tableb colb tableb cola tableb colb colc select calculationa cola calculationb colb tablea tableb case would hope calculations would performed please someone confirm refute assumptions instruct test something like thanks
253166 im reading sql server high availability solutions disaster recovery among available resources sql server snapshot feature theory seems like beautiful also read snapshot copy database point time use restore database answer comment peter schofield sql server snapshots support useful development environment quick rollbacks perhaps biggest hindrance adoption management studio didnt offer support sounds like ideal use snapshots dev environment quick script deployments quick roll backs would like know snapshots really useful production environments examples usage production please include personal examples youve used snapshots provide solution production systems principal objective provide examples real usage examples get useful ideas everyone reading post case use sql server enterprise edition production environment
253873 habit never use select production code use ad hoc scrap queries typically learning schema object ran across case im tempted use would feel cheap use case inside stored procedure local temp table created always match underlying table used create whenever stored procedure runs temp table populated much later quick hack create temp table without verbose would select temptable realtable especially table hundreds columns consumer stored procedure agnostic dynamic result sets issues selling services select
253924 stored procedure returns multiple recordsets use application sometimes recordsets empty id like reduce overhead return rows question return recordsets rows application simply expects recordsets loops prints know skip application code trying prevent returned empty procedure simple create procedure bfsp proc nm begin select table select table select table return end go actual procedure queries expensive dont want test query returns row execute would expensive
254252 today wanted define uuid value sql server man id usually select cast0x0 uniqueidentifier im postgres world whipped sensible select cast x00 bytea uuid error cast type bytea uuid line select cast x00 bytea uuid damn head postgres docs type conversion hoping see doc like one review datatypes cast default without needing create explicit cast chart exist docs well hidden google likewise super helpful regard good documentation reference default permissible type casts postgresql clear dont actually care uuid
